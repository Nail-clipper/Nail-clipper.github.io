{"meta":{"title":"Ciallo～(∠・ω< )⌒★","subtitle":"","description":"","author":"Nail Clipper","url":"https://wxwdaydayup.top","root":"/"},"pages":[{"title":"about","date":"2025-02-08T08:31:34.000Z","updated":"2025-02-08T08:32:28.403Z","comments":false,"path":"about/index.html","permalink":"https://wxwdaydayup.top/about/index.html","excerpt":"","text":""}],"posts":[{"title":"linux 系统打开虎牙直播等网页出现 xdg-open 弹窗解决办法","slug":"linux 系统打开虎牙直播等网页出现 xdg-open 弹窗解决办法","date":"2025-03-21T12:00:00.000Z","updated":"2025-03-21T08:32:05.103Z","comments":true,"path":"linux 系统打开虎牙直播等网页出现 xdg-open 弹窗解决办法/","permalink":"https://wxwdaydayup.top/linux%20%E7%B3%BB%E7%BB%9F%E6%89%93%E5%BC%80%E8%99%8E%E7%89%99%E7%9B%B4%E6%92%AD%E7%AD%89%E7%BD%91%E9%A1%B5%E5%87%BA%E7%8E%B0%20xdg-open%20%E5%BC%B9%E7%AA%97%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/","excerpt":"在 Arch Linux 使用 Google Chrome 访问虎牙直播的某些直播间时，Chrome 会尝试调用 xdg-open 来打开 kiwi://domcontentloaded 这样的 URL，导致一连串弹窗报错。","text":"01. xdg-open 是什么？xdg-open 是 XDG Utilities 提供的一个命令，它用于 打开 URL 或文件，并调用系统默认的应用来处理。例如： xdg-open https://www.google.com 会调用默认浏览器打开网页。 xdg-open file.pdf 会调用默认的 PDF 阅读器。 xdg-open mailto:someone@example.com 会调用默认的邮件客户端。 当 Chrome 访问虎牙直播时，虎牙的网页可能会尝试使用 xdg-open 来打开某些自定义协议（如 kiwi://），但 Linux 上 没有注册 kiwi:// 的处理程序，所以 xdg-open 无法正确处理，最终导致错误弹窗。 02. kiwi:// 是什么？kiwi:// 可能是虎牙直播用来处理 Web 事件的一个 自定义协议，可能用于： 直播插件或扩展的内部通信（比如检测网页状态）。 调用某个本地应用（如虎牙 PC 客户端）。 触发特定的浏览器事件（如 domcontentloaded ）。 在 Windows 或 macOS，虎牙可能有相应的软件可以处理 kiwi:// 协议，但在 Linux，这个协议没有被正确注册，所以 xdg-open 直接报错。 03. Chrome 为什么调用 xdg-open？Chrome 会调用 xdg-open 处理某些协议（如 mailto:、webcal:），以及一些网站定义的自定义协议。虎牙直播的 JavaScript 可能包含类似的代码： 1window.location.href = &quot;kiwi://domcontentloaded&quot;; 或者： 1window.open(&quot;kiwi://domcontentloaded&quot;); 这会导致 Chrome 触发 xdg-open kiwi://domcontentloaded，然后 xdg-open 由于找不到处理程序而报错。 问题在于： Chrome 不检查 kiwi:// 是否有处理程序，直接调用 xdg-open。 xdg-open 发现 kiwi:// 不是标准 URL，也 没有找到相应的应用，就会报错。 04. 强行解决问题sudo vim /usr/bin/xdg-open 在 xdg-open 文件的最前面添加： 123if [[ &quot;$1&quot; =~ ^kiwi:// ]]; then exit 0fi 这样它在执行任何逻辑之前就会检查 kiwi:// 相关的 URL，从而告诉 xdg-open： 如果 URL 以 kiwi:// 开头，直接退出，不执行任何操作。 这样，Chrome 即使调用 xdg-open kiwi://domcontentloaded，也不会触发弹窗。 最终，xdg-open 不会继续执行 默认的 URL 解析逻辑，错误弹窗也不会出现。 在 /usr/bin/xdg-open 里添加拦截规则，可以避免不必要的错误。 这个方法适用于 任何未知的、导致错误的协议，比如： 123&gt;if [[ &quot;$1&quot; =~ ^(kiwi|huya|wegame):// ]]; then exit 0&gt;fi 05. 温和的解决方案在 Linux 上注册 kiwi:// 处理程序（静默处理请求） 可以手动创建一个假的 kiwi:// 处理器： 123456echo &quot;[Desktop Entry]Name=Ignore KiwiExec=/bin/trueType=ApplicationNoDisplay=trueMimeType=x-scheme-handler/kiwi;&quot; &gt; ~/.local/share/applications/ignore-kiwi.desktop 然后注册它： 1xdg-mime default ignore-kiwi.desktop x-scheme-handler/kiwi 这样 xdg-open kiwi://xxx 就不会弹窗了。","categories":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/categories/Arch/"}],"tags":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/tags/Arch/"},{"name":"疑难杂症","slug":"疑难杂症","permalink":"https://wxwdaydayup.top/tags/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"}]},{"title":"Arch Linux 命令行美化","slug":"Arch Linux  konsole 美化","date":"2025-03-21T02:00:00.000Z","updated":"2025-03-21T08:14:49.084Z","comments":true,"path":"Arch Linux  konsole 美化/","permalink":"https://wxwdaydayup.top/Arch%20Linux%20%20konsole%20%E7%BE%8E%E5%8C%96/","excerpt":"zsh 是日常开发过程中最常用的 shell，它大幅提升了开发效率，也不再为忘记命令而苦恼。配合使用 oh-my-zsh 在短时间内就可以配置出一个高效的命令行，推荐大家使用。","text":"zsh 是一个兼容 bash 的 shell，相较 bash 具有以下优点： Tab 补全功能强大。命令、命令参数、文件路径均可以补全。 插件丰富。快速输入以前使用过的命令、快速跳转文件夹、显示系统负载这些都可以通过插件实现。 主题丰富。 可定制性高。 01. 安装 zsh1sudo pacman -S zsh 安装好后，使用 cat /etc/shells 查看系统可以用的 shell。 使用 chsh -s /bin/zsh 命令将 zsh 设置为系统默认 shell。注销重新登陆，就可以开始使用 zsh 了，此时可以使用 echo $SHELL 查看默认 shell 是否为 zsh。 第一次运行 zsh 时会进入配置引导页面： 输入 q 会直接退出配置引导，下一次运行 zsh 时会再次进入配置引导。 输入 0，也会退出配置引导，但是会在当前用户目录生成一个空白的文件 .zshrc，下一次运行时就不会再进入配置引导。下一次运行时是否再进入配置引导，取决于用户目录下是否存在.zshrc 文件。 输入输入 1 后，就开始进行配置，由于 zsh 配置较为复杂，推荐大家使用配置管理工具来配置 zsh，花很少时间就可以得到一个称手的 zsh。下面介绍如何使用 oh-my-zsh 来修改 zsh 的主题和安装常用的插件。 02. 安装 oh-my-zsh安装 oh-my-zsh 之前，需要确保本地已经安装了 git 1sudo pacman -S git 安装 0h-my-zsh 软件包 1yay -S oh-my-zsh-git 复制 oh-my-zsh 配置文件到本地 1sudo cp /usr/share/oh-my-zsh/zshrc ~/.zshrc 03. 修改主题在 ohmyzsh 项目 中查看内置的主题样式和对应的主题名。这些内置主题已经放在 /usr/share/oh-my-zsh/themes 目录下，不需要再下载。 编辑 .zshrc 配置文件使用内置主题，使用random 值会随机选择内置主题 12$ vim ~/.zshrcZSH_THEME=&quot;random&quot; 除了内置主题外，还可以选择其他开源的主题，推荐使用 powerlevel10k 主题，项目地址为：https://github.com/romkatv/powerlevel10k 安装主题： 12cd /usr/share/oh-my-zsh/themesgit clone https://github.com/romkatv/powerlevel10k.git 修改配置文件应用主题： 12vim ~/.zshrcZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot; 安装并配置 powerlevel10k README.md 中提及的 Meslo Nerd Font 字体: 直接在这里下载sources里面的 ttf 文件吧，目前通过yay -S ttf-meslo-nerd-font-powerlevel10k下载会失败，下载完成后安装字体，然后到 konsole 配置里面修改字体为 MesloLGS NF 。 最后，执行 source ~/.zshrc 配置生效，这时会提示对主题进行配置，按照提示进行即可。 04. 安装插件oh-my-zsh 已经内置了 git 插件，内置插件可以在 /usr/share/oh-my-zsh/plugins 中查看 ，下面介绍一下常用插件。 zsh-autocomplete：根据历史记录自动补全 1234567cd /usr/share/oh-my-zsh/pluginssudo git clone https://github.com/zsh-users/zsh-autosuggestions.gitvim ~/.zshrcplugins=( git zsh-dircolors-solarized zsh-autosuggestions ) zsh-syntax-highlighting：语法校验，无效命令会提示为红色 12345678cd /usr/share/oh-my-zsh/pluginssudo git clone https://github.com/zsh-users/zsh-syntax-highlighting.gitvim ~/.zshrcplugins=( git zsh-dircolors-solarized zsh-autosuggestions zsh-syntax-highlighting ) z：对于曾经跳转过的目录，只需要输入最终目标文件夹名称，就可以快速跳转，此为内置插件不用下 1234567vim ~/.zshrcplugins=( git zsh-dircolors-solarized zsh-autosuggestions zsh-syntax-highlighting z ) 05. 设置 aliaszsh 支持为较长命令设置一个别名，这样在使用时可以快捷输入。 这里以 cd ~/projects/learn/blog 这个命令来举例： 在 .zshrc 中键入： 1alias cdblog=&quot;cd ~/projects/learn/blog&quot; \\2. 开启新的 Shell 或 source ~/.zshrc，以使配置生效。生效后就可以使用 cdblog 进行跳转了。 除了自己设置 alias 之外，一些插件也内置内很多 alias。最常用的是 git 插件内置的 alias。例如，ga 就代表 git add，更多 git 插件内置 alias 可以在 git plugin alias 中查看。","categories":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/categories/Arch/"}],"tags":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/tags/Arch/"},{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"}]},{"title":"Shell 编程进阶（知其所以然）","slug":"Shell 编程进阶（知其所以然）","date":"2025-03-16T02:00:00.000Z","updated":"2025-03-17T04:13:47.040Z","comments":true,"path":"Shell 编程进阶（知其所以然）/","permalink":"https://wxwdaydayup.top/Shell%20%E7%BC%96%E7%A8%8B%E8%BF%9B%E9%98%B6%EF%BC%88%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%89/","excerpt":"本节详细介绍 Shell 编程的进阶用法。","text":"初识脚本编程到目前为止我们已经知道了 Linux 系统和命令行的基础知识，是时候开始编程了。本章讨论编写 shell 脚本的基础知识。在开始编写自己的 shell 脚本大作前，你必须了解这些基本概念。 使用多个命令到目前为止，你已经了解了如何使用 shell 的命令行界面提示符来输入命令和查看命令的结果。shell 脚本的关键在于输入多个命令并处理每个命令的结果，甚至需要将一个命令的结果传给另一个命令。shell 可以让你将多个命令串起来，一次执行完成。如果要两个命令一起运行，可以把它们放在同一行中，彼此间用分号隔开。 123456$ date ; whoSun Dec 20 08:59:29 AM CST 2020testuser tty1 2020-12-20 08:11 (:0)testuser pts/0 2020-12-20 08:11 (:0)testuser pts/1 2020-12-20 08:59 (:0)$ 恭喜，你刚刚已经写好了一个脚本。这个简单的脚本只用到了两个 bash shell 命令。date 命令先运行，显示了当前日期和时间，后面紧跟着 who 命令的输出，显示当前是谁登录到了系统上。使用这种办法就能将任意多个命令串连在一起使用了，只要不超过最大命令行字符数 255 就行。 这种技术对于小型脚本尚可，但它有一个很大的缺陷：每次运行之前，你都必须在命令提示符下输入整个命令。可以将这些命令组合成一个简单的文本文件，这样就不需要在命令行中手动输入了。在需要运行这些命令时，只用运行这个文本文件就行了。 创建 shell 脚本文件要将 shell 命令放到文本文件中，首先需要用文本编辑器来创建一个文件，然后将命令输入到文件中。在创建 shell 脚本文件时，必须在文件的第一行指定要使用的 shell。其格式为： 1#!/bin/bash 在通常的 shell 脚本中，井号（#）用作注释行。shell 并不会处理 shell 脚本中的注释行。然而，shell 脚本文件的第一行是个例外，#后面的惊叹号会告诉 shell 用哪个 shell 来运行脚本（是的，你可以使用 bash shell，同时还可以使用另一个 shell 来运行你的脚本）。 在指定了 shell 之后，就可以在文件的每一行中输入命令，然后加一个回车符。之前提到过，注释可用#添加。例如： 123# This script displays the date and who&#x27;s logged ondatewho 这就是脚本的所有内容了。可以根据需要，使用分号将两个命令放在一行上，但在 shell 脚本中，你可以在独立的行中书写命令。shell 会按根据命令在文件中出现的顺序进行处理。 还有，要注意另有一行也以#开头，并添加了一个注释。shell 不会解释以#开头的行（除了以#!开头的第一行）。留下注释来说明脚本做了什么，这种方法非常好。当两年后回过来再看这个脚本时，你还可以很容易回忆起做过什么。 将这个脚本保存在名为 test1 的文件中，基本就好了。在运行新脚本前，还要做其他一些事。现在运行脚本，结果可能会叫你有点失望。 12$ test1bash: test1: command not found 你要跨过的第一个障碍是让 bash shell 能找到你的脚本文件。如之前所述，shell 会通过 PATH 环境变量来查找命令。快速查看一下 PATH 环境变量就可以弄清问题所在。 12$ echo $PATH/usr/kerberos/sbin:/usr/kerberos/bin:/usr/local/bin:/usr/bin :/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/user/bin PATH 环境变量被设置成只在一组目录中查找命令。要让 shell 找到 test1 脚本，只需采取以下两种作法之一： 将 shell 脚本文件所处的目录添加到 PATH 环境变量中； 在提示符中用绝对或相对文件路径来引用 shell 脚本文件。 有些 Linux 发行版将$HOME&#x2F;bin 目录添加进了 PATH 环境变量。它在每个用户的 HOME 目录下提供了一个存放文件的地方，shell 可以在那里查找要执行的命令。 在这个例子中，我们将用第二种方式将脚本文件的确切位置告诉 shell。记住，为了引用当前目录下的文件，可以在 shell 中使用单点操作符。 12$ ./test1bash: ./test1: Permission denied 现在 shell 找到了脚本文件，但还有一个问题。shell 指明了你还没有执行文件的权限。快速查看一下文件权限就能找到问题所在。 12$ ls -l test1-rw-rw-r-- 1 user user 73 Sep 24 19:56 test1 在创建 test1 文件时，umask 的值决定了新文件的默认权限设置。由于 umask 变量在 ArchLinux 中被设成了 022，所以系统创建的文件的文件属主只有读&#x2F;写权限。 下一步是通过 chmod 命令赋予文件属主执行文件的权限。 123456$ chmod u+x test1$ ./test1Sun Dec 20 08:59:29 AM CST 2020testuser tty1 2020-12-20 08:11 (:0)testuser pts/0 2020-12-20 08:11 (:0)testuser pts/1 2020-12-20 08:59 (:0) 成功了！ 显示消息大多数 shell 命令都会产生自己的输出，这些输出会显示在脚本所运行的控制台显示器上。很多时候，你可能想要添加自己的文本消息来告诉脚本用户脚本正在做什么。可以通过 echo 命令来实现这一点。如果在 echo 命令后面加上了一个字符串，该命令就能显示出这个文本字符串。 12$ echo This is a testThis is a test 注意，默认情况下，不需要使用引号将要显示的文本字符串划定出来。但有时在字符串中出现引号的话就比较麻烦了。 12$ echo Let&#x27;s see if this&#x27;ll workLets see if thisll work echo 命令可用单引号或双引号来划定文本字符串。如果在字符串中用到了它们，你需要在文本中使用其中一种引号，而用另外一种来将字符串划定起来。 1234$ echo &quot;This is a test to see if you&#x27;re paying attention&quot;This is a test to see if you&#x27;re paying attention$ echo &#x27;Rich says &quot;scripting is easy&quot;.&#x27;Rich says &quot;scripting is easy&quot;. 所有的引号都可以正常输出了。 如果想把文本字符串和命令输出显示在同一行中，该怎么办呢？可以用 echo 语句的-n 参数。只要将第一个 echo 语句改成这样就行： 123echo -n &quot;The time and date are: &quot;date#输出: The time and date are: Mon Feb 21 15:42:23 EST 2014 完美！echo 命令是 shell 脚本中与用户交互的重要工具。你会发现在很多地方都能用到它，尤其是需要显示脚本中变量的值的时候。我们下面继续了解这个。 使用变量运行 shell 脚本中的单个命令自然有用，但这有其自身的限制。通常你会需要在 shell 命令使用其他数据来处理信息。这可以通过变量来实现。变量允许你临时性地将信息存储在 shell 脚本中，以便和脚本中的其他命令一起使用。本节将介绍如何在 shell 脚本中使用变量。 环境变量你已经看到过 Linux 的一种变量在实际中的应用。前面介绍了 Linux 系统的环境变量。也可以在脚本中访问这些值。shell 维护着一组环境变量，用来记录特定的系统信息。比如系统的名称、登录到系统上的用户名、用户的系统 ID（也称为 UID）、用户的默认主目录以及 shell 查找程序的搜索路径。可以用 set 命令来显示一份完整的当前环境变量列表。 123456789101112$ setBASH=/bin/bash[...]HOME=/home/SamanthaHOSTNAME=localhost.localdomainHOSTTYPE=i386IFS=$&#x27; \\t\\n&#x27;LANG=en_US.utf8LESSOPEN=&#x27;|/usr/bin/lesspipe.sh %s&#x27;LINES=24LOGNAME=Samantha[...] 在脚本中，你可以在环境变量名称之前加上美元符（$）来使用这些环境变量。下面的脚本演示了这种用法。 1234567$ cat test2#!/bin/bash# display user information from the system.echo &quot;User info for userid: $USER&quot; #若为单引号包裹则不会变更$USER的值echo UID: $UIDecho HOME: $HOME$ $USER、$UID 和$HOME 环境变量用来显示已登录用户的有关信息。脚本输出如下： 12345$ chmod u+x test2$ ./test2User info for userid: SamanthaUID: 1001HOME: /home/Samantha 你可能还见过通过${variable}形式引用的变量。变量名两侧额外的花括号通常用来帮助识别美元符后的变量名。 注意，echo 命令中的环境变量会在脚本运行时替换成当前值。另外，在第一个字符串中可以将$USER 系统变量放置到双引号中，而 shell 依然能够知道我们的意图。但采用这种方法也有一个问题。看看下面这个例子会怎么样。 12$ echo &quot;The cost of the item is $15&quot;The cost of the item is 5 显然这不是我们想要的。只要脚本在引号中出现美元符，它就会以为你在引用一个变量。在这个例子中，脚本会尝试显示变量$1（但并未定义），再显示数字 5。要显示美元符，你必须在它前面放置一个反斜线。 123$ echo &quot;The cost of the item is \\$15&quot;The cost of the item is $15 看起来好多了。反斜线允许 shell 脚本将美元符解读为实际的美元符，而不是变量。下一节将会介绍如何在脚本中创建自己的变量。 用户变量除了环境变量，shell 脚本还允许在脚本中定义和使用自己的变量。定义变量允许临时存储数据并在整个脚本中使用，从而使 shell 脚本看起来更像一个真正的计算机程序。用户变量可以是任何由字母、数字或下划线组成的文本字符串，长度不超过 20 个。用户变量区分大小写，所以变量 Var1 和变量 var1 是不同的。这个小规矩经常让脚本编程初学者感到头疼。使用等号将值赋给用户变量。在变量、等号和值之间不能出现空格（另一个困扰初学者的用法）。这里有一些给用户变量赋值的例子。 1234var1=10var2=-57var3=testingvar4=&quot;still more testing&quot; shell 脚本会自动决定变量值的数据类型。在脚本的整个生命周期里，shell 脚本中定义的变量会一直保持着它们的值，但在 shell 脚本结束时会被删除掉。 与系统变量类似，用户变量可通过美元符引用。变量每次被引用时，都会输出当前赋给它的值。重要的是要记住，引用一个变量值时需要使用美元符，而引用变量来对其进行赋值时则不要使用美元符。通过一个例子你就能明白我的意思。 123456$ cat test4#!/bin/bash# assigning a variable value to another variablevalue1=10value2=$value1echo The resulting value is $value2 在赋值语句中使用 value1 变量的值时，仍然必须用美元符。这段代码产生如下输出。 1234$ chmod u+x test4$ ./test4The resulting value is 10 要是忘了用美元符，使得 value2 的赋值行变成了这样： 1value2=value1 那你会得到如下输出： 12$ ./test4The resulting value is value1 没有美元符，shell 会将变量名解释成普通的文本字符串，通常这并不是你想要的结果。 命令替换shell 脚本中最有用的特性之一就是可以从命令输出中提取信息，并将其赋给变量。把输出赋给变量之后，就可以随意在脚本中使用了。这个特性在处理脚本数据时尤为方便。 有两种方法可以将命令输出赋给变量： 反引号字符(`) testing&#x3D;`date` $()格式 testing&#x3D;$(date) shell 会运行命令替换符号中的命令，并将其输出赋给变量 testing。注意，赋值等号和命令替换字符之间没有空格。下面这个例子很常见，它在脚本中通过命令替换获得当前日期并用它来生成唯一文件名。 1234#!/bin/bash# copy the /usr/bin directory listing to a log filetoday=$(date +%y%m%d)ls /usr/bin -al &gt; log.$today today 变量被赋予格式化后的 date 命令的输出。这是提取日期信息来生成日志文件名常用的一种技术。+%y%m%d 格式告诉 date 命令将日期显示为两位数的年月日的组合。 12$ date +%y%m%d201220 这个脚本将日期值赋给一个变量，之后再将其作为文件名的一部分。文件自身含有&#x2F;usr&#x2F;bin 目录列表的重定向输出（将在后续详细讨论）。运行该脚本之后，应该能在目录中看到一个新文件。 1-rw-r--r-- 1 user user 769 Jan 31 10:15 log.140131 目录中出现的日志文件采用$today 变量的值作为文件名的一部分。日志文件的内容是&#x2F;usr&#x2F;bin 目录内容的列表输出。如果脚本在明天运行，日志文件名会是 log.201221，就这样为新的一天创建一个新文件。 命令替换会创建一个子 shell 来运行对应的命令。子 shell（subshell）是由运行该脚本的 shell 所创建出来的一个独立的子 shell（child shell）。正因如此，由该子 shell 所执行命令是无法使用脚本中所创建的变量的。 重定向输入和输出有些时候你想要保存某个命令的输出而不仅仅只是让它显示在显示器上。bash shell 提供了几个操作符，可以将命令的输出重定向到另一个位置（比如文件）。重定向可以用于输入，也可以用于输出，可以将文件重定向到命令输入。 输出重定向最基本的重定向将命令的输出发送到一个文件中。bash shell 用大于号（&gt;）来完成这项功能，之前显示器上出现的命令输出会被保存到指定的输出文件中。 12345$ date &gt; test6$ ls -l test6-rw-r--r-- 1 user user 29 Feb 10 17:56 test6$ cat test6Thu Feb 10 17:56:58 EDT 2020 重定向操作符创建了一个文件 test6（通过默认的 umask 设置），并将 date 命令的输出重定向到该文件中。如果输出文件已经存在了，重定向操作符会用新的文件数据覆盖已有文件。 有时，你可能并不想覆盖文件原有内容，而是想要将新命令的输出追加到已有文件内容的后面，比如你正在创建一个记录系统上某个操作的日志文件。在这种情况下，可以用双大于号（&gt;&gt;）来追加数据。 123456$ who &gt; test6$ date &gt;&gt; test6$ cat test6user pts/0 Feb 10 17:55Thu Feb 10 18:02:14 EDT 2020 test6 文件仍然包含早些时候 who 命令的数据，现在又加上了来自 date 命令的输出。 输入重定向输入重定向和输出重定向正好相反。输入重定向将文件的内容重定向到命令，而非将命令的输出重定向到文件。输入重定向符号是小于号（&lt;）。 一个简单的记忆方法就是：在命令行上，命令总是在左侧，而重定向符号“指向”数据流动的方向。小于号说明数据正在从输入文件流向命令。这里有个和 wc 命令一起使用输入重定向的例子。 123$ wc &lt; test6 2 11 60$ wc 命令可以对对数据中的文本进行计数。默认情况下，它会输出 3 个值： 文本的行数 文本的词数 文本的字节数 通过将文本文件重定向到 wc 命令，你立刻就可以得到文件中的行、词和字节的计数。这个例子说明 test6 文件有 2 行、11 个单词以及 60 字节。 还有另外一种输入重定向的方法，称为内联输入重定向（inline input redirection）。这种方法无需使用文件进行重定向，只需要在命令行中指定用于输入重定向的数据就可以了。乍看一眼，这可能有点奇怪，但有些应用会用到这种方式。 内联输入重定向符号是远小于号（&lt;&lt;）。除了这个符号，你必须指定一个文本标记来划分输入数据的开始和结尾。任何字符串都可作为文本标记，但在数据的开始和结尾文本标记必须一致。 在命令行上使用内联输入重定向时，shell 会用 PS2 环境变量中定义的次提示符（即’&gt;’符号）来提示输入数据。下面是它的使用情况。 1234567$ wc &lt;&lt; EOF&gt; test string 1&gt; test string 2&gt; test string 3&gt; EOF 3 9 42$ 次提示符会持续提示，以获取更多的输入数据，直到你输入了作为文本标记的那个字符串。wc 命令会对内联输入重定向提供的数据进行行、词和字节计数。 管道有时需要将一个命令的输出作为另一个命令的输入。这可以用重定向来实现，只是有些笨拙。 1234567$ rpm -qa &gt; rpm.list$ sort &lt; rpm.listabrt-1.1.14-1.fc14.i686abrt-addon-ccpp-1.1.14-1.fc14.i686abrt-addon-kerneloops-1.1.14-1.fc14.i686abrt-addon-python-1.1.14-1.fc14.i686... rpm 命令通过 Red Hat 包管理系统（RPM）对系统（比如上例中的 Fedora 系统）上安装的软件包进行管理。配合-qa 选项使用时，它会生成已安装包的列表，但这个列表并不会遵循某种特定的顺序。如果你在查找某个或某组特定的包，想在 rpm 命令的输出中找到就比较困难了。过标准输出重定向，rpm 命令的输出被重定向到了文件 rpm.list。命令完成后，rpm.list 保存着系统中所有已安装的软件包列表。接下来，输入重定向将 rpm.list 文件的内容发送给 sort 命令，该命令按字母顺序对软件包名称进行排序。 这种方法的确管用，但仍然是一种比较繁琐的信息生成方式。我们用不着将命令输出重定向到文件中，可以将其直接重定向到另一个命令。这个过程叫作管道连接（piping）。管道被放在命令之间，将一个命令的输出重定向到另一个命令中： 1command1 | command2 不要以为由管道串起的两个命令会依次执行。Linux 系统实际上会同时运行这两个命令，在系统内部将它们连接起来。在第一个命令产生输出的同时，输出会被立即送给第二个命令。数据传输不会用到任何中间文件或缓冲区。 现在，可以利用管道将 rpm 命令的输出送入 sort 命令来产生结果。 1rpm -qa | sort 除非你的眼神特别好，否则可能根本来不及看清楚命令的输出。由于管道操作是实时运行的，所以只要 rpm 命令一输出数据，sort 命令就会立即对其进行排序。等到 rpm 命令输出完数据，sort 命令就已经将数据排好序并显示了在显示器上。 可以在一条命令中使用任意多条管道。可以持续地将命令的输出通过管道传给其他命令来细化操作。 在这个例子中，sort 命令的输出会一闪而过，所以可以用一条文本分页命令（例如 less 或 more）来强行将输出按屏显示。 1$ rpm -qa | sort | more 这行命令序列会先执行 rpm 命令，将它的输出通过管道传给 sort 命令，然后再将 sort 的输出通过管道传给 more 命令来显示，在显示完一屏信息后停下来。这样你就可以在继续处理前停下来阅读显示器上显示的信息。 如果想要更别致点，也可以搭配使用重定向和管道来将输出保存到文件中。 1$ rpm -qa | sort &gt; rpm.list 不出所料，rpm.list 文件中的数据现在已经排好序了。 到目前为止，管道最流行的用法之一是将命令产生的大量输出通过管道传送给 more 命令。这对 ls 命令来说尤为常见，ls -l 命令产生了目录中所有文件的长列表。对包含大量文件的目录来说，这个列表会相当长。通过将输出管道连接到 more 命令，可以强制输出在一屏数据显示后停下来。 执行数学运算另一个对任何编程语言都很重要的特性是操作数字的能力。遗憾的是，对 shell 脚本来说，这个处理过程会比较麻烦。在 shell 脚本中有两种途径来进行数学运算。 expr 命令最开始，Bourne shell 提供了一个特别的命令用来处理数学表达式。expr 命令允许在命令行上处理数学表达式，但是特别笨拙。 12$ expr 1 + 56 expr 命令能够识别少数的数学和字符串操作符。尽管标准操作符在 expr 命令中工作得很好，但在脚本或命令行上使用它们时仍有问题出现。许多 expr 命令操作符在 shell 中另有含义（比如星号）。当它们出现在在 expr 命令中时，会得到一些诡异的结果。 12$ expr 5 * 2expr: syntax error 要解决这个问题，对于那些容易被 shell 错误解释的字符，在它们传入 expr 命令之前，需要使用 shell 的转义字符（反斜线）将其标出来。 12$ expr 5 \\* 210 现在，麻烦才刚刚开始！在 shell 脚本中使用 expr 命令也同样复杂： 1234567$ cat test6#!/bin/bash# An example of using the expr commandvar1=10var2=20var3=$(expr $var2 / $var1) #命令替换的方式echo The result is $var3 要将一个数学算式的结果赋给一个变量，需要使用命令替换来获取 expr 命令的输出： 123$ chmod u+x test6$ ./test6The result is 2 幸好 bash shell 有一个针对处理数学运算符的改进，那就是方括号。 使用方括号bash shell 为了保持跟 Bourne shell 的兼容而包含了 expr 命令，但它同样也提供了一种更简单的方法来执行数学表达式。在 bash 中，在将一个数学运算结果赋给某个变量时，可以用美元符和方括号（$[ operation ]）将数学表达式围起来。 1234567$ var1=$[1 + 5]$ echo $var16$ var2=$[$var1 * 2]$ echo $var212$ 用方括号执行 shell 数学运算比用 expr 命令方便很多。这种技术也适用于 shell 脚本。 1234567$ cat test7#!/bin/bashvar1=100var2=50var3=45var4=$[$var1 * ($var2 - $var3)]echo The final result is $var4 #The final result is 500 同样，注意在使用方括号来计算公式时，不用担心 shell 会误解乘号或其他符号。shell 知道它不是通配符，因为它在方括号内。 在 bash shell 脚本中进行算术运算会有一个主要的限制。请看下例： 1234567$ cat test8#!/bin/bashvar1=100var2=45var3=$[$var1 / $var2]echo The final result is $var3 #The final result is 2$ bash shell 数学运算符只支持整数运算。若要进行任何实际的数学计算，这是一个巨大的限制。 z shell（zsh）提供了完整的浮点数算术操作。如果需要在 shell 脚本中进行浮点数运算，可以考虑看看 z shell。 浮点解决方案有几种解决方案能够克服 bash 中数学运算的整数限制。最常见的方案是用内建的 bash 计算器，叫作 bc。 bash 计算器实际上是一种编程语言，它允许在命令行中输入浮点表达式，然后解释并计算该表达式，最后返回结果。bash 计算器能够识别： 数字（整数和浮点数） 变量（简单变量和数组） 注释（以#或 C 语言中的&#x2F;* *&#x2F;开始的行） 表达式 编程语句（例如 if-then 语句） 函数 可以在 shell 提示符下通过 bc 命令访问 bash 计算器： 123456789101112131415$ bcbc 1.07.1Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006, 2008, 2012-2017 Free Software Foundation, Inc.This is free software with ABSOLUTELY NO WARRANTY.For details type `warranty&#x27;.12 * 5.464.83.156 * (3 + 5)25.248quit$ 浮点运算是由内建变量 scale 控制的。必须将这个值设置为你希望在计算结果中保留的小数位数，否则无法得到期望的结果。 123456789$ bc -q3.44 / 50scale=43.44 / 5.6880quit$ scale 变量的默认值是 0。在 scale 值被设置前，bash 计算器的计算结果不包含小数位。在将其值设置成 4 后，bash 计算器显示的结果包含四位小数。-q 命令行选项可以不显示 bash 计算器冗长的欢迎信息。 除了普通数字，bash 计算器还能支持变量。 123456789$ bc -qvar1=10var1 * 440var2 = var1 / 5print var22quit$ 变量一旦被定义，你就可以在整个 bash 计算器会话中使用该变量了。print 语句允许你打印变量和数字。 现在你可能想问 bash 计算器是如何在 shell 脚本中帮助处理浮点运算的。还记得命令替换吗？是的，可以用命令替换运行 bc 命令，并将输出赋给一个变量。 1234$ cat test9#!/bin/bashvar1=$(echo &quot;scale=4; 3.44 / 5&quot; | bc)echo The answer is $var1 #The answer is .6880 也可以用 shell 脚本中定义好的变量进行运算： 123456$ cat test10#!/bin/bashvar1=100var2=45var3=$(echo &quot;scale=4; $var1 / $var2&quot; | bc)echo The answer for this is $var3 #The answer for this is 2.2222 当然，一旦变量被赋值，那个变量也可以用于其他运算。 12345678$ cat test11#!/bin/bashvar1=20var2=3.14159var3=$(echo &quot;scale=4; $var1 * $var1&quot; | bc)var4=$(echo &quot;scale=4; $var3 * $var2&quot; | bc)echo The final result is $var4$ 这个方法适用于较短的运算，但有时你会涉及更多的数字。如果需要进行大量运算，在一个命令行中列出多个表达式就会有点麻烦。 有一个方法可以解决这个问题。bc 命令能识别输入重定向，允许你将一个文件重定向到 bc 命令来处理。但这同样会叫人头疼，因为你还得将表达式存放到文件中。 最好的办法是使用内联输入重定向，它允许你直接在命令行中重定向数据，可以将所有 bash 计算器涉及的部分都放到同一个脚本文件的不同行。下面是在脚本中使用这种技术的例子。 1234567891011121314$ cat test12#!/bin/bashvar1=10.46var2=43.67var3=33.2var4=71var5=$(bc &lt;&lt; EOFscale = 4a1 = ($var1 * $var2)b1 = ($var3 * $var4)a1 + b1EOF)echo The final answer for this mess is $var5 将选项和表达式放在脚本的不同行中可以让处理过程变得更清晰，提高易读性。EOF 字符串标识了重定向给 bc 命令的数据的起止。当然，必须用命令替换符号标识出用来给变量赋值的命令。 你还会注意到，在这个例子中，你可以在 bash 计算器中赋值给变量。有一点很重要：在 bash 计算器中创建的变量只在 bash 计算器中有效，不能在 shell 脚本中使用。 退出脚本迄今为止所有的示例脚本中，我们都是直接停止的。运行完最后一条命令时，脚本就结束了。其实还有另外一种更优雅的方法可以为脚本划上一个句号。 shell 中运行的每个命令都使用退出状态码（exit status）告诉 shell 它已经运行完毕。退出状态码是一个 0 ～ 255 的整数值，在命令结束运行时由命令传给 shell。可以捕获这个值并在脚本中使用。 查看退出状态码Linux 提供了一个专门的变量$?来保存上个已执行命令的退出状态码。对于需要进行检查的命令，必须在其运行完毕后立刻查看或使用$?变量。它的值会变成由 shell 所执行的最后一条命令的退出状态码。 12345$ dateSun Dec 20 01:35:39 PM CST 2020$ echo $?0$ 按照惯例，一个成功结束的命令的退出状态码是 0。如果一个命令结束时有错误，退出状态码就是一个正数值。 1234$ asdfg-bash: asdfg: command not found$ echo $?127 无效命令会返回一个退出状态码 127。Linux 错误退出状态码没有什么标准可循，但有一些可用的参考。 0 命令成功结束 1 一般性未知错误 2 不适合的 shell 命令 126 命令不可执行 127 没找到命令 128 无效的退出参数 128+x 与 Linux 信号 x 相关的严重错误 130 通过 Ctrl+C 终止的命令 225 正常范围之外的退出状态码 退出状态码 126 表明用户没有执行命令的正确权限。 12345$ ./myprog.c-bash: ./myprog.c: Permission denied$ echo $?126$ 另一个会碰到的常见错误是给某个命令提供了无效参数。 12345$ date %tdate: invalid date &#x27;%t&#x27;$ echo $?1$ 这会产生一般性的退出状态码 1，表明在命令中发生了未知错误。 exit 命令默认情况下，shell 脚本会以脚本中的最后一个命令的退出状态码退出。你可以改变这种默认行为，返回自己的退出状态码。exit 命令允许你在脚本结束时指定一个退出状态码。 123456789$ cat test13#!/bin/bash# testing the exit statusvar1=10var2=30var3=$[$var1 + $var2]echo The answer is $var3exit 5$ 当查看脚本的退出码时，你会得到作为参数传给 exit 命令的值。 123456$ chmod u+x test13$ ./test13The answer is 40$ echo $?5$ 也可以在 exit 命令的参数中使用变量。 12345678$ cat test14#!/bin/bash# testing the exit statusvar1=10var2=30var3=$[$var1 + $var2]exit $var3$ 当你运行这个命令时，它会产生如下退出状态。 12345$ chmod u+x test14$ ./test14$ echo $?40$ 在以往，exit 退出状态码最大只能是 255，如果超过了 255，最终的结果是指定的数值除以 256 后得到的余数。比如，指定的值是 300（返回值），余数是 44，因此这个余数就成了最后的状态退出码。但是在现在，此限制已经不存在，你可以使用 exit 指令指定更大的数值。 到目前为止，脚本中的命令都是按照有序的方式一个接着一个处理的。在下章中，你将学习如何用一些逻辑流程控制来更改命令的执行次序，也会了解到如何用 if-then 语句来检查某个命令返回的错误状态，以便知道命令是否成功。 结构化命令-条件判断上一章给出的那些 shell 脚本里，shell 按照命令在脚本中出现的顺序依次进行处理。对顺序操作来说，这已经足够了，因为在这种操作环境下，你想要的就是所有的命令按照正确的顺序执行。然而，并非所有程序都如此操作。许多程序要求对 shell 脚本中的命令施加一些逻辑流程控制。有一类命令会根据条件使脚本跳过某些命令。这样的命令通常称为结构化命令（structured command）。结构化命令允许你改变程序执行的顺序。在 bash shell 中有不少结构化命令，我们会逐个研究。 if 语句最基本的结构化命令就是 if-then 语句。if-then 语句有如下格式。 1234if command then commandsfi 如果你在用其他编程语言的 if-then 语句，这种形式可能会让你有点困惑。在其他编程语言中，if 语句之后的对象是一个等式，这个等式的求值结果为 TRUE 或 FALSE。但 bash shell 的 if 语句并不是这么做的。 bash shell 的 if 语句会运行 if 后面的那个命令。如果该命令的退出状态码是 0（该命令成功运行），位于 then 部分的命令就会被执行。如果该命令的退出状态码是其他值，then 部分的命令就不会被执行，bash shell 会继续执行脚本中的下一个命令。fi 语句用来表示 if-then 语句到此结束。 这里有个简单的例子可解释这个概念。 12345678$ cat test1.sh#!/bin/bash# testing the if statementif pwdthen echo &quot;It worked&quot;fi$ 这个脚本在 if 行采用了 pwd 命令。如果命令成功结束，echo 语句就会显示该文本字符串。在命令行运行该脚本时，会得到如下结果。 1234$ ./test1.sh/home/ChristineIt worked$ shell 执行了 if 行中的 pwd 命令。由于退出状态码是 0，它就又执行了 then 部分的 echo 语句。 你可能在有些脚本中看到过 if-then 语句的另一种形式： 123if command; then commandsfi 通过把分号放在待求值的命令尾部，就可以将 then 语句放在同一行上了，这样看起来更像其他编程语言中的 if-then 语句。 在 then 部分，你可以使用不止一条命令。可以像在脚本中的其他地方一样在这里列出多条命令。bash shell 会将这些命令当成一个块，如果 if 语句行的命令的退出状态值为 0，所有的命令都会被执行；如果 if 语句行的命令的退出状态不为 0，所有的命令都会被跳过。 12345678910111213$ cat test3.sh#!/bin/bash# testing multiple commands in the then section#testuser=Christine#if grep $testuser /etc/passwd; then echo &quot;This is my first command&quot; echo &quot;This is my second command&quot; echo &quot;I can even put in other commands besides echo:&quot; ls -a /home/$testuser/.b*fi$ if 语句行使用 grep 命令在&#x2F;etc&#x2F;passwd 文件中查找某个用户名当前是否在系统上使用。如果有用户使用了那个登录名，脚本会显示一些文本信息并列出该用户 HOME 目录的 bash 文件。 12345678$ ./test3.shChristine:x:501:501:Christine B:/home/Christine:/bin/bashThis is my first commandThis is my second commandI can even put in other commands besides echo:/home/Christine/.bash_history /home/Christine/.bash_profile/home/Christine/.bash_logout /home/Christine/.bashrc$ 但是，如果将 testuser 变量设置成一个系统上不存在的用户，则什么都不会显示。看起来也没什么新鲜的。如果在这里显示的一些消息可说明这个用户名在系统中未找到，这样可能就会显得更友好。此时可以用 if-then-else 语句来做到这一点。当 if 语句中的命令返回非零退出状态码时，bash shell 会执行 else 部分中的命令。现在可以复制并修改测试脚本来加入 else 部分。 1234567891011121314151617181920212223$ cp test3.sh test4.sh$$ vim test4.sh$$ cat test4.sh#!/bin/bash# testing the else section#testuser=NoSuchUser#if grep $testuser /etc/passwdthen echo &quot;The bash files for user $testuser are:&quot; ls -a /home/$testuser/.b* echoelse echo &quot;The user $testuser does not exist on this system.&quot; echofi$$ ./test4.shThe user NoSuchUser does not exist on this system.$ 这样就更友好了。跟 then 部分一样，else 部分也可以包含多条命令。 嵌套 if有时你需要检查脚本代码中的多种条件。对此，可以使用嵌套的 if-then 语句。 要检查&#x2F;etc&#x2F;passwd 文件中是否存在某个用户名以及该用户的目录是否尚在，可以使用嵌套的 if-then 语句。嵌套的 if-then 语句位于主 if-then-else 语句的 else 代码块中。 12345678910111213141516171819202122232425$ ls -d /home/NoSuchUser//home/NoSuchUser/$$ cat test5.sh#!/bin/bash# Testing nested ifs#testuser=NoSuchUser#if grep $testuser /etc/passwdthenecho &quot;The user $testuser exists on this system.&quot;else echo &quot;The user $testuser does not exist on this system.&quot; if ls -d /home/$testuser/ then echo &quot;However, $testuser has a directory.&quot; fifi$$ ./test5.shThe user NoSuchUser does not exist on this system./home/NoSuchUser/However, NoSuchUser has a directory.$ 这个脚本准确无误地发现，尽管登录名已经从&#x2F;etc&#x2F;passwd 中删除了，但是该用户的目录仍然存在。在脚本中使用这种嵌套 if-then 语句的问题在于代码不易阅读，很难理清逻辑流程。可以使用 else 部分的另一种形式：elif。这样就不用再书写多个 if-then 语句了。elif 使用另一个 if-then 语句延续 else 部分。elif 语句行提供了另一个要测试的命令，这类似于原始的 if 语句行。如果 elif 后命令的退出状态码是 0，则 bash 会执行第二个 then 语句部分的命令。使用这种嵌套方法，代码更清晰，逻辑更易懂。甚至可以更进一步，让脚本检查拥有目录的不存在用户以及没有拥有目录的不存在用户。这可以通过在嵌套 elif 中加入一个 else 语句来实现。 123456789101112131415161718192021222324252627282930313233$ cat test5.sh#!/bin/bash# Testing nested ifs - use elif &amp; else#testuser=NoSuchUser#if grep $testuser /etc/passwdthen echo &quot;The user $testuser exists on this system.&quot;#elif ls -d /home/$testuserthen echo &quot;The user $testuser does not exist on this system.&quot; echo &quot;However, $testuser has a directory.&quot;#else echo &quot;The user $testuser does not exist on this system.&quot; echo &quot;And, $testuser does not have a directory.&quot;fi$$ ./test5.sh/home/NoSuchUserThe user NoSuchUser does not exist on this system.However, NoSuchUser has a directory.$$ sudo rmdir /home/NoSuchUser[sudo] password for Christine:$$ ./test5.shls: cannot access /home/NoSuchUser: No such file or directoryThe user NoSuchUser does not exist on this system.And, NoSuchUser does not have a directory.$ 在&#x2F;home&#x2F;NoSuchUser 目录被删除之前，这个测试脚本执行的是 elif 语句，返回零值的退出状态。因此 elif 的 then 代码块中的语句得以执行。删除了&#x2F;home&#x2F;NoSuchUser 目录之后，elif 语句返回的是非零值的退出状态。这使得 elif 块中的 else 代码块得以执行。 记住，在 elif 语句中，紧跟其后的 else 语句属于 elif 代码块。它们并不属于之前的 if-then 代码块。 可以继续将多个 elif 语句串起来，形成一个大的 if-then-elif 嵌套组合。每块命令都会根据命令是否会返回退出状态码 0 来执行。记住，bash shell 会依次执行 if 语句，只有第一个返回退出状态码 0 的语句中的 then 部分会被执行。 12345678910111213if command1then command set 1elif command2then command set 2elif command3then command set 3elif command4then command set 4fi 尽管使用了 elif 语句的代码看起来更清晰，但是脚本的逻辑仍然会让人犯晕。在本章稍后你会看到如何使用 case 命令代替 if-then 语句的大量嵌套。 test 命令到目前为止，在 if 语句中看到的都是普通 shell 命令。你可能想问，if-then 语句是否能直接测试命令退出状态码之外的条件。答案是不能。但在 bash shell 中有个好用的工具可以帮你通过 if-then 语句测试其他条件。 test 命令提供了在 if-then 语句中测试不同条件的途径。如果 test 命令中列出的条件成立，test 命令就会退出并返回退出状态码 0。这样 if-then 语句就与其他编程语言中的 if-then 语句以类似的方式工作了。如果条件不成立，test 命令就会退出并返回非零的退出状态码，这使得 if-then 语句不会再被执行。 如果只执行 test 命令本身，不写 test 命令的条件部分，它会以非零的退出状态码退出，并执行 else 语句块。当你加入一个条件时，test 命令会测试该条件。例如，可以使用 test 命令确定变量中是否有内容。这只需要一个简单的条件表达式。 1234567891011121314151617$ cat test6.sh#!/bin/bash# Testing the test command#my_variable=&quot;Full&quot;#if test $my_variablethen echo &quot;The $my_variable expression returns a True&quot;#else echo &quot;The $my_variable expression returns a False&quot;fi$$ ./test6.shThe Full expression returns a True$ 变量 my_variable 中包含有内容（Full），因此当 test 命令测试条件时，返回的退出状态为 0。这使得 then 语句块中的语句得以执行。如你所料，如果该变量中没有包含内容，就会出现相反的情况。 bash shell 提供了另一种条件测试方法，无需在 if-then 语句中声明 test 命令。 1234if [ condition ]then commandsfi 方括号定义了测试条件，是与 test 命令同义的特殊 bash 命令。注意，第一个方括号之后和第二个方括号之前必须加上一个空格，否则就会报错。test 命令可以判断三类条件： 数值比较 字符串比较 文件比较 接下来将会介绍如何在 if-then 语句中使用这些条件测试。 数值比较使用 test 命令最常见的情形是对两个数值进行比较。如下列出了测试两个值时可用的条件参数。 n1 -eq n2 检查 n1 是否与 n2 相等 n1 -ge n2 检查 n1 是否大于或等于 n2 n1 -gt n2 检查 n1 是否大于 n2 n1 -le n2 检查 n1 是否小于或等于 n2 n1 -lt n2 检查 n1 是否小于 n2 n1 -ne n2 检查 n1 是否不等于 n2 数值条件测试可以用在数字和变量上。这里有个例子。 1234567891011121314151617181920$ cat numeric_test.sh#!/bin/bash# Using numeric test evaluations#value1=10value2=11#if [ $value1 -gt 5 ]then echo &quot;The test value $value1 is greater than 5&quot;fi#if [ $value1 -eq $value2 ]then echo &quot;The values are equal&quot;else echo &quot;The values are different&quot;fi#$ 第一个条件测试测试变量 value1 的值是否大于 5。第二个条件测试测试变量 value1 的值是否和变量 value2 的值相等。两个数值条件测试的结果和预想一致。 但是涉及浮点值时，数值条件测试会有一个限制。bash shell 只能处理整数。如果你只是要通过 echo 语句来显示这个结果，那没问题。但是，在基于数字的函数中就不行了，比如数值测试条件，不能在 test 命令中使用浮点值。 字符串比较条件测试还允许比较字符串值。比较字符串比较烦琐。 str1 &#x3D; str2 检查 str1 是否和 str2 相同 str1 !&#x3D; str2 检查 str1 是否和 str2 不同 str1 &lt; str2 检查 str1 是否比 str2 小 str1 &gt; str2 检查 str1 是否比 str2 大 -n str1 检查 str1 的长度是否非 0 -z str1 检查 str1 的长度是否为 0 记住，在比较字符串的相等性时，比较测试会将所有的标点和大小写情况都考虑在内。 要测试一个字符串是否比另一个字符串大就是麻烦的开始。当要开始使用测试条件的大于或小于功能时，就会出现两个经常困扰 shell 程序员的问题： 大于号和小于号必须转义，否则 shell 会把它们当作重定向符号，把字符串值当作文件名； 大于和小于顺序和 sort 命令所采用的不同。 在编写脚本时，第一条可能会导致一个不易察觉的严重问题。下面的例子展示了 shell 脚本编程初学者时常碰到的问题。 12345678910111213141516171819$ cat badtest.sh#!/bin/bash# mis-using string comparisons#val1=baseballval2=hockey#if [ $val1 &gt; $val2 ]then echo &quot;$val1 is greater than $val2&quot;else echo &quot;$val1 is less than $val2&quot;fi$$ ./badtest.shbaseball is greater than hockey$ ls -l hockey-rw-r--r-- 1 rich rich 0 Sep 30 19:08 hockey$ 这个脚本中只用了大于号，没有出现错误，但结果是错的。脚本把大于号解释成了输出重定向。因此，它创建了一个名为 hockey 的文件。由于重定向的顺利完成，test 命令返回了退出状态码 0，if 语句便以为所有命令都成功结束了。要解决这个问题，就需要使用反斜杠\\&gt;正确转义大于号。 第二个问题更细微，除非你经常处理大小写字母，否则几乎遇不到。sort 命令处理大写字母的方法刚好跟 test 命令相反。比如两个变量val1=Testing val2=testing，在 test 命令中，大写字母被认为是小于小写字母的。但 sort 命令恰好相反。当你将同样的字符串放进文件中并用 sort 命令排序时，小写字母会先出现。这是由各个命令使用的排序技术不同造成的。 test 命令中使用的是标准的 ASCII 顺序，根据每个字符的 ASCII 数值来决定排序结果。sort 命令使用的是系统的本地化语言设置中定义的排序顺序。对于英语，本地化设置指定了在排序顺序中小写字母出现在大写字母前。 test 命令测试表达式使用标准的数学比较符号来表示字符串比较，而用文本代码来表示数值比较。这个细微的特性被很多程序员理解反了。如果你对数值使用了数学运算符号，shell 会将它们当成字符串值，可能无法得到正确的结果。 最后，-n 和-z 可以检查一个变量是否含有数据。如果一个变量为空字符串，或其从未被定义，那么均会被认为它的字符串长度为 0。 空的和未初始化的变量会对 shell 脚本测试造成灾难性的影响。如果不是很确定一个变量的内容，最好在将其用于数值或字符串比较之前先通过-n 或-z 来测试一下变量是否含有值。 文件比较最后一类比较测试很有可能是 shell 编程中最为强大、也是用得最多的比较形式。它允许你测试 Linux 文件系统上文件和目录的状态。 -d file 检查 file 是否存在并是一个目录 -e file 检查 file 是否存在（文件或目录） -f file 检查 file 是否存在并是一个文件 -r file 检查 file 是否存在并可读 -s file 检查 file 是否存在并非空 -w file 检查 file 是否存在并可写 -x file 检查 file 是否存在并可执行 -O file 检查 file 是否存在并属当前用户所有 -G file 检查 file 是否存在并且默认组与当前用户相同 file1 -nt file2 检查 file1 是否比 file2 新 file1 -ot file2 检查 file1 是否比 file2 旧 这些测试条件使你能够在 shell 脚本中检查文件系统中的文件。它们经常出现在需要进行文件访问的脚本中。鉴于其使用广泛，建议熟练掌握。用于比较文件路径是相对你运行该脚本的目录而言的。 需要注意的是，-G 比较会检查文件的默认组，如果它匹配了用户的默认组，则测试成功。由于-G 比较只会检查默认组而非用户所属的所有组，这会叫人有点困惑。如果文件的组被改成了某个组，用户也是其中的一员，但用户并不以其为默认组，此时-G 比较会失败，因为它只比较默认组，不会去比较其他的组。 此外，在比较两个文件的新旧时，这些比较都不会先检查文件是否存在，如果你要检查的文件已经移走，就会出现问题。在你尝试使用-nt 或-ot 比较文件之前，必须先确认文件是存在的。 复合条件测试if-then 语句允许你使用布尔逻辑来组合测试。有两种布尔运算符可用： [ condition1 ] &amp;&amp; [ condition2 ] [ condition1 ] || [ condition2 ] 结合方括号测试方式和布尔逻辑组合，可以测试更多条件。 if 语句的高级特性bash shell 提供了两项可在 if-then 语句中使用的高级特性： 用于数学表达式的双括号 用于高级字符串处理功能的双方括号 使用双括号双括号命令允许你在比较过程中使用高级数学表达式。test 命令只能在比较中使用简单的算术操作。双括号命令提供了更多的数学符号，这些符号对于用过其他编程语言的程序员而言并不陌生。除了 test 命令使用的标准数学运算符，如下列出了双括号命令中还可以使用的其他运算符。 val++ 后增 val– 后减 ++val 先增 –val 先减 ! 逻辑求反 ~ 位求反 ** 幂运算 &lt;&lt; 左位移 &gt;&gt; 右位移 &amp; 位布尔和 | 位布尔或 &amp;&amp; 逻辑和 || 逻辑或 可以在 if 语句中用双括号命令，也可以在脚本中的普通命令里使用来赋值。 123456789101112131415$ cat test23.sh#!/bin/bash# using double parenthesis#val1=10#if (( $val1 ** 2 &gt; 90 ))then (( val2 = $val1 ** 2 )) echo &quot;The square of $val1 is $val2&quot;fi$$ ./test23.shThe square of 10 is 100$ 注意，不需要将双括号中表达式里的大于号转义。这是双括号命令提供的另一个高级特性。 使用双方括号双方括号命令提供了针对字符串比较的高级特性。双方括号使用了 test 命令中采用的标准字符串比较。但它提供了 test 命令未提供的另一个特性——模式匹配（pattern matching）。 双方括号在 bash shell 中工作良好。不过要小心，不是所有的 shell 都支持双方括号。 在模式匹配中，可以定义一个正则表达式（后续将详细讨论）来匹配字符串值。 123456789101112131415$ cat test24.sh#!/bin/bash# using pattern matching#if [[ $USER == r* ]]then echo &quot;Hello $USER&quot;else echo &quot;Sorry, I do not know you&quot;fi$$ ./test24.shHello rich$ 在上面的脚本中，我们使用了双等号（&#x3D;&#x3D;）。双等号将右边的字符串（r*）视为一个模式，并应用模式匹配规则。双方括号命令$USER 环境变量进行匹配，看它是否以字母 r 开头。如果是的话，比较通过，shell 会执行 then 部分的命令。 case 命令你会经常发现自己在尝试计算一个变量的值，在一组可能的值中寻找特定值。在这种情形下，你不得不写出很长的 if-then-else 语句，就像下面这样。 1234567891011121314151617181920212223242526$ cat test25.sh#!/bin/bash# looking for a possible value#if [ $USER = &quot;rich&quot; ]then echo &quot;Welcome $USER&quot; echo &quot;Please enjoy your visit&quot;elif [ $USER = &quot;barbara&quot; ]then echo &quot;Welcome $USER&quot; echo &quot;Please enjoy your visit&quot;elif [ $USER = &quot;testing&quot; ]then echo &quot;Special testing account&quot;elif [ $USER = &quot;jessica&quot; ]then echo &quot;Do not forget to logout when you&#x27;re done&quot;else echo &quot;Sorry, you are not allowed here&quot;fi$$ ./test25.shWelcome richPlease enjoy your visit$ elif 语句继续 if-then 检查，为比较变量寻找特定的值。有了 case 命令，就不需要再写出所有的 elif 语句来不停地检查同一个变量的值了。case 命令会采用列表格式来检查单个变量的多个值。 case 命令会将指定的变量与不同模式进行比较。如果变量和模式是匹配的，那么 shell 会执行为该模式指定的命令。可以通过竖线操作符在一行中分隔出多个模式模式。星号会捕获所有与已知模式不匹配的值。这里有个将 if-then-else 程序转换成用 case 命令的例子。 1234567891011121314151617181920$ cat test26.sh#!/bin/bash# using the case command#case $USER inrich | barbara) echo &quot;Welcome, $USER&quot; echo &quot;Please enjoy your visit&quot;;;testing) echo &quot;Special testing account&quot;;;jessica) echo &quot;Do not forget to log off when you&#x27;re done&quot;;;*) echo &quot;Sorry, you are not allowed here&quot;;;esac$$ ./test26.shWelcome, richPlease enjoy your visit$ case 命令提供了一个更清晰的方法来为变量每个可能的值指定不同的选项。 结构化命令-循环上一章里，你看到了如何通过检查命令的输出和变量的值来改变 shell 脚本程序的流程。本章会继续介绍能够控制 shell 脚本流程的结构化命令。你会了解如何重复一些过程和命令，也就是循环执行一组命令直至达到了某个特定条件。本章将会讨论和演示 bash shell 的循环命令 for、while 和 until 等。 for 命令重复执行一系列命令在编程中很常见。通常你需要重复一组命令直至达到某个特定条件，比如处理某个目录下的所有文件、系统上的所有用户或是某个文本文件中的所有行。for 命令有几种不同的方式来读取列表中的值，下面几节将会介绍各种方式。 读取列表中的值for 命令最基本的用法就是遍历 for 命令自身所定义的一系列值。 1234567891011121314151617181920$ cat test1 #!/bin/bash# basic for commandfor test in Alabama Alaska Arizona Arkansas California Coloradodo echo The next state is $testdoneecho &quot;The last state we visited was $test&quot;test=Connecticutecho &quot;Wait, now we&#x27;re visiting $test&quot;$ ./test1The next state is AlabamaThe next state is AlaskaThe next state is ArizonaThe next state is ArkansasThe next state is CaliforniaThe next state is ColoradoThe last state we visited was ColoradoWait, now we&#x27;re visiting Connecticut$ 每次 for 命令遍历值列表，它都会将列表中的下个值赋给$test变量。$test 变量可以像 for 命令语句中的其他脚本变量一样使用。在最后一次迭代后，$test 变量的值会在 shell 脚本的剩余部分一直保持有效。它会一直保持最后一次迭代的值（除非你修改了它）。$test 变量保持了其值，也允许我们修改它的值，并在 for 命令循环之外跟其他变量一样使用 事情并不会总像你在 for 循环中看到的那么简单。有时会遇到难处理的数据。有时 for 循环的值列表中可能存在中间有空格的值，此时使用单引号或者双引号将中间存在空格的值括起来即可。有时候，有的值自身中存在单引号或双引号，这时需要用另外一种相反的引号将其括起来，或者使用反斜杠转义即可正常使用。 从变量读取列表通常 shell 脚本遇到的情况是，你将一系列值都集中存储在了一个变量中，然后需要遍历变量中的整个列表。也可以通过 for 命令完成这个任务。 1234567891011121314151617$ cat test4#!/bin/bash# using a variable to hold the listlist=&quot;Alabama Alaska Arizona Arkansas Colorado&quot;list=$list&quot; Connecticut&quot;for state in $listdoecho &quot;Have you ever visited $state?&quot;done$ ./test4Have you ever visited Alabama?Have you ever visited Alaska?Have you ever visited Arizona?Have you ever visited Arkansas?Have you ever visited Colorado?Have you ever visited Connecticut? $list变量包含了用于迭代的标准文本值列表。注意，代码还是用了另一个赋值语句向$list 变量包含的已有列表中添加（或者说是拼接）了一个值。这是向变量中存储的已有文本字符串尾部添加文本的一个常用方法。 从命令读取值生成列表中所需值的另外一个途径就是使用命令的输出。可以用命令替换来执行任何能产生输出的命令，然后在 for 命令中使用该命令的输出。 1234567891011121314151617181920212223242526272829$ cat test5#!/bin/bash# reading values from a filefile=&quot;states&quot;for state in $(cat $file)doecho &quot;Visit beautiful $state&quot;done$ cat statesAlabamaAlaskaArizonaArkansasColoradoConnecticutDelawareFloridaGeorgia$ ./test5Visit beautiful AlabamaVisit beautiful AlaskaVisit beautiful ArizonaVisit beautiful ArkansasVisit beautiful ColoradoVisit beautiful ConnecticutVisit beautiful DelawareVisit beautiful FloridaVisit beautiful Georgia$ 这个例子在命令替换中使用了 cat 命令来输出文件 states 的内容。你会注意到 states 文件中每一行有一个州，而不是通过空格分隔的。for 命令仍然以每次一行的方式遍历了 cat 命令的输出，假定每个州都是在单独的一行上。但这并没有解决数据中有空格的问题。如果你列出了一个名字中有空格的州，for 命令仍然会将每个单词当作单独的值。这是有原因的，下一节我们将会了解。 test5 的代码范例将文件名赋给变量，文件名中没有加入路径。这要求文件和脚本位于同一个目录中。如果不是的话，你需要使用全路径名（不管是绝对路径还是相对路径）来引用文件位置。 更改字段分隔符造成这个问题的原因是特殊的环境变量 IFS，叫作内部字段分隔符（internal field separator）。IFS 环境变量定义了 bash shell 用作字段分隔符的一系列字符。默认情况下，bash shell 会将下列字符当作字段分隔符： 空格 制表符 换行符 如果 bash shell 在数据中看到了这些字符中的任意一个，它就会假定这表明了列表中一个新数据字段的开始。在处理可能含有空格的数据（比如文件名）时，这会非常麻烦，就像你在上一个脚本示例中看到的。 要解决这个问题，可以在 shell 脚本中临时更改 IFS 环境变量的值来限制被 bash shell 当作字段分隔符的字符。例如，如果你想修改 IFS 的值，使其只能识别换行符，那就必须这么做： 1IFS=$&#x27;\\n&#x27; 将这个语句加入到脚本中，告诉 bash shell 在数据值中忽略空格和制表符。对前一个脚本使用这种方法，shell 脚本就能够使用列表中含有空格的值了。 在处理代码量较大的脚本时，可能在一个地方需要修改 IFS 的值，然后忽略这次修改，在脚本的其他地方继续沿用 IFS 的默认值。一个可参考的安全实践是在改变 IFS 之前保存原来的 IFS 值，之后再恢复它。这种技术可以这样实现： IFS.OLD&#x3D;$IFS IFS&#x3D;$’\\n’ &lt;在代码中使用新的 IFS 值&gt; IFS&#x3D;$IFS.OLD 这就保证了在脚本的后续操作中使用的是 IFS 的默认值。 还有其他一些 IFS 环境变量的绝妙用法。假定你要遍历一个文件中用冒号分隔的值（比如在&#x2F;etc&#x2F;passwd 文件中）。你要做的就是将 IFS 的值设为冒号 1IFS=: 如果要指定多个 IFS 字符，只要将它们在赋值行串起来就行。 1IFS=$&#x27;\\n&#x27;:;&quot; 这个赋值会将换行符、冒号、分号和双引号作为字段分隔符。如何使用 IFS 字符解析数据没有任何限制。 用通配符读取目录最后，可以用 for 命令来自动遍历目录中的文件。进行此操作时，必须在文件名或路径名中使用通配符。它会强制 shell 使用文件扩展匹配。文件扩展匹配是生成匹配指定通配符的文件名或路径名的过程。 如果不知道所有的文件名，这个特性在处理目录中的文件时就非常好用。 1234567891011121314151617181920212223242526$ cat test6#!/bin/bash# iterate through all the files in a directoryfor file in /home/rich/test/*do if [ -d &quot;$file&quot; ] then echo &quot;$file is a directory&quot; elif [ -f &quot;$file&quot; ] then echo &quot;$file is a file&quot; fidone$ ./test6/home/rich/test/dir1 is a directory/home/rich/test/myprog.c is a file/home/rich/test/myprog is a file/home/rich/test/myscript is a file/home/rich/test/newdir is a directory/home/rich/test/newfile is a file/home/rich/test/newfile2 is a file/home/rich/test/testdir is a directory/home/rich/test/testing is a file/home/rich/test/testprog is a file/home/rich/test/testprog.c is a file$ for 命令会遍历&#x2F;home&#x2F;rich&#x2F;test&#x2F;*输出的结果。该代码用 test 命令测试了每个条目（使用方括号方法），以查看它是目录（通过-d 参数）还是文件（通过-f 参数） 注意，我们在这个例子的 if 语句中做了一些不同的处理 1if [ -d &quot;$file&quot; ] 在 Linux 中，目录名和文件名中包含空格当然是合法的。要适应这种情况，应该将$file 变量用双引号圈起来。如果不这么做，遇到含有空格的目录名或文件名时就会有错误产生。 12./test6: line 6: [: too many arguments./test6: line 9: [: too many arguments 在 test 命令中，bash shell 会将额外的单词当作参数，进而造成错误。 也可以在 for 命令中列出多个目录通配符，将目录查找和列表合并进同一个 for 语句。 123456789101112131415161718192021222324$ cat test7#!/bin/bash# iterating through multiple directoriesfor file in /home/rich/.b* /home/rich/badtestdo if [ -d &quot;$file&quot; ] then echo &quot;$file is a directory&quot; elif [ -f &quot;$file&quot; ] then echo &quot;$file is a file&quot; else echo &quot;$file doesn&#x27;t exist&quot; fidone$ ./test7/home/rich/.backup.timestamp is a file/home/rich/.bash_history is a file/home/rich/.bash_logout is a file/home/rich/.bash_profile is a file/home/rich/.bashrc is a file/home/rich/badtest doesn&#x27;t exist$ for 语句首先使用了文件扩展匹配来遍历通配符生成的文件列表，然后它会遍历列表中的下一个文件。可以将任意多的通配符放进列表中。 注意，你可以在数据列表中放入任何东西。即使文件或目录不存在，for 语句也会尝试处理列表中的内容。在处理文件或目录时，这可能会是个问题。你无法知道你正在尝试遍历的目录是否存在：在处理之前测试一下文件或目录总是好的。 C 语言风格的 for 命令如果你从事过 C 语言编程，可能会对 bash shell 中 for 命令的工作方式有点惊奇。在 C 语言中，for 循环通常定义一个变量，然后这个变量会在每次迭代时自动改变。通常程序员会将这个变量用作计数器，并在每次迭代中让计数器增一或减一。bash 的 for 命令也提供了这个功能。本节将会告诉你如何在 bash shell 脚本中使用 C 语言风格的 for 命令。 C 语言的 for 命令有一个用来指明变量的特定方法，一个必须保持成立才能继续迭代的条件，以及另一个在每个迭代中改变变量的方法。当指定的条件不成立时，for 循环就会停止。条件等式通过标准的数学符号定义。比如，考虑下面的 C 语言代码： 123for (i = 0; i &lt; 10; i++) &#123; printf(&quot;The next number is %d\\n&quot;, i);&#125; 这段代码产生了一个简单的迭代循环，其中变量 i 作为计数器。第一部分将一个默认值赋给该变量。中间的部分定义了循环重复的条件。当定义的条件不成立时，for 循环就停止迭代。最后一部分定义了迭代的过程。在每次迭代之后，最后一部分中定义的表达式会被执行。在本例中，i 变量会在每次迭代后增一。 bash shell 也支持一种 for 循环，它看起来跟 C 语言风格的 for 循环类似，但有一些细微的不同，其中包括一些让 shell 脚本程序员困惑的东西。以下是 bash 中 C 语言风格的 for 循环的基本格式。 1for (( variableassignment ; condition ; iterationprocess )) C 语言风格的 for 循环的格式会让 bash shell 脚本程序员摸不着头脑，因为它使用了 C 语言风格的变量引用方式而不是 shell 风格的变量引用方式。C 语言风格的 for 命令看起来如下。 1for (( a = 1; a &lt; 10; a++ )) 注意，有些部分并没有遵循 bash shell 标准的 for 命令： 变量赋值可以有空格； 条件中的变量不以美元符开头； 迭代过程的算式未用 expr 命令格式。 shell 开发人员创建了这种格式以更贴切地模仿 C 语言风格的 for 命令。这虽然对 C 语言程序员来说很好，但也会把专家级的 shell 程序员弄得一头雾水。在脚本中使用 C 语言风格的 for 循环时要小心。 以下例子是在 bash shell 程序中使用 C 语言风格的 for 命令 123456789101112$ cat test8#!/bin/bash# testing the C-style for loopfor (( i=1; i &lt;= 3; i++ ))do echo &quot;The next number is $i&quot;done$ ./test8The next number is 1The next number is 2The next number is 3$ for 循环通过定义好的变量（本例中是变量 i）来迭代执行这些命令。在每次迭代中，$i 变量包含了 for 循环中赋予的值。在每次迭代后，循环的迭代过程会作用在变量上，在本例中，变量增一。 C 语言风格的 for 命令也允许为迭代使用多个变量。循环会单独处理每个变量，你可以为每个变量定义不同的迭代过程。尽管可以使用多个变量，但你只能在 for 循环中定义一种条件。 123456789101112$ cat test9#!/bin/bash# multiple variablesfor (( a=1, b=10; a &lt;= 3; a++, b-- ))do echo &quot;$a - $b&quot;done$ ./test91 - 102 - 93 - 8$ 变量 a 和 b 分别用不同的值来初始化并且定义了不同的迭代过程。循环的每次迭代在增加变量 a 的同时减小了变量 b。 while 命令while 命令某种意义上是 if-then 语句和 for 循环的混杂体。while 命令允许定义一个要测试的命令，然后循环执行一组命令，只要定义的测试命令返回的是退出状态码 0。它会在每次迭代的一开始测试 test 命令。在 test 命令返回非零退出状态码时，while 命令会停止执行那组命令。 while 命令的格式是： 1234while test commanddo other commandsdone while 命令中定义的 test command 和 if-then 语句中的格式一模一样。可以使用任何普通的 bash shell 命令，或者用 test 命令进行条件测试，比如测试变量值。while 命令的关键在于所指定的 test command 的退出状态码必须随着循环中运行的命令而改变。如果退出状态码不发生变化，while 循环就将一直不停地进行下去。最常见的 test command 的用法是用方括号来检查循环命令中用到的 shell 变量的值。 12345678910111213141516171819202122$ cat test10#!/bin/bash# while command testvar1=10while [ $var1 -gt 0 ]do echo $var1 var1=$[ $var1 - 1 ]done$ ./test1010987654321$ while 命令定义了每次迭代时检查的测试条件：while [ $var1 -gt 0 ] 。只要测试条件成立，while 命令就会不停地循环执行定义好的命令。在这些命令中，测试条件中用到的变量必须被修改，否则就会陷入无限循环。在本例中，我们用 shell 算术来将变量值减一：var1=$[ $var1 - 1 ] 。while 循环会在测试条件不再成立时停止。 while 命令允许你在 while 语句行定义多个测试命令。只有最后一个测试命令的退出状态码会被用来决定什么时候结束循环。如果你不够小心，可能会导致一些有意思的结果。下面的例子将说明这一点。 12345678910111213141516171819202122232425262728293031323334$ cat test11#!/bin/bash# testing a multicommand while loopvar1=10while echo $var1 [ $var1 -ge 0 ]do echo &quot;This is inside the loop&quot; var1=$[ $var1 - 1 ]done$ ./test1110This is inside the loop9This is inside the loop8This is inside the loop7This is inside the loop6This is inside the loop5This is inside the loop4This is inside the loop3This is inside the loop2This is inside the loop1This is inside the loop0This is inside the loop-1 while 语句中定义了两个测试命令。第一个测试简单地显示了 var1 变量的当前值。第二个测试用方括号来判断 var1 变量的值。在循环内部，echo 语句会显示一条简单的消息，说明循环被执行了。注意当你运行本例时输出最后还有一个-1。 while 循环会在 var1 变量等于 0 时执行 echo 语句，然后将 var1 变量的值减一。接下来再次执行测试命令，用于下一次迭代。echo 测试命令被执行并显示了 var 变量的值（现在小于 0 了）。直到 shell 执行 test 测试命令，whle 循环才会停止。 until 命令until 命令和 while 命令工作的方式完全相反。until 命令要求你指定一个通常返回非零退出状态码的测试命令。只有测试命令的退出状态码不为 0，bash shell 才会执行循环中列出的命令。一旦测试命令返回了退出状态码 0，循环就结束了。和 while 命令类似，你可以在 until 命令语句中放入多个测试命令。只有最后一个命令的退出状态码决定了 bash shell 是否执行已定义的 other commands。下面是使用 until 命令的一个例子。 123456789101112131415$ cat test12#!/bin/bash# using the until commandvar1=100until [ $var1 -eq 0 ]do echo $var1 var1=$[ $var1 - 25 ]done$ ./test12100755025$ 本例中会测试 var1 变量来决定 until 循环何时停止。只要该变量的值等于 0，until 命令就会停止循环。同 while 命令一样，在 until 命令中使用多个测试命令时要注意。 12345678910111213141516171819202122$ cat test13#!/bin/bash# using the until commandvar1=100until echo $var1 [ $var1 -eq 0 ]do echo Inside the loop: $var1 var1=$[ $var1 - 25 ]done$ ./test13100Inside the loop: 10075Inside the loop: 7550Inside the loop: 5025Inside the loop: 250$ 嵌套循环循环语句可以在循环内使用任意类型的命令，包括其他循环命令。这种循环叫作嵌套循环（nested loop）。注意，在使用嵌套循环时，你是在迭代中使用迭代，与命令运行的次数是乘积关系。不注意这点的话，有可能会在脚本中造成问题。 12345678910111213141516171819202122232425$ cat test14#!/bin/bash# nesting for loopsfor (( a = 1; a &lt;= 3; a++ ))do echo &quot;Starting loop $a:&quot; for (( b = 1; b &lt;= 3; b++ )) do echo &quot; Inside loop: $b&quot; donedone$ ./test14Starting loop 1: Inside loop: 1 Inside loop: 2 Inside loop: 3Starting loop 2: Inside loop: 1 Inside loop: 2 Inside loop: 3Starting loop 3: Inside loop: 1 Inside loop: 2 Inside loop: 3$ 这个被嵌套的循环（也称为内部循环，inner loop）会在外部循环的每次迭代中遍历一次它所有的值。注意，两个循环的 do 和 done 命令没有任何差别。bash shell 知道当第一个 done 命令执行时是指内部循环而非外部循环。 在混用循环命令时也一样，比如在 while 循环内部放置一个 for 循环。 12345678910111213141516171819202122232425262728293031323334$ cat test15#!/bin/bash# placing a for loop inside a while loopvar1=5while [ $var1 -ge 0 ]do echo &quot;Outer loop: $var1&quot; for (( var2 = 1; $var2 &lt; 3; var2++ )) do var3=$[ $var1 * $var2 ] echo &quot; Inner loop: $var1 * $var2 = $var3&quot; donevar1=$[ $var1 - 1 ]done$ ./test15Outer loop: 5 Inner loop: 5 * 1 = 5 Inner loop: 5 * 2 = 10Outer loop: 4 Inner loop: 4 * 1 = 4 Inner loop: 4 * 2 = 8Outer loop: 3 Inner loop: 3 * 1 = 3 Inner loop: 3 * 2 = 6Outer loop: 2 Inner loop: 2 * 1 = 2 Inner loop: 2 * 2 = 4Outer loop: 1 Inner loop: 1 * 1 = 1 Inner loop: 1 * 2 = 2Outer loop: 0 Inner loop: 0 * 1 = 0 Inner loop: 0 * 2 = 0$ 同样，shell 能够区分开内部 for 循环和外部 while 循环各自的 do 和 done 命令。如果真的想挑战脑力，可以混用 until 和 while 循环。 123456789101112131415161718192021222324252627282930313233$ cat test16#!/bin/bash# using until and while loopsvar1=3until [ $var1 -eq 0 ]do echo &quot;Outer loop: $var1&quot; var2=1 while [ $var2 -lt 5 ] do var3=$(echo &quot;scale=4; $var1 / $var2&quot; | bc) echo &quot; Inner loop: $var1 / $var2 = $var3&quot; var2=$[ $var2 + 1 ] done var1=$[ $var1 - 1 ]done$ ./test16Outer loop: 3 Inner loop: 3 / 1 = 3.0000 Inner loop: 3 / 2 = 1.5000 Inner loop: 3 / 3 = 1.0000 Inner loop: 3 / 4 = .7500Outer loop: 2 Inner loop: 2 / 1 = 2.0000 Inner loop: 2 / 2 = 1.0000 Inner loop: 2 / 3 = .6666 Inner loop: 2 / 4 = .5000Outer loop: 1 Inner loop: 1 / 1 = 1.0000 Inner loop: 1 / 2 = .5000 Inner loop: 1 / 3 = .3333 Inner loop: 1 / 4 = .2500$ 外部的 until 循环以值 3 开始，并继续执行到值等于 0。内部 while 循环以值 1 开始并一直执行，只要值小于 5。每个循环都必须改变在测试条件中用到的值，否则循环就会无止尽进行下去。 循环处理文件数据如果需要遍历存储在文件中的数据，则需要结合已经讲过的两种技术： 使用嵌套循环 修改 IFS 环境变量 通过修改 IFS 环境变量，就能强制 for 命令将文件中的每行都当成单独的一个条目来处理，即便数据中有空格也是如此。一旦从文件中提取出了单独的行，可能需要再次利用循环来提取行中的数据。 典型的例子是处理&#x2F;etc&#x2F;passwd 文件中的数据。这要求你逐行遍历&#x2F;etc&#x2F;passwd 文件，然后将 IFS 变量的值改成冒号，这样就能分隔开每行中的各个数据段了。 1234567891011121314#!/bin/bash# changing the IFS valueIFS.OLD=$IFSIFS=$&#x27;\\n&#x27;for entry in $(cat /etc/passwd)do echo &quot;Values in $entry –&quot; IFS=: for value in $entry do echo &quot; $value&quot; donedone$ 这个脚本使用了两个不同的 IFS 值来解析数据。第一个 IFS 值解析出&#x2F;etc&#x2F;passwd 文件中的单独的行。内部 for 循环接着将 IFS 的值修改为冒号，允许你从&#x2F;etc&#x2F;passwd 的行中解析出单独的值。内部循环会解析出&#x2F;etc&#x2F;passwd 每行中的各个值。这种方法在处理外部导入电子表格所采用的逗号分隔的数据时也很方便。 控制循环你可能会想，一旦启动了循环，就必须苦等到循环完成所有的迭代。并不是这样的。有两个命令能帮我们控制循环内部的情况： break 命令 continue 命令 每个命令在如何控制循环的执行方面有不同的用法。下面几节将介绍如何使用这些命令来控制循环。 break 命令break 命令是退出循环的一个简单方法。可以用 break 命令来退出任意类型的循环，包括 while 和 until 循环。有几种情况可以使用 break 命令，本节将介绍这些方法。 跳出单个循环 在 shell 执行 break 命令时，它会尝试跳出当前正在执行的循环。 123456789101112131415161718192021cat test17#!/bin/bash# breaking out of a for loopfor var1 in 1 2 3 4 5 6 7 8 9 10do if [ $var1 -eq 5 ] then break fi echo &quot;Iteration number: $var1&quot;doneecho &quot;The for loop is completed&quot;$ ./test17Iteration number: 1Iteration number: 2Iteration number: 3Iteration number: 4The for loop is completed$ for 循环通常都会遍历列表中指定的所有值。但当满足 if-then 的条件时，shell 会执行 break 命令，停止 for 循环。这种方法同样适用于 while 和 until 循环。 123456789101112131415161718192021$ cat test18#!/bin/bash# breaking out of a while loopvar1=1while [ $var1 -lt 10 ]do if [ $var1 -eq 5 ] then break fi echo &quot;Iteration: $var1&quot; var1=$[ $var1 + 1 ]doneecho &quot;The while loop is completed&quot;$ ./test18Iteration: 1Iteration: 2Iteration: 3Iteration: 4The while loop is completed$ while 循环会在 if-then 的条件满足时执行 break 命令，终止。 跳出内部循环 在处理多个循环时，break 命令会自动终止你所在的最内层的循环。 1234567891011121314151617181920212223242526272829303132$ cat test19#!/bin/bash# breaking out of an inner loopfor (( a = 1; a &lt; 4; a++ ))do echo &quot;Outer loop: $a&quot; for (( b = 1; b &lt; 100; b++ )) do if [ $b -eq 5 ] then break fi echo &quot; Inner loop: $b&quot; donedone$ ./test19Outer loop: 1 Inner loop: 1 Inner loop: 2 Inner loop: 3 Inner loop: 4Outer loop: 2 Inner loop: 1 Inner loop: 2 Inner loop: 3 Inner loop: 4Outer loop: 3 Inner loop: 1 Inner loop: 2 Inner loop: 3 Inner loop: 4$ 内部循环里的 for 语句指明当变量 b 等于 100 时停止迭代。但内部循环的 if-then 语句指明当变量 b 的值等于 5 时执行 break 命令。注意，即使内部循环通过 break 命令终止了，外部循环依然继续执行。 跳出外部循环 有时你在内部循环，但需要停止外部循环。break 命令接受单个命令行参数值： 1break n 其中 n 指定了要跳出的循环层级。默认情况下，n 为 1，表明跳出的是当前的循环。如果你将 n 设为 2，break 命令就会停止下一级的外部循环。 12345678910111213141516171819202122$ cat test20#!/bin/bash# breaking out of an outer loopfor (( a = 1; a &lt; 4; a++ ))do echo &quot;Outer loop: $a&quot; for (( b = 1; b &lt; 100; b++ )) do if [ $b -gt 4 ] then break 2 fi echo &quot; Inner loop: $b&quot; donedone$ ./test20Outer loop: 1 Inner loop: 1 Inner loop: 2 Inner loop: 3 Inner loop: 4$ 注意，当 shell 执行了 break 命令后，外部循环就停止了。 continue 命令continue 命令可以提前中止某次循环中的命令，但并不会完全终止整个循环。可以在循环内部设置 shell 不执行命令的条件。这里有个在 for 循环中使用 continue 命令的简单例子。 1234567891011121314151617181920212223$ cat test21#!/bin/bash# using the continue commandfor (( var1 = 1; var1 &lt; 15; var1++ ))do if [ $var1 -gt 5 ] &amp;&amp; [ $var1 -lt 10 ] then continue fi echo &quot;Iteration number: $var1&quot;done$ ./test21Iteration number: 1Iteration number: 2Iteration number: 3Iteration number: 4Iteration number: 5Iteration number: 10Iteration number: 11Iteration number: 12Iteration number: 13Iteration number: 14$ 当 if-then 语句的条件被满足时（值大于 5 且小于 10），shell 会执行 continue 命令，跳过此次循环中剩余的命令，但整个循环还会继续。当 if-then 的条件不再被满足时，一切又回到正轨。 也可以在 while 和 until 循环中使用 continue 命令，但要特别小心。记住，当 shell 执行 continue 命令时，它会跳过剩余的命令。如果你在其中某个条件里对测试条件变量进行增值，问题就会出现。 1234567891011121314151617181920212223242526272829303132333435363738$ cat badtest3#!/bin/bash# improperly using the continue command in a while loopvar1=0while echo &quot;while iteration: $var1&quot; [ $var1 -lt 15 ]do if [ $var1 -gt 5 ] &amp;&amp; [ $var1 -lt 10 ] then continue fi echo &quot; Inside iteration number: $var1&quot; var1=$[ $var1 + 1 ]done$ ./badtest3 | morewhile iteration: 0 Inside iteration number: 0while iteration: 1 Inside iteration number: 1while iteration: 2 Inside iteration number: 2while iteration: 3 Inside iteration number: 3while iteration: 4 Inside iteration number: 4while iteration: 5 Inside iteration number: 5while iteration: 6while iteration: 6while iteration: 6while iteration: 6while iteration: 6while iteration: 6while iteration: 6while iteration: 6while iteration: 6while iteration: 6while iteration: 6 你得确保将脚本的输出重定向到了 more 命令，这样才能停止输出。在 if-then 的条件成立之前，所有一切看起来都很正常，然后 shell 执行了 continue 命令。当 shell 执行 continue 命令时，它跳过了 while 循环中余下的命令。不幸的是，被跳过的部分正是$var1 计数变量增值的地方，而这个变量又被用于 while 测试命令中。这意味着这个变量的值不会再变化了，从前面连续的输出显示中你也可以看出来。 和 break 命令一样，continue 命令也允许通过命令行参数指定要继续执行哪一级循环： 1continue n 其中 n 定义了要继续的循环层级。下面是继续外部 for 循环的一个例子。 1234567891011121314151617181920212223242526272829303132$ cat test22#!/bin/bash# continuing an outer loopfor (( a = 1; a &lt;= 5; a++ ))do echo &quot;Iteration $a:&quot; for (( b = 1; b &lt; 3; b++ )) do if [ $a -gt 2 ] &amp;&amp; [ $a -lt 4 ] then continue 2 fi var3=$[ $a * $b ] echo &quot; The result of $a * $b is $var3&quot; donedone$ ./test22Iteration 1: The result of 1 * 1 is 1 The result of 1 * 2 is 2Iteration 2: The result of 2 * 1 is 2 The result of 2 * 2 is 4Iteration 3:Iteration 4: The result of 4 * 1 is 4 The result of 4 * 2 is 8Iteration 5: The result of 5 * 1 is 5 The result of 5 * 2 is 10$ 此处用 continue 命令来停止处理循环内的命令，但会继续处理外部循环。注意，值为 3 的那次迭代并没有处理任何内部循环语句。尽管 continue 命令停止了内部处理过程，但外部循环依然会继续。 处理循环的输出最后，在 shell 脚本中，你可以对循环的输出使用管道或进行重定向。这可以通过在 done 命令之后添加一个处理命令来实现。 123456789for file in /home/rich/*do if [ -d &quot;$file&quot; ] then echo &quot;$file is a directory&quot; elif echo &quot;$file is a file&quot; fidone &gt; output.txt shell 会将 for 命令的结果重定向到文件 output.txt 中，而不是显示在屏幕上。考虑下面将 for 命令的输出重定向到文件的例子。 123456789101112131415161718192021$ cat test23#!/bin/bash# redirecting the for output to a filefor (( a = 1; a &lt; 10; a++ ))do echo &quot;The number is $a&quot;done &gt; test23.txtecho &quot;The command is finished.&quot;$ ./test23The command is finished.$ cat test23.txtThe number is 1The number is 2The number is 3The number is 4The number is 5The number is 6The number is 7The number is 8The number is 9$ shell 创建了文件 test23.txt 并将 for 命令的输出重定向到这个文件。shell 在 for 命令之后正常显示了 echo 语句。 这种方法同样适用于将循环的结果管接给另一个命令。 12345678910111213141516$ cat test24#!/bin/bash# piping a loop to another commandfor state in &quot;North Dakota&quot; Connecticut Illinois Alabama Tennesseedo echo &quot;$state is the next place to go&quot;done | sortecho &quot;This completes our travels&quot;$ ./test24Alabama is the next place to goConnecticut is the next place to goIllinois is the next place to goNorth Dakota is the next place to goTennessee is the next place to goThis completes our travels$ state 值并没有在 for 命令列表中以特定次序列出。for 命令的输出传给了 sort 命令，该命令会改变 for 命令输出结果的顺序。运行这个脚本实际上说明了结果已经在脚本内部排好序了。 实战例子现在你已经看到了 shell 脚本中各种循环的使用方法，来看一些实际应用的例子吧。循环是对系统数据进行迭代的常用方法，无论是目录中的文件还是文件中的数据。下面的一些例子演示了如何使用简单的循环来处理数据。 查找可执行文件当你从命令行中运行一个程序的时候，Linux 系统会搜索一系列目录来查找对应的文件。这些目录被定义在环境变量 PATH 中。如果你想找出系统中有哪些可执行文件可供使用，只需要扫描 PATH 环境变量中所有的目录就行了。如果要徒手查找的话，就得花点时间了。不过我们可以编写一个小小的脚本，轻而易举地搞定这件事。 首先是创建一个 for 循环，对环境变量 PATH 中的目录进行迭代。处理的时候别忘了设置 IFS 分隔符。 123IFS=:for folder in $PATHdo 现在你已经将各个目录存放在了变量$folder 中，可以使用另一个 for 循环来迭代特定目录中的所有文件。 12for file in $folder/*do 最后一步是检查各个文件是否具有可执行权限，你可以使用 if-then 测试功能来实现。 1234if [ -x $file ]then echo &quot; $file&quot;fi 好了，搞定了！将这些代码片段组合成脚本就行了。 12345678910111213141516$ cat test25#!/bin/bash# finding files in the PATHIFS=:for folder in $PATHdo echo &quot;$folder:&quot; for file in $folder/* do if [ -x $file ] then echo &quot; $file&quot; fi donedone$ 运行这段代码时，你会得到一个可以在命令行中使用的可执行文件的列表。输出显示了在环境变量 PATH 所包含的所有目录中找到的全部可执行文件。 创建多个用户账户shell 脚本的目标是让系统管理员过得更轻松。如果你碰巧工作在一个拥有大量用户的环境中，最烦人的工作之一就是创建新用户账户。好在可以使用 while 循环来降低工作的难度。 你不用为每个需要创建的新用户账户手动输入 useradd 命令，而是可以将需要添加的新用户账户放在一个文本文件中，然后创建一个简单的脚本进行处理。这个文本文件的格式如下： 1userid,user name 第一个条目是你为新用户账户所选用的用户 ID。第二个条目是用户的全名。两个值之间使用逗号分隔，这样就形成了一种名为逗号分隔值的文件格式（或者是.csv）。这种文件格式在电子表格中极其常见，所以你可以轻松地在电子表格程序中创建用户账户列表，然后将其保存成.csv 格式，以备 shell 脚本读取及处理。 要读取文件中的数据，得用上一点 shell 脚本编程技巧。我们将 IFS 分隔符设置成逗号，并将其放入 while 语句的条件测试部分。然后使用 read 命令读取文件中的各行。实现代码如下： 1while IFS=’,’ read –r userid name read 命令会自动读取.csv 文本文件的下一行内容，所以不需要专门再写一个循环来处理。当 read 命令返回 FALSE 时（也就是读取完整个文件时），while 命令就会退出。妙极了！要想把数据从文件中送入 while 命令，只需在 while 命令尾部使用一个重定向符就可以了。将各部分处理过程写成脚本如下。 12345678910$ cat test26#!/bin/bash# process new user accountsinput=&quot;users.csv&quot;while IFS=&#x27;,&#x27; read -r userid namedo echo &quot;adding $userid&quot; useradd -c &quot;$name&quot; -m $useriddone &lt; &quot;$input&quot;$ $input 变量指向数据文件，并且该变量被作为 while 命令的重定向数据。users.csv 文件内容如下。 123456$ cat users.csvrich,Richard Blumchristine,Christine Bresnahanbarbara,Barbara Blumtim,Timothy Bresnahan$ 必须作为 root 用户才能运行这个脚本，因为 useradd 命令需要 root 权限。执行此脚本后，看一眼&#x2F;etc&#x2F;passwd 文件，你会发现账户已经创建好了。 循环是编程的一部分。bash shell 提供了三种可用于脚本中的循环命令。for 命令允许你遍历一系列的值，不管是在命令行里提供好的、包含在变量中的还是通过文件扩展匹配获得的文件名和目录名。while 命令使用普通命令或测试命令提供了基于命令条件的循环。只有在命令（或条件）产生退出状态码 0 时，while 循环才会继续迭代指定的一组命令。until 命令也提供了迭代命令的一种方法，但它的迭代是建立在命令（或条件）产生非零退出状态码的基础上。这个特性允许你设置一个迭代结束前都必须满足的条件。可以在 shell 脚本中对循环进行组合，生成多层循环。bash shell 提供了 continue 和 break 命令，允许你根据循环内的不同值改变循环的正常流程。bash shell 还允许使用标准的命令重定向和管道来改变循环的输出。你可以使用重定向来将循环的输出重定向到一个文件或是另一个命令。这就为控制 shell 脚本执行提供了丰富的功能。下一章将会讨论如何和 shell 脚本用户交互。shell 脚本通常并不完全是自成一体的。它们需要在运行时被提供某些外部数据。下一章将讨论各种可用来向 shell 脚本提供实时数据的方法。 处理 Shell 输入到目前为止，你已经看到了如何编写脚本，处理数据、变量和 Linux 系统上的文件。有时，你编写的脚本还得能够与使用者进行交互。bash shell 提供了一些不同的方法来从用户处获得数据，包括命令行参数（添加在命令后的数据）、命令行选项（可修改命令行为的单个字母）以及直接从键盘读取输入的能力。本章将会讨论如何在你的 bash shell 脚本运用这些方法来从脚本用户处获得数据。 命令行参数向 shell 脚本传递数据的最基本方法是使用命令行参数。命令行参数允许在运行脚本时向命令行添加数据。 1$ ./addem 10 30 本例向脚本 addem 传递了两个命令行参数（10 和 30）。脚本会通过特殊的变量来处理命令行参数。后面几节将会介绍如何在 bash shell 脚本中使用命令行参数。 读取参数bash shell 会将一些称为位置参数（positional parameter）的特殊变量分配给输入到命令行中的所有参数。这也包括 shell 所执行的脚本名称。位置参数变量是标准的数字：$0 是程序名，$1 是第一个参数，$2 是第二个参数，依次类推，直到第九个参数$9。 下面是在 shell 脚本中使用单个命令行参数的简单例子。 1234567891011121314$ cat test1.sh#!/bin/bash# using one command line parameter#factorial=1for (( number = 1; number &lt;= $1 ; number++ ))do factorial=$[ $factorial * $number ]doneecho The factorial of $1 is $factorial$$ ./test1.sh 5The factorial of 5 is 120$ 可以在 shell 脚本中像使用其他变量一样使用$1 变量。shell 脚本会自动将命令行参数的值分配给变量，不需要你作任何处理。 如果需要输入更多的命令行参数，则每个参数都必须用空格分开。 1234567891011121314$ cat test2.sh#!/bin/bash# testing two command line parameters#total=$[ $1 * $2 ]echo The first parameter is $1.echo The second parameter is $2.echo The total value is $total.$$ ./test2.sh 2 5The first parameter is 2.The second parameter is 5.The total value is 10.$ shell 会将每个参数分配给对应的变量。在前面的例子中，用到的命令行参数都是数值。也可以在命令行上用文本字符串。shell 将输入到命令行的字符串值传给脚本。但碰到含有空格的文本字符串时就会出现问题。记住，每个参数都是用空格分隔的，所以 shell 会将空格当成两个值的分隔符。要在参数值中包含空格，必须要用引号（单引号或双引号均可）。 将文本字符串作为参数传递时，引号并非数据的一部分。它们只是表明数据的起止位置。 如果脚本需要的命令行参数不止 9 个，你仍然可以处理，但是需要稍微修改一下变量名。在第 9 个变量之后，你必须在变量数字周围加上花括号，比如${10}。这种方法允许你根据需要向脚本添加任意多的命令行参数。加上花括号会显得比较直观，不过经过测试，目前版本的 bash 不加花括号也可以正常运行，只是不是那么直观罢了。 读取脚本名可以用$0 参数获取 shell 在命令行启动的脚本名。这在编写多功能工具时很方便。 12345678910$ cat test5.sh#!/bin/bash# Testing the $0 parameter#echo The zero parameter is set to: $0#$$ bash test5.shThe zero parameter is set to: test5.sh$ 但是这里存在一个潜在的问题。如果使用另一种方式来运行 shell 脚本，命令会和脚本名混在一起，出现在$0 参数中。 123$ ./test5.shThe zero parameter is set to: ./test5.sh$ 这还不是唯一的问题。当传给$0 变量的实际字符串不仅仅是脚本名，而是完整的脚本路径时，变量$0 就会使用整个路径。 123$ bash /home/Christine/test5.shThe zero parameter is set to: /home/Christine/test5.sh$ 如果你要编写一个根据脚本名来执行不同功能的脚本，就得做点额外工作。你得把脚本的运行路径给剥离掉。另外，还要删除与脚本名混杂在一起的命令。幸好有个方便的小命令可以帮到我们。basename 命令会返回不包含路径的脚本名。 12345678910111213141516$ cat test5b.sh#!/bin/bash# Using basename with the $0 parameter#name=$(basename $0)echoecho The script name is: $name#$$ bash /home/Christine/test5b.shThe script name is: test5b.sh$$ ./test5b.shThe script name is: test5b.sh$ 现在好多了。可以用这种方法来编写基于脚本名执行不同功能的脚本。这里有个简单的例子。 123456789101112131415161718192021222324252627282930313233$ cat test6.sh#!/bin/bash# Testing a Multi-function script#name=$(basename $0)#if [ $name = &quot;addem&quot; ]then total=$[ $1 + $2 ]#elif [ $name = &quot;multem&quot; ]then total=$[ $1 * $2 ]fi#echo echo The calculated value is $total#$$ cp test6.sh addem$ chmod u+x addem$$ ln -s test6.sh multem$$ ls -l *em-rwxrw-r--. 1 Christine Christine 224 Jun 30 23:50 addemlrwxrwxrwx. 1 Christine Christine 8 Jun 30 23:50 multem -&gt; test6.sh$$ ./addem 2 5The calculated value is 7$$ ./multem 2 5The calculated value is 10$ 本例从 test6.sh 脚本中创建了两个不同的文件名：一个通过复制文件创建（addem），另一个通过链接（参见第 3 章）创建（multem）。在两种情况下都会先获得脚本的基本名称，然后根据该值执行相应的功能。 测试参数在 shell 脚本中使用命令行参数时要小心些。如果脚本不加参数运行，可能会出问题。 12345$ ./addem 2./addem: line 8: 2 + : syntax error: operand expected (errortoken is &quot; &quot;)The calculated value is$ 当脚本认为参数变量中会有数据而实际上并没有时，脚本很有可能会产生错误消息。这种写脚本的方法并不可取。在使用参数前一定要检查其中是否存在数据。 1234567891011121314151617$ cat test7.sh#!/bin/bash# testing parameters before use#if [ -n &quot;$1&quot; ]then echo Hello $1, glad to meet you.else echo &quot;Sorry, you did not identify yourself. &quot;fi$$ ./test7.sh RichHello Rich, glad to meet you.$$ ./test7.shSorry, you did not identify yourself.$ 在本例中，使用了-n 测试来检查命令行参数$1 中是否有数据。在下一节中，你会看到还有另一种检查命令行参数的方法。 特殊参数变量在 bash shell 中有些特殊变量，它们会记录命令行参数。本节将会介绍这些变量及其用法。 参数统计如在上一节中看到的，在脚本中使用命令行参数之前应该检查一下命令行参数。对于使用多个命令行参数的脚本来说，这有点麻烦。你可以统计一下命令行中输入了多少个参数，无需测试每个参数。bash shell 为此提供了一个特殊变量。 特殊变量 $# 含有脚本运行时携带的命令行参数的个数。可以在脚本中任何地方使用这个特殊变量，就跟普通变量一样。 1234567891011$ cat test8.sh#!/bin/bash# getting the number of parameters#echo There were $# parameters supplied.$$ ./test8.shThere were 0 parameters supplied.$$ ./test8.sh 1 2 3 4 5There were 5 parameters supplied. 现在你就能在使用参数前测试参数的总数了。 12345678910111213141516171819202122$ cat test9.sh#!/bin/bash# Testing parameters#if [ $# -ne 2 ]then echo echo Usage: test9.sh a b echoelse total=$[ $1 + $2 ] echo echo The total is $total echofi#$$ bash test9.shUsage: test9.sh a b$ bash test9.sh 10 15The total is 25$ if-then 语句用 -ne 测试命令行参数数量。如果参数数量不对，会显示一条错误消息告知脚本的正确用法。 这个变量还提供了一个简便方法来获取命令行中最后一个参数，完全不需要知道实际上到底用了多少个参数。不过要实现这一点，得稍微多花点工夫。如果你仔细考虑过，可能会觉得既然 $# 变量含有参数的总数，那么变量 $&#123;$#&#125; 就代表了最后一个命令行参数变量。试试看会发生什么。 123456789$ cat badtest1.sh#!/bin/bash# testing grabbing last parameter#echo The last parameter was $&#123;$#&#125;$$ ./badtest1.sh 10The last parameter was 15354$ 怎么了？显然，出了点问题。它表明你不能在花括号内使用美元符。必须将美元符换成感叹号。很奇怪，但的确管用。 12345678910111213141516171819$ cat test10.sh#!/bin/bash# Grabbing the last parameter#params=$#echoecho The last parameter is $paramsecho The last parameter is $&#123;!#&#125;echo#$$ bash test10.sh 1 2 3 4 5The last parameter is 5The last parameter is 5$$ bash test10.shThe last parameter is 0The last parameter is test10.sh$ 这个测试将 $# 变量的值赋给了变量 params，然后也按特殊命令行参数变量的格式使用了该变量。两种方法都没问题。重要的是要注意，当命令行上没有任何参数时，$# 的值为 0，params 变量的值也一样，但 $&#123;!#&#125; 变量会返回命令行用到的脚本名。 抓取所有的数据有时候需要抓取命令行上提供的所有参数。这时候不需要先用$#变量来判断命令行上有多少参数，然后再进行遍历，你可以使用一组其他的特殊变量来解决这个问题。$* 和 $@ 变量可以用来轻松访问所有的参数。这两个变量都能够在单个变量中存储所有的命令行参数。$* 变量会将命令行上提供的所有参数当作一个单词保存。这个单词包含了命令行中出现的每一个参数值。基本上 $* 变量会将这些参数视为一个整体，而不是多个个体。另一方面，$@ 变量会将命令行上提供的所有参数当作同一字符串中的多个独立的单词。这样你就能够遍历所有的参数值，得到每个参数。这通常通过 for 命令完成。这两个变量的工作方式不太容易理解。看个例子，你就能理解二者之间的区别了。 1234567891011121314$ cat test11.sh#!/bin/bash# testing $* and $@#echoecho &quot;Using the \\$* method: $*&quot;echoecho &quot;Using the \\$@ method: $@&quot;$$ ./test11.sh rich barbara katie jessicaUsing the $* method: rich barbara katie jessicaUsing the $@ method: rich barbara katie jessica$ 注意，从表面上看，两个变量产生的是同样的输出，都显示出了所有命令行参数。下面的例子给出了二者的差异。 1234567891011121314151617181920212223242526272829$ cat test12.sh#!/bin/bash# testing $* and $@#echocount=1#for param in &quot;$*&quot;do echo &quot;\\$* Parameter #$count = $param&quot; count=$[ $count + 1 ]done#echocount=1#for param in &quot;$@&quot;do echo &quot;\\$@ Parameter #$count = $param&quot; count=$[ $count + 1 ]done$$ ./test12.sh rich barbara katie jessica$* Parameter #1 = rich barbara katie jessica$@ Parameter #1 = rich$@ Parameter #2 = barbara$@ Parameter #3 = katie$@ Parameter #4 = jessica$ 现在清楚多了。通过使用 for 命令遍历这两个特殊变量，你能看到它们是如何不同地处理命令行参数的。$* 变量会将所有参数当成单个参数，而 $@ 变量会单独处理每个参数。这是遍历命令行参数的一个绝妙方法。 移动变量bash shell 工具箱中另一件工具是 shift 命令。bash shell 的 shift 命令能够用来操作命令行参数。跟字面上的意思一样，shift 命令会根据它们的相对位置来移动命令行参数。 在使用 shift 命令时，默认情况下它会将每个参数变量向左移动一个位置。所以，变量 $3 的值会移到 $2 中，变量 $2 的值会移到 $1 中，而变量 $1 的值则会被删除（注意，变量 $0 的值，也就是程序名，不会改变）。 这是遍历命令行参数的另一个好方法，尤其是在你不知道到底有多少参数时。你可以只操作第一个参数，移动参数，然后继续操作第一个参数。这里有个例子来解释它是如何工作的。 123456789101112131415161718$ cat test13.sh#!/bin/bash# demonstrating the shift commandechocount=1while [ -n &quot;$1&quot; ]do echo &quot;Parameter #$count = $1&quot; count=$[ $count + 1 ] shiftdone$$ ./test13.sh rich barbara katie jessicaParameter #1 = richParameter #2 = barbaraParameter #3 = katieParameter #4 = jessica$ 这个脚本通过测试第一个参数值的长度执行了一个 while 循环。当第一个参数的长度为零时，循环结束。测试完第一个参数后，shift 命令会将所有参数的位置移动一个位置。 使用 shift 命令的时候要小心。如果某个参数被移出，它的值就被丢弃了，无法再恢复。 另外，你也可以一次性移动多个位置，只需要给 shift 命令提供一个参数，指明要移动的位置数就行了。如shift 2一次性移动两个位置。 处理选项如果你认真读过本书前面的所有内容，应该就见过了一些同时提供了参数和选项的 bash 命令。选项是跟在单破折线后面的单个字母，它能改变命令的行为。本节将会介绍 3 种在脚本中处理选项的方法。 查找选项表面上看，命令行选项也没什么特殊的。在命令行上，它们紧跟在脚本名之后，就跟命令行参数一样。实际上，如果愿意，你可以像处理命令行参数一样处理命令行选项。 处理简单选项 在前面的 test13.sh 脚本中，你看到了如何使用 shift 命令来依次处理脚本程序携带的命令行参数。你也可以用同样的方法来处理命令行选项。在提取每个单独参数时，用 case 语句来判断某个参数是否为选项。 12345678910111213141516171819202122$ cat test15.sh#!/bin/bash# extracting command line options as parameters#echowhile [ -n &quot;$1&quot; ]do case &quot;$1&quot; in -a) echo &quot;Found the -a option&quot; ;; -b) echo &quot;Found the -b option&quot; ;; -c) echo &quot;Found the -c option&quot; ;; *) echo &quot;$1 is not an option&quot; ;; esac shiftdone$$ ./test15.sh -a -b -c -dFound the -a optionFound the -b optionFound the -c option-d is not an option$ case 语句会检查每个参数是不是有效选项。如果是的话，就运行对应 case 语句中的命令。不管选项按什么顺序出现在命令行上，这种方法都适用。case 语句在命令行参数中找到一个选项，就处理一个选项。如果命令行上还提供了其他参数，你可以在 case 语句的通用情况处理部分中处理。 分离参数和选项 你会经常遇到在 shell 脚本中同时使用选项和参数的情况。Linux 中处理这个问题的标准方式是用特殊字符来将二者分开，该字符会告诉脚本何时选项结束以及普通参数何时开始。对 Linux 来说，这个特殊字符是双破折线（–）。shell 会用双破折线来表明选项列表结束。在双破折线之后，脚本就可以放心地将剩下的命令行参数当作参数，而不是选项来处理了。 要检查双破折线，只要在 case 语句中加一项就行了。 12345678910111213141516171819202122232425$ cat test16.sh#!/bin/bash# extracting options and parameters#echowhile [ -n &quot;$1&quot; ]do case &quot;$1&quot; in -a) echo &quot;Found the -a option&quot; ;; -b) echo &quot;Found the -b option&quot; ;; -c) echo &quot;Found the -c option&quot; ;; --) shift break ;; *) echo &quot;$1 is not an option&quot; ;; esac shiftdonecount=1for param in $@do echo &quot;Parameter #$count: $param&quot; count=$[ $count + 1 ]done 在遇到双破折线时，脚本用 break 命令来跳出 while 循环。由于过早地跳出了循环，我们需要再加一条 shift 命令来将双破折线移出参数变量。对于第一个测试，试试用一组普通的选项和参数来运行这个脚本。 123456789$$ ./test16.sh -c -a -b test1 test2 test3Found the -c optionFound the -a optionFound the -b optiontest1 is not an optiontest2 is not an optiontest3 is not an option$ 结果说明在处理时脚本认为所有的命令行参数都是选项。接下来，进行同样的测试，只是这次会用双破折线来将命令行上的选项和参数划分开来。 12345678$ ./test16.sh -c -a -b -- test1 test2 test3Found the -c optionFound the -a optionFound the -b optionParameter #1: test1Parameter #2: test2Parameter #3: test3$ 当脚本遇到双破折线时，它会停止处理选项，并将剩下的参数都当作命令行参数。 处理带值的选项 有些选项会带上一个额外的参数值。在这种情况下，命令行看起来像下面这样。 12$ ./testing.sh -a test1 -b -c -d test2 当命令行选项要求额外的参数时，脚本必须能检测到并正确处理。下面是如何处理的例子。 12345678910111213141516171819202122232425262728293031$ cat test17.sh#!/bin/bash# extracting command line options and valuesechowhile [ -n &quot;$1&quot; ]do case &quot;$1&quot; in -a) echo &quot;Found the -a option&quot;;; -b) param=&quot;$2&quot; echo &quot;Found the -b option, with parameter value $param&quot; shift ;; -c) echo &quot;Found the -c option&quot;;; --) shift break ;; *) echo &quot;$1 is not an option&quot;;; esac shiftdone#count=1for param in &quot;$@&quot;do echo &quot;Parameter #$count: $param&quot; count=$[ $count + 1 ]done$$ ./test17.sh -a -b test1 -dFound the -a optionFound the -b option, with parameter value test1-d is not an option$ 在这个例子中，case 语句定义了三个它要处理的选项。-b 选项还需要一个额外的参数值。由于要处理的参数是$1，额外的参数值就应该位于$2（因为所有的参数在处理完之后都会被移出）。只要将参数值从$2 变量中提取出来就可以了。当然，因为这个选项占用了两个参数位，所以你还需要使用 shift 命令多移动一个位置。 只用这些基本的特性，整个过程就能正常工作，不管按什么顺序放置选项（但要记住包含每个选项相应的选项参数）。现在 shell 脚本中已经有了处理命令行选项的基本能力，但还有一些限制。比如，如果你想将多个选项放进一个参数中时，它就不能工作了。 123$ ./test17.sh -ac-ac is not an option$ 在 Linux 中，合并选项是一个很常见的用法，而且如果脚本想要对用户更友好一些，也要给用户提供这种特性。幸好，有另外一种处理选项的方法能够帮忙。 使用 getopt 命令getopt 命令是一个在处理命令行选项和参数时非常方便的工具。它能够识别命令行参数，从而在脚本中解析它们时更方便。 命令的格式 getopt 命令可以接受一系列任意形式的命令行选项和参数，并自动将它们转换成适当的格式。它的命令格式如下： 1getopt optstring parameters optstring 是这个过程的关键所在。它定义了命令行有效的选项字母，还定义了哪些选项字母需要参数值。 首先，在 optstring 中列出你要在脚本中用到的每个命令行选项字母。然后，在每个需要参数值的选项字母后加一个冒号。getopt 命令会基于你定义的 optstring 解析提供的参数。 getopt 命令有一个更高级的版本叫作 getopts（注意这是复数形式）。getopts 命令会在本章随后部分讲到。因为这两个命令的拼写几乎一模一样，所以很容易搞混。一定要小心 下面是个 getopt 如何工作的简单例子。 123$ getopt ab:cd -a -b test1 -cd test2 test3-a -b test1 -c -d -- test2 test3$ optstring 定义了四个有效选项字母：a、b、c 和 d。冒号（:）被放在了字母 b 后面，因为 b 选项需要一个参数值。当 getopt 命令运行时，它会检查提供的参数列表（-a -b test1 -cd test2 test3），并基于提供的 optstring 进行解析。注意，它会自动将-cd 选项分成两个单独的选项，并插入双破折线来分隔行中的额外参数。 如果指定了一个不在 optstring 中的选项，默认情况下，getopt 命令会产生一条错误消息。 1234$ getopt ab:cd -a -b test1 -cde test2 test3getopt: invalid option -- e-a -b test1 -c -d -- test2 test3$ 如果想忽略这条错误消息，可以在命令后加-q 选项。 123$ getopt -q ab:cd -a -b test1 -cde test2 test3-a -b test1 -c -d -- test2 test3$ 注意，getopt 命令选项必须出现在 optstring 之前。现在应该可以在脚本中使用此命令处理命令行选项了 在脚本中使用 getopt 可以在脚本中使用 getopt 来格式化脚本所携带的任何命令行选项或参数，但用起来略微复杂。方法是用 getopt 命令生成的格式化后的版本来替换已有的命令行选项和参数。用 set 命令能够做到。在环境变量的章节中，你就已经见过 set 命令了。set 命令能够处理 shell 中的各种变量。 set 命令的选项之一是双破折线（–），它会将命令行参数替换成 set 命令的命令行值。然后，该方法会将原始脚本的命令行参数传给 getopt 命令，之后再将 getopt 命令的输出传给 set 命令，用 getopt 格式化后的命令行参数来替换原始的命令行参数，看起来如下所示。 1set -- $(getopt -q ab:cd &quot;$@&quot;) 现在原始的命令行参数变量的值会被 getopt 命令的输出替换，而 getopt 已经为我们格式化好了命令行参数。利用该方法，现在就可以写出能帮我们处理命令行参数的脚本。 123456789101112131415161718192021222324252627282930$ cat test18.sh#!/bin/bash# Extract command line options &amp; values with getopt#set -- $(getopt -q ab:cd &quot;$@&quot;)#echowhile [ -n &quot;$1&quot; ]do case &quot;$1&quot; in -a) echo &quot;Found the -a option&quot; ;; -b) param=&quot;$2&quot; echo &quot;Found the -b option, with parameter value $param&quot; shift ;; -c) echo &quot;Found the -c option&quot; ;; --) shift break ;; *) echo &quot;$1 is not an option&quot;;; esac shiftdone#count=1for param in &quot;$@&quot;do echo &quot;Parameter #$count: $param&quot; count=$[ $count + 1 ]done#$ 你会注意到它跟脚本 test17.sh 一样，唯一不同的是加入了 getopt 命令来帮助格式化命令行参数。现在如果运行带有复杂选项的脚本，就可以看出效果更好了。 1234$ ./test18.sh -acFound the -a optionFound the -c option$ 当然，之前的功能照样没有问题。 123456789$ ./test18.sh -a -b test1 -cd test2 test3 test4Found the -a optionFound the -b option, with parameter value &#x27;test1&#x27;Found the -c option-d is not an optionParameter #1: &#x27;test2&#x27;Parameter #2: &#x27;test3&#x27;Parameter #3: &#x27;test4&#x27;$ 现在看起来相当不错了。但是，在 getopt 命令中仍然隐藏着一个小问题。看看这个例子。 123456789$ ./test18.sh -a -b test1 -cd &quot;test2 test3&quot; test4Found the -a optionFound the -b option, with parameter value &#x27;test1&#x27;Found the -c option-d is not an optionParameter #1: &#x27;test2Parameter #2: test3&#x27;Parameter #3: &#x27;test4&#x27;$ getopt 命令并不擅长处理带空格和引号的参数值。它会将空格当作参数分隔符，而不是根据双引号将二者当作一个参数。幸而还有另外一个办法能解决这个问题。 使用更高级的 getoptsgetopts 命令（注意是复数）内建于 bash shell。它跟近亲 getopt 看起来很像，但多了一些扩展功能。 与 getopt 不同，前者将命令行上选项和参数处理后只生成一个输出，而 getopts 命令能够和已有的 shell 参数变量配合默契。 每次调用它时，它一次只处理命令行上检测到的一个参数。处理完所有的参数后，它会退出并返回一个大于 0 的退出状态码。这让它非常适合用于解析命令行所有参数的循环中。getopts 命令的格式如下： 1getopts optstring variable optstring 值类似于 getopt 命令中的那个。有效的选项字母都会列在 optstring 中，如果选项字母要求有个参数值，就加一个冒号。要去掉错误消息的话，可以在 optstring 之前加一个冒号。getopts 命令将当前参数保存在命令行中定义的 variable 中。 getopts 命令会用到两个环境变量。如果选项需要跟一个参数值，OPTARG 环境变量就会保存这个值。OPTIND 环境变量保存了参数列表中 getopts 正在处理的参数位置。这样你就能在处理完选项之后继续处理其他命令行参数了。让我们看个使用 getopts 命令的简单例子。 1234567891011121314151617181920$ cat test19.sh#!/bin/bash# simple demonstration of the getopts command#echowhile getopts :ab:c optdo case &quot;$opt&quot; in a) echo &quot;Found the -a option&quot; ;; b) echo &quot;Found the -b option, with value $OPTARG&quot;;; c) echo &quot;Found the -c option&quot; ;; *) echo &quot;Unknown option: $opt&quot;;; esacdone$$ ./test19.sh -ab test1 -cFound the -a optionFound the -b option, with value test1Found the -c option$ while 语句定义了 getopts 命令，指明了要查找哪些命令行选项，以及每次迭代中存储它们的变量名（opt）。 你会注意到在本例中 case 语句的用法有些不同。getopts 命令解析命令行选项时会移除开头的单破折线，所以在 case 定义中不用单破折线。 getopts 命令有几个好用的功能。对新手来说，可以在参数值中包含空格。 1234$ ./test19.sh -b &quot;test1 test2&quot; -aFound the -b option, with value test1 test2Found the -a option$ 另一个好用的功能是将选项字母和参数值放在一起使用，而不用加空格。 1234$ ./test19.sh -abtest1Found the -a optionFound the -b option, with value test1$ getopts 命令能够从-b 选项中正确解析出 test1 值。除此之外，getopts 还能够将命令行上找到的所有未定义的选项统一输出成问号。 123456789$ ./test19.sh -dUnknown option: ?$$ ./test19.sh -acdeFound the -a optionFound the -c optionUnknown option: ?Unknown option: ?$ optstring 中未定义的选项字母会以问号形式发送给代码。 getopts 命令知道何时停止处理选项，并将参数留给你处理。在 getopts 处理每个选项时，它会将 OPTIND 环境变量值增一。在 getopts 完成处理时，你可以使用 shift 命令和 OPTIND 值来移动参数。 1234567891011121314151617181920212223242526272829303132333435$ cat test20.sh#!/bin/bash# Processing options &amp; parameters with getopts#echowhile getopts :ab:cd optdo case &quot;$opt&quot; in a) echo &quot;Found the -a option&quot; ;; b) echo &quot;Found the -b option, with value $OPTARG&quot; ;; c) echo &quot;Found the -c option&quot; ;; d) echo &quot;Found the -d option&quot; ;; *) echo &quot;Unknown option: $opt&quot; ;; esacdone#shift $[ $OPTIND - 1 ]#echocount=1for param in &quot;$@&quot;do echo &quot;Parameter $count: $param&quot; count=$[ $count + 1 ]done#$$ ./test20.sh -a -b test1 -d test2 test3 test4Found the -a optionFound the -b option, with value test1Found the -d optionParameter 1: test2Parameter 2: test3Parameter 3: test4$ 现在你就拥有了一个能在所有 shell 脚本中使用的全功能命令行选项和参数处理工具。 将选项标准化在创建 shell 脚本时，显然可以控制具体怎么做。你完全可以决定用哪些字母选项以及它们的用法。但有些字母选项在 Linux 世界里已经拥有了某种程度的标准含义。如果你能在 shell 脚本中支持这些选项，脚本看起来能更友好一些。下面展示了 Linux 中用到的一些命令行选项的常用含义。 -a 显示所有对象 -c 生成一个计数 -d 指定一个目录 -e 扩展一个对象 -f 指定读入数据的文件 -h 显示命令的帮助信息 -i 忽略文本大小写 -l 产生输出的长格式版本 -n 使用非交互模式（批处理） -o 将所有输出重定向到的指定的输出文件 -q 以安静模式运行 -r 递归地处理目录和文件 -s 以安静模式运行 -v 生成详细输出 -x 排除某个对象 -y 对所有问题回答 yes 通过学习本书时遇到的各种 bash 命令，你大概已经知道这些选项中大部分的含义了。如果你的选项也采用同样的含义，这样用户在使用你的脚本时就不用去查手册了。 获得用户输入尽管命令行选项和参数是从脚本用户处获得输入的一种重要方式，但有时脚本的交互性还需要更强一些。比如你想要在脚本运行时问个问题，并等待运行脚本的人来回答。bash shell 为此提供了 read 命令。 基本的读取read 命令从标准输入（键盘）或另一个文件描述符中接受输入。在收到输入后，read 命令会将数据放进一个变量。下面是 read 命令的最简单用法。 12345678910111213$ cat test21.sh#!/bin/bash# testing the read command#echo -n &quot;Enter your name: &quot;read nameecho &quot;Hello $name, welcome to my program. &quot;#$$ ./test21.shEnter your name: Rich BlumHello Rich Blum, welcome to my program.$ 相当简单。注意，生成提示的 echo 命令使用了-n 选项。该选项不会在字符串末尾输出换行符，允许脚本用户紧跟其后输入数据，而不是下一行。这让脚本看起来更像表单。 实际上，read 命令包含了-p 选项，允许你直接在 read 命令行指定提示符。 1234567891011121314$ cat test22.sh#!/bin/bash# testing the read -p option#read -p &quot;Please enter your age: &quot; agedays=$[ $age * 365 ]echo&quot;That makes you over $days days old! &quot;#$$ ./test22.shPlease enter your age: 10That makes you over 3650 days old!$ 你会注意到，在第一个例子中当有名字输入时，read 命令会将姓和名保存在同一个变量中。read 命令会将提示符后输入的所有数据分配给单个变量，要么你就指定多个变量。输入的每个数据值都会分配给变量列表中的下一个变量。如果变量数量不够，剩下的数据就全部分配给最后一个变量。 1234567891011$ cat test23.sh#!/bin/bash# entering multiple variables#read -p &quot;Enter your name: &quot; first lastecho &quot;Checking data for $last, $first...&quot;$$ ./test23.shEnter your name: Rich BlumChecking data for Blum, Rich...$ 也可以在 read 命令行中不指定变量。如果是这样，read 命令会将它收到的任何数据都放进特殊环境变量 REPLY 中。 12345678910111213$ cat test24.sh#!/bin/bash# Testing the REPLY Environment variable#read -p &quot;Enter your name: &quot;echoecho Hello $REPLY, welcome to my program.#$$ ./test24.shEnter your name: ChristineHello Christine, welcome to my program.$ REPLY 环境变量会保存输入的所有数据，可以在 shell 脚本中像其他变量一样使用。 超时使用 read 命令时要当心。脚本很可能会一直苦等着脚本用户的输入。如果不管是否有数据输入，脚本都必须继续执行，你可以用-t 选项来指定一个计时器。-t 选项指定了 read 命令等待输入的秒数。当计时器过期后，read 命令会返回一个非零退出状态码。 12345678910111213141516$ cat test25.sh#!/bin/bash# timing the data entry#if read -t 5 -p &quot;Please enter your name: &quot; namethen echo &quot;Hello $name, welcome to my script&quot;else echo echo &quot;Sorry, too slow! &quot;fi$$ ./test25.shPlease enter your name: RichHello Rich, welcome to my script$ 如果计时器过期，read 命令会以非零退出状态码退出，可以使用如 if-then 语句或 while 循环这种标准的结构化语句来理清所发生的具体情况。在本例中，计时器过期时，if 语句不成立，shell 会执行 else 部分的命令。 也可以不对输入过程计时，而是让 read 命令来统计输入的字符数。当输入的字符达到预设的字符数时，就自动退出，将输入的数据赋给变量。 1234567891011121314151617181920212223$ cat test26.sh#!/bin/bash# getting just one character of input#read -n1 -p &quot;Do you want to continue [Y/N]? &quot; answercase $answer inY | y) echo echo &quot;fine, continue on...&quot;;;N | n) echo echo OK, goodbye exit;;esacecho &quot;This is the end of the script&quot;$$ ./test26.shDo you want to continue [Y/N]? Yfine, continue on...This is the end of the script$$ ./test26.shDo you want to continue [Y/N]? nOK, goodbye$ 本例中将-n 选项和值 1 一起使用，告诉 read 命令在接受单个字符后退出。只要按下单个字符回答后，read 命令就会接受输入并将它传给变量，无需按回车键。 隐藏方式读取有时你需要从脚本用户处得到输入，但又不在屏幕上显示输入信息。其中典型的例子就是输入的密码，但除此之外还有很多其他需要隐藏的数据类型。 -s 选项可以避免在 read 命令中输入的数据出现在显示器上（实际上，数据会被显示，只是 read 命令会将文本颜色设成跟背景色一样）。这里有个在脚本中使用-s 选项的例子。 123456789101112$ cat test27.sh#!/bin/bash# hiding input data from the monitor#read -s -p &quot;Enter your password: &quot; passechoecho &quot;Is your password really $pass? &quot;$$ ./test27.shEnter your password:Is your password really T3st1ng?$ 输入提示符输入的数据不会出现在屏幕上，但会赋给变量，以便在脚本中使用。 从文件中读取最后，也可以用 read 命令来读取 Linux 系统上文件里保存的数据。每次调用 read 命令，它都会从文件中读取一行文本。当文件中再没有内容时，read 命令会退出并返回非零退出状态码。 其中最难的部分是将文件中的数据传给 read 命令。最常见的方法是对文件使用 cat 命令，将结果通过管道直接传给含有 read 命令的 while 命令。下面的例子说明怎么处理。 1234567891011121314151617181920212223$ cat test28.sh#!/bin/bash# reading data from a file#count=1cat test | while read linedo echo &quot;Line $count: $line&quot; count=$[ $count + 1]doneecho &quot;Finished processing the file&quot;$$ cat testThe quick brown dog jumps over the lazy fox.This is a test, this is only a test.O Romeo, Romeo! Wherefore art thou Romeo?$$ ./test28.shLine 1: The quick brown dog jumps over the lazy fox.Line 2: This is a test, this is only a test.Line 3: O Romeo, Romeo! Wherefore art thou Romeo?Finished processing the file$ while 循环会持续通过 read 命令处理文件中的行，直到 read 命令以非零退出状态码退出。 处理 Shell 输出到目前为止，本书中出现的脚本都是通过将数据打印在屏幕上或将数据重定向到文件中来显示信息。之前演示了如何将命令的输出重定向到文件中。本章将会展开这个主题，演示如何将脚本的输出重定向到 Linux 系统的不同位置。 理解输入和输出至此你已经知道了两种显示脚本输出的方法： 在显示器屏幕上显示输出 将输出重定向到文件中 这两种方法要么将数据输出全部显示，要么什么都不显示。但有时将一部分数据在显示器上显示，另一部分数据保存到文件中也是不错的。对此，了解 Linux 如何处理输入输出能够帮助你就能将脚本输出放到正确位置。 下面几节会介绍如何用标准的 Linux 输入和输出系统来将脚本输出导向特定位置。 标准文件描述符Linux 系统将每个对象当作文件处理。这包括输入和输出进程。Linux 用文件描述符（filedescriptor）来标识每个文件对象。文件描述符是一个非负整数，可以唯一标识会话中打开的文件。每个进程一次最多可以有九个文件描述符。出于特殊目的，bash shell 保留了前三个文件描述符（0、1 和 2）。这三个特殊文件描述符会处理脚本的输入和输出。 0 缩写:STDIN 含义:标准输入 1 缩写:STDOUT 含义:标准输出 2 缩写:STDERR 含义:标准错误 shell 用它们将 shell 默认的输入和输出导向到相应的位置。下面几节将会进一步介绍这些标准文件描述符。 STDIN STDIN 文件描述符代表 shell 的标准输入。对终端界面来说，标准输入是键盘。shell 从 STDIN 文件描述符对应的键盘获得输入，在用户输入时处理每个字符。 在使用输入重定向符号（&lt;）时，Linux 会用重定向指定的文件来替换标准输入文件描述符。它会读取文件并提取数据，就如同它是键盘上键入的。 许多 bash 命令能接受 STDIN 的输入，尤其是没有在命令行上指定文件的话。下面是个用 cat 命令处理 STDIN 输入的数据的例子。 12345$ catthis is a testthis is a testthis is a second test.this is a second test. 当在命令行上只输入 cat 命令时，它会从 STDIN 接受输入。输入一行，cat 命令就会显示出一行。但你也可以通过 STDIN 重定向符号强制 cat 命令接受来自另一个非 STDIN 文件的输入。 12345$ cat &lt; testfileThis is the first line.This is the second line.This is the third line.$ 现在 cat 命令会用 testfile 文件中的行作为输入。你可以使用这种技术将数据输入到任何能从 STDIN 接受数据的 shell 命令中。 STDOUT STDOUT 文件描述符代表 shell 的标准输出。在终端界面上，标准输出就是终端显示器。shell 的所有输出（包括 shell 中运行的程序和脚本）会被定向到标准输出中，也就是显示器。 默认情况下，大多数 bash 命令会将输出导向 STDOUT 文件描述符。你可以用输出重定向来改变输出位置。 12345$ ls -l &gt; test2$ cat test2total 20-rw-rw-r-- 1 rich rich 53 2014-10-16 11:30 test-rw-rw-r-- 1 rich rich 0 2014-10-16 11:32 test2 通过输出重定向符号，通常会显示到显示器的所有输出会被 shell 重定向到指定的重定向文件。你也可以将数据追加到某个文件。这可以用&gt;&gt;符号来完成 12345678$ who &gt;&gt; test2$ cat test2total 20-rw-rw-r-- 1 rich rich 53 2014-10-16 11:30 test-rw-rw-r-- 1 rich rich 0 2014-10-16 11:32 test2rich pts/0 2014-10-17 15:34 (192.168.1.2)$ who 命令生成的输出会被追加到 test2 文件中已有数据的后面。 但是，如果你对脚本使用了标准输出重定向，你会遇到一个问题。下面的例子说明了可能会出现什么情况。 1234$ ls -al badfile &gt; test3ls: cannot access badfile: No such file or directory$ cat test3$ 当命令生成错误消息时，shell 并未将错误消息重定向到输出重定向文件。shell 创建了输出重定向文件，但错误消息却显示在了显示器屏幕上。注意，在显示 test3 文件的内容时并没有任何错误。test3 文件创建成功了，只是里面是空的。 shell 对于错误消息的处理是跟普通输出分开的。如果你创建了在后台模式下运行的 shell 脚本，通常你必须依赖发送到日志文件的输出消息。用这种方法的话，如果出现了错误信息，这些信息是不会出现在日志文件中的。你需要换种方法来处理。 STDERR shell 通过特殊的 STDERR 文件描述符来处理错误消息。STDERR 文件描述符代表 shell 的标准错误输出。shell 或 shell 中运行的程序和脚本出错时生成的错误消息都会发送到这个位置。默认情况下，STDERR 文件描述符会和 STDOUT 文件描述符指向同样的地方（尽管分配给它们的文件描述符值不同）。也就是说，默认情况下，错误消息也会输出到显示器输出中。但从上面的例子可以看出，STDERR 并不会随着 STDOUT 的重定向而发生改变。使用脚本时，你常常会想改变这种行为，尤其是当你希望将错误消息保存到日志文件中的时候。 重定向错误你已经知道如何用重定向符号来重定向 STDOUT 数据。重定向 STDERR 数据也没太大差别，只要在使用重定向符号时定义 STDERR 文件描述符就可以了。有几种办法实现方法。 只重定向错误 你已经知道，STDERR 文件描述符被设成 2。可以选择只重定向错误消息，将该文件描述符值放在重定向符号前。该值必须紧紧地放在重定向符号前，否则不会工作。 1234$ ls -al badfile 2&gt; test4$ cat test4ls: cannot access badfile: No such file or directory$ 现在运行该命令，错误消息不会出现在屏幕上了。该命令生成的任何错误消息都会保存在输出文件中。用这种方法，shell 会只重定向错误消息，而非普通数据。这里是另一个将 STDOUT 和 STDERR 消息混杂在同一输出中的例子。 123456$ ls -al test badtest test2 2&gt; test5-rw-rw-r-- 1 rich rich 158 2014-10-16 11:32 test2$ cat test5ls: cannot access test: No such file or directoryls: cannot access badtest: No such file or directory$ ls 命令的正常 STDOUT 输出仍然会发送到默认的 STDOUT 文件描述符，也就是显示器。由于该命令将文件描述符 2 的输出（STDERR）重定向到了一个输出文件，shell 会将生成的所有错误消息直接发送到指定的重定向文件中。 重定向错误和正常输出 如果想重定向错误和正常输出，必须用两个重定向符号。需要在符号前面放上待重定向数据所对应的文件描述符，然后指向用于保存数据的输出文件。 12345678$ ls -al test test2 test3 badtest 2&gt; test6 1&gt; test7$ cat test6ls: cannot access test: No such file or directoryls: cannot access badtest: No such file or directory$ cat test7-rw-rw-r-- 1 rich rich 158 2014-10-16 11:32 test2-rw-rw-r-- 1 rich rich 0 2014-10-16 11:33 test3$ shell 利用 1&gt;符号将 ls 命令的正常输出重定向到了 test7 文件，而这些输出本该是进入 STDOUT 的。所有本该输出到 STDERR 的错误消息通过 2&gt;符号被重定向到了 test6 文件。可以用这种方法将脚本的正常输出和脚本生成的错误消息分离开来。这样就可以轻松地识别出错误信息，再不用在成千上万行正常输出数据中翻腾了。另外，如果愿意，也可以将 STDERR 和 STDOUT 的输出重定向到同一个输出文件。为此 bash shell 提供了特殊的重定向符号&amp;&gt;。 123456$ ls -al test test2 test3 badtest &amp;&gt; test7$ cat test7ls: cannot access test: No such file or directoryls: cannot access badtest: No such file or directory-rw-rw-r-- 1 rich rich 158 2014-10-16 11:32 test2-rw-rw-r-- 1 rich rich 0 2014-10-16 11:33 test3 $ 当使用&amp;&gt;符时，命令生成的所有输出都会发送到同一位置，包括数据和错误。你会注意到其中一条错误消息出现的位置和预想中的不一样。badtest 文件（列出的最后一个文件）的这条错误消息出现在输出文件中的第二行。为了避免错误信息散落在输出文件中，相较于标准输出，bash shell 自动赋予了错误消息更高的优先级。这样你能够集中浏览错误信息了。 在脚本中重定向输出可以在脚本中用 STDOUT 和 STDERR 文件描述符以在多个位置生成输出，只要简单地重定向相应的文件描述符就行了。有两种方法来在脚本中重定向输出： 临时重定向行输出 永久重定向脚本中的所有命令 临时重定向如果有意在脚本中生成错误消息，可以将单独的一行输出重定向到 STDERR。你所需要做的是使用输出重定向符来将输出信息重定向到 STDERR 文件描述符。在重定向到文件描述符时，你必须在文件描述符数字之前加一个&amp;： 1echo &quot;This is an error message&quot; &gt;&amp;2 这行会在脚本的 STDERR 文件描述符所指向的位置显示文本，而不是通常的 STDOUT。下面这个例子就利用了这项功能。 123456$ cat test8#!/bin/bash# testing STDERR messagesecho &quot;This is an error&quot; &gt;&amp;2echo &quot;This is normal output&quot;$ 如果像平常一样运行这个脚本，你可能看不出什么区别。 1234$ ./test8This is an errorThis is normal output$ 记住，默认情况下，Linux 会将 STDERR 导向 STDOUT。但是，如果你在运行脚本时重定向了 STDERR，脚本中所有导向 STDERR 的文本都会被重定向。 12345$ ./test8 2&gt; test9This is normal output$ cat test9This is an error$ 太好了！通过 STDOUT 显示的文本显示在了屏幕上，而发送给 STDERR 的 echo 语句的文本则被重定向到了输出文件。这个方法非常适合在脚本中生成错误消息。如果有人用了你的脚本，他们可以像上面的例子中那样轻松地通过 STDERR 文件描述符重定向错误消息。 永久重定向如果脚本中有大量数据需要重定向，那重定向每个 echo 语句就会很烦琐。取而代之，你可以用 exec 命令告诉 shell 在脚本执行期间重定向某个特定文件描述符。 12345678910111213$ cat test10#!/bin/bash# redirecting all output to a fileexec 1&gt;testoutecho &quot;This is a test of redirecting all output&quot;echo &quot;from a script to another file.&quot;echo &quot;without having to redirect every individual line&quot;$ ./test10$ cat testoutThis is a test of redirecting all outputfrom a script to another file.without having to redirect every individual line$ exec 命令会启动一个新 shell 并将 STDOUT 文件描述符重定向到文件。脚本中发给 STDOUT 的所有输出会被重定向到文件。 可以在脚本执行过程中重定向 STDOUT。 123456789101112131415161718$ cat test11#!/bin/bash# redirecting output to different locationsexec 2&gt;testerrorecho &quot;This is the start of the script&quot;echo &quot;now redirecting all output to another location&quot;exec 1&gt;testoutecho &quot;This output should go to the testout file&quot;echo &quot;but this should go to the testerror file&quot; &gt;&amp;2$$ ./test11This is the start of the scriptnow redirecting all output to another location$ cat testoutThis output should go to the testout file$ cat testerrorbut this should go to the testerror file$ 这个脚本用 exec 命令来将发给 STDERR 的输出重定向到文件 testerror。接下来，脚本用 echo 语句向 STDOUT 显示了几行文本。随后再次使用 exec 命令来将 STDOUT 重定向到 testout 文件。注意，尽管 STDOUT 被重定向了，但你仍然可以将 echo 语句的输出发给 STDERR，在本例中还是重定向到 testerror 文件。 当你只想将脚本的部分输出重定向到其他位置时（如错误日志），这个特性用起来非常方便。不过这样做的话，会碰到一个问题。 一旦重定向了 STDOUT 或 STDERR，就很难再将它们重定向回原来的位置。如果你需要在重定向中来回切换的话，有个办法可以用，后文将会讨论该方法以及如何在脚本中使用。 在脚本中重定向输入你可以使用与脚本中重定向 STDOUT 和 STDERR 相同的方法来将 STDIN 从键盘重定向到其他位置。exec 命令允许你将 STDIN 重定向到 Linux 系统上的文件中： 1exec 0&lt; testfile 这个命令会告诉 shell 它应该从文件 testfile 中获得输入，而不是 STDIN。这个重定向只要在脚本需要输入时就会作用。下面是该用法的实例。 123456789101112131415$ cat test12#!/bin/bash# redirecting file inputexec 0&lt; testfilecount=1while read linedo echo &quot;Line #$count: $line&quot; count=$[ $count + 1 ]done$ ./test12Line #1: This is the first line.Line #2: This is the second line.Line #3: This is the third line.$ 上一章介绍了如何使用 read 命令读取用户在键盘上输入的数据。将 STDIN 重定向到文件后，当 read 命令试图从 STDIN 读入数据时，它会到文件去取数据，而不是键盘。这是在脚本中从待处理的文件中读取数据的绝妙办法。Linux 系统管理员的一项日常任务就是从日志文件中读取数据并处理。这是完成该任务最简单的办法。 创建自己的重定向在脚本中重定向输入和输出时，并不局限于这 3 个默认的文件描述符。我曾提到过，在 shell 中最多可以有 9 个打开的文件描述符。其他 6 个从 3~8 的文件描述符均可用作输入或输出重定向。你可以将这些文件描述符中的任意一个分配给文件，然后在脚本中使用它们。本节将介绍如何在脚本中使用其他文件描述符。 创建输出文件描述符可以用 exec 命令来给输出分配文件描述符。和标准的文件描述符一样，一旦将另一个文件描述符分配给一个文件，这个重定向就会一直有效，直到你重新分配。这里有个在脚本中使用其他文件描述符的简单例子。 12345678910111213$ cat test13#!/bin/bash# using an alternative file descriptorexec 3&gt;test13outecho &quot;This should display on the monitor&quot;echo &quot;and this should be stored in the file&quot; &gt;&amp;3echo &quot;Then this should be back on the monitor&quot;$ ./test13This should display on the monitorThen this should be back on the monitor$ cat test13outand this should be stored in the file$ 这个脚本用 exec 命令将文件描述符 3 重定向到另一个文件。当脚本执行 echo 语句时，输出内容会像预想中那样显示在 STDOUT 上。但你重定向到文件描述符 3 的那行 echo 语句的输出却进入了另一个文件。这样你就可以在显示器上保持正常的输出，而将特定信息重定向到文件中（比如日志文件）。 也可以不用创建新文件，而是使用 exec 命令来将输出追加到现有文件中。 1exec 3&gt;&gt;test13out 现在输出会被追加到 test13out 文件，而不是创建一个新文件。 重定向文件描述符现在介绍怎么恢复已重定向的文件描述符。你可以分配另外一个文件描述符给标准文件描述符，反之亦然。这意味着你可以将 STDOUT 的原来位置重定向到另一个文件描述符，然后再利用该文件描述符重定向回 STDOUT。听起来可能有点复杂，但实际上相当直接。这个简单的例子能帮你理清楚。 12345678910111213141516$ cat test14#!/bin/bash# storing STDOUT, then coming back to itexec 3&gt;&amp;1exec 1&gt;test14outecho &quot;This should store in the output file&quot;echo &quot;along with this line.&quot;exec 1&gt;&amp;3echo &quot;Now things should be back to normal&quot;$$ ./test14Now things should be back to normal$ cat test14outThis should store in the output filealong with this line.$ 这个例子有点叫人抓狂，来一段一段地看。首先，脚本将文件描述符 3 重定向到文件描述符 1 的当前位置，也就是 STDOUT。这意味着任何发送给文件描述符 3 的输出都将出现在显示器上。第二个 exec 命令将 STDOUT 重定向到文件，shell 现在会将发送给 STDOUT 的输出直接重定向到输出文件中。但是，文件描述符 3 仍然指向 STDOUT 原来的位置，也就是显示器。如果此时将输出数据发送给文件描述符 3，它仍然会出现在显示器上，尽管 STDOUT 已经被重定向了。在向 STDOUT（现在指向一个文件）发送一些输出之后，脚本将 STDOUT 重定向到文件描述符 3 的当前位置（现在仍然是显示器）。这意味着现在 STDOUT 又指向了它原来的位置：显示器。这个方法可能有点叫人困惑，但这是一种在脚本中临时重定向输出，然后恢复默认输出设置的常用方法。 创建输入文件描述符可以用和重定向输出文件描述符同样的办法重定向输入文件描述符。在重定向到文件之前，先将 STDIN 文件描述符保存到另外一个文件描述符，然后在读取完文件之后再将 STDIN 恢复到它原来的位置。 123456789101112131415161718192021222324$ cat test15#!/bin/bash# redirecting input file descriptorsexec 6&lt;&amp;0exec 0&lt; testfilecount=1while read linedo echo &quot;Line #$count: $line&quot; count=$[ $count + 1 ]doneexec 0&lt;&amp;6read -p &quot;Are you done now? &quot; answercase $answer in Y|y) echo &quot;Goodbye&quot;;; N|n) echo &quot;Sorry, this is the end.&quot;;;esac$ ./test15Line #1: This is the first line.Line #2: This is the second line.Line #3: This is the third line.Are you done now? yGoodbye$ 在这个例子中，文件描述符 6 用来保存 STDIN 的位置。然后脚本将 STDIN 重定向到一个文件。read 命令的所有输入都来自重定向后的 STDIN（也就是输入文件）。在读取了所有行之后，脚本会将 STDIN 重定向到文件描述符 6，从而将 STDIN 恢复到原先的位置。该脚本用了另外一个 read 命令来测试 STDIN 是否恢复正常了。这次它会等待键盘的输入。 创建读写文件描述符尽管看起来可能会很奇怪，但是你也可以打开单个文件描述符来作为输入和输出。可以用同一个文件描述符对同一个文件进行读写。不过用这种方法时，你要特别小心。由于你是对同一个文件进行数据读写，shell 会维护一个内部指针，指明在文件中的当前位置。任何读或写都会从文件指针上次的位置开始。如果不够小心，它会产生一些令人瞠目的结果。看看下面这个例子。 12345678910111213141516171819$ cat test16#!/bin/bash# testing input/output file descriptorexec 3&lt;&gt; testfileread line &lt;&amp;3echo &quot;Read: $line&quot;echo &quot;This is a test line&quot; &gt;&amp;3$ cat testfileThis is the first line.This is the second line.This is the third line.$ ./test16Read: This is the first line.$ cat testfileThis is the first line.This is a test lineine.This is the third line.$ 这个例子用了 exec 命令将文件描述符 3 分配给文件 testfile 以进行文件读写。接下来，它通过分配好的文件描述符，使用 read 命令读取文件中的第一行，然后将这一行显示在 STDOUT 上。最后，它用 echo 语句将一行数据写入由同一个文件描述符打开的文件中。 在运行脚本时，一开始还算正常。输出内容表明脚本读取了 testfile 文件中的第一行。但如果你在脚本运行完毕后，查看 testfile 文件内容的话，你会发现写入文件中的数据覆盖了已有的数据。 当脚本向文件中写入数据时，它会从文件指针所处的位置开始。read 命令读取了第一行数据，所以它使得文件指针指向了第二行数据的第一个字符。在 echo 语句将数据输出到文件时，它会将数据放在文件指针的当前位置，覆盖了该位置的已有数据。 关闭文件描述符如果你创建了新的输入或输出文件描述符，shell 会在脚本退出时自动关闭它们。然而在有些情况下，你需要在脚本结束前手动关闭文件描述符。 要关闭文件描述符，将它重定向到特殊符号&amp;-。脚本中看起来如下： 1exec 3&gt;&amp;- 该语句会关闭文件描述符 3，不再在脚本中使用它。这里有个例子来说明当你尝试使用已关闭的文件描述符时会怎样。 12345678910$ cat badtest#!/bin/bash# testing closing file descriptorsexec 3&gt; test17fileecho &quot;This is a test line of data&quot; &gt;&amp;3exec 3&gt;&amp;-echo &quot;This won&#x27;t work&quot; &gt;&amp;3$ ./badtest./badtest: 3: Bad file descriptor$ 一旦关闭了文件描述符，就不能在脚本中向它写入任何数据，否则 shell 会生成错误消息。在关闭文件描述符时还要注意另一件事。如果随后你在脚本中打开了同一个输出文件，shell 会用一个新文件来替换已有文件。这意味着如果你输出数据，它就会覆盖已有文件。考虑下面这个问题的例子。 1234567891011121314$ cat test17#!/bin/bash# testing closing file descriptorsexec 3&gt; test17fileecho &quot;This is a test line of data&quot; &gt;&amp;3exec 3&gt;&amp;-cat test17fileexec 3&gt; test17fileecho &quot;This&#x27;ll be bad&quot; &gt;&amp;3$ ./test17This is a test line of data$ cat test17fileThis&#x27;ll be bad$ 在向 test17file 文件发送一个数据字符串并关闭该文件描述符之后，脚本用了 cat 命令来显示文件的内容。到目前为止，一切都还好。下一步，脚本重新打开了该输出文件并向它发送了另一个数据字符串。当显示该输出文件的内容时，你所能看到的只有第二个数据字符串。shell 覆盖了原来的输出文件。 列出打开的文件描述符你能用的文件描述符只有 9 个，你可能会觉得这没什么复杂的。但有时要记住哪个文件描述符被重定向到了哪里很难。为了帮助你理清条理，bash shell 提供了 lsof 命令。lsof 命令会列出整个 Linux 系统打开的所有文件描述符。这是个有争议的功能，因为它会向非系统管理员用户提供 Linux 系统的信息。鉴于此，许多 Linux 系统隐藏了该命令，这样用户就不会一不小心就发现了。 有大量的命令行选项和参数可以用来帮助过滤 lsof 的输出。最常用的有-p 和-d，前者允许指定进程 ID（PID），后者允许指定要显示的文件描述符编号。 要想知道进程的当前 PID，可以用特殊环境变量$$（shell 会将它设为当前 PID）。-a 选项用来对其他两个选项的结果执行布尔 AND 运算，这会产生如下输出。 1234567$ lsof -a -p $$ -d 0,1,2lsof: WARNING: can&#x27;t stat() tracefs file system /sys/kernel/debug/tracing Output information may be incomplete.COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEbash 162540 testuser 0u CHR 136,1 0t0 4 /dev/pts/1bash 162540 testuser 1u CHR 136,1 0t0 4 /dev/pts/1bash 162540 testuser 2u CHR 136,1 0t0 4 /dev/pts/1 上例显示了当前进程（bash shell）的默认文件描述符（0、1 和 2）。同时可以注意到，因为是以非 root 用户执行，没有权限查看全部文件描述符信息，lsof 提示了你信息可能不完整。lsof 的默认输出中有 7 列信息，详情如下。 COMMAND 正在运行的命令名的前 9 个字符 PID 进程的 PID USER 进程属主的登录名 FD 文件描述符号以及访问类型（r 代表读，w 代表写，u 代表读写） TYPE 文件的类型（CHR 代表字符型，BLK 代表块型，DIR 代表目录，REG 代表常规文件） DEVICE 设备的设备号（主设备号和从设备号） SIZE 如果有的话，表示文件的大小 NODE 本地文件的节点号 NAME 文件名 与 STDIN、STDOUT 和 STDERR 关联的文件类型是字符型。因为 STDIN、STDOUT 和 STDERR 文件描述符都指向终端，所以输出文件的名称就是终端的设备名。所有 3 种标准文件都支持读和写（尽管向 STDIN 写数据以及从 STDOUT 读数据看起来有点奇怪）。 现在看一下在打开了多个替代性文件描述符的脚本中使用 lsof 命令的结果。 1234567891011121314151617$ cat test18#!/bin/bash# testing lsof with file descriptorsexec 3&gt; test18file1exec 6&gt; test18file2exec 7&lt; testfilelsof -a -p $$ -d0,1,2,3,6,7$ ./test18lsof: WARNING: can&#x27;t stat() tracefs file system /sys/kernel/debug/tracing Output information may be incomplete.COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEtt 177709 testuser 0u CHR 136,1 0t0 4 /dev/pts/1tt 177709 testuser 1u CHR 136,1 0t0 4 /dev/pts/1tt 177709 testuser 2u CHR 136,1 0t0 4 /dev/pts/1tt 177709 testuser 3w REG 259,4 0 33822498 /home/testuser/test18file1tt 177709 testuser 6w REG 259,4 0 33822697 /home/testuser/test18file2tt 177709 testuser 7r REG 259,4 73 33823059 /home/testuser/testfile 该脚本创建了 3 个替代性文件描述符，两个作为输出（3 和 6），一个作为输入（7）。在脚本运行 lsof 命令时，可以在输出中看到新的文件描述符。我们去掉了输出中的第一部分，这样你就能看到文件名的结果了。文件名显示了文件描述符所使用的文件的完整路径名。它将每个文件都显示成 REG 类型的，这说明它们是文件系统中的常规文件。 阻止命令输出有时候，你可能不想显示脚本的输出。这在将脚本作为后台进程运行时很常见，尤其是当运行会生成很多烦琐的小错误的脚本时。要解决这个问题，可以将 STDERR 重定向到一个叫作 null 文件的特殊文件。null 文件跟它的名字很像，文件里什么都没有。shell 输出到 null 文件的任何数据都不会保存，全部都被丢掉了。 在 Linux 系统上 null 文件的标准位置是&#x2F;dev&#x2F;null。你重定向到该位置的任何数据都会被丢掉，不会显示。 123$ ls -al &gt; /dev/null$ cat /dev/null$ 这是避免出现错误消息，也无需保存它们的一个常用方法。 123$ ls -al badfile test16 2&gt; /dev/null-rwxr--r-- 1 rich rich 135 Oct 29 19:57 test16*$ 也可以在输入重定向中将&#x2F;dev&#x2F;null 作为输入文件。由于&#x2F;dev&#x2F;null 文件不含有任何内容，程序员通常用它来快速清除现有文件中的数据，而不用先删除文件再重新创建。 1234567$ cat testfileThis is the first line.This is the second line.This is the third line.$ cat /dev/null &gt; testfile$ cat testfile$ 文件 testfile 仍然存在系统上，但现在它是空文件。这是清除日志文件的一个常用方法，因为日志文件必须时刻准备等待应用程序操作。 创建临时文件Linux 系统有特殊的目录，专供临时文件使用。Linux 使用&#x2F;tmp 目录来存放不需要永久保留的文件。大多数 Linux 发行版配置了系统在启动时自动删除&#x2F;tmp 目录的所有文件。系统上的任何用户账户都有权限在读写&#x2F;tmp 目录中的文件。这个特性为你提供了一种创建临时文件的简单方法，而且还不用操心清理工作。 有个特殊命令可以用来创建临时文件。mktemp 命令可以在&#x2F;tmp 目录中创建一个唯一的临时文件。shell 会创建这个文件，但不用默认的 umask 值 。它会将文件的读和写权限分配给文件的属主，并将你设成文件的属主。一旦创建了文件，你就在脚本中有了完整的读写权限，但其他人没法访问它（当然，root 用户除外）。 创建本地临时文件默认情况下，mktemp 会在本地目录中创建一个文件。要用 mktemp 命令在本地目录中创建一个临时文件，你只要指定一个文件名模板就行了。模板可以包含任意文本文件名，在文件名末尾加上 2 个以上 X 就行了。 12345$ mktemp testing.XXXXXXtesting.4OnP2E$ ls -al testing*-rw------- 1 rich rich 0 Oct 17 21:30 testing.UfIi13$ mktemp 命令会用 6 个字符码替换这 6 个 X，从而保证文件名在目录中是唯一的。你可以创建多个临时文件，它可以保证每个文件都是唯一的。mktemp 命令的输出正是它所创建的文件的名字。在脚本中使用 mktemp 命令时，可能要将文件名保存到变量中，这样就能在后面的脚本中引用了。 1234567891011121314151617181920212223$ cat test19#!/bin/bash# creating and using a temp filetempfile=$(mktemp test19.XXXXXX)exec 3&gt;$tempfileecho &quot;This script writes to temp file $tempfile&quot;echo &quot;This is the first line&quot; &gt;&amp;3echo &quot;This is the second line.&quot; &gt;&amp;3echo &quot;This is the last line.&quot; &gt;&amp;3exec 3&gt;&amp;-echo &quot;Done creating temp file. The contents are:&quot;cat $tempfilerm -f $tempfile 2&gt; /dev/null$ ./test19This script writes to temp file test19.vCHoyaDone creating temp file.The contents are:This is the first lineThis is the second line.This is the last line.$ ls -al test19*-rwxr--r-- 1 rich rich 356 Oct 29 22:03 test19*$ 这个脚本用 mktemp 命令来创建临时文件并将文件名赋给$tempfile 变量。接着将这个临时文件作为文件描述符 3 的输出重定向文件。在将临时文件名显示在 STDOUT 之后，向临时文件中写入了几行文本，然后关闭了文件描述符。最后，显示出临时文件的内容，并用 rm 命令将其删除。 在&#x2F;tmp 目录创建临时文件-t 选项会强制 mktemp 命令来在系统的临时目录来创建该文件。在用这个特性时，mktemp 命令会返回用来创建临时文件的全路径，而不是只有文件名。 12345$ mktemp -t test.XXXXXX/tmp/test.xG3374$ ls -al /tmp/test*-rw------- 1 rich rich 0 2014-10-29 18:41 /tmp/test.xG3374$ 由于 mktemp 命令返回了全路径名，你可以在 Linux 系统上的任何目录下引用该临时文件，不管临时目录在哪里。 1234567891011121314$ cat test20#!/bin/bash# creating a temp file in /tmptempfile=$(mktemp -t tmp.XXXXXX)echo &quot;This is a test file.&quot; &gt; $tempfileecho &quot;This is the second line of the test.&quot; &gt;&gt; $tempfileecho &quot;The temp file is located at: $tempfile&quot;cat $tempfilerm -f $tempfile$ ./test20The temp file is located at: /tmp/tmp.Ma3390This is a test file.This is the second line of the test.$ 在 mktemp 创建临时文件时，它会将全路径名返回给变量。这样你就能在任何命令中使用该值来引用临时文件了。 创建临时目录-d 选项告诉 mktemp 命令来创建一个临时目录而不是临时文件。这样你就能用该目录进行任何需要的操作了，比如创建其他的临时文件。 1234567891011121314151617181920212223242526272829303132$ cat test21#!/bin/bash# using a temporary directorytempdir=$(mktemp -d dir.XXXXXX)cd $tempdirtempfile1=$(mktemp temp.XXXXXX)tempfile2=$(mktemp temp.XXXXXX)exec 7&gt; $tempfile1exec 8&gt; $tempfile2echo &quot;Sending data to directory $tempdir&quot;echo &quot;This is a test line of data for $tempfile1&quot; &gt;&amp;7echo &quot;This is a test line of data for $tempfile2&quot; &gt;&amp;8$ ./test21Sending data to directory dir.ouT8S8$ ls -altotal 72drwxr-xr-x 3 rich rich 4096 Oct 17 22:20 ./drwxr-xr-x 9 rich rich 4096 Oct 17 09:44 ../drwx------ 2 rich rich 4096 Oct 17 22:20 dir.ouT8S8/-rwxr--r-- 1 rich rich 338 Oct 17 22:20 test21*$ cd dir.ouT8S8[dir.ouT8S8]$ ls -altotal 16drwx------ 2 rich rich 4096 Oct 17 22:20 ./drwxr-xr-x 3 rich rich 4096 Oct 17 22:20 ../-rw------- 1 rich rich 44 Oct 17 22:20 temp.N5F3O6-rw------- 1 rich rich 44 Oct 17 22:20 temp.SQslb7[dir.ouT8S8]$ cat temp.N5F3O6This is a test line of data for temp.N5F3O6[dir.ouT8S8]$ cat temp.SQslb7This is a test line of data for temp.SQslb7[dir.ouT8S8]$ 这段脚本在当前目录创建了一个临时目录，然后它用 cd 命令进入该目录，并创建了两个临时文件。之后这两个临时文件被分配给文件描述符，用来存储脚本的输出。 记录消息将输出同时发送到显示器和日志文件，这种做法有时候能够派上用场。你不用将输出重定向两次，只要用特殊的 tee 命令就行。tee 命令相当于管道的一个 T 型接头。它将从 STDIN 过来的数据同时发往两处。一处是 STDOUT，另一处是 tee 命令行所指定的文件名：tee filename 由于 tee 会重定向来自 STDIN 的数据，你可以用它配合管道命令来重定向命令输出。 12345$ date | tee testfileSun Oct 19 18:56:21 EDT 2014$ cat testfileSun Oct 19 18:56:21 EDT 2014$ 输出出现在了 STDOUT 中，同时也写入了指定的文件中。注意，默认情况下，tee 命令会在每次使用时覆盖输出文件内容。 12345$ who | tee testfilerich pts/0 2014-10-17 18:41 (192.168.1.2)$ cat testfilerich pts/0 2014-10-17 18:41 (192.168.1.2)$ 如果你想将数据追加到文件中，必须用-a 选项。 利用 tee，既能将数据保存在文件中，也能将数据显示在屏幕上。现在你就可以在为用户显示输出的同时再永久保存一份输出内容了。 12345678910111213141516$ cat test22#!/bin/bash# using the tee command for loggingtempfile=test22fileecho &quot;This is the start of the test&quot; | tee $tempfileecho &quot;This is the second line of the test&quot; | tee -a $tempfileecho &quot;This is the end of the test&quot; | tee -a $tempfile$ ./test22This is the start of the testThis is the second line of the testThis is the end of the test$ cat test22fileThis is the start of the testThis is the second line of the testThis is the end of the test$ 实例文件重定向常见于脚本需要读入文件和输出文件时。下面的样例脚本两件事都做了。它读取.csv 格式的数据文件，输出 SQL INSERT 语句来将数据插入数据库。shell 脚本使用命令行参数指定待读取的.csv 文件。.csv 格式用于从电子表格中导出数据，所以你可以把数据库数据放入电子表格中，把电子表格保存成.csv 格式，读取文件，然后创建 INSERT 语句将数据插入 MySQL 数据库。 12345678910111213$cat test23#!/bin/bash# read file and create INSERT statements for MySQLoutfile=&#x27;members.sql&#x27;IFS=&#x27;,&#x27;while read lname fname address city state zipdo cat &gt;&gt; $outfile &lt;&lt; EOF INSERT INTO members (lname,fname,address,city,state,zip) VALUES (&#x27;$lname&#x27;, &#x27;$fname&#x27;, &#x27;$address&#x27;, &#x27;$city&#x27;, &#x27;$state&#x27;, &#x27;$zip&#x27;);EOFdone &lt; $&#123;1&#125;$ 这个脚本很短小，这都要感谢有了文件重定向！脚本中出现了三处重定向操作。while 循环使用 read 语句从数据文件中读取文本。注意在 done 语句中出现的重定向符号： 1done &lt; $&#123;1&#125; 当运行程序 test23 时，$1 代表第一个命令行参数。它指明了待读取数据的文件。read 语句会使用 IFS 字符解析读入的文本，我们在这里将 IFS 指定为逗号。 脚本中另外两处重定向操作出现在同一条语句中： 1cat &gt;&gt; $outfile &lt;&lt; EOF 这条语句中包含一个输出追加重定向（双大于号）和一个输入追加重定向（双小于号）。输出重定向将 cat 命令的输出追加到由$outfile 变量指定的文件中。cat 命令的输入不再取自标准输入，而是被重定向到脚本中存储的数据。EOF 符号标记了追加到文件中的数据的起止。 12INSERT INTO members (lname,fname,address,city,state,zip) VALUES(&#x27;$lname&#x27;, &#x27;$fname&#x27;, &#x27;$address&#x27;, &#x27;$city&#x27;, &#x27;$state&#x27;, &#x27;$zip&#x27;); 上面的文本生成了一个标准的 SQL INSERT 语句。注意，其中的数据会由变量来替换，变量中内容则是由 read 语句存入的。所以 while 循环一次读取一行数据，将这些值放入 INSERT 语句模板中，然后将结果输出到输出文件中。 在这个例子中，使用以下输入数据文件。 123456$ cat members.csvBlum,Richard,123 Main St.,Chicago,IL,60601Blum,Barbara,123 Main St.,Chicago,IL,60601Bresnahan,Christine,456 Oak Ave.,Columbus,OH,43201Bresnahan,Timothy,456 Oak Ave.,Columbus,OH,43201$ 运行脚本时，显示器上不会出现任何输出： 12$ ./test23 members.csv$ 但是在 members.sql 输出文件中，你会看到如下输出内容。 123456$ cat members.sqlINSERT INTO members (lname,fname,address,city,state,zip) VALUES (&#x27;Blum&#x27;, &#x27;Richard&#x27;, &#x27;123 Main St.&#x27;, &#x27;Chicago&#x27;, &#x27;IL&#x27;, &#x27;60601&#x27;);INSERT INTO members (lname,fname,address,city,state,zip) VALUES (&#x27;Blum&#x27;, &#x27;Barbara&#x27;, &#x27;123 Main St.&#x27;, &#x27;Chicago&#x27;, &#x27;IL&#x27;, &#x27;60601&#x27;);INSERT INTO members (lname,fname,address,city,state,zip) VALUES (&#x27;Bresnahan&#x27;, &#x27;Christine&#x27;, &#x27;456 Oak Ave.&#x27;, &#x27;Columbus&#x27;, &#x27;OH&#x27;, &#x27;43201&#x27;);INSERT INTO members (lname,fname,address,city,state,zip) VALUES (&#x27;Bresnahan&#x27;, &#x27;Timothy&#x27;, &#x27;456 Oak Ave.&#x27;, &#x27;Columbus&#x27;, &#x27;OH&#x27;, &#x27;43201&#x27;);$ 结果和我们预想的一样！现在可以将 members.sql 文件导入 MySQL 数据表中了。 控制 Shell 脚本当开始构建高级脚本时，你大概会问如何在 Linux 系统上运行和控制它们。在本书中，到目前为止，我们运行脚本的唯一方式就是以实时模式在命令行界面上直接运行。这并不是 Linux 上运行脚本的唯一方式。有不少方法可以用来运行 shell 脚本。另外还有一些选项能够用于控制脚本。这些控制方法包括向脚本发送信号、修改脚本的优先级以及在脚本运行时切换到运行模式。本章将会对逐一介绍这些方法。 处理信号Linux 利用信号与运行在系统中的进程进行通信。之前介绍了不同的 Linux 信号以及 Linux 如何用这些信号来停止、启动、终止进程。可以通过对脚本进行编程，使其在收到特定信号时执行某些命令，从而控制 shell 脚本的操作。 重温 Linux 信号Linux 系统和应用程序可以生成超过 30 个信号。如下列出了在 Linux 编程时会遇到的最常见的 Linux 系统信号。 1 SIGHUP 挂起进程 2 SIGINT 终止进程 3 SIGQUIT 停止进程 9 SIGKILL 无条件终止进程 15 SIGTERM 尽可能终止进程 17 SIGSTOP 无条件停止进程，但不是终止进程 18 IGTSTP 停止或暂停进程，但不终止进程 19 SIGCONT 继续运行停止的进程 默认情况下，bash shell 会忽略收到的任何 SIGQUIT (3)和 SIGTERM (15)信号（正因为这样，交互式 shell 才不会被意外终止）。但是 bash shell 会处理收到的 SIGHUP (1)和 SIGINT (2)信号。 如果 bash shell 收到了 SIGHUP 信号，比如当你要离开一个交互式 shell，它就会退出。但在退出之前，它会将 SIGHUP 信号传给所有由该 shell 所启动的进程（包括正在运行的 shell 脚本）。 通过 SIGINT 信号，可以中断 shell。Linux 内核会停止为 shell 分配 CPU 处理时间。这种情况发生时，shell 会将 SIGINT 信号传给所有由它所启动的进程，以此告知出现的状况。 你可能也注意到了，shell 会将这些信号传给 shell 脚本程序来处理。而 shell 脚本的默认行为是忽略这些信号。它们可能会不利于脚本的运行。要避免这种情况，你可以脚本中加入识别信号的代码，并执行命令来处理信号。 生成信号bash shell 允许用键盘上的组合键生成两种基本的 Linux 信号。这个特性在需要停止或暂停失控程序时非常方便。 中断进程 Ctrl+C 组合键会生成 SIGINT 信号，并将其发送给当前在 shell 中运行的所有进程。可以运行一条需要很长时间才能完成的命令，然后按下 Ctrl+C 组合键来测试它。 123$ sleep 100^C$ Ctrl+C 组合键会发送 SIGINT 信号，停止 shell 中当前运行的进程。sleep 命令会使得 shell 暂停指定的秒数，命令提示符直到计时器超时才会返回。在超时前按下 Ctrl+C 组合键，就可以提前终止 sleep 命令。 暂停进程 你可以在进程运行期间暂停进程，而无需终止它。尽管有时这可能会比较危险（比如，脚本打开了一个关键的系统文件的文件锁），但通常它可以在不终止进程的情况下使你能够深入脚本内部一窥究竟。 Ctrl+Z 组合键会生成一个 SIGTSTP 信号，停止 shell 中运行的任何进程。停止（stopping）进程跟终止（terminating）进程不同：停止进程会让程序继续保留在内存中，并能从上次停止的位置继续运行。随后你会了解如何重启一个已经停止的进程。 当用 Ctrl+Z 组合键时，shell 会通知你进程已经被停止了。 1234$ sleep 100^Z[1]+ Stopped sleep 100$ 方括号中的数字是 shell 分配的作业号（job number）。shell 将 shell 中运行的每个进程称为作业，并为每个作业分配唯一的作业号。它会给第一个作业分配作业号 1，第二个作业号 2，以此类推。 如果你的 shell 会话中有一个已停止的作业，在退出 shell 时，bash 会提醒你。 123456$ sleep 100^Z[1]+ Stopped sleep 100$ exitexit There are stopped jobs.$ 可以用 ps 命令来查看已停止的作业。 123456789$ sleep 100^Z [1]+ Stopped sleep 100$$ ps -lFS UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD0 S 501 2431 2430 0 80 0 - 27118 wait pts/0 00:00:00 bash0 T 501 2456 2431 0 80 0 - 25227 signal pts/0 00:00:00 sleep0 R 501 2458 2431 0 80 0 - 27034 - pts/0 00:00:00 ps$ 在 S 列中（进程状态），ps 命令将已停止作业的状态为显示为 T。这说明命令已经被停止了。 如果在有已停止作业存在的情况下，你仍旧想退出 shell，只要再输入一遍 exit 命令就行了。shell 会退出，终止已停止作业。或者，既然你已经知道了已停止作业的 PID，就可以用 kill 命令来发送一个 SIGKILL 信号来终止它。 123$ kill -9 2456$ [1]+ Killed sleep 100$ 在终止作业时，最开始你不会得到任何回应。但下次如果你做了能够产生 shell 提示符的操作（比如按回车键），你就会看到一条消息，显示作业已经被终止了。每当 shell 产生一个提示符时，它就会显示 shell 中状态发生改变的作业的状态。在你终止一个作业后，下次强制 shell 生成一个提示符时，shell 会显示一条消息，说明作业在运行时被终止了。 捕获信号也可以不忽略信号，在信号出现时捕获它们并执行其他命令。trap 命令允许你来指定 shell 脚本要监看并从 shell 中拦截的 Linux 信号。如果脚本收到了 trap 命令中列出的信号，该信号不再由 shell 处理，而是交由本地处理。 1trap commands signals 非常简单！在 trap 命令行上，你只要列出想要 shell 执行的命令，以及一组用空格分开的待捕获的信号。你可以用数值或 Linux 信号名来指定信号。 这里有个简单例子，展示了如何使用 trap 命令来忽略 SIGINT 信号，并控制脚本的行为。 1234567891011121314151617$ cat test1.sh#!/bin/bash# Testing signal trapping#trap &quot;echo &#x27; Sorry! I have trapped Ctrl-C&#x27;&quot; SIGINT#echo This is a test script#count=1while [ $count -le 10 ]do echo &quot;Loop #$count&quot; sleep 1 count=$[ $count + 1 ]done#echo &quot;This is the end of the test script&quot; # 本例中用到的 trap 命令会在每次检测到 SIGINT 信号时显示一行简单的文本消息。捕获这些信号会阻止用户用 bash shell 组合键 Ctrl+C 来停止程序。 12345678910111213141516$ ./test1.shThis is a test scriptLoop #1Loop #2Loop #3Loop #4Loop #5^C Sorry! I have trapped Ctrl-CLoop #6Loop #7Loop #8^C Sorry! I have trapped Ctrl-CLoop #9Loop #10This is the end of the test script$ 每次使用 Ctrl+C 组合键，脚本都会执行 trap 命令中指定的 echo 语句，而不是处理该信号并允许 shell 停止该脚本。 捕获脚本退出除了在 shell 脚本中捕获信号，你也可以在 shell 脚本退出时进行捕获。这是在 shell 完成任务时执行命令的一种简便方法。 要捕获 shell 脚本的退出，只要在 trap 命令后加上 EXIT 信号就行。 1234567891011121314151617181920212223$ cat test2.sh#!/bin/bash# Trapping the script exit#trap &quot;echo Goodbye...&quot; EXIT#count=1while [ $count -le 5 ]do echo &quot;Loop #$count&quot; sleep 1 count=$[ $count + 1 ]done#$$ ./test2.shLoop #1Loop #2Loop #3Loop #4Loop #5Goodbye...$ 当脚本运行到正常的退出位置时，捕获就被触发了，shell 会执行在 trap 命令行指定的命令。如果提前退出脚本，同样能够捕获到 EXIT。 123456$ ./test2.shLoop #1Loop #2Loop #3^CGoodbye...$ 因为 SIGINT 信号并没有出现在 trap 命令的捕获列表中，当按下 Ctrl+C 组合键发送 SIGINT 信号时，脚本就退出了。但在脚本退出前捕获到了 EXIT，于是 shell 执行了 trap 命令 修改或移除捕获要想在脚本中的不同位置进行不同的捕获处理，只需重新使用带有新选项的 trap 命令。 12345678910111213141516171819202122232425$ cat test3.sh#!/bin/bash# Modifying a set trap#trap &quot;echo &#x27; Sorry... Ctrl-C is trapped.&#x27;&quot; SIGINT#count=1while [ $count -le 5 ]do echo &quot;Loop #$count&quot; sleep 1 count=$[ $count + 1 ]done#trap &quot;echo &#x27; I modified the trap!&#x27;&quot; SIGINT#count=1while [ $count -le 5 ]do echo &quot;Second Loop #$count&quot; sleep 1 count=$[ $count + 1 ]done#$ 修改了信号捕获之后，脚本处理信号的方式就会发生变化。但如果一个信号是在捕获被修改前接收到的，那么脚本仍然会根据最初的 trap 命令进行处理。 1234567891011121314$ ./test3.shLoop #1Loop #2Loop #3^C Sorry... Ctrl-C is trapped.Loop #4Loop #5Second Loop #1Second Loop #2^C I modified the trap!Second Loop #3Second Loop #4Second Loop #5$ 也可以删除已设置好的捕获。只需要在 trap 命令与希望恢复默认行为的信号列表之间加上两个破折号就行了。 12345678910111213141516171819202122232425262728293031323334353637$ cat test3b.sh#!/bin/bash# Removing a set trap#trap &quot;echo &#x27; Sorry... Ctrl-C is trapped.&#x27;&quot; SIGINT#count=1while [ $count -le 5 ]do echo &quot;Loop #$count&quot; sleep 1 count=$[ $count + 1 ]done## Remove the traptrap -- SIGINTecho &quot;I just removed the trap&quot;#count=1while [ $count -le 5 ]do echo &quot;Second Loop #$count&quot; sleep 1 count=$[ $count + 1 ]done#$ ./test3b.shLoop #1Loop #2Loop #3Loop #4Loop #5I just removed the trapSecond Loop #1Second Loop #2Second Loop #3 ^C$ 也可以在 trap 命令后使用单破折号来恢复信号的默认行为。单破折号和双破折号都可以正常发挥作用。 移除信号捕获后，脚本按照默认行为来处理 SIGINT 信号，也就是终止脚本运行。但如果信号是在捕获被移除前接收到的，那么脚本会按照原先 trap 命令中的设置进行处理。 123456789101112$ ./test3b.shLoop #1Loop #2Loop #3^C Sorry... Ctrl-C is trapped.Loop #4Loop #5I just removed the trapSecond Loop #1Second Loop #2^C$ 在本例中，第一个 Ctrl+C 组合键用于提前终止脚本。因为信号在捕获被移除前已经接收到了，脚本会照旧执行 trap 中指定的命令。捕获随后被移除，再按 Ctrl+C 就能够提前终止脚本了。 以后台模式运行脚本直接在命令行界面运行 shell 脚本有时不怎么方便。一些脚本可能要执行很长一段时间，而你可能不想在命令行界面一直干等着。当脚本在运行时，你没法在终端会话里做别的事情。幸好有个简单的方法可以解决。 在用 ps 命令时，会看到运行在 Linux 系统上的一系列不同进程。显然，所有这些进程都不是运行在你的终端显示器上的。这样的现象被称为在后台（background）运行进程。在后台模式中，进程运行时不会和终端会话上的 STDIN、STDOUT 以及 STDERR 关联。 也可以在 shell 脚本中试试这个特性，允许它们在后台运行而不用占用终端会话。之前简单讲述过后台模式，下面几节将会继续介绍如何在 Linux 系统上以后台模式运行脚本。 后台运行脚本以后台模式运行 shell 脚本非常简单。只要在命令后加个&amp;符就行了。 123456789101112131415$ cat test4.sh#!/bin/bash# Test running in the background#count=1while [ $count -le 10 ]do sleep 1 count=$[ $count + 1 ]done#$$ ./test4.sh &amp;[1] 3231$ 当&amp;符放到命令后时，它会将命令和 bash shell 分离开来，将命令作为系统中的一个独立的后台进程运行。显示的第一行是： 1[1] 3231 方括号中的数字是 shell 分配给后台进程的作业号。下一个数是 Linux 系统分配给进程的进程 ID（PID）。Linux 系统上运行的每个进程都必须有一个唯一的 PID。一旦系统显示了这些内容，新的命令行界面提示符就出现了。你可以回到 shell，而你所执行的命令正在以后台模式安全的运行。这时，你可以在提示符输入新的命令。 当后台进程结束时，它会在终端上显示出一条消息： 1[1] Done ./test4.sh 这表明了作业的作业号以及作业状态（Done），还有用于启动作业的命令。注意，当后台进程运行时，它仍然会使用终端显示器来显示 STDOUT 和 STDERR 消息。 123456789101112131415161718192021222324252627$ cat test5.sh#!/bin/bash# Test running in the background with output#echo &quot;Start the test script&quot;count=1while [ $count -le 5 ]do echo &quot;Loop #$count&quot; sleep 5 count=$[ $count + 1 ]done#echo &quot;Test script is complete&quot;#$$ ./test5.sh &amp;[1] 3275$ Start the test scriptLoop #1Loop #2Loop #3Loop #4Loop #5Test script is complete[1] Done ./test5.sh$ 你会注意到在上面的例子中，脚本 test5.sh 的输出与 shell 提示符混杂在了一起，这也是为什么 Start the test script 会出现在提示符旁边的原因。在显示输出的同时，你仍然可以运行命令。 123456789101112$ ./test5.sh &amp;[1] 3319$ Start the test scriptLoop #1Loop #2Loop #3ls myprog* myprog myprog.c$ Loop #4Loop #5st script is complete[1]+ Done ./test5.sh$$ 当脚本 test5.sh 运行在后台模式时，我们输入了命令 ls myprog*。脚本输出、输入的命令以及命令输出全都混在了一起。真是让人头昏脑胀！最好是将后台运行的脚本的 STDOUT 和 STDERR 进行重定向，避免这种杂乱的输出。 运行多个后台作业可以在命令行提示符下同时启动多个后台作业。 123456789101112$ ./test6.sh &amp;[1] 3568$ This is Test Script #1$ ./test7.sh &amp;[2] 3570$ This is Test Script #2$ ./test8.sh &amp;[3] 3573$ And...another Test script$ ./test9.sh &amp;[4] 3576$ Then...there was one more test script$ 每次启动新作业时，Linux 系统都会为其分配一个新的作业号和 PID。通过 ps 命令，可以看到所有脚本处于运行状态。 12345678910111213$ psPID TTY TIME CMD2431 pts/0 00:00:00 bash3568 pts/0 00:00:00 test6.sh3570 pts/0 00:00:00 test7.sh3573 pts/0 00:00:00 test8.sh3574 pts/0 00:00:00 sleep3575 pts/0 00:00:00 sleep3576 pts/0 00:00:00 test9.sh3577 pts/0 00:00:00 sleep3578 pts/0 00:00:00 sleep3579 pts/0 00:00:00 ps$ 在终端会话中使用后台进程时一定要小心。注意，在 ps 命令的输出中，每一个后台进程都和终端会话（pts&#x2F;0）终端联系在一起。如果终端会话退出，那么后台进程也会随之退出。 本章之前曾经提到过当你要退出终端会话时，要是存在被停止的进程，会出现警告信息。但如果使用了后台进程，只有某些终端仿真器会在你退出终端会话前提醒你还有后台作业在运行。 如果希望运行在后台模式的脚本在登出控制台后能够继续运行，需要借助于别的手段。下一节中我们会讨论怎么来实现。 在非控制台下运行脚本有时你会想在终端会话中启动 shell 脚本，然后让脚本一直以后台模式运行到结束，即使你退出了终端会话。这可以用 nohup 命令来实现。nohup 命令运行了另外一个命令来阻断所有发送给该进程的 SIGHUP 信号。这会在退出终端会话时阻止进程退出。 nohup 命令的格式如下： 1234$ nohup ./test1.sh &amp;[1] 3856$ nohup: ignoring input and appending output to &#x27;nohup.out&#x27;$ 和普通后台进程一样，shell 会给命令分配一个作业号，Linux 系统会为其分配一个 PID 号。区别在于，当你使用 nohup 命令时，如果关闭该会话，脚本会忽略终端会话发过来的 SIGHUP 信号。 由于 nohup 命令会解除终端与进程的关联，进程也就不再同 STDOUT 和 STDERR 联系在一起。为了保存该命令产生的输出，nohup 命令会自动将 STDOUT 和 STDERR 的消息重定向到一个名为 nohup.out 的文件中。 如果使用 nohup 运行了另一个命令，该命令的输出会被追加到已有的 nohup.out 文件中。当运行位于同一个目录中的多个命令时一定要当心，因为所有的输出都会被发送到同一个 nohup.out 文件中，结果会让人摸不清头脑。 nohup.out 文件包含了通常会发送到终端显示器上的所有输出。在进程完成运行后，你可以查看 nohup.out 文件中的输出结果。输出会出现在 nohup.out 文件中，就跟进程在命令行下运行时一样。 作业控制在本章的前面部分，你已经知道了如何用组合键停止 shell 中正在运行的作业。在作业停止后，可以选择是终止还是重启。你可以用 kill 命令终止该进程。要重启停止的进程需要向其发送一个 SIGCONT 信号。 启动、停止、终止以及恢复作业的这些功能统称为作业控制。通过作业控制，就能完全控制 shell 环境中所有进程的运行方式了。本节将介绍用于查看和控制在 shell 中运行的作业的命令。 查看作业作业控制中的关键命令是 jobs 命令。jobs 命令允许查看 shell 当前正在处理的作业。 123456789101112131415161718$ cat test10.sh#!/bin/bash# Test job control#echo &quot;Script Process ID: $$&quot;#count=1while [ $count -le 10 ]do echo &quot;Loop #$count&quot; sleep 10 count=$[ $count + 1 ]done#echo &quot;End of script...&quot;#$ 脚本用$$变量来显示 Linux 系统分配给该脚本的 PID，然后进入循环，每次迭代都休眠 10 秒。可以从命令行中启动脚本，然后使用 Ctrl+Z 组合键来停止脚本。 1234567$ ./test10.shScript Process ID: 1897Loop #1Loop #2^Z[1]+ Stopped ./test10.sh$ 还是使用同样的脚本，利用&amp;将另外一个作业作为后台进程启动。出于简化的目的，脚本的输出被重定向到文件中，避免出现在屏幕上。 123$ ./test10.sh &gt; test10.out &amp;[2] 1917$ jobs 命令可以查看分配给 shell 的作业。jobs 命令会显示这两个已停止&#x2F;运行中的作业，以及它们的作业号和作业中使用的命令。 1234$ jobs[1]+ Stopped ./test10.sh[2]- Running ./test10.sh &gt; test10.out &amp;$ 要想查看作业的 PID，可以在 jobs 命令中加入-l 选项（小写的 L）。 1234$ jobs -l[1]+ 1897 Stopped ./test10.sh[2]- 1917 Running ./test10.sh &gt; test10.out &amp;$ jobs 命令使用一些不同的命令行参数如下 l 列出进程的 PID 以及作业号 n 只列出上次 shell 发出的通知后改变了状态的作业 p 只列出作业的 PID r 只列出运行中的作业 s 只列出已停止的作业 你可能注意到了 jobs 命令输出中的加号和减号。带加号的作业会被当做默认作业。在使用作业控制命令时，如果未在命令行指定任何作业号，该作业会被当成作业控制命令的操作对象。当前的默认作业完成处理后，带减号的作业成为下一个默认作业。任何时候都只有一个带加号的作业和一个带减号的作业，不管 shell 中有多少个正在运行的作业。 下面例子说明了队列中的下一个作业在默认作业移除时是如何成为默认作业的。有 3 个独立的进程在后台被启动。jobs 命令显示出了这些进程、进程的 PID 及其状态。注意，默认进程（带有加号的那个）是最后启动的那个进程，也就是 3 号作业。 123456789101112$ ./test10.sh &gt; test10a.out &amp;[1] 1950$ ./test10.sh &gt; test10b.out &amp;[2] 1952$ ./test10.sh &gt; test10c.out &amp;[3] 1955$$ jobs -l[1] 1950 Running ./test10.sh &gt; test10a.out &amp;[2]- 1952 Running ./test10.sh &gt; test10b.out &amp;[3]+ 1955 Running ./test10.sh &gt; test10c.out &amp;$ 我们调用了 kill 命令向默认进程发送一个 SIGHUP 信号，终止了该作业。在接下来的 jobs 命令输出中，先前带有减号的作业成了现在的默认作业，减号也变成了加号。 1234567891011121314$ kill 1955$ [3]+ Terminated ./test10.sh &gt; test10c.out$$ jobs -l[1]- 1950 Running ./test10.sh &gt; test10a.out &amp;[2]+ 1952 Running ./test10.sh &gt; test10b.out &amp;$$ kill 1952$[2]+ Terminated ./test10.sh &gt; test10b.out$$ jobs -l[1]+ 1950 Running ./test10.sh &gt; test10a.out &amp;$ 尽管将一个后台作业更改为默认进程很有趣，但这并不意味着有用。下一节，你将学习在不用 PID 或作业号的情况下，使用命令和默认进程交互。 重启停止的作业在 bash 作业控制中，可以将已停止的作业作为后台进程或前台进程重启。前台进程会接管你当前工作的终端，所以在使用该功能时要小心了。要以后台模式重启一个作业，可用 bg 命令加上作业号。 12345678910$ ./test11.sh^Z[1]+ Stopped ./test11.sh$$ bg[1]+ ./test11.sh &amp;$$ jobs[1]+ Running ./test11.sh &amp;$ 因为该作业是默认作业（从加号可以看出），只需要使用 bg 命令就可以将其以后台模式重启。注意，当作业被转入后台模式时，并不会列出其 PID。如果有多个作业，你得在 bg 命令后加上作业号。 123456789101112131415$ ./test11.sh^Z[1]+ Stopped ./test11.sh$$ ./test12.sh^Z[2]+ Stopped ./test12.sh$$ bg 2[2]+ ./test12.sh &amp;$$ jobs[1]+ Stopped ./test11.sh[2]- Running ./test12.sh &amp;$ 命令 bg 2 用于将第二个作业置于后台模式。注意，当使用 jobs 命令时，它列出了作业及其状态，即便是默认作业当前并未处于后台模式。 要以前台模式重启作业，可用带有作业号的 fg 命令。 1234$ fg 2./test12.shThis is the script&#x27;s end...$ 由于作业是以前台模式运行的，直到该作业完成后，命令行界面的提示符才会出现。 调整谦让度在多任务操作系统中（Linux 就是），内核负责将 CPU 时间分配给系统上运行的每个进程。调度优先级（scheduling priority）是内核分配给进程的 CPU 时间（相对于其他进程）。在 Linux 系统中，由 shell 启动的所有进程的调度优先级默认都是相同的。 调度优先级是个整数值，从 -20（最高优先级）到+19（最低优先级）。默认情况下，bash shell 以优先级 0 来启动所有进程。 最低值 -20 是最高优先级，而最高值 19 是最低优先级，这太容易记混了。只要记住那句俗语“好人难做”就行了。越是“好”或高的值，获得 CPU 时间的机会越低。 有时你想要改变一个 shell 脚本的优先级。不管是降低它的优先级（这样它就不会从占用其他进程过多的处理能力），还是给予它更高的优先级（这样它就能获得更多的处理时间），你都可以通过 nice 命令做到。 nice 命令nice 命令允许你设置命令启动时的调度优先级。要让命令以更低的优先级运行，只要用 nice 的-n 命令行来指定新的优先级级别。 1234567$ nice -n 10 ./test4.sh &gt; test4.out &amp;[1] 4973$$ ps -p 4973 -o pid,ppid,ni,cmdPID PPID NI CMD4973 4721 10 /bin/bash ./test4.sh$ 注意，必须将 nice 命令和要启动的命令放在同一行中。ps 命令的输出验证了谦让度值（NI 列）已经被调整到了 10。 nice 命令会让脚本以更低的优先级运行。但如果想提高某个命令的优先级，你可能会吃惊。 12345$ nice -n -10 ./test4.sh &gt; test4.out &amp;[1] 4985$ nice: cannot set niceness: Permission denied[1]+ Done nice -n -10 ./test4.sh &gt; test4.out$ nice 命令阻止普通系统用户来提高命令的优先级。注意，指定的作业的确运行了，但是试图使用 nice 命令提高其优先级的操作却失败了。 nice 命令的-n 选项并不是必须的，只需要在破折号后面跟上优先级就行了。 1234567$ nice -10 ./test4.sh &gt; test4.out &amp;[1] 4993$$ ps -p 4993 -o pid,ppid,ni,cmdPID PPID NI CMD4993 4721 10 /bin/bash ./test4.sh$ renice 命令有时你想改变系统上已运行命令的优先级。这正是 renice 命令可以做到的。它允许你指定运行进程的 PID 来改变它的优先级。 renice 命令会自动更新当前运行进程的调度优先级。和 nice 命令一样，renice 命令也有一些限制： 1234567891011121314$ ./test11.sh &amp;[1] 5055$$ ps -p 5055 -o pid,ppid,ni,cmdPID PPID NI CMD5055 4721 0 /bin/bash ./test11.sh$$ renice -n 10 -p 50555055: old priority 0, new priority 10$$ ps -p 5055 -o pid,ppid,ni,cmdPID PPID NI CMD5055 4721 10 /bin/bash ./test11.sh$ 只能对属于你的进程执行 renice 只能通过 renice 降低进程的优先级 root 用户可以通过 renice 来任意调整进程的优先级。 如果想完全控制运行进程，必须以 root 账户身份登录或使用 sudo 命令。 定时运行作业当你开始使用脚本时，可能会想要在某个预设时间运行脚本，这通常是在你不在场的时候。Linux 系统提供了多个在预选时间运行脚本的方法：at 命令和 cron 表。每个方法都使用不同的技术来安排脚本的运行时间和频率。接下来会依次介绍这些方法。 用 at 命令来计划执行作业at 命令允许指定 Linux 系统何时运行脚本。at 命令会将作业提交到队列中，指定 shell 何时运行该作业。at 的守护进程 atd 会以后台模式运行，检查作业队列来运行作业。大多数 Linux 发行版会在启动时运行此守护进程(archlinux 需要安装at包)。 atd 守护进程会检查系统上的一个特殊目录（通常位于&#x2F;var&#x2F;spool&#x2F;atd）来获取用 at 命令提交的作业。默认情况下，atd 守护进程会每 60 秒检查一下这个目录。有作业时，atd 守护进程会检查作业设置运行的时间。如果时间跟当前时间匹配，atd 守护进程就会运行此作业。 后面几节会介绍如何用 at 命令提交要运行的作业以及如何管理这些作业。 at 命令的格式 at 命令的基本格式非常简单： 1at [-f filename] time 默认情况下，at 命令会将 STDIN 的输入放到队列中。你可以用-f 参数来指定用于读取命令（脚本文件）的文件名。time 参数指定了 Linux 系统何时运行该作业。如果你指定的时间已经错过，at 命令会在第二天的那个时间运行指定的作业。在如何指定时间这个问题上，你可以非常灵活。at 命令能识别多种不同的时间格式。 标准的小时和分钟格式，比如 10:15。 AM&#x2F;PM 指示符，比如 10:15 PM。 特定可命名时间，比如 now、noon、midnight 或者 teatime（4 PM）。 除了指定运行作业的时间，也可以通过不同的日期格式指定特定的日期。 标准日期格式，比如 MMDDYY、MM&#x2F;DD&#x2F;YY 或 DD.MM.YY。 文本日期，比如 Jul 4 或 Dec 25，加不加年份均可。 你也可以指定时间增量。 当前时间+25 min 明天 10:15 PM 10:15+7 天 在你使用 at 命令时，该作业会被提交到作业队列（job queue）。作业队列会保存通过 at 命令提交的待处理的作业。针对不同优先级，存在 26 种不同的作业队列。作业队列通常用小写字母 az 和大写字母 AZ 来指代。 在几年前，也可以使用 batch 命令在指定时间执行某个脚本。batch 命令很特别，你可以安排脚本在系统处于低负载时运行。但现在 batch 命令只不过是一个脚本而已（&#x2F;usr&#x2F;bin&#x2F;batch），它会调用 at 命令并将作业提交到 b 队列中。 作业队列的字母排序越高，作业运行的优先级就越低（更高的 nice 值）。默认情况下，at 的作业会被提交到 a 作业队列。如果想以更高优先级运行作业，可以用-q 参数指定不同的队列字母。 获取作业的输出 当作业在 Linux 系统上运行时，显示器并不会关联到该作业。取而代之的是，Linux 系统会将提交该作业的用户的电子邮件地址作为 STDOUT 和 STDERR。任何发到 STDOUT 或 STDERR 的输出都会通过邮件系统发送给该用户。 这里有个在 CentOS 发行版中使用 at 命令安排作业执行的例子。 1234567891011$ cat test13.sh#!/bin/bash# Test using at command#echo &quot;This script ran at $(date +%B%d,%T)&quot;echo sleep 5echo &quot;This is the script&#x27;s end...&quot;#$ at -f test13.sh nowjob 7 at 2015-07-14 12:38$ at 命令会显示分配给作业的作业号以及为作业安排的运行时间。-f 选项指明使用哪个脚本文件，now 指示 at 命令立刻执行该脚本。 使用 e-mail 作为 at 命令的输出极其不便。at 命令利用 sendmail 应用程序来发送邮件。如果你的系统中没有安装 sendmail，那就无法获得任何输出！因此在使用 at 命令时，最好在脚本中对 STDOUT 和 STDERR 进行重定向，如下例所示。 123456789101112131415161718$ cat test13b.sh#!/bin/bash# Test using at command#echo &quot;This script ran at $(date +%B%d,%T)&quot; &gt; test13b.outecho &gt;&gt; test13b.outsleep 5echo &quot;This is the script&#x27;s end...&quot; &gt;&gt; test13b.out#$$ at -M -f test13b.sh nowjob 8 at 2015-07-14 12:48$$ cat test13b.outThis script ran at July14,12:48:18This is the script&#x27;s end...$ 如果不想在 at 命令中使用邮件或重定向，最好加上-M 选项来屏蔽作业产生的输出信息。 列出等待的作业 atq 命令可以查看系统中有哪些作业在等待。 123456789101112131415161718$ at -M -f test13b.sh teatimejob 17 at 2015-07-14 16:00$$ at -M -f test13b.sh tomorrowjob 18 at 2015-07-15 13:03$$ at -M -f test13b.sh 13:30job 19 at 2015-07-14 13:30$$ at -M -f test13b.sh nowjob 20 at 2015-07-14 13:03$$ atq20 2015-07-14 13:03 = Christine18 2015-07-15 13:03 a Christine17 2015-07-14 16:00 a Christine19 2015-07-14 13:30 a Christine$ 作业列表中显示了作业号、系统运行该作业的日期和时间及其所在的作业队列。 删除作业 一旦知道了哪些作业在作业队列中等待，就能用 atrm 命令来删除等待中的作业。 1234567891011$ atq18 2015-07-15 13:03 a Christine17 2015-07-14 16:00 a Christine19 2015-07-14 13:30 a Christine$$ atrm 18$$ atq17 2015-07-14 16:00 a Christine19 2015-07-14 13:30 a Christine$ 只要指定想要删除的作业号就行了。只能删除你提交的作业，不能删除其他人的 安排需要定期执行的脚本用 at 命令在预设时间安排脚本执行非常好用，但如果你需要脚本在每天的同一时间运行或是每周一次、每月一次呢？用不着再使用 at 不断提交作业了，你可以利用 Linux 系统的另一个功能。 Linux 系统使用 cron 程序来安排要定期执行的作业。cron 程序会在后台运行并检查一个特殊的表（被称作 cron 时间表），以获知已安排执行的作业。 cron 时间表 cron 时间表采用一种特别的格式来指定作业何时运行。其格式如下： 1min hour dayofmonth month dayofweek command cron 时间表允许你用特定值、取值范围（比如 1~5）或者是通配符（星号）来指定条目。例如，如果想在每天的 10:15 运行一个命令，可以用 cron 时间表条目： 115 10 * * * command 在 dayofmonth、month 以及 dayofweek 字段中使用了通配符，表明 cron 会在每个月每天的 10:15 执行该命令。要指定在每周一 4:15 PM 运行的命令，可以用下面的条目： 115 16 * * 1 command 可以用三字符的文本值（mon、tue、wed、thu、fri、sat、sun）或数值（0 为周日，6 为周六）来指定 dayofweek 表项。这里还有另外一个例子：在每个月的第一天中午 12 点执行命令。可以用下面的格式： 100 12 1 * * command dayofmonth 表项指定月份中的日期值（1~31）。 聪明的读者可能会问如何设置一个在每个月的最后一天执行的命令，因为你无法设置 dayofmonth 的值来涵盖所有的月份。这个问题困扰着 Linux 和 Unix 程序员，也激发了不少解决办法。常用的方法是加一条使用 date 命令的 if-then 语句来检查明天的日期是不是 01：00 12 * * * if [date +%d -d tomorrow = 01 ] ; then ; command 它会在每天中午 12 点来检查是不是当月的最后一天，如果是，cron 将会运行该命令。 命令列表必须指定要运行的命令或脚本的全路径名。你可以像在普通的命令行中那样，添加任何想要的命令行参数和重定向符号。 115 10 * * * /home/rich/test4.sh &gt; test4out cron 程序会用提交作业的用户账户运行该脚本。因此，你必须有访问该命令和命令中指定的输出文件的权限。 构建 cron 时间表 每个系统用户（包括 root 用户）都可以用自己的 cron 时间表来运行安排好的任务。Linux 提供了 crontab 命令来处理 cron 时间表。要列出已有的 cron 时间表，可以用-l 选项。archlinux 下需要安装 cronie 包 123$ crontab -lno crontab for rich$ 默认情况下，用户的 cron 时间表文件并不存在。要为 cron 时间表添加条目，可以用-e 选项。在添加条目时，crontab 命令会启用一个文本编辑器，使用已有的 cron 时间表作为文件内容（或者是一个空文件，如果时间表不存在的话）。如果想要以指定编辑打开，可以加上 EDITOR 前缀，如EDITOR=vim crontab -e 浏览 cron 目录 如果你创建的脚本对精确的执行时间要求不高，用预配置的 cron 脚本目录会更方便。有 4 个基本目录：hourly、daily、monthly 和 weekly。 123456789$ ls /etc/cron.*ly/etc/cron.daily:/etc/cron.hourly:0anacron/etc/cron.monthly:/etc/cron.weekly: 因此，例如如果脚本需要每天运行一次，只要将脚本复制到 daily 目录，cron 就会每天执行它。 anacron 程序 cron 程序的唯一问题是它假定 Linux 系统是 7×24 小时运行的。除非将 Linux 当成服务器环境来运行，否则此假设未必成立。 如果某个作业在 cron 时间表中安排运行的时间已到，但这时候 Linux 系统处于关机状态，那么这个作业就不会被运行。当系统开机时，cron 程序不会再去运行那些错过的作业。要解决这个问题，许多 Linux 发行版还包含了 anacron 程序。 如果 anacron 知道某个作业错过了执行时间，它会尽快运行该作业。这意味着如果 Linux 系统关机了几天，当它再次开机时，原定在关机期间运行的作业会自动运行。 这个功能常用于进行常规日志维护的脚本。如果系统在脚本应该运行的时间刚好关机，日志文件就不会被整理，可能会变很大。通过 anacron，至少可以保证系统每次启动时整理日志文件 anacron 程序只会处理位于 cron 目录的程序，比如&#x2F;etc&#x2F;cron.monthly。它用时间戳来决定作业是否在正确的计划间隔内运行了。每个 cron 目录都有个时间戳文件，该文件位于&#x2F;var&#x2F;spool&#x2F;anacron。 123$ sudo cat /var/spool/anacron/cron.monthly20150626$ anacron 程序使用自己的时间表（通常位于&#x2F;etc&#x2F;anacrontab）来检查作业目录。 123456789101112131415161718$ sudo cat /etc/anacrontab# /etc/anacrontab: configuration file for anacron# See anacron(8) and anacrontab(5) for details.SHELL=/bin/shPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# the maximal random delay added to the base delay of the jobsRANDOM_DELAY=45# the jobs will be started during the following hours onlySTART_HOURS_RANGE=3-22#period in days delay in minutes job-identifier command1 5 cron.daily nice run-parts /etc/cron.daily7 25 cron.weekly nice run-parts /etc/cron.weekly@monthly 45 cron.monthly nice run-parts /etc/cron.monthly anacron 时间表的基本格式和 cron 时间表略有不同： 1period delay identifier command period 条目定义了作业多久运行一次，以天为单位。anacron 程序用此条目来检查作业的时间戳文件。delay 条目会指定系统启动后 anacron 程序需要等待多少分钟再开始运行错过的脚本。command 条目包含了 run-parts 程序和一个 cron 脚本目录名。run-parts 程序负责运行目录中传给它的任何脚本。 注意，anacron 不会运行位于&#x2F;etc&#x2F;cron.hourly 的脚本。这是因为 anacron 程序不会处理执行时间需求小于一天的脚本。identifier 条目是一种特别的非空字符串，如 cron-weekly。它用于唯一标识日志消息和错误邮件中的作业。 使用新 shell 启动脚本如果每次运行脚本的时候都能够启动一个新的 bash shell（即便只是某个用户启动了一个 bash shell），将会非常的方便。有时候，你希望为 shell 会话设置某些 shell 功能，或者只是为了确保已经设置了某个文件。 回想一下当用户登入 bash shell 时需要运行的启动文件（参见第 6 章）。另外别忘了，不是所有的发行版中都包含这些启动文件。基本上，依照下列顺序所找到的第一个文件会被运行，其余的文件会被忽略 $HOME&#x2F;.bash_profile $HOME&#x2F;.bash_login $HOME&#x2F;.profile 因此，应该将需要在登录时运行的脚本放在上面第一个文件中。每次启动一个新 shell 时，bash shell 都会运行.bashrc 文件。可以这样来验证：在主目录下的.bashrc 文件中加入一条简单的 echo 语句，然后启动一个新 shell。 123456789101112131415$ cat .bashrc# .bashrc# Source global definitionsif [ -f /etc/bashrc ]; then . /etc/bashrcfi# User specific aliases and functionsecho &quot;I&#x27;m in a new shell!&quot;$$ bashI&#x27;m in a new shell!$$ exitexit$ .bashrc 文件通常也是通过某个 bash 启动文件来运行的。因为.bashrc 文件会运行两次：一次是当你登入 bash shell 时，另一次是当你启动一个 bash shell 时。如果你需要一个脚本在两个时刻都得以运行，可以把这个脚本放进该文件中。 函数在编写 shell 脚本时，你经常会发现在多个地方使用了同一段代码。如果只是一小段代码，一般也无关紧要。但要在 shell 脚本中多次重写大块代码段就太累人了。bash shell 提供的用户自定义函数功能可以解决这个问题。可以将 shell 脚本代码放进函数中封装起来，这样就能在脚本中的任何地方多次使用它了。本章将会带你逐步了解如何创建自己的 shell 脚本函数，并演示如何在 shell 脚本应用中使用它们。 函数基础在开始编写较复杂的 shell 脚本时，你会发现自己重复使用了部分能够执行特定任务的代码。这些代码有时很简单，比如显示一条文本消息，或者从脚本用户那里获得一个答案；有时则会比较复杂，需要作为大型处理过程中的一部分被多次使用。在后一类情况下，在脚本中一遍又一遍地编写同样的代码会很烦人。如果能只写一次，随后在脚本中可多次引用这部分代码就好了。 bash shell 提供了这种功能。函数是一个脚本代码块，你可以为其命名并在代码中任何位置重用。要在脚本中使用该代码块时，只要使用所起的函数名就行了（这个过程称为调用函数）。本节将会介绍如何在 shell 脚本中创建和使用函数。 创建函数有两种格式可以用来在 bash shell 脚本中创建函数。第一种格式采用关键字 function，后跟分配给该代码块的函数名。 123function name &#123; commands&#125; name 属性定义了赋予函数的唯一名称。脚本中定义的每个函数都必须有一个唯一的名称。commands 是构成函数的一条或多条 bash shell 命令。在调用该函数时，bash shell 会按命令在函数中出现的顺序依次执行，就像在普通脚本中一样。 在 bash shell 脚本中定义函数的第二种格式更接近于其他编程语言中定义函数的方式。 123name() &#123; commands&#125; 函数名后的空括号表明正在定义的是一个函数。这种格式的命名规则和之前定义 shell 脚本函数的格式一样。 使用函数要在脚本中使用函数，只需要像其他 shell 命令一样，在行中指定函数名就行了。 1234567891011121314151617181920212223242526$ cat test1#!/bin/bash# using a function in a scriptfunction func1 &#123; echo &quot;This is an example of a function&quot;&#125;count=1while [ $count -le 5 ]do func1 count=$[ $count + 1 ]doneecho &quot;This is the end of the loop&quot;func1echo &quot;Now this is the end of the script&quot;$$ ./test1This is an example of a functionThis is an example of a functionThis is an example of a functionThis is an example of a functionThis is an example of a functionThis is the end of the loopThis is an example of a functionNow this is the end of the script$ 每次引用函数名 func1 时，bash shell 会找到 func1 函数的定义并执行你在那里定义的命令。 函数定义不一定非得是 shell 脚本中首先要做的事，但一定要小心。如果在函数被定义前使用函数，你会收到一条错误消息。 12345678910111213141516171819202122232425262728293031$ cat test2#!/bin/bash# using a function located in the middle of a scriptcount=1echo &quot;This line comes before the function definition&quot;function func1 &#123; echo &quot;This is an example of a function&quot;&#125;while [ $count -le 5 ]do func1 count=$[ $count + 1 ]doneecho &quot;This is the end of the loop&quot;func2echo &quot;Now this is the end of the script&quot;function func2 &#123; echo &quot;This is an example of a function&quot;&#125;$$ ./test2This line comes before the function definitionThis is an example of a functionThis is an example of a functionThis is an example of a functionThis is an example of a functionThis is an example of a functionThis is the end of the loop./test2: func2: command not foundNow this is the end of the script$ 第一个函数 func1 的定义出现在脚本中的几条语句之后，这当然没任何问题。当 func1 函数在脚本中被使用时，shell 知道去哪里找它。然而，脚本试图在 func2 函数被定义之前使用它。由于 func2 函数还没有定义，脚本运行函数调用处时，产生了一条错误消息。你也必须注意函数名。记住，函数名必须是唯一的，否则也会有问题。如果你重定义了函数，新定义会覆盖原来函数的定义，这一切不会产生任何错误消息。 123456789101112131415161718$ cat test3#!/bin/bash# testing using a duplicate function namefunction func1 &#123; echo &quot;This is the first definition of the function name&quot;&#125;func1function func1 &#123; echo &quot;This is a repeat of the same function name&quot;&#125;func1echo &quot;This is the end of the script&quot;$$ ./test3This is the first definition of the function nameThis is a repeat of the same function nameThis is the end of the script$ func1 函数最初的定义工作正常，但重新定义该函数后，后续的函数调用都会使用第二个定义。 返回值bash shell 会把函数当作一个小型脚本，运行结束时会返回一个退出状态码。有 3 种不同的方法来为函数生成退出状态码。 默认退出状态码默认情况下，函数的退出状态码是函数中最后一条命令返回的退出状态码。在函数执行结束后，可以用标准变量$?来确定函数的退出状态码。 123456789101112131415161718$ cat test4#!/bin/bash# testing the exit status of a functionfunc1() &#123; echo &quot;trying to display a non-existent file&quot; ls -l badfile&#125;echo &quot;testing the function: &quot;func1 echo&quot;The exit status is: $?&quot;$$ ./test4testing the function:trying to display a non-existent filels: badfile: No such file or directoryThe exit status is: 1$ 函数的退出状态码是 1，这是因为函数中的最后一条命令没有成功运行。但你无法知道函数中其他命令中是否成功运行。看下面的例子。 1234567891011121314151617$ cat test4b#!/bin/bash# testing the exit status of a functionfunc1() &#123; ls -l badfile echo &quot;This was a test of a bad command&quot;&#125;echo &quot;testing the function:&quot;func1echo &quot;The exit status is: $?&quot;$$ ./test4btesting the function:ls: badfile: No such file or directoryThis was a test of a bad commandThe exit status is: 0$ 这次，由于函数最后一条语句 echo 运行成功，该函数的退出状态码就是 0，尽管其中有一条命令并没有正常运行。使用函数的默认退出状态码是很危险的。幸运的是，有几种办法可以解决这个问题。 使用 return 命令bash shell 使用 return 命令来退出函数并返回特定的退出状态码。return 命令允许指定一个整数值来定义函数的退出状态码，从而提供了一种简单的途径来编程设定函数退出状态码。 1234567891011$ cat test5#!/bin/bash# using the return command in a functionfunction dbl &#123; read -p &quot;Enter a value: &quot; value echo &quot;doubling the value&quot; return $[ $value * 2 ]&#125;dblecho &quot;The new value is $?&quot;$ dbl 函数会将$value变量中用户输入的值翻倍，然后用return命令返回结果。脚本用$?变量显示了该值。但当用这种方法从函数中返回值时，要小心了。记住下面两条技巧来避免问题： 记住，函数一结束就取返回值； 记住，退出状态码必须是 0~255。 如果在用$?变量提取函数返回值之前执行了其他命令，函数的返回值就会丢失。记住，$?变量会返回执行的最后一条命令的退出状态码。 第二个问题界定了返回值的取值范围。由于退出状态码必须小于 256，函数的结果必须生成一个小于 256 的整数值。任何大于 256 的值都会产生一个错误值,输出为计算结果对 256 取模。 1234$ ./test5Enter a value: 200doubling the value The new value is 144$ 要返回较大的整数值或者字符串值的话，你就不能用这种返回值的方法了。我们在下一节中将会介绍另一种方法。 使用函数输出正如可以将命令的输出保存到 shell 变量中一样，你也可以对函数的输出采用同样的处理办法。可以用这种技术来获得任何类型的函数输出，并将其保存到变量中： 1result=`dbl` 这个命令会将 dbl 函数的输出赋给$result 变量。下面是在脚本中使用这种方法的例子。 123456789101112131415161718$ cat test5b#!/bin/bash# using the echo to return a valuefunction dbl &#123; read -p &quot;Enter a value: &quot; value echo $[ $value * 2 ]&#125;result=$(dbl)echo &quot;The new value is $result&quot;$$ ./test5bEnter a value: 200The new value is 400$$ ./test5bEnter a value: 1000The new value is 2000$ 新函数会用 echo 语句来显示计算的结果。该脚本会获取 dbl 函数的输出，而不是查看退出状态码。 这个例子中演示了一个不易察觉的技巧。你会注意到 dbl 函数实际上输出了两条消息。read 命令输出了一条简短的消息来向用户询问输入值。bash shell 脚本非常聪明，并不将其作为 STDOUT 输出的一部分，并且忽略掉它。如果你用 echo 语句生成这条消息来向用户查询，那么它会与输出值一起被读进 shell 变量中。 通过这种技术，你还可以返回浮点值和字符串值。这使它成为一种获取函数返回值的强大方法。 在函数中使用变量你可能已经注意到，在上面的 test5 例子中，我们在函数里用了一个叫作$result 的变量来保存处理后的值。在函数中使用变量时，你需要注意它们的定义方式以及处理方式。这是 shell 脚本中常见错误的根源。本节将会介绍一些处理 shell 脚本函数内外变量的方法。 向函数传递参数我们在之前提到过，bash shell 会将函数当作小型脚本来对待。这意味着你可以像普通脚本那样向函数传递参数。函数可以使用标准的参数环境变量来表示命令行上传给函数的参数。例如，函数名会在$0变量中定义，函数命令行上的任何参数都会通过$1、$2等定义。也可以用特殊变量$#来判断传给函数的参数数目。在脚本中指定函数时，必须将参数和函数放在同一行，像这样： 1func1 $value1 10 然后函数可以用参数环境变量来获得参数值。这里有个使用此方法向函数传值的例子。 123456789101112131415161718192021222324252627282930313233$ cat test6#!/bin/bash# passing parameters to a functionfunction addem &#123; if [ $# -eq 0 ] || [ $# -gt 2 ] then echo -1 elif [ $# -eq 1 ] then echo $[ $1 + $1 ] else echo $[ $1 + $2 ] fi&#125;echo -n &quot;Adding 10 and 15: &quot;value=$(addem 10 15)echo $valueecho -n &quot;Let&#x27;s try adding just one number: &quot;value=$(addem 10)echo $valueecho -n &quot;Now trying adding no numbers: &quot;value=$(addem)echo $valueecho -n &quot;Finally, try adding three numbers: &quot;value=$(addem 10 15 20)echo $value$$ ./test6Adding 10 and 15: 25Let&#x27;s try adding just one number: 20Now trying adding no numbers: -1Finally, try adding three numbers: -1$ test6 脚本中的 addem 函数首先会检查脚本传给它的参数数目。如果没有任何参数，或者参数多于两个，addem 会返回值-1。如果只有一个参数，addem 会将参数与自身相加。如果有两个参数，addem 会将它们进行相加。 由于函数使用特殊参数环境变量作为自己的参数值，因此它无法直接获取脚本在命令行中的参数值。下面的例子将会运行失败。 1234567891011121314151617181920$ cat badtest1#!/bin/bash# trying to access script parameters inside a functionfunction badfunc1 &#123; echo $[ $1 * $2 ]&#125;if [ $# -eq 2 ]then value=$(badfunc1) echo &quot;The result is $value&quot;else echo &quot;Usage: badtest1 a b&quot;fi$$ ./badtest1Usage: badtest1 a b$ ./badtest1 10 15./badtest1: * : syntax error: operand expected (error token is &quot;* &quot;)The result is$ 尽管函数也使用了$1 和$2 变量，但它们和脚本主体中的$1 和$2 变量并不相同。要在函数中使用这些值，必须在调用函数时手动将它们传过去。 12345678910111213141516171819$ cat test7#!/bin/bash# trying to access script parameters inside a functionfunction func7 &#123; echo $[ $1 * $2 ]&#125;if [ $# -eq 2 ]then value=$(func7 $1 $2) echo &quot;The result is $value&quot;else echo &quot;Usage: badtest1 a b&quot;fi$$ ./test7Usage: badtest1 a b$ ./test7 10 15The result is 150$ 通过将$1 和$2 变量传给函数，它们就能跟其他变量一样供函数使用了。 在函数中处理变量给 shell 脚本程序员带来麻烦的原因之一就是变量的作用域。作用域是变量可见的区域。函数中定义的变量与普通变量的作用域不同。也就是说，对脚本的其他部分而言，它们是隐藏的。函数使用两种类型的变量： 全局变量 局部变量 下面几节将会介绍这两种类型的变量在函数中的用法。 全局变量 全局变量是在 shell 脚本中任何地方都有效的变量。如果你在脚本的主体部分定义了一个全局变量，那么可以在函数内读取它的值。类似地，如果你在函数内定义了一个全局变量，可以在脚本的主体部分读取它的值。 默认情况下，你在脚本中定义的任何变量都是全局变量。在函数外定义的变量可在函数内正常访问。 1234567891011121314$ cat test8#!/bin/bash# using a global variable to pass a valuefunction dbl &#123; value=$[ $value * 2 ]&#125;read -p &quot;Enter a value: &quot; valuedblecho &quot;The new value is: $value&quot;$$ ./test8Enter a value: 450The new value is: 900$ $value 变量在函数外定义并被赋值。当 dbl 函数被调用时，该变量及其值在函数中都依然有效。如果变量在函数内被赋予了新值，那么在脚本中引用该变量时，新值也依然有效。 但这其实很危险，尤其是如果你想在不同的 shell 脚本中使用函数的话。它要求你清清楚楚地知道函数中具体使用了哪些变量，包括那些用来计算非返回值的变量。这里有个例子可说明事情是如何搞砸的。 12345678910111213141516171819202122$ cat badtest2#!/bin/bash# demonstrating a bad use of variablesfunction func1 &#123; temp=$[ $value + 5 ] result=$[ $temp * 2 ]&#125;temp=4value=6func1echo &quot;The result is $result&quot;if [ $temp -gt $value ]then echo &quot;temp is larger&quot;else echo &quot;temp is smaller&quot;fi$$ ./badtest2The result is 22temp is larger$ 由于函数中用到了$temp 变量，它的值在脚本中使用时受到了影响，产生了意想不到的后果。有个简单的办法可以在函数中解决这个问题，下面将会介绍。 局部变量 无需在函数中使用全局变量，函数内部使用的任何变量都可以被声明成局部变量。要实现这一点，只要在变量声明的前面加上 local 关键字就可以了。 1local temp 也可以在变量赋值语句中使用 local 关键字： 1local temp=$[ $value + 5 ] local 关键字保证了变量只局限在该函数中。如果脚本中在该函数之外有同样名字的变量，那么 shell 将会保持这两个变量的值是分离的。现在你就能很轻松地将函数变量和脚本变量隔离开了，只共享需要共享的变量。 123456789101112131415161718192021$ cat test9#!/bin/bash# demonstrating the local keywordfunction func1 &#123; local temp=$[ $value + 5 ] result=$[ $temp * 2 ]&#125;temp=4value=6func1echo &quot;The result is $result&quot;if [ $temp -gt $value ]then echo &quot;temp is larger&quot;else echo &quot;temp is smaller&quot;fi$$ ./test9 The result is 22temp is smaller$ 现在，在 func1 函数中使用$temp变量时，并不会影响在脚本主体中赋给$temp 变量的值。 数组变量和函数在之前我们讨论了使用数组来在单个变量中保存多个值的高级用法。在函数中使用数组变量值有点麻烦，而且还需要一些特殊考虑。本节将会介绍一种方法来解决这个问题。 向函数传数组参数向脚本函数传递数组变量的方法会有点不好理解。将数组变量当作单个参数传递的话，它不会起作用。 1234567891011121314151617$ cat badtest3#!/bin/bash# trying to pass an array variablefunction testit &#123; echo &quot;The parameters are: $@&quot; thisarray=$1 echo &quot;The received array is $&#123;thisarray[*]&#125;&quot;&#125;myarray=(1 2 3 4 5)echo &quot;The original array is: $&#123;myarray[*]&#125;&quot;testit $myarray$$ ./badtest3The original array is: 1 2 3 4 5The parameters are: 1The received array is 1$ 如果你试图将该数组变量作为函数参数，函数只会取数组变量的第一个值。 要解决这个问题，你必须将该数组变量的值分解成单个的值，然后将这些值作为函数参数使用。在函数内部，可以将所有的参数重新组合成一个新的变量。下面是个具体的例子。 12345678910111213141516$ cat test10#!/bin/bash# array variable to function testfunction testit &#123; local newarray newarray=`echo &quot;$@&quot;` echo &quot;The new array value is: $&#123;newarray[*]&#125;&quot;&#125;myarray=(1 2 3 4 5)echo &quot;The original array is $&#123;myarray[*]&#125;&quot;testit $&#123;myarray[*]&#125;$$ ./test10The original array is 1 2 3 4 5The new array value is: 1 2 3 4 5$ 该脚本用$myarray 变量来保存所有的数组元素，然后将它们都放在函数的命令行上。该函数随后从命令行参数中重建数组变量。在函数内部，数组仍然可以像其他数组一样使用。 1234567891011121314151617181920212223$ cat test11#!/bin/bash# adding values in an arrayfunction addarray &#123; local sum=0 local newarray newarray=($(echo &quot;$@&quot;)) for value in $&#123;newarray[*]&#125; do sum=$[ $sum + $value ] done echo $sum&#125;myarray=(1 2 3 4 5)echo &quot;The original array is: $&#123;myarray[*]&#125;&quot;arg1=$(echo $&#123;myarray[*]&#125;)result=$(addarray $arg1)echo &quot;The result is $result&quot;$$ ./test11The original array is: 1 2 3 4 5The result is 15$ addarray 函数会遍历所有的数组元素，将它们累加在一起。你可以在 myarray 数组变量中放置任意多的值，addarry 函数会将它们都加起来。 从函数返回数组从函数里向 shell 脚本传回数组变量也用类似的方法。函数用 echo 语句来按正确顺序输出单个数组值，然后脚本再将它们重新放进一个新的数组变量中。 1234567891011121314151617181920212223242526$ cat test12#!/bin/bash# returning an array valuefunction arraydblr &#123; local origarray local newarray local elements local i origarray=($(echo &quot;$@&quot;)) newarray=($(echo &quot;$@&quot;)) elements=$[ $# - 1 ] for (( i = 0; i &lt;= $elements; i++ )) &#123; newarray[$i]=$[ $&#123;origarray[$i]&#125; * 2 ] &#125; echo $&#123;newarray[*]&#125;&#125;myarray=(1 2 3 4 5)echo &quot;The original array is: $&#123;myarray[*]&#125;&quot;arg1=$(echo $&#123;myarray[*]&#125;)result=($(arraydblr $arg1))echo &quot;The new array is: $&#123;result[*]&#125;&quot;$$ ./test12The original array is: 1 2 3 4 5The new array is: 2 4 6 8 10 该脚本用$arg1 变量将数组值传给 arraydblr 函数。arraydblr 函数将该数组重组到新的数组变量中，生成该输出数组变量的一个副本。然后对数据元素进行遍历，将每个元素值翻倍，并将结果存入函数中该数组变量的副本。 arraydblr 函数使用 echo 语句来输出每个数组元素的值。脚本用 arraydblr 函数的输出来重新生成一个新的数组变量。 函数递归局部函数变量的一个特性是自成体系。除了从脚本命令行处获得的变量，自成体系的函数不需要使用任何外部资源。 这个特性使得函数可以递归地调用，也就是说，函数可以调用自己来得到结果。通常递归函数都有一个最终可以迭代到的基准值。许多高级数学算法用递归对复杂的方程进行逐级规约，直到基准值定义的那级。 递归算法的经典例子是计算阶乘。一个数的阶乘是该数之前的所有数乘以该数的值。因此，要计算 5 的阶乘，可以执行如下方程： 15! = 1 * 2 * 3 * 4 * 5 = 120 使用递归，方程可以简化成以下形式： 1x! = x * (x-1)! 也就是说，x 的阶乘等于 x 乘以 x-1 的阶乘。这可以用简单的递归脚本表达为： 12345678910function factorial &#123; if [ $1 -eq 1 ] then echo 1 else local temp=$[ $1 - 1 ] local result=`factorial $temp` echo $[ $result * $1 ] fi&#125; 阶乘函数用它自己来计算阶乘的值： 123456789101112131415161718192021$ cat test13#!/bin/bash# using recursionfunction factorial &#123; if [ $1 -eq 1 ] then echo 1 else local temp=$[ $1 - 1 ] local result=`factorial $temp` echo $[ $result * $1 ] fi&#125;read -p &quot;Enter value: &quot; valueresult=$(factorial $value)echo &quot;The factorial of $value is: $result&quot;$$ ./test13Enter value: 5The factorial of 5 is: 120$ 使用阶乘函数很容易。创建了这样的函数后，你可能想把它用在其他脚本中。接下来，我们来看看如何有效地利用函数。 创建库使用函数可以在脚本中省去一些输入工作，这一点是显而易见的。但如果你碰巧要在多个脚本中使用同一段代码呢？显然，为了使用一次而在每个脚本中都定义同样的函数太过麻烦。 有个方法能解决这个问题！bash shell 允许创建函数库文件，然后在多个脚本中引用该库文件。 这个过程的第一步是创建一个包含脚本中所需函数的公用库文件。这里有个叫作 myfuncs 的库文件，它定义了 3 个简单的函数。 1234567891011121314151617$ cat myfuncs# my script functionsfunction addem &#123; echo $[ $1 + $2 ]&#125;function multem &#123; echo $[ $1 * $2 ]&#125;function divem &#123; if [ $2 -ne 0 ] then echo $[ $1 / $2 ] else echo -1 fi&#125;$ 下一步是在用到这些函数的脚本文件中包含 myfuncs 库文件。从这里开始，事情就变复杂了。 问题出在 shell 函数的作用域上。和环境变量一样，shell 函数仅在定义它的 shell 会话内有效。如果你在 shell 命令行界面的提示符下运行 myfuncs shell 脚本，shell 会创建一个新的 shell 并在其中运行这个脚本。它会为那个新 shell 定义这三个函数，但当你运行另外一个要用到这些函数的脚本时，它们是无法使用的。 这同样适用于脚本。如果你尝试像普通脚本文件那样运行库文件，函数并不会出现在脚本中。 123456789101112$ cat badtest4#!/bin/bash# using a library file the wrong way./myfuncsresult=$(addem 10 15)echo &quot;The result is $result&quot;$$ ./badtest4./badtest4: addem: command not foundThe result is$ 使用函数库的关键在于 source 命令。source 命令会在当前 shell 上下文中执行命令，而不是创建一个新 shell。可以用 source 命令来在 shell 脚本中运行库文件脚本。这样脚本就可以使用库中的函数了。 source 命令有个快捷的别名，称作点操作符（dot operator）。要在 shell 脚本中运行 myfuncs 库文件，只需添加下面这行： 1. ./myfuncs 这个例子假定 myfuncs 库文件和 shell 脚本位于同一目录。如果不是，你需要使用相应路径访问该文件。这里有个用 myfuncs 库文件创建脚本的例子。 123456789101112131415161718$ cat test14#!/bin/bash# using functions defined in a library file. ./myfuncsvalue1=10value2=5result1=$(addem $value1 $value2)result2=$(multem $value1 $value2)result3=$(divem $value1 $value2)echo &quot;The result of adding them is: $result1&quot;echo &quot;The result of multiplying them is: $result2&quot;echo &quot;The result of dividing them is: $result3&quot;$$ ./test14The result of adding them is: 15The result of multiplying them is: 50The result of dividing them is: 2$ 该脚本成功地使用了 myfuncs 库文件中定义的函数。 在命令行上使用函数可以用脚本函数来执行一些十分复杂的操作。有时也很有必要在命令行界面的提示符下直接使用这些函数。和在 shell 脚本中将脚本函数当命令使用一样，在命令行界面中你也可以这样做。这个功能很不错，因为一旦在 shell 中定义了函数，你就可以在整个系统中使用它了，无需担心脚本是不是在 PATH 环境变量里。重点在于让 shell 能够识别这些函数。有几种方法可以实现。 在命令行上创建函数因为 shell 会解释用户输入的命令，所以可以在命令行上直接定义一个函数。有两种方法。一种方法是采用单行方式定义函数。 1234$ function divem &#123; echo $[ $1 / $2 ]; &#125;$ divem 100 520$ 当在命令行上定义函数时，你必须记得在每个命令后面加个分号，这样 shell 就能知道在哪里是命令的起止了。 123456$ function doubleit &#123; read -p &quot;Enter value: &quot; value; echo $[ $value * 2 ]; &#125;$$ doubleit Enter value: 2040$ 另一种方法是采用多行方式来定义函数。在定义时，bash shell 会使用次提示符来提示输入更多命令。用这种方法，你不用在每条命令的末尾放一个分号，只要按下回车键就行。 123456$ function multem &#123;&gt; echo $[ $1 * $2 ]&gt; &#125;$ multem 2 510$ 在函数的尾部使用花括号，shell 就会知道你已经完成了函数的定义。 在命令行上创建函数时要特别小心。如果你给函数起了个跟内建命令或另一个命令相同的名字，函数将会覆盖原来的命令。 在.bashrc 文件中定义函数在命令行上直接定义 shell 函数的明显缺点是退出 shell 时，函数就消失了。对于复杂的函数来说，这可是个麻烦事。一个非常简单的方法是将函数定义在一个特定的位置，这个位置在每次启动一个新 shell 的时候，都会由 shell 重新载入。最佳地点就是.bashrc 文件。bash shell 在每次启动时都会在主目录下查找这个文件，不管是交互式 shell 还是从现有 shell 中启动的新 shell。 直接定义函数 可以直接在主目录下的.bashrc 文件中定义函数。许多 Linux 发行版已经在.bashrc 文件中定义了一些东西，所以注意不要误删了。把你写的函数放在文件末尾就行了。这里有个例子。 12345678910$ cat .bashrc# .bashrc# Source global definitionsif [ -r /etc/bashrc ]; then . /etc/bashrcfifunction addem &#123; echo $[ $1 + $2 ]&#125;$ 该函数会在下次启动新 bash shell 时生效。随后你就能在系统上任意地方使用这个函数了。 读取函数文件 只要是在 shell 脚本中，都可以用 source 命令（或者它的别名点操作符）将库文件中的函数添加到你的.bashrc 脚本中。 12345678$ cat .bashrc# .bashrc# Source global definitionsif [ -r /etc/bashrc ]; then . /etc/bashrcfi . /home/rich/libraries/myfuncs$ 要确保库文件的路径名正确，以便 bash shell 能够找到该文件。下次启动 shell 时，库中的所有函数都可在命令行界面下使用了。 1234567$ addem 10 515$ multem 10 550$ divem 10 52$ 更好的是，shell 还会将定义好的函数传给子 shell 进程，这样一来，这些函数就自动能够用于该 shell 会话中的任何 shell 脚本了。你可以写个脚本，试试在不定义或使用 source 的情况下，直接使用这些函数。 1234567891011121314151617$ cat test15#!/bin/bash# using a function defined in the .bashrc filevalue1=10value2=5result1=$(addem $value1 $value2)result2=$(multem $value1 $value2)result3=$(divem $value1 $value2)echo &quot;The result of adding them is: $result1&quot;echo &quot;The result of multiplying them is: $result2&quot;echo &quot;The result of dividing them is: $result3&quot;$$ ./test15The result of adding them is: 15The result of multiplying them is: 50The result of dividing them is: 2$ 甚至都不用对库文件使用 source，这些函数就可以完美地运行在 shell 脚本中。 实例函数的应用绝不仅限于创建自己的函数自娱自乐。在开源世界中，共享代码才是关键，而这一点同样适用于脚本函数。你可以下载大量各式各样的函数，并将其用于自己的应用程序中。本节介绍了如何使用 GNU shtool shell 脚本函数库。shtool 库提供了一些简单的 shell 脚本函数，可以用来完成日常的 shell 功能，例如处理临时文件和目录或者格式化输出显示。在 arch linux 下，可通过如下命令安装： 1yay -S shtool shtool 库提供了大量方便的、可用于 shell 脚本的函数。下面列出了库中可用的函数。 arx 创建归档文件（包含一些扩展功能） echo 显示字符串，并提供了一些扩展构件 fixperm 改变目录树中的文件权限 install 安装脚本或文件 mdate 显示文件或目录的修改时间 mkdir 创建一个或更多目录 mkln 使用相对路径创建链接 mkshadow 创建一棵阴影树 move 带有替换功能的文件移动 ath 处理程序路径 platform 显示平台标识 prop 显示一个带有动画效果的进度条 rotate 转置日志文件 scpp 共享的 C 预处理器 slo 根据库的类别，分离链接器选项 subst 使用 sed 的替换操作 table 以表格的形式显示由字段分隔（field-separated）的数据 tarball 从文件和目录中创建 tar 文件 version 创建版本信息文件 每个 shtool 函数都包含大量的选项和参数，你可以利用它们改变函数的工作方式。更多内容可使用 man 查看。可以在命令行或自己的 shell 脚本中直接使用 shtool 函数。下面是一个在 shell 脚本中使用 platform 函数的例子。 123456$ cat test16#!/bin/bashshtool platform$ ./test16Arch rolling (AMD64)$ platform 函数会返回 Linux 发行版以及系统所使用的 CPU 硬件的相关信息。另一个函数是 prop 函数。它可以使用\\、|、&#x2F;和-字符创建一个旋转的进度条。这是一个非常漂亮的工具，可以告诉 shell 脚本用户目前正在进行一些后台处理工作。要使用 prop 函数，只需要将希望监看的输出管接到 shtool 脚本就行了。 123$ ls –al /usr/bin | shtool prop –p &quot;waiting...&quot;wating......\\$ prop 函数会在处理过程中不停地变换进度条字符。在本例中，输出信息来自于 ls 命令。你能看到多少进度条取决于 CPU 能以多快的速度列出&#x2F;usr&#x2F;bin 中的文件！-p 选项允许你定制输出文本，这段文本会出现在进度条字符之前。好了，尽情享受吧！ 文本编辑工具 sed 和 gawk到目前为止， shell 脚本最常见的一个用途就是处理文本文件。检查日志文件、读取配置文件、处理数据元素，shell 脚本可以帮助我们将文本文件中各种数据的日常处理任务自动化。但仅靠 shell 脚本命令来处理文本文件的内容有点勉为其难。如果想在 shell 脚本中处理任何类型的数据，你得熟悉 Linux 中的 sed 和 gawk 工具。这两个工具能够极大简化需要进行的数据处理任务。 大多数情况，我们使用 vim 这类编辑器处理文本，但有时候，你会发现需要自动处理文本文件，可你又不想动用全副武装的交互式文本编辑器。在这种情况下，有个能够轻松实现自动格式化、插入、修改或删除文本元素的简单命令行编辑器就方便多了。 Linux 系统提供了两个常见的具备上述功能的工具。本节将会介绍 Linux 世界中最广泛使用的两个命令行编辑器：sed 和 gawk。 sed 编辑器sed 编辑器被称作流编辑器（stream editor），和普通的交互式文本编辑器恰好相反。在交互式文本编辑器中（比如 vim），你可以用键盘命令来交互式地插入、删除或替换数据中的文本。流编辑器则会在编辑器处理数据之前基于预先提供的一组规则来编辑数据流。 sed 编辑器可以根据命令来处理数据流中的数据，这些命令要么从命令行中输入，要么存储在一个命令文本文件中。sed 编辑器会执行下列操作。 一次从输入中读取一行数据。 根据所提供的编辑器命令匹配数据。 按照命令修改流中的数据。 将新的数据输出到 STDOUT。 在流编辑器将所有命令与一行数据匹配完毕后，它会读取下一行数据并重复这个过程。在流编辑器处理完流中的所有数据行后，它就会终止。 由于命令是按顺序逐行给出的，sed 编辑器只需对数据流进行一遍处理就可以完成编辑操作。这使得 sed 编辑器要比交互式编辑器快得多，你可以快速完成对数据的自动修改。 sed 命令的格式如下。 1sed options script file 选项允许你修改 sed 命令的行为，可以使用的选项已在下面列出 -e script 在处理输入时，将 script 中指定的命令添加到已有的命令中 -f file 在处理输入时，将 file 中指定的命令添加到已有的命令中 -n 不产生命令输出，使用 print 命令来完成输出 script 参数指定了应用于流数据上的单个命令。如果需要用多个命令，要么使用-e 选项在命令行中指定，要么使用-f 选项在单独的文件中指定。有大量的命令可用来处理数据。我们将会在本章后面介绍一些 sed 编辑器的基本命令，然后在后续章节中会看到另外一些高级命令。 在命令行定义编辑器命令默认情况下，sed 编辑器会将指定的命令应用到 STDIN 输入流上。这样你可以直接将数据通过管道输入 sed 编辑器处理。这里有个简单的示例。 123$ echo &quot;This is a test&quot; | sed &#x27;s/test/big test/&#x27;This is a big test$ 这个例子在 sed 编辑器中使用了 s 命令。s 命令会用斜线间指定的第二个文本字符串来替换第一个文本字符串模式。在本例中是 big test 替换了 test。在运行这个例子时，结果应该立即就会显示出来。这就是使用 sed 编辑器的强大之处。你可以同时对数据做出多处修改，而所消耗的时间却只够一些交互式编辑器启动而已。当然，这个简单的测试只是修改了一行数据。不过就算编辑整个文件，处理速度也相差无几。 123456789101112$ cat data1.txtThe quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog.$$ sed &#x27;s/dog/cat/&#x27; data1.txtThe quick brown fox jumps over the lazy cat.The quick brown fox jumps over the lazy cat.The quick brown fox jumps over the lazy cat.The quick brown fox jumps over the lazy cat.$ sed 命令几乎瞬间就执行完并返回数据。在处理每行数据的同时，结果也显示出来了。可以在 sed 编辑器处理完整个文件之前就开始观察结果。重要的是，要记住，sed 编辑器并不会修改文本文件的数据。它只会将修改后的数据发送到 STDOUT。如果你查看原来的文本文件，它仍然保留着原始数据。 在命令行使用多个编辑器命令要在 sed 命令行上执行多个命令时，只要用-e 选项就可以了。 12345$ sed -e &#x27;s/brown/green/; s/dog/cat/&#x27; data1.txtThe quick green fox jumps over the lazy cat.The quick green fox jumps over the lazy cat.The quick green fox jumps over the lazy cat.The quick green fox jumps over the lazy cat. 两个命令都作用到文件中的每行数据上。命令之间必须用分号隔开，并且在命令末尾和分号之间不能有空格。 如果不想用分号，也可以用 bash shell 中的次提示符来分隔命令。只要输入第一个单引号标示出 sed 程序脚本的起始（sed 编辑器命令列表），bash 会继续提示你输入更多命令，直到输入了标示结束的单引号。 123456789$ sed -e &#x27;&gt; s/brown/green/&gt; s/fox/elephant/&gt; s/dog/cat/&#x27; data1.txtThe quick green elephant jumps over the lazy cat.The quick green elephant jumps over the lazy cat.The quick green elephant jumps over the lazy cat.The quick green elephant jumps over the lazy cat.$ 必须记住，要在封尾单引号所在行结束命令。bash shell 一旦发现了封尾的单引号，就会执行命令。开始后，sed 命令就会将你指定的每条命令应用到文本文件中的每一行上。 从文件中读取编辑器命令最后，如果有大量要处理的 sed 命令，那么将它们放进一个单独的文件中通常会更方便一些。可以在 sed 命令中用-f 选项来指定文件。 1234567891011$ cat script1.seds/brown/green/s/fox/elephant/s/dog/cat/$$ sed -f script1.sed data1.txtThe quick green elephant jumps over the lazy cat.The quick green elephant jumps over the lazy cat.The quick green elephant jumps over the lazy cat.The quick green elephant jumps over the lazy cat.$ 在这种情况下，不用在每条命令后面放一个分号。sed 编辑器知道每行都是一条单独的命令。跟在命令行输入命令一样，sed 编辑器会从指定文件中读取命令，并将它们应用到数据文件中的每一行上。 我们很容易就会把 sed 编辑器脚本文件与 bash shell 脚本文件搞混。为了避免这种情况，可以使用.sed 作为 sed 脚本文件的扩展名。 更多的替换选项你已经懂得了如何用 s 命令（substitute）来在行中替换文本。这个命令还有另外一些选项能让事情变得更为简单。关于替换命令如何替换字符串中所匹配的模式需要注意一点。看看下面这个例子中会出现什么情况。 12345678$ cat data4.txtThis is a test of the test script.This is the second test of the test script.$$ sed &#x27;s/test/trial/&#x27; data4.txtThis is a trial of the test script.This is the second trial of the test script.$ 替换命令在替换多行中的文本时能正常工作，但默认情况下它只替换每行中出现的第一处。要让替换命令能够替换一行中不同地方出现的文本必须使用替换标记（substitution flag）。替换标记会在替换命令字符串之后设置。 1s/pattern/replacement/flags 有 4 种可用的替换标记： 数字，表明新文本将替换第几处模式匹配的地方； g，表明新文本将会替换所有匹配的文本； p，表明原先行的内容要打印出来； w file，将替换的结果写到文件中。 在第一类替换中，可以指定 sed 编辑器用新文本替换第几处模式匹配的地方。 1234$ sed &#x27;s/test/trial/2&#x27; data4.txtThis is a test of the trial script.This is the second test of the trial script.$ 将替换标记指定为 2 的结果就是：sed 编辑器只替换每行中第二次出现的匹配模式。而 g 替换标记使你能替换文本中匹配模式所匹配的每处地方。p 替换标记会打印与替换命令中指定的模式匹配的行。这通常会和 sed 的-n 选项一起使用。 1234567$ cat data5.txtThis is a test line.This is a different line.$$ sed -n &#x27;s/test/trial/p&#x27; data5.txtThis is a trial line.$ -n 选项将禁止 sed 编辑器输出。但 p 替换标记会输出修改过的行。将二者配合使用的效果就是只输出被替换命令修改过的行。 w 替换标记会产生同样的输出，不过会将输出保存到指定文件中。 1234567$ sed &#x27;s/test/trial/w test.txt&#x27; data5.txtThis is a trial line.This is a different line.$$ cat test.txtThis is a trial line.$ sed 编辑器的正常输出是在 STDOUT 中，而只有那些包含匹配模式的行才会保存在指定的输出文件中。 有时你会在文本字符串中遇到一些不太方便在替换模式中使用的字符。Linux 中一个常见的例子就是正斜线（&#x2F;）。替换文件中的路径名会比较麻烦。比如，如果想用 C shell 替换&#x2F;etc&#x2F;passwd 文件中的 bash shell，必须这么做： 1$ sed &#x27;s/\\/bin\\/bash/\\/bin\\/csh/&#x27; /etc/passwd 由于正斜线通常用作字符串分隔符，因而如果它出现在了模式文本中的话，必须用反斜线来转义。这通常会带来一些困惑和错误。要解决这个问题，sed 编辑器允许选择其他字符来作为替换命令中的字符串分隔符： 1$ sed &#x27;s!/bin/bash!/bin/csh!&#x27; /etc/passwd 在这个例子中，感叹号被用作字符串分隔符，这样路径名就更容易阅读和理解了 使用地址默认情况下，在 sed 编辑器中使用的命令会作用于文本数据的所有行。如果只想将命令作用于特定行或某些行，则必须用行寻址（line addressing）。在 sed 编辑器中有两种形式的行寻址： 以数字形式表示行区间 用文本模式来过滤出行 两种形式都使用相同的格式来指定地址： 1[address]command 也可以将特定地址的多个命令分组： 12345address &#123; command1 command2 command3&#125; sed 编辑器会将指定的每条命令作用到匹配指定地址的行上。下面将会演示如何在 sed 编辑器脚本中使用两种寻址方法。 当使用数字方式的行寻址时，可以用行在文本流中的行位置来引用。sed 编辑器会将文本流中的第一行编号为 1，然后继续按顺序为接下来的行分配行号。在命令中指定的地址可以是单个行号，或是用起始行号、逗号以及结尾行号指定的一定区间范围内的行。这里有个 sed 命令作用到指定行号的例子。 123456$ sed &#x27;2s/dog/cat/&#x27; data1.txtThe quick brown fox jumps over the lazy dogThe quick brown fox jumps over the lazy catThe quick brown fox jumps over the lazy dogThe quick brown fox jumps over the lazy dog$ sed 编辑器只修改地址指定的第二行的文本。这里有另一个例子，这次使用了行地址区间。 123456$ sed &#x27;2,3s/dog/cat/&#x27; data1.txtThe quick brown fox jumps over the lazy dogThe quick brown fox jumps over the lazy catThe quick brown fox jumps over the lazy catThe quick brown fox jumps over the lazy dog$ 如果想将命令作用到文本中从某行开始的所有行，可以用特殊地址——美元符。可能你并不知道文本中到底有多少行数据，因此美元符用起来通常很方便。 123456$ sed &#x27;2,$s/dog/cat/&#x27; data1.txtThe quick brown fox jumps over the lazy dogThe quick brown fox jumps over the lazy catThe quick brown fox jumps over the lazy catThe quick brown fox jumps over the lazy cat$ 另一种限制命令作用到哪些行上的方法会稍稍复杂一些。sed 编辑器允许指定文本模式来过滤出命令要作用的行。格式如下： 1/pattern/command 必须用正斜线将要指定的 pattern 封起来。sed 编辑器会将该命令作用到包含指定文本模式的行上。举个例子，如果你想只修改用户 Samantha 的默认 shell，可以使用 sed 命令。 1234567891011$ grep Samantha /etc/passwdSamantha:x:502:502::/home/Samantha:/bin/bash$$ sed &#x27;/Samantha/s/bash/csh/&#x27; /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologin[...]Christine:x:501:501:Christine B:/home/Christine:/bin/bashSamantha:x:502:502::/home/Samantha:/bin/cshTimothy:x:503:503::/home/Timothy:/bin/bash$ 该命令只作用到匹配文本模式的行上。虽然使用固定文本模式能帮你过滤出特定的值，就跟上面这个用户名的例子一样，但其作用难免有限。sed 编辑器在文本模式中采用了一种称为正则表达式（regular expression）的特性来帮助你创建匹配效果更好的模式。正则表达式允许创建高级文本模式匹配表达式来匹配各种数据。这些表达式结合了一系列通配符、特殊字符以及固定文本字符来生成能够匹配几乎任何形式文本的简练模式。正则表达式是 shell 脚本编程中令人心生退意的部分之一，下一章将会详细介绍相关内容。 如果需要在单行上执行多条命令，可以用花括号将多条命令组合在一起。sed 编辑器会处理地址行处列出的每条命令。 123456789$ sed &#x27;2&#123;&gt; s/fox/elephant/&gt; s/dog/cat/&gt; &#125;&#x27; data1.txtThe quick brown fox jumps over the lazy dog.The quick brown elephant jumps over the lazy cat.The quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog.$ 两条命令都会作用到该地址上。当然，也可以在一组命令前指定一个地址区间。sed 编辑器会将所有命令作用到该地址区间内的所有行上。 123456789$ sed &#x27;3,$&#123;&gt; s/brown/green/&gt; s/lazy/active/&gt; &#125;&#x27; data1.txtThe quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog.The quick green fox jumps over the active dog.The quick green fox jumps over the active dog.$ 删除行文本替换命令不是 sed 编辑器唯一的命令。如果需要删除文本流中的特定行，可以用删除命令。删除命令 d 名副其实，它会删除匹配指定寻址模式的所有行。使用该命令时要特别小心，如果你忘记加入寻址模式的话，流中的所有文本行都会被删除。 12345678$ cat data1.txtThe quick brown fox jumps over the lazy dogThe quick brown fox jumps over the lazy dogThe quick brown fox jumps over the lazy dogThe quick brown fox jumps over the lazy dog$$ sed &#x27;d&#x27; data1.txt$ 当和指定地址一起使用时，删除命令显然能发挥出最大的功用。可以从数据流中删除特定的文本行，通过行号指定： 1234567891011$ cat data6.txtThis is line number 1.This is line number 2.This is line number 3.This is line number 4.$$ sed &#x27;3d&#x27; data6.txtThis is line number 1.This is line number 2.This is line number 4.$ 或者通过特定行区间指定： 1234$ sed &#x27;2,3d&#x27; data6.txtThis is line number 1.This is line number 4.$ 或者通过特殊的文件结尾字符： 1234$ sed &#x27;3,$d&#x27; data6.txtThis is line number 1.This is line number 2.$ sed 编辑器的模式匹配特性也适用于删除命令。sed 编辑器会删掉包含匹配指定模式的行。 12345$ sed &#x27;/number 1/d&#x27; data6.txtThis is line number 2.This is line number 3.This is line number 4.$ 记住，sed 编辑器不会修改原始文件。你删除的行只是从 sed 编辑器的输出中消失了。原始文件仍然包含那些“删掉的”行。 也可以使用两个文本模式来删除某个区间内的行，但这么做时要小心。你指定的第一个模式会“打开”行删除功能，第二个模式会“关闭”行删除功能。sed 编辑器会删除两个指定行之间的所有行（包括指定的行）。 123$ sed &#x27;/1/,/3/d&#x27; data6.txtThis is line number 4.$ 除此之外，你要特别小心，因为只要 sed 编辑器在数据流中匹配到了开始模式，删除功能就会打开。这可能会导致意外的结果。 123456789101112$ cat data7.txtThis is line number 1.This is line number 2.This is line number 3.This is line number 4.This is line number 1 again.This is text you want to keep.This is the last line in the file.$$ sed &#x27;/1/,/3/d&#x27; data7.txtThis is line number 4.$ 第二个出现数字“1”的行再次触发了删除命令，因为没有找到停止模式，所以就将数据流中的剩余行全部删除了。当然，如果你指定了一个从未在文本中出现的停止模式，显然会出现另外一个问题。 12$ sed &#x27;/1/,/5/d&#x27; data7.txt$ 因为删除功能在匹配到第一个模式的时候打开了，但一直没匹配到结束模式，所以整个数据流都被删掉了。 插入和附加文本如你所期望的，跟其他编辑器类似，sed 编辑器允许向数据流插入和附加文本行。两个操作的区别可能比较让人费解： 插入（insert）命令（i）会在指定行前增加一个新行； 附加（append）命令（a）会在指定行后增加一个新行。 这两条命令的费解之处在于它们的格式。它们不能在单个命令行上使用。你必须指定是要将行插入还是附加到另一行。格式如下： 12sed &#x27;[address]command\\new line&#x27; new line 中的文本将会出现在 sed 编辑器输出中你指定的位置。记住，当使用插入命令时，文本会出现在数据流文本的前面。 1234$ echo &quot;Test Line 2&quot; | sed &#x27;i\\Test Line 1&#x27;Test Line 1Test Line 2$ 当使用附加命令时，文本会出现在数据流文本的后面。 1234$ echo &quot;Test Line 2&quot; | sed &#x27;a\\Test Line 1&#x27;Test Line 2Test Line 1$ 在命令行界面提示符上使用 sed 编辑器时，你会看到次提示符来提醒输入新的行数据。你必须在该行完成 sed 编辑器命令。一旦你输入了结尾的单引号，bash shell 就会执行该命令。 12345$ echo &quot;Test Line 2&quot; | sed &#x27;i\\&gt; Test Line 1&#x27;Test Line 1Test Line 2$ 这样能够给数据流中的文本前面或后面添加文本，但如果要向数据流内部添加文本呢？要向数据流行内部插入或附加数据，你必须用寻址来告诉 sed 编辑器你想让数据出现在什么位置。可以在用这些命令时只指定一个行地址。可以匹配一个数字行号或文本模式，但不能用地址区间。这合乎逻辑，因为你只能将文本插入或附加到单个行的前面或后面，而不是行区间的前面或后面。下面的例子是将一个新行插入到数据流第三行前。 12345678$ sed &#x27;3i\\&gt; This is an inserted line.&#x27; data6.txtThis is line number 1.This is line number 2.This is an inserted line.This is line number 3.This is line number 4.$ 下面的例子是将一个新行附加到数据流中第三行后。 12345678$ sed &#x27;3a\\&gt; This is an inserted line.&#x27; data6.txtThis is line number 1.This is line number 2.This is line number 3.This is an inserted line.This is line number 4.$ 它使用与插入命令相同的过程，只是将新文本行放到了指定的行号后面。如果你有一个多行数据流，想要将新行附加到数据流的末尾，只要用代表数据最后一行的美元符就可以了。 12345678$ sed &#x27;$a\\&gt; This is an inserted line.&#x27; data6.txtThis is line number 1.This is line number 2.This is line number 3.This is line number 4.This is an inserted line.$ 同样的方法也适用于要在数据流起始位置增加一个新行。只要在第一行之前插入新行即可。要插入或附加多行文本，就必须对要插入或附加的新文本中的每一行使用反斜线，直到最后一行。 12345678910$ sed &#x27;1i\\&gt; This is one line of new text.\\&gt; This is another line of new text.&#x27; data6.txtThis is one line of new text.This is another line of new text.This is line number 1.This is line number 2.This is line number 3.This is line number 4.$ 指定的两行都会被添加到数据流中。 修改行修改（change）命令允许修改数据流中整行文本的内容。它跟插入和附加命令的工作机制一样，你必须在 sed 命令中单独指定新行。 1234567$ sed &#x27;3c\\&gt; This is a changed line of text.&#x27; data6.txtThis is line number 1.This is line number 2.This is a changed line of text.This is line number 4.$ 在这个例子中，sed 编辑器会修改第三行中的文本。也可以用文本模式来寻址。 1234567$ sed &#x27;/number 3/c\\&gt; This is a changed line of text.&#x27; data6.txtThis is line number 1.This is line number 2.This is a changed line of text.This is line number 4.$ 文本模式修改命令会修改它匹配的数据流中的任意文本行。 12345678910111213141516171819$ cat data8.txtThis is line number 1.This is line number 2.This is line number 3.This is line number 4.This is line number 1 again.This is yet another line.This is the last line in the file.$$ sed &#x27;/number 1/c\\&gt; This is a changed line of text.&#x27; data8.txtThis is a changed line of text.This is line number 2.This is line number 3.This is line number 4.This is a changed line of text.This is yet another line.This is the last line in the file.$ 你可以在修改命令中使用地址区间，但结果未必如愿。 123456$ sed &#x27;2,3c\\&gt; This is a new line of text.&#x27; data6.txtThis is line number 1.This is a new line of text.This is line number 4.$ sed 编辑器会用这一行文本来替换数据流中的两行文本，而不是逐一修改这两行文本。 转换命令转换（transform）命令（y）是唯一可以处理单个字符的 sed 编辑器命令。转换命令格式如下。 1[address]y/inchars/outchars/ 转换命令会对 inchars 和 outchars 值进行一对一的映射。inchars 中的第一个字符会被转换为 outchars 中的第一个字符，第二个字符会被转换成 outchars 中的第二个字符。这个映射过程会一直持续到处理完指定字符。如果 inchars 和 outchars 的长度不同，则 sed 编辑器会产生一条错误消息。这里有个使用转换命令的简单例子。 123456789$ sed &#x27;y/123/789/&#x27; data8.txtThis is line number 7.This is line number 8.This is line number 9.This is line number 4.This is line number 7 again.This is yet another line.This is the last line in the file.$ 如你在输出中看到的，inchars 模式中指定字符的每个实例都会被替换成 outchars 模式中相同位置的那个字符。转换命令是一个全局命令，也就是说，它会文本行中找到的所有指定字符自动进行转换，而不会考虑它们出现的位置。 123$ echo &quot;This 1 is a test of 1 try.&quot; | sed &#x27;y/123/456/&#x27;This 4 is a test of 4 try.$ sed 编辑器转换了在文本行中匹配到的字符 1 的两个实例。你无法限定只转换在特定地方出现的字符。 回顾打印之前介绍了如何使用 p 标记和替换命令显示 sed 编辑器修改过的行。另外有 3 个命令也能用来打印数据流中的信息： p 命令用来打印文本行； 等号（&#x3D;）命令用来打印行号； l（小写的 L）命令用来列出行。 跟替换命令中的 p 标记类似，p 命令可以打印 sed 编辑器输出中的一行。如果只用这个命令，也没什么特别的。 1234$ echo &quot;this is a test&quot; | sed &#x27;p&#x27;this is a testthis is a test$ 它所做的就是打印已有的数据文本。打印命令最常见的用法是打印包含匹配文本模式的行。 123456789$ cat data6.txtThis is line number 1.This is line number 2.This is line number 3.This is line number 4.$$ sed -n &#x27;/number 3/p&#x27; data6.txtThis is line number 3.$ 在命令行上用-n 选项，你可以禁止输出其他行，只打印包含匹配文本模式的行。也可以用它来快速打印数据流中的某些行。 1234$ sed -n &#x27;2,3p&#x27; data6.txtThis is line number 2.This is line number 3.$ 如果需要在修改之前查看行，也可以使用打印命令，比如与替换或修改命令一起使用。可以创建一个脚本在修改行之前显示该行。 1234567$ sed -n &#x27;/3/&#123;&gt; p&gt; s/line/test/p&gt; &#125;&#x27; data6.txtThis is line number 3.This is test number 3.$ sed 编辑器命令会查找包含数字 3 的行，然后执行两条命令。首先，脚本用 p 命令来打印出原始行；然后它用 s 命令替换文本，并用 p 标记打印出替换结果。输出同时显示了原来的行文本和新的行文本。 等号命令会打印行在数据流中的当前行号。行号由数据流中的换行符决定。每次数据流中出现一个换行符，sed 编辑器会认为一行文本结束了。 12345678910111213141516$ cat data1.txtThe quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog.The quick brown fox jumps over the lazy dog.$$ sed &#x27;=&#x27; data1.txt1The quick brown fox jumps over the lazy dog.2The quick brown fox jumps over the lazy dog.3The quick brown fox jumps over the lazy dog.4The quick brown fox jumps over the lazy dog.$ sed 编辑器在实际的文本行出现前打印了行号。如果你要在数据流中查找特定文本模式的话，等号命令用起来非常方便。 1234567$ sed -n &#x27;/number 4/&#123;&gt; =&gt; p&gt; &#125;&#x27; data6.txt4This is line number 4.$ 利用-n 选项，你就能让 sed 编辑器只显示包含匹配文本模式的行的行号和文本。 列出（list）命令（l）可以打印数据流中的文本和不可打印的 ASCII 字符。任何不可打印字符要么在其八进制值前加一个反斜线，要么使用标准 C 风格的命名法（用于常见的不可打印字符），比如\\t，来代表制表符。 123456$ cat data9.txtThis line contains tabs.$$ sed -n &#x27;l&#x27; data9.txtThis\\tline\\tcontains\\ttabs.$$ 制表符的位置使用\\t 来显示。行尾的美元符表示换行符。如果数据流包含了转义字符，列出命令会在必要时候用八进制码来显示。 123456$ cat data10.txtThis line contains an escape character.$$ sed -n &#x27;l&#x27; data10.txtThis line contains an escape character. \\a$$ data10.txt 文本文件包含了一个转义控制码来产生铃声。当用 cat 命令来显示文本文件时，你看不到转义控制码，只能听到声音（如果你的音箱打开的话）。但是，利用列出命令，你就能显示出所使用的转义控制码。 使用 sed 处理文件替换命令包含一些可以用于文件的标记。还有一些 sed 编辑器命令也可以实现同样的目标，不需要非得替换文本。 w 命令用来向文件写入行。该命令的格式如下： 1[address]w filename0 filename 可以使用相对路径或绝对路径，但不管是哪种，运行 sed 编辑器的用户都必须有文件的写权限。地址可以是 sed 中支持的任意类型的寻址方式，例如单个行号、文本模式、行区间或文本模式。 下面的例子是将数据流中的前两行打印到一个文本文件中。 12345678910$ sed &#x27;1,2w test.txt&#x27; data6.txtThis is line number 1.This is line number 2.This is line number 3.This is line number 4.$$ cat test.txtThis is line number 1.This is line number 2.$ 当然，如果你不想让行显示到 STDOUT 上，你可以用 sed 命令的-n 选项。如果要根据一些公用的文本值从主文件中创建一份数据文件，比如下面的邮件列表中的，那么 w 命令会非常好用。 123456789101112$ cat data11.txtBlum, R BrowncoatMcGuiness, A AllianceBresnahan, C BrowncoatHarken, C Alliance$$ sed -n &#x27;/Browncoat/w Browncoats.txt&#x27; data11.txt$$ cat Browncoats.txtBlum, R BrowncoatBresnahan, C Browncoat$ sed 编辑器会只将包含文本模式的数据行写入目标文件。 你已经了解了如何在 sed 命令行上向数据流中插入或附加文本。读取（read）命令（r）允许你将一个独立文件中的数据插入到数据流中。读取命令的格式如下： 1[address]r filename filename 参数指定了数据文件的绝对路径或相对路径。你在读取命令中使用地址区间，只能指定单独一个行号或文本模式地址。sed 编辑器会将文件中的文本插入到指定地址后。 123456789101112$ cat data12.txtThis is an added line.This is the second added line.$$ sed &#x27;3r data12.txt&#x27; data6.txtThis is line number 1.This is line number 2.This is line number 3.This is an added line.This is the second added line.This is line number 4.$ sed 编辑器会将数据文件中的所有文本行都插入到数据流中。同样的方法在使用文本模式地址时也适用。 12345678$ sed &#x27;/number 2/r data12.txt&#x27; data6.txtThis is line number 1.This is line number 2.This is an added line.This is the second added line.This is line number 3.This is line number 4.$ 如果你要在数据流的末尾添加文本，只需用美元符地址符就行了。 12345678$ sed &#x27;$r data12.txt&#x27; data6.txtThis is line number 1.This is line number 2.This is line number 3.This is line number 4.This is an added line.This is the second added line.$ 读取命令的另一个很酷的用法是和删除命令配合使用：利用另一个文件中的数据来替换文件中的占位文本。举例来说，假定你有一份套用信件保存在文本文件中： 12345$ cat notice.stdWould the following people:LISTplease report to the ship&#x27;s captain.$ 套用信件将通用占位文本 LIST 放在人物名单的位置。要在占位文本后插入名单，只需读取命令就行了。但这样的话，占位文本仍然会留在输出中。要删除占位文本的话，你可以用删除命令。结果如下： 1234567891011$ sed &#x27;/LIST/&#123;&gt; r data11.txt&gt; d&gt; &#125;&#x27; notice.stdWould the following people:Blum, R BrowncoatMcGuiness, A AllianceBresnahan, C BrowncoatHarken, C Allianceplease report to the ship&#x27;s captain.$ 现在占位文本已经被替换成了数据文件中的名单。 gawk 程序虽然 sed 编辑器是非常方便自动修改文本文件的工具，但其也有自身的限制。通常你需要一个用来处理文件中的数据的更高级工具，它能提供一个类编程环境来修改和重新组织文件中的数据。这正是 gawk 能够做到的。 很多发行版中都没有默认安装 gawk 程序。如果你所用的 Linux 发行版中没有包含 gawk，请自行安装。arch linux 可直接安装包组 base-devel 来使用 gawk gawk 程序是 Unix 中的原始 awk 程序的 GNU 版本。gawk 程序让流编辑迈上了一个新的台阶，它提供了一种编程语言而不只是编辑器命令。在 gawk 编程语言中，你可以做下面的事情： 定义变量来保存数据； 使用算术和字符串操作符来处理数据； 使用结构化编程概念（比如 if-then 语句和循环）来为数据处理增加处理逻辑； 通过提取数据文件中的数据元素，将其重新排列或格式化，生成格式化报告。 gawk 程序的报告生成能力通常用来从大文本文件中提取数据元素，并将它们格式化成可读的报告。其中最完美的例子是格式化日志文件。在日志文件中找出错误行会很难，gawk 程序可以让你从日志文件中过滤出需要的数据元素，然后你可以将其格式化，使得重要的数据更易于阅读。gawk 的强大之处在于程序脚本。可以写脚本来读取文本行的数据，然后处理并显示数据，创建任何类型的输出报告。 基础用法gawk 程序的基本格式如下： 1gawk options program file 如下显示了 gawk 程序的可用选项。命令行选项提供了一个简单的途径来定制 gawk 程序中的功能。我们会在探索 gawk 时进一步了解这些选项。 -F fs 指定行中划分数据字段的字段分隔符 -f file 从指定的文件中读取程序 -v var&#x3D;value 定义 gawk 程序中的一个变量及其默认值 -mf N 指定要处理的数据文件中的最大字段数 -mr N 指定数据文件中的最大数据行数 -W keyword 指定 gawk 的兼容模式或警告等级 gawk 程序脚本用一对花括号来定义。你必须将脚本命令放到两个花括号（{}）中。如果你错误地使用了圆括号来包含 gawk 脚本，就会得到一条类似于下面的错误提示。 123$ gawk &#x27;(print &quot;Hello World!&quot;&#125;&#x27;gawk: (print &quot;Hello World!&quot;&#125;gawk: ^ syntax error 由于 gawk 命令行假定脚本是单个文本字符串，你还必须将脚本放到单引号中。下面的例子在命令行上指定了一个简单的 gawk 程序脚本： 1$ gawk &#x27;&#123;print &quot;Hello World!&quot;&#125;&#x27; 这个程序脚本定义了一个命令：print 命令。这个命令名副其实：它会将文本打印到 STDOUT。如果尝试运行这个命令，你可能会有些失望，因为什么都不会发生。原因在于没有在命令行上指定文件名，所以 gawk 程序会从 STDIN 接收数据。在运行这个程序时，它会一直等待从 STDIN 输入的文本。如果你输入一行文本并按下回车键，gawk 会对这行文本运行一遍程序脚本。跟 sed 编辑器一样，gawk 程序会针对数据流中的每行文本执行程序脚本。由于程序脚本被设为显示一行固定的文本字符串，因此不管你在数据流中输入什么文本，都会得到同样的文本输出。要终止这个 gawk 程序，你必须表明数据流已经结束了。bash shell 提供了一个组合键来生成 EOF（End-of-File）字符。Ctrl+D 组合键会在 bash 中产生一个 EOF 字符。这个组合键能够终止该 gawk 程序并返回到命令行界面提示符下。 使用数据字段变量gawk 的主要特性之一是其处理文本文件中数据的能力。它会自动给一行中的每个数据元素分配一个变量。默认情况下，gawk 会将如下变量分配给它在文本行中发现的数据字段： $0 代表整个文本行； $1 代表文本行中的第 1 个数据字段； $2 代表文本行中的第 2 个数据字段； $n 代表文本行中的第 n 个数据字段。 在文本行中，每个数据字段都是通过字段分隔符划分的。gawk 在读取一行文本时，会用预定义的字段分隔符划分每个数据字段。gawk 中默认的字段分隔符是任意的空白字符（例如空格或制表符）。 在下面的例子中，gawk 程序读取文本文件，只显示第 1 个数据字段的值。 12345678910$ cat data2.txtOne line of test text.Two lines of test text.Three lines of test text.$$ gawk &#x27;&#123;print $1&#125;&#x27; data2.txtOneTwoThree$ 该程序用$1 字段变量来仅显示每行文本的第 1 个数据字段。 如果你要读取采用了其他字段分隔符的文件，可以用-F 选项指定。 1234567891011$ gawk -F: &#x27;&#123;print $1&#125;&#x27; /etc/passwdrootbindaemonadmlpsyncshutdownhaltmail[...] 这个简短的程序显示了系统中密码文件的第 1 个数据字段。由于&#x2F;etc&#x2F;passwd 文件用冒号来分隔数字字段，因而如果要划分开每个数据元素，则必须在 gawk 选项中将冒号指定为字段分隔符。 在程序脚本中使用多个命令如果一种编程语言只能执行一条命令，那么它不会有太大用处。gawk 编程语言允许你将多条命令组合成一个正常的程序。要在命令行上的程序脚本中使用多条命令，只要在命令之间放个分号即可。 123$ echo &quot;My name is Rich&quot; | gawk &#x27;&#123;$4=&quot;Christine&quot;; print $0&#125;&#x27;My name is Christine$ 第一条命令会给字段变量$4 赋值。第二条命令会打印整个数据字段。注意， gawk 程序在输出中已经将原文本中的第四个数据字段替换成了新值。也可以用次提示符一次一行地输入程序脚本命令。 123456$ gawk &#x27;&#123;&gt; $4=&quot;Christine&quot;&gt; print $0&#125;&#x27;My name is RichMy name is Christine$ 在你用了表示起始的单引号后，bash shell 会使用次提示符来提示你输入更多数据。你可以每次在每行加一条命令，直到输入了结尾的单引号。因为没有在命令行中指定文件名，gawk 程序会从 STDIN 中获得数据。当运行这个程序的时候，它会等着读取来自 STDIN 的文本。要退出程序，只需按下 Ctrl+D 组合键来表明数据结束。 从文件中读取程序跟 sed 编辑器一样，gawk 编辑器允许将程序存储到文件中，然后再在命令行中引用。 12345678910111213$ cat script2.gawk&#123;print $1 &quot;&#x27;s home directory is &quot; $6&#125;$$ gawk -F: -f script2.gawk /etc/passwdroot&#x27;s home directory is /rootbin&#x27;s home directory is /bindaemon&#x27;s home directory is /sbinadm&#x27;s home directory is /var/admlp&#x27;s home directory is /var/spool/lpd[...]Christine&#x27;s home directory is /home/ChristineSamantha&#x27;s home directory is /home/Samantha$ script2.gawk 程序脚本会再次使用 print 命令打印&#x2F;etc&#x2F;passwd 文件的主目录数据字段（字段变量$6），以及 userid 数据字段（字段变量$1）可以在程序文件中指定多条命令。要这么做的话，只要一条命令放一行即可，不需要用分号。 12345678910111213141516$ cat script3.gawk&#123;text = &quot;&#x27;s home directory is &quot;print $1 text $6&#125;$$ gawk -F: -f script3.gawk /etc/passwdroot&#x27;s home directory is /rootbin&#x27;s home directory is /bindaemon&#x27;s home directory is /sbinadm&#x27;s home directory is /var/admlp&#x27;s home directory is /var/spool/lpd[...]Christine&#x27;s home directory is /home/Christine Samantha&#x27;s home directory is /home/Samantha$ script3.gawk 程序脚本定义了一个变量来保存 print 命令中用到的文本字符串。注意，gawk 程序在引用变量值时并未像 shell 脚本一样使用美元符。 在处理数据前运行脚本gawk 还允许指定程序脚本何时运行。默认情况下，gawk 会从输入中读取一行文本，然后针对该行的数据执行程序脚本。有时可能需要在处理数据前运行脚本，比如为报告创建标题。BEGIN 关键字就是用来做这个的。它会强制 gawk 在读取数据前执行 BEGIN 关键字后指定的程序脚本。 123$ gawk &#x27;BEGIN &#123;print &quot;Hello World!&quot;&#125;&#x27;Hello World!$ 这次 print 命令会在读取数据前显示文本。但在它显示了文本后，它会快速退出，不等待任何数据。如果想使用正常的程序脚本中处理数据，必须用另一个脚本区域来定义程序。 123456789101112$ cat data3.txtLine 1Line 2Line 3$$ gawk &#x27;BEGIN &#123;print &quot;The data3 File Contents:&quot;&#125;&gt; &#123;print $0&#125;&#x27; data3.txtThe data3 File Contents:Line 1Line 2Line 3$ 在 gawk 执行了 BEGIN 脚本后，它会用第二段脚本来处理文件数据。这么做时要小心，两段脚本仍然被认为是 gawk 命令行中的一个文本字符串。你需要相应地加上单引号。 在处理数据后运行脚本与 BEGIN 关键字类似，END 关键字允许你指定一个程序脚本，gawk 会在读完数据后执行它。 123456789$ gawk &#x27;BEGIN &#123;print &quot;The data3 File Contents:&quot;&#125;&gt; &#123;print $0&#125;&gt; END &#123;print &quot;End of File&quot;&#125;&#x27; data3.txtThe data3 File Contents:Line 1Line 2Line 3End of File$ 当 gawk 程序打印完文件内容后，它会执行 END 脚本中的命令。这是在处理完所有正常数据后给报告添加页脚的最佳方法。 可以将所有这些内容放到一起组成一个漂亮的小程序脚本文件，用它从一个简单的数据文件中创建一份完整的报告。 1234567891011121314$ cat script4.gawk BEGIN &#123;print &quot;The latest list of users and shells&quot;print &quot; UserID \\t Shell&quot;print &quot;-------- \\t -------&quot;FS=&quot;:&quot;&#125;&#123; print $1 &quot; \\t &quot; $7&#125;END &#123;print &quot;This concludes the listing&quot;&#125;$ 这个脚本用 BEGIN 脚本来为报告创建标题。它还定义了一个叫作 FS 的特殊变量。这是定义字段分隔符的另一种方法。这样你就不用依靠脚本用户在命令行选项中定义字段分隔符了。 下面是这个 gawk 程序脚本的输出（有部分删节）。 123456789101112$ gawk -f script4.gawk /etc/passwdThe latest list of users and shellsUserID Shell-------- -------root /bin/bashbin /sbin/nologindaemon /sbin/nologin[...]Christine /bin/bashmysql /bin/bashThis concludes the listing$ 与预想的一样，BEGIN 脚本创建了标题，程序脚本处理特定数据文件（&#x2F;etc&#x2F;passwd）中的信息，END 脚本生成页脚。 这个简单的脚本让你小试了一把 gawk 的强大威力。后续将继续介绍另外一些编写 gawk 脚本时的简单原则，以及一些可用于 gawk 程序脚本中的高级编程概念。学会了它们之后，就算是面对最晦涩的数据文件，你也能够创建出专业范儿的报告。 使用 sed 和 gawk 程序的关键在于了解如何使用正则表达式。正则表达式是为提取和处理文本文件中数据创建定制过滤器的关键。下一章将会深入经常被人们误解的正则表达式世界，并演示如何构建正则表达式来操作各种类型的数据。 正则表达式在 shell 脚本中成功运用 sed 编辑器和 gawk 程序的关键在于熟练使用正则表达式。这可不是件简单的事，从大量数据中过滤出特定数据可能会（而且经常会）很复杂。本章将介绍如何在 sed 编辑器和 gawk 程序中创建正则表达式来过滤出需要的数据。 什么是正则表达式理解正则表达式的第一步在于弄清它们到底是什么。本节将会解释什么是正则表达式并介绍 Linux 如何使用正则表达式。 定义正则表达式是你所定义的模式模板（pattern template），Linux 工具可以用它来过滤文本。Linux 工具（比如 sed 编辑器或 gawk 程序）能够在处理数据时使用正则表达式对数据进行模式匹配。如果数据匹配模式，它就会被接受并进一步处理；如果数据不匹配模式，它就会被滤掉。 正则表达式模式利用通配符来描述数据流中的一个或多个字符。Linux 中有很多场景都可以使用通配符来描述不确定的数据。在本书之前你已经看到过在 Linux 的 ls 命令中使用通配符列出文件和目录的例子。 星号通配符允许你只列出满足特定条件的文件，例如： 123456789$ ls -al da*-rw-r--r-- 1 rich rich 45 Nov 26 12:42 data-rw-r--r-- 1 rich rich 25 Dec 4 12:40 data.tst-rw-r--r-- 1 rich rich 180 Nov 26 12:42 data1-rw-r--r-- 1 rich rich 45 Nov 26 12:44 data2-rw-r--r-- 1 rich rich 73 Nov 27 12:31 data3-rw-r--r-- 1 rich rich 79 Nov 28 14:01 data4-rw-r--r-- 1 rich rich 187 Dec 4 09:45 datatest$ da*参数会让 ls 命令只列出名字以 da 开头的文件。文件名中 da 之后可以有任意多个字符（包括什么也没有）。ls 命令会读取目录中所有文件的信息，但只显示跟通配符匹配的文件的信息。 正则表达式通配符模式的工作原理与之类似。正则表达式模式含有文本或特殊字符，为 sed 编辑器和 gawk 程序定义了一个匹配数据时采用的模板。可以在正则表达式中使用不同的特殊字符来定义特定的数据过滤模式。 正则表达式的类型使用正则表达式最大的问题在于有不止一种类型的正则表达式。Linux 中的不同应用程序可能会用不同类型的正则表达式。这其中包括编程语言（Java、Perl 和 Python）、Linux 实用工具（比如 sed 编辑器、gawk 程序和 grep 工具）以及主流应用（比如 MySQL 和 PostgreSQL 数据库服务器）。 正则表达式是通过正则表达式引擎（regular expression engine）实现的。正则表达式引擎是一套底层软件，负责解释正则表达式模式并使用这些模式进行文本匹配。在 Linux 中，有两种流行的正则表达式引擎： POSIX 基础正则表达式（basic regular expression，BRE）引擎 POSIX 扩展正则表达式（extended regular expression，ERE）引擎 大多数 Linux 工具都至少符合 POSIX BRE 引擎规范，能够识别该规范定义的所有模式符号。遗憾的是，有些工具（比如 sed 编辑器）只符合了 BRE 引擎规范的子集。这是出于速度方面的考虑导致的，因为 sed 编辑器希望能尽可能快地处理数据流中的文本。 POSIX BRE 引擎通常出现在依赖正则表达式进行文本过滤的编程语言中。它为常见模式提供了高级模式符号和特殊符号，比如匹配数字、单词以及按字母排序的字符。gawk 程序用 ERE 引擎来处理它的正则表达式模式。 由于实现正则表达式的方法太多，很难用一个简洁的描述来涵盖所有可能的正则表达式。后续几节将会讨论最常见的正则表达式，并演示如何在 sed 编辑器和 gawk 程序中使用它们。 定义 BRE 模式最基本的 BRE 模式是匹配数据流中的文本字符。本节将会演示如何在正则表达式中定义文本以及会得到什么样的结果。 纯文本前面演示了如何在 sed 编辑器和 gawk 程序中用标准文本字符串来过滤数据。通过下面的例子来复习一下。 12345678$ echo &quot;This is a test&quot; | sed -n &#x27;/test/p&#x27;This is a test$ echo &quot;This is a test&quot; | sed -n &#x27;/trial/p&#x27;$$ echo &quot;This is a test&quot; | gawk &#x27;/test/&#123;print $0&#125;&#x27;This is a test$ echo &quot;This is a test&quot; | gawk &#x27;/trial/&#123;print $0&#125;&#x27;$ 第一个模式定义了一个单词 test。sed 编辑器和 gawk 程序脚本用它们各自的 print 命令打印出匹配该正则表达式模式的所有行。由于 echo 语句在文本字符串中包含了单词 test，数据流文本能够匹配所定义的正则表达式模式，因此 sed 编辑器显示了该行。 第二个模式也定义了一个单词，这次是 trial。因为 echo 语句文本字符串没包含该单词，所以正则表达式模式没有匹配，因此 sed 编辑器和 gawk 程序都没打印该行。 你可能注意到了，正则表达式并不关心模式在数据流中的位置。它也不关心模式出现了多少次。一旦正则表达式匹配了文本字符串中任意位置上的模式，它就会将该字符串传回 Linux 工具。 关键在于将正则表达式模式匹配到数据流文本上。重要的是记住正则表达式对匹配的模式非常挑剔。第一条原则就是：正则表达式模式都区分大小写。这意味着它们只会匹配大小写也相符的模式。 12345$ echo &quot;This is a test&quot; | sed -n &#x27;/this/p&#x27;$$ echo &quot;This is a test&quot; | sed -n &#x27;/This/p&#x27;This is a test$ 第一次尝试没能匹配成功，因为 this 在字符串中并不都是小写，而第二次尝试在模式中使用大写字母，所以能正常工作。 在正则表达式中，你不用写出整个单词。只要定义的文本出现在数据流中，正则表达式就能够匹配。 123$ echo &quot;The books are expensive&quot; | sed -n &#x27;/book/p&#x27;The books are expensive$ 尽管数据流中的文本是 books，但数据中含有正则表达式 book，因此正则表达式模式跟数据匹配。当然，反之正则表达式就不成立了。 12$ echo &quot;The book is expensive&quot; | sed -n &#x27;/books/p&#x27;$ 完整的正则表达式文本并未在数据流中出现，因此匹配失败，sed 编辑器不会显示任何文本。 你也不用局限于在正则表达式中只用单个文本单词，可以在正则表达式中使用空格和数字。 123$ echo &quot;This is line number 1&quot; | sed -n &#x27;/ber 1/p&#x27;This is line number 1$ 在正则表达式中，空格和其他的字符并没有什么区别。 12$ echo &quot;This is line number1&quot; | sed -n &#x27;/ber 1/p&#x27;$ 如果你在正则表达式中定义了空格，那么它必须出现在数据流中。甚至可以创建匹配多个连续空格的正则表达式模式。 123456$ cat data1This is a normal line of text.This is a line with too many spaces.$ sed -n &#x27;/ /p&#x27; data1This is a line with too many spaces.$ 单词间有两个空格的行匹配正则表达式模式。这是用来查看文本文件中空格问题的好办法。 特殊字符在正则表达式模式中使用文本字符时，有些事情值得注意。在正则表达式中定义文本字符时有一些特例。有些字符在正则表达式中有特别的含义。如果要在文本模式中使用这些字符，结果会超出你的意料。 正则表达式识别的特殊字符包括： 1.*[]^$&#123;&#125;\\+?|() 随着本章内容的继续，你会了解到这些特殊字符在正则表达式中有何用处。不过现在只要记住不能在文本模式中单独使用这些字符就行了。果要用某个特殊字符作为文本字符，就必须转义。在转义特殊字符时，你需要在它前面加一个特殊字符来告诉正则表达式引擎应该将接下来的字符当作普通的文本字符。这个特殊字符就是反斜线（\\）。举个例子，如果要查找文本中的美元符，只要在它前面加个反斜线。 12345$ cat data2The cost is $4.00$ sed -n &#x27;/\\$/p&#x27; data2The cost is $4.00$ 由于反斜线是特殊字符，如果要在正则表达式模式中使用它，你必须对其转义，这样就产生了两个反斜线。 123$ echo &quot;\\ is a special character&quot; | sed -n &#x27;/\\\\/p&#x27;\\ is a special character$ 最终，尽管正斜线不是正则表达式的特殊字符，但如果它出现在 sed 编辑器或 gawk 程序的正则表达式中，你就会得到一个错误。 123$ echo &quot;3 / 2&quot; | sed -n &#x27;///p&#x27;sed: -e expression #1, char 2: No previous regular expression$ 要使用正斜线，也需要进行转义。 123$ echo &quot;3 / 2&quot; | sed -n &#x27;/\\//p&#x27;3 / 2$ 现在 sed 编辑器能正确解释正则表达式模式了，一切都很顺利。 锚字符默认情况下，当指定一个正则表达式模式时，只要模式出现在数据流中的任何地方，它就能匹配。有两个特殊字符可以用来将模式锁定在数据流中的行首或行尾。 脱字符（^）定义从数据流中文本行的行首开始的模式。如果模式出现在行首之外的位置，正则表达式模式则无法匹配。要用脱字符，就必须将它放在正则表达式中指定的模式前面。 12345$ echo &quot;The book store&quot; | sed -n &#x27;/^book/p&#x27;$$ echo &quot;Books are great&quot; | sed -n &#x27;/^Book/p&#x27;Books are great$ 脱字符会在每个由换行符决定的新数据行的行首检查模式。 12345678$ cat data3This is a test line.this is another test line.A line that tests this feature.Yet more testing of this$ sed -n &#x27;/^this/p&#x27; data3this is another test line.$ 只要模式出现在新行的行首，脱字符就能够发现它。如果你将脱字符放到模式开头之外的其他位置，那么它就跟普通字符一样，不再是特殊字符了： 123$ echo &quot;This ^ is a test&quot; | sed -n &#x27;/s ^/p&#x27;This ^ is a test$ 由于脱字符出现在正则表达式模式的尾部，sed 编辑器会将它当作普通字符来匹配。 如果指定正则表达式模式时只用了脱字符，就不需要用反斜线来转义。但如果你在模式中先指定了脱字符，随后还有其他一些文本，那么你必须在脱字符前用转义字符。 跟在行首查找模式相反的就是在行尾查找。特殊字符美元符（$）定义了行尾锚点。将这个特殊字符放在文本模式之后来指明数据行必须以该文本模式结尾。 1234$ echo &quot;This is a good book&quot; | sed -n &#x27;/book$/p&#x27;This is a good book$ echo &quot;This book is good&quot; | sed -n &#x27;/book$/p&#x27;$ 使用结尾文本模式的问题在于你必须要留意到底要查找什么。 12$ echo &quot;There are a lot of good books&quot; | sed -n &#x27;/book$/p&#x27;$ 将行尾的单词 book 改成复数形式，就意味着它不再匹配正则表达式模式了，尽管 book 仍然在数据流中。要想匹配，文本模式必须是行的最后一部分。 在一些常见情况下，可以在同一行中将行首锚点和行尾锚点组合在一起使用。在第一种情况中，假定你要查找只含有特定文本模式的数据行。 12345678$ cat data4this is a test of using both anchorsI said this is a testthis is a testI&#x27;m sure this is a test.$ sed -n &#x27;/^this is a test$/p&#x27; data4this is a test$ sed 编辑器忽略了那些不单单包含指定的文本的行。 第二种情况乍一看可能有些怪异，但极其有用。将两个锚点直接组合在一起，之间不加任何文本，这样过滤出数据流中的空白行。考虑下面这个例子。 12345678$ cat data5This is one test line.This is another test line.$ sed &#x27;/^$/d&#x27; data5This is one test line.This is another test line.$ 定义的正则表达式模式会查找行首和行尾之间什么都没有的那些行。由于空白行在两个换行符之间没有文本，刚好匹配了正则表达式模式。sed 编辑器用删除命令 d 来删除匹配该正则表达式模式的行，因此删除了文本中的所有空白行。这是从文档中删除空白行的有效方法。 点号字符特殊字符点号用来匹配除换行符之外的任意单个字符。它必须匹配一个字符，如果在点号字符的位置没有字符，那么模式就不成立。来看一些在正则表达式模式中使用点号字符的例子。 123456789101112$ cat data6This is a test of a line.The cat is sleeping.That is a very nice hat.This test is at line four.at ten o&#x27;clock we&#x27;ll go home.$ sed -n &#x27;/.at/p&#x27;data6The cat is sleeping.That is a very nice hat.This test is at line four.$ 你应该能够明白为什么第一行无法匹配，而第二行和第三行就可以。第四行有点复杂。注意，我们匹配了 at，但在 at 前面并没有任何字符来匹配点号字符。其实是有的！在正则表达式中，空格也是字符，因此 at 前面的空格刚好匹配了该模式。第五行证明了这点，将 at 放在行首就不会匹配该模式了。 字符组点号特殊字符在匹配某个字符位置上的任意字符时很有用。但如果你想要限定待匹配的具体字符呢？在正则表达式中，这称为字符组（character class）。可以定义用来匹配文本模式中某个位置的一组字符。如果字符组中的某个字符出现在了数据流中，那它就匹配了该模式。 使用方括号来定义一个字符组。方括号中包含所有你希望出现在该字符组中的字符。然后你可以在模式中使用整个组，就跟使用其他通配符一样。这需要一点时间来适应，但一旦你适应了，效果可是令人惊叹的。下面是个创建字符组的例子。 1234$ sed -n &#x27;/[ch]at/p&#x27; data6The cat is sleeping.That is a very nice hat.$ 这里用到的数据文件和点号特殊字符例子中的一样，但得到的结果却不一样。这次我们成功滤掉了只包含单词 at 的行。匹配这个模式的单词只有 cat 和 hat。还要注意以 at 开头的行也没有匹配。字符组中必须有个字符来匹配相应的位置。 在不太确定某个字符的大小写时，字符组会非常有用。 12345$ echo &quot;Yes&quot; | sed -n &#x27;/[Yy]es/p&#x27;Yes$ echo &quot;yes&quot; | sed -n &#x27;/[Yy]es/p&#x27;yes$ 可以在单个表达式中用多个字符组。 1234567$ echo &quot;Yes&quot; | sed -n &#x27;/[Yy][Ee][Ss]/p&#x27;Yes$ echo &quot;yEs&quot; | sed -n &#x27;/[Yy][Ee][Ss]/p&#x27;yEs$ echo &quot;yeS&quot; | sed -n &#x27;/[Yy][Ee][Ss]/p&#x27;yeS$ 正则表达式使用了 3 个字符组来涵盖了 3 个字符位置含有大小写的情况。字符组不必只含有字母，也可以在其中使用数字。 123456789$ cat data7This line doesn&#x27;t contain a number.This line has 1 number on it.This line a number 2 on it.This line has a number 4 on it.$ sed -n &#x27;/[0123]/p&#x27; data7This line has 1 number on it.This line a number 2 on it.$ 这个正则表达式模式匹配了任意含有数字 0、1、2 或 3 的行。含有其他数字以及不含有数字的行都会被忽略掉。 可以将字符组组合在一起，以检查数字是否具备正确的格式，比如电话号码和邮编。但当你尝试匹配某种特定格式时，必须小心。这里有个匹配邮编出错的例子。 1234567891011121314$ cat data86063346201223001435322203$ sed -n &#x27;&gt;/[0123456789][0123456789][0123456789][0123456789][0123456789]/p&gt;&#x27; data8606334620122300122203$ 这个结果出乎意料。它成功过滤掉了不可能是邮编的那些过短的数字，因为最后一个字符组没有字符可匹配。但它也通过了那个六位数，尽管我们只定义了 5 个字符组。 记住，正则表达式模式可见于数据流中文本的任何位置。经常有匹配模式的字符之外的其他字符。如果要确保只匹配五位数，就必须将匹配的字符和其他字符分开，要么用空格，要么像这个例子中这样，指明它们就在行首和行尾。 123456789$ sed -n &#x27;&gt; /^[0123456789][0123456789][0123456789][0123456789][0123456789]$/p&gt; &#x27; data8606334620122203$ 现在好多了！本章随后会看到如何进一步进行简化。 字符组的一个极其常见的用法是解析拼错的单词，比如用户表单输入的数据。你可以创建正则表达式来接受数据中常见的拼写错误。 123456789101112$ cat data9I need to have some maintenence done on my car.I&#x27;ll pay that in a seperate invoice.After I pay for the maintenance my car will be as good as new.$ sed -n &#x27;/maint[ea]n[ae]nce/p/sep[ea]r[ea]te/p&#x27; data9I need to have some maintenence done on my car.I&#x27;ll pay that in a seperate invoice.After I pay for the maintenance my car will be as good as new.$ 本例中的两个 sed 打印命令利用正则表达式字符组来帮助找到文本中拼错的单词 maintenance 和 separate。同样的正则表达式模式也能匹配正确拼写的 maintenance。 排除型字符组在正则表达式模式中，也可以反转字符组的作用。可以寻找组中没有的字符，而不是去寻找组中含有的字符。要这么做的话，只要在字符组的开头加个脱字符。 123$ sed -n &#x27;/[^ch]at/p&#x27; data6This test is at line four.$ 通过排除型字符组，正则表达式模式会匹配 c 或 h 之外的任何字符以及文本模式。由于空格字符属于这个范围，它通过了模式匹配。但即使是排除，字符组仍然必须匹配一个字符，所以以 at 开头的行仍然未能匹配模式。 区间你可能注意到了，我之前演示邮编的例子的时候，必须在每个字符组中列出所有可能的数字，这实在有点麻烦。好在有一种便捷的方法可以让人免受这番劳苦。可以用单破折线符号在字符组中表示字符区间。只需要指定区间的第一个字符、单破折线以及区间的最后一个字符就行了。根据 Linux 系统采用的字符集，正则表达式会包括此区间内的任意字符。现在你可以通过指定数字区间来简化邮编的例子。 12345$ sed -n &#x27;/^[0-9][0-9][0-9][0-9][0-9]$/p&#x27; data8606334620145902$ 这样可是节省了不少的键盘输入！每个字符组都会匹配 0~9 的任意数字。如果字母出现在数据中的任何位置，这个模式都将不成立。 同样的方法也适用于字母。 1234$ sed -n &#x27;/[c-h]at/p&#x27; data6The cat is sleeping.That is a very nice hat.$ 新的模式[c-h]at 匹配了首字母在字母 c 和字母 h 之间的单词。这种情况下，只含有单词 at 的行将无法匹配该模式。 还可以在单个字符组指定多个不连续的区间。 1234$ sed -n &#x27;/[a-ch-m]at/p&#x27; data6The cat is sleeping.That is a very nice hat.$ 该字符组允许区间 ac、hm 中的字母出现在 at 文本前，但不允许出现 d~g 的字母。 12$ echo &quot;I&#x27;m getting too fat.&quot; | sed -n &#x27;/[a-ch-m]at/p&#x27;$ 该模式不匹配 fat 文本，因为它没在指定的区间。 特殊的字符组除了定义自己的字符组外，BRE 还包含了一些特殊的字符组，可用来匹配特定类型的字符。下面介绍了可用的 BRE 特殊的字符组。 [[:alpha:]] 匹配任意字母字符，不管是大写还是小写 [[:alnum:]] 匹配任意字母数字字符 09、AZ 或 a~z [[:blank:]] 匹配空格或制表符 [[:digit:]] 匹配 0~9 之间的数字 [[:lower:]] 匹配小写字母字符 a~z [[:upper:]] 匹配任意大写字母字符 A~Z [[:print:]] 匹配任意可打印字符 [[:punct:]] 匹配标点符号 [[:space:]] 匹配任意空白字符：空格、制表符、NL、FF、VT 和 CR 可以在正则表达式模式中将特殊字符组像普通字符组一样使用。 12345678910$ echo &quot;abc&quot; | sed -n &#x27;/[[:digit:]]/p&#x27;$$ echo &quot;abc&quot; | sed -n &#x27;/[[:alpha:]]/p&#x27;abc$ echo &quot;abc123&quot; | sed -n &#x27;/[[:digit:]]/p&#x27;abc123$ echo &quot;This is, a test&quot; | sed -n &#x27;/[[:punct:]]/p&#x27;This is, a test$ echo &quot;This is a test&quot; | sed -n &#x27;/[[:punct:]]/p&#x27;$ 使用特殊字符组可以很方便地定义区间。如可以用[[:digit:]]来代替区间[0-9]。 星号在字符后面放置星号表明该字符必须在匹配模式的文本中出现 0 次或多次。 1234567891011$ echo &quot;ik&quot; | sed -n &#x27;/ie*k/p&#x27;ik$ echo &quot;iek&quot; | sed -n &#x27;/ie*k/p&#x27;iek$ echo &quot;ieek&quot; | sed -n &#x27;/ie*k/p&#x27;ieek$ echo &quot;ieeek&quot; | sed -n &#x27;/ie*k/p&#x27;ieeek$ echo &quot;ieeeek&quot; | sed -n &#x27;/ie*k/p&#x27;ieeeek$ 这个模式符号广泛用于处理有常见拼写错误或在不同语言中有拼写变化的单词。举个例子，如果需要写个可能用在美式或英式英语中的脚本，可以这么写： 12345$ echo &quot;I&#x27;m getting a color TV&quot; | sed -n &#x27;/colou*r/p&#x27;I&#x27;m getting a color TV$ echo &quot;I&#x27;m getting a colour TV&quot; | sed -n &#x27;/colou*r/p&#x27;I&#x27;m getting a colour TV$ 模式中的 u*表明字母 u 可能出现或不出现在匹配模式的文本中。类似地，如果你知道一个单词经常被拼错，你可以用星号来允许这种错误。 12345$ echo &quot;I ate a potatoe with my lunch.&quot; | sed -n &#x27;/potatoe*/p&#x27;I ate a potatoe with my lunch.$ echo &quot;I ate a potato with my lunch.&quot; | sed -n &#x27;/potatoe*/p&#x27;I ate a potato with my lunch.$ 在可能出现的额外字母后面放个星号将允许接受拼错的单词。 另一个方便的特性是将点号特殊字符和星号特殊字符组合起来。这个组合能够匹配任意数量的任意字符。它通常用在数据流中两个可能相邻或不相邻的文本字符串之间。 1234$ echo &quot;this is a regular pattern expression&quot; | sed -n &#x27;&gt; /regular.*expression/p&#x27;this is a regular pattern expression$ 可以使用这个模式轻松查找可能出现在数据流中文本行内任意位置的多个单词。 星号还能用在字符组上。它允许指定可能在文本中出现多次的字符组或字符区间。 1234567891011121314151617$ echo &quot;bt&quot; | sed -n &#x27;/b[ae]*t/p&#x27;bt$ echo &quot;bat&quot; | sed -n &#x27;/b[ae]*t/p&#x27;bat$ echo &quot;bet&quot; | sed -n &#x27;/b[ae]*t/p&#x27;bet$ echo &quot;btt&quot; | sed -n &#x27;/b[ae]*t/p&#x27;btt$$ echo &quot;baat&quot; | sed -n &#x27;/b[ae]*t/p&#x27;baat$ echo &quot;baaeeet&quot; | sed -n &#x27;/b[ae]*t/p&#x27;baaeeet$ echo &quot;baeeaeeat&quot; | sed -n &#x27;/b[ae]*t/p&#x27;baeeaeeat$ echo &quot;baakeeet&quot; | sed -n &#x27;/b[ae]*t/p&#x27;$ 只要 a 和 e 字符以任何组合形式出现在 b 和 t 字符之间（就算完全不出现也行），模式就能够匹配。如果出现了字符组之外的字符，该模式匹配就会不成立。 扩展正则表达式POSIX ERE 模式包括了一些可供 Linux 应用和工具使用的额外符号。gawk 程序能够识别 ERE 模式，但 sed 编辑器不能。 记住，sed 编辑器和 gawk 程序的正则表达式引擎之间是有区别的。gawk 程序可以使用大多数扩展正则表达式模式符号，并且能提供一些额外过滤功能，而这些功能都是 sed 编辑器所不具备的。但正因为如此，gawk 程序在处理数据流时通常才比较慢。 本节将介绍可用在 gawk 程序脚本中的较常见的 ERE 模式符号。 问号问号类似于星号，不过有点细微的不同。问号表明前面的字符可以出现 0 次或 1 次，但只限于此。它不会匹配多次出现的字符。 12345678$ echo &quot;bt&quot; | gawk &#x27;/be?t/&#123;print $0&#125;&#x27;bt$ echo &quot;bet&quot; | gawk &#x27;/be?t/&#123;print $0&#125;&#x27;bet$ echo &quot;beet&quot; | gawk &#x27;/be?t/&#123;print $0&#125;&#x27;$$ echo &quot;beeet&quot; | gawk &#x27;/be?t/&#123;print $0&#125;&#x27;$ 如果字符 e 并未在文本中出现，或者它只在文本中出现了 1 次，那么模式会匹配。 与星号一样，你可以将问号和字符组一起使用。 1234567891011121314$ echo &quot;bt&quot; | gawk &#x27;/b[ae]?t/&#123;print $0&#125;&#x27;bt$ echo &quot;bat&quot; | gawk &#x27;/b[ae]?t/&#123;print $0&#125;&#x27;bat$ echo &quot;bot&quot; | gawk &#x27;/b[ae]?t/&#123;print $0&#125;&#x27;$$ echo &quot;bet&quot; | gawk &#x27;/b[ae]?t/&#123;print $0&#125;&#x27;bet$ echo &quot;baet&quot; | gawk &#x27;/b[ae]?t/&#123;print $0&#125;&#x27;$$ echo &quot;beat&quot; | gawk &#x27;/b[ae]?t/&#123;print $0&#125;&#x27;$$ echo &quot;beet&quot; | gawk &#x27;/b[ae]?t/&#123;print $0&#125;&#x27;$ 如果字符组中的字符出现了 0 次或 1 次，模式匹配就成立。但如果两个字符都出现了，或者其中一个字符出现了 2 次，模式匹配就不成立。 加号加号是类似于星号的另一个模式符号，但跟问号也有不同。加号表明前面的字符可以出现 1 次或多次，但必须至少出现 1 次。如果该字符没有出现，那么模式就不会匹配。 12345678$ echo &quot;beeet&quot; | gawk &#x27;/be+t/&#123;print $0&#125;&#x27;beeet$ echo &quot;beet&quot; | gawk &#x27;/be+t/&#123;print $0&#125;&#x27;beet$ echo &quot;bet&quot; | gawk &#x27;/be+t/&#123;print $0&#125;&#x27;bet$ echo &quot;bt&quot; | gawk &#x27;/be+t/&#123;print $0&#125;&#x27;$ 如果字符 e 没有出现，模式匹配就不成立。加号同样适用于字符组，与星号和问号的使用方式相同。 12345678910111213$ echo &quot;bt&quot; | gawk &#x27;/b[ae]+t/&#123;print $0&#125;&#x27;$$ echo &quot;bat&quot; | gawk &#x27;/b[ae]+t/&#123;print $0&#125;&#x27;bat$ echo &quot;bet&quot; | gawk &#x27;/b[ae]+t/&#123;print $0&#125;&#x27;bet$ echo &quot;beat&quot; | gawk &#x27;/b[ae]+t/&#123;print $0&#125;&#x27;beat$ echo &quot;beet&quot; | gawk &#x27;/b[ae]+t/&#123;print $0&#125;&#x27;beet$ echo &quot;beeat&quot; | gawk &#x27;/b[ae]+t/&#123;print $0&#125;&#x27;beeat$ 这次如果字符组中定义的任一字符出现了，文本就会匹配指定的模式。 使用花括号ERE 中的花括号允许你为可重复的正则表达式指定一个上限。这通常称为间隔（interval）。可以用两种格式来指定区间。 正则表达式准确出现 m 次。 m, n：正则表达式至少出现 m 次，至多 n 次。 这个特性可以精确调整字符或字符集在模式中具体出现的次数。 如果你的 gawk 版本过老，gawk 程序不会识别正则表达式间隔。必须额外指定 gawk 程序的–re- interval 命令行选项才能识别正则表达式间隔。 这里有个使用简单的单值间隔的例子。 123456$ echo &quot;bt&quot; | gawk --re-interval &#x27;/be&#123;1&#125;t/&#123;print $0&#125;&#x27;$$ echo &quot;bet&quot; | gawk --re-interval &#x27;/be&#123;1&#125;t/&#123;print $0&#125;&#x27;bet$ echo &quot;beet&quot; | gawk --re-interval &#x27;/be&#123;1&#125;t/&#123;print $0&#125;&#x27;$ 通过指定间隔为 1，限定了该字符在匹配模式的字符串中出现的次数。如果该字符出现多次，模式匹配就不成立。 很多时候，同时指定下限和上限也很方便。 12345678$ echo &quot;bt&quot; | gawk --re-interval &#x27;/be&#123;1,2&#125;t/&#123;print $0&#125;&#x27;$$ echo &quot;bet&quot; | gawk --re-interval &#x27;/be&#123;1,2&#125;t/&#123;print $0&#125;&#x27;bet$ echo &quot;beet&quot; | gawk --re-interval &#x27;/be&#123;1,2&#125;t/&#123;print $0&#125;&#x27;beet$ echo &quot;beeet&quot; | gawk --re-interval &#x27;/be&#123;1,2&#125;t/&#123;print $0&#125;&#x27;$ 在这个例子中，字符 e 可以出现 1 次或 2 次，这样模式就能匹配；否则，模式无法匹配 间隔模式匹配同样适用于字符组。 12345678910111213141516$ echo &quot;bt&quot; | gawk --re-interval &#x27;/b[ae]&#123;1,2&#125;t/&#123;print $0&#125;&#x27;$$ echo &quot;bat&quot; | gawk --re-interval &#x27;/b[ae]&#123;1,2&#125;t/&#123;print $0&#125;&#x27;bat$ echo &quot;bet&quot; | gawk --re-interval &#x27;/b[ae]&#123;1,2&#125;t/&#123;print $0&#125;&#x27;bet$ echo &quot;beat&quot; | gawk --re-interval &#x27;/b[ae]&#123;1,2&#125;t/&#123;print $0&#125;&#x27;beat$ echo &quot;beet&quot; | gawk --re-interval &#x27;/b[ae]&#123;1,2&#125;t/&#123;print $0&#125;&#x27;beet$ echo &quot;beeat&quot; | gawk --re-interval &#x27;/b[ae]&#123;1,2&#125;t/&#123;print $0&#125;&#x27;$$ echo &quot;baeet&quot; | gawk --re-interval &#x27;/b[ae]&#123;1,2&#125;t/&#123;print $0&#125;&#x27;$$ echo &quot;baeaet&quot; | gawk --re-interval &#x27;/b[ae]&#123;1,2&#125;t/&#123;print $0&#125;&#x27;$ 如果字母 a 或 e 在文本模式中只出现了 1~2 次，则正则表达式模式匹配；否则，模式匹配失败。 管道符号管道符号允许你在检查数据流时，用逻辑 OR 方式指定正则表达式引擎要用的两个或多个模式。如果任何一个模式匹配了数据流文本，文本就通过测试。如果没有模式匹配，则数据流文本匹配失败。 使用管道符号的格式如下： 1expr1|expr2|... 这里有个例子。 123456$ echo &quot;The cat is asleep&quot; | gawk &#x27;/cat|dog/&#123;print $0&#125;&#x27;The cat is asleep$ echo &quot;The dog is asleep&quot; | gawk &#x27;/cat|dog/&#123;print $0&#125;&#x27;The dog is asleep$ echo &quot;The sheep is asleep&quot; | gawk &#x27;/cat|dog/&#123;print $0&#125;&#x27;$ 这个例子会在数据流中查找正则表达式 cat 或 dog。正则表达式和管道符号之间不能有空格，否则它们也会被认为是正则表达式模式的一部分。管道符号两侧的正则表达式可以采用任何正则表达式模式（包括字符组）来定义文本。 123$ echo &quot;He has a hat.&quot; | gawk &#x27;/[ch]at|dog/&#123;print $0&#125;&#x27;He has a hat.$ 这个例子会匹配数据流文本中的 cat、hat 或 dog。 圆括号正则表达式模式也可以用圆括号进行分组。当你将正则表达式模式分组时，该组会被视为一个标准字符。可以像对普通字符一样给该组使用特殊字符。举个例子： 12345$ echo &quot;Sat&quot; | gawk &#x27;/Sat(urday)?/&#123;print $0&#125;&#x27;Sat$ echo &quot;Saturday&quot; | gawk &#x27;/Sat(urday)?/&#123;print $0&#125;&#x27;Saturday$ 结尾的 urday 分组以及问号，使得模式能够匹配完整的 Saturday 或缩写 Sat。将分组和管道符号一起使用来创建可能的模式匹配组是很常见的做法。 123456789101112$ echo &quot;cat&quot; | gawk &#x27;/(c|b)a(b|t)/&#123;print $0&#125;&#x27;cat$ echo &quot;cab&quot; | gawk &#x27;/(c|b)a(b|t)/&#123;print $0&#125;&#x27;cab$ echo &quot;bat&quot; | gawk &#x27;/(c|b)a(b|t)/&#123;print $0&#125;&#x27;bat$ echo &quot;bab&quot; | gawk &#x27;/(c|b)a(b|t)/&#123;print $0&#125;&#x27;bab$ echo &quot;tab&quot; | gawk &#x27;/(c|b)a(b|t)/&#123;print $0&#125;&#x27;$$ echo &quot;tac&quot; | gawk &#x27;/(c|b)a(b|t)/&#123;print $0&#125;&#x27;$ 模式(c|b)a(b|t)会匹配第一组中字母的任意组合以及第二组中字母的任意组合 正则表达式实战现在你已经了解了使用正则表达式模式的规则和一些简单的例子，该把理论用于实践了。随后几节将会演示 shell 脚本中常见的一些正则表达式例子。 目录文件计数让我们先看一个 shell 脚本，它会对 PATH 环境变量中定义的目录里的可执行文件进行计数。要这么做的话，首先你得将 PATH 变量解析成单独的目录名。前面介绍过如何显示 PATH 环境变量。 12$ echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/ local/games$ 根据 Linux 系统上应用程序所处的位置，PATH 环境变量会有所不同。关键是要意识到 PATH 中的每个路径由冒号分隔。要获取可在脚本中使用的目录列表，就必须用空格来替换冒号。现在你会发现 sed 编辑器用一条简单表达式就能完成替换工作。 123$ echo $PATH | sed &#x27;s/:/ /g&#x27;/usr/local/sbin /usr/local/bin /usr/sbin /usr/bin /sbin /bin /usr/games /usr/local/games$ 分离出目录之后，你就可以使用标准 for 语句中来遍历每个目录。 12345mypath=$(echo $PATH | sed &#x27;s/:/ /g&#x27;)for directory in $mypathdo ...done 一旦获得了单个目录，就可以用 ls 命令来列出每个目录中的文件，并用另一个 for 语句来遍历每个文件，为文件计数器增值。这个脚本的最终版本如下。 123456789101112131415$ cat countfiles#!/bin/bash# count number of files in your PATHmypath=$(echo $PATH | sed &#x27;s/:/ /g&#x27;)count=0for directory in $mypathdo check=$(ls $directory) for item in $check do count=$[ $count + 1 ] done echo &quot;$directory - $count&quot; count=0done 12345678910$ ./countfiles/usr/local/sbin - 0/usr/local/bin - 2/usr/sbin - 213/usr/bin - 1427/sbin - 186/bin - 152/usr/games - 5/usr/local/games – 0$ 现在我们开始体会到正则表达式背后的强大之处了！ 验证电话号码前面的例子演示了在处理数据时，如何将简单的正则表达式和 sed 配合使用来替换数据流中的字符。正则表达式通常用于验证数据，确保脚本中数据格式的正确性。一个常见的数据验证应用就是检查电话号码。数据输入表单通常会要求填入电话号码，而用户输入格式错误的电话号码是常有的事。在美国，电话号码有几种常见的形式： 1234(123)456-7890(123) 456-7890123-456-7890123.456.7890 这样用户在表单中输入的电话号码就有 4 种可能。正则表达式必须足够强大，才能处理每一种情况。 在构建正则表达式时，最好从左手边开始，然后构建用来匹配可能遇到的字符的模式。在这个例子中，电话号码中可能有也可能没有左圆括号。这可以用如下模式来匹配： 1^\\(? 脱字符用来表明数据的开始。由于左圆括号是个特殊字符，因此必须将它转义成普通字符。问号表明左圆括号可能出现，也可能不出现。紧接着就是 3 位区号。在美国，区号以数字 2 开始（没有以数字 0 或 1 开始的区号），最大可到 9。要匹配区号，可以用如下模式。 1[2-9][0-9]&#123;2&#125; 这要求第一个字符是 2~9 的数字，后跟任意两位数字。在区号后面，收尾的右圆括号可能存在，也可能不存在。 1\\)? 在区号后，存在如下可能：有一个空格，没有空格，有一条单破折线或一个点。你可以对它们使用管道符号，并用圆括号进行分组。 1(| |-|\\.) 第一个管道符号紧跟在左圆括号后，用来匹配没有空格的情形。你必须将点字符转义，否则它会被解释成可匹配任意字符。紧接着是 3 位电话交换机号码。这里没什么需要特别注意的。 1[0-9]&#123;3&#125; 在电话交换机号码之后，你必须匹配一个空格、一条单破折线或一个点。 1( |-|\\.) 最后，必须在字符串尾部匹配 4 位本地电话分机号。 1[0-9]&#123;4&#125;$ 完整的模式如下。 1^\\(?[2-9][0-9]&#123;2&#125;\\)?(| |-|\\.)[0-9]&#123;3&#125;( |-|\\.)[0-9]&#123;4&#125;$ 你可以在 gawk 程序中用这个正则表达式模式来过滤掉不符合格式的电话号码。现在你只需要在 gawk 程序中创建一个使用该正则表达式的简单脚本，然后用这个脚本来过滤你的电话薄。脚本如下,可以将电话号码重定向到脚本来处理。 12345$ cat isphone#!/bin/bash# script to filter out bad phone numbersgawk --re-interval &#x27;/^\\(?[2-9][0-9]&#123;2&#125;\\)?(| |-|\\.)[0-9]&#123;3&#125;( |-|\\.)[0-9]&#123;4&#125;$/&#123;print $0&#125;&#x27;$ 123456$ echo &quot;317-555-1234&quot; | ./isphone317-555-1234$ echo &quot;000-555-1234&quot; | ./isphone$ echo &quot;312 555-1234&quot; | ./isphone312 555-1234$ 或者也可以将含有电话号码的整个文件重定向到脚本来过滤掉无效的号码。 123456789101112131415$ cat phonelist000-000-0000123-456-7890212-555-1234(317)555-1234(202) 555-9876335231234567890234.123.4567$ cat phonelist | ./isphone212-555-1234(317)555-1234(202) 555-9876234.123.4567$ 只有匹配该正则表达式模式的有效电话号码才会出现。 解析邮件地址如今这个时代，电子邮件地址已经成为一种重要的通信方式。验证邮件地址成为脚本程序员的一个不小的挑战，因为邮件地址的形式实在是千奇百怪。邮件地址的基本格式为： 1username@hostname username 值可用字母数字字符以及以下特殊字符： 点号 单破折线 加号 下划线 在有效的邮件用户名中，这些字符可能以任意组合形式出现。邮件地址的 hostname 部分由一个或多个域名和一个服务器名组成。服务器名和域名也必须遵照严格的命名规则，只允许字母数字字符以及以下特殊字符： 点号 下划线 服务器名和域名都用点分隔，先指定服务器名，紧接着指定子域名，最后是后面不带点号的顶级域名。顶级域名的数量在过去十分有限，正则表达式模式编写者会尝试将它们都加到验证模式中。然而遗憾的是，随着互联网的发展，可用的顶级域名也增多了。这种方法已经不再可行。从左侧开始构建这个正则表达式模式。我们知道，用户名中可以有多个有效字符。这个相当容易。 1^([a-zA-Z0-9_\\-\\.\\+]+)@ 这个分组指定了用户名中允许的字符，加号表明必须有至少一个字符。下一个字符很明显是@，没什么意外的。 hostname 模式使用同样的方法来匹配服务器名和子域名。 1([a-zA-Z0-9_\\-\\.]+) 这个模式可以匹配文本: 123serverserver.subdomainserver.subdomain.subdomain 对于顶级域名，有一些特殊的规则。顶级域名只能是字母字符，必须不少于二个字符（国家或地区代码中使用），并且长度上不得超过五个字符。下面就是顶级域名用的正则表达式模式。 1\\.([a-zA-Z]&#123;2,5&#125;)$ 将整个模式放在一起会生成如下模式。 1^([a-zA-Z0-9_\\-\\.\\+]+)@([a-zA-Z0-9_\\-\\.]+)\\.([a-zA-Z]&#123;2,5&#125;)$ 这个模式会从数据列表中过滤掉那些格式不正确的邮件地址。现在可以创建脚本来实现这个正则表达式了。 12345678910111213141516171819$ echo &quot;rich@here.now&quot; | ./isemailrich@here.now$ echo &quot;rich@here.now.&quot; | ./isemail$$echo &quot;rich@here.n&quot; | ./isemail$$ echo &quot;rich@here-now&quot; | ./isemail$$ echo &quot;rich.blum@here.now&quot; | ./isemailrich.blum@here.now$ echo &quot;rich_blum@here.now&quot; | ./isemailrich_blum@here.now$ echo &quot;rich/blum@here.now&quot; | ./isemail$$ echo &quot;rich#blum@here.now&quot; | ./isemail$$ echo &quot;rich*blum@here.now&quot; | ./isemail$","categories":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/categories/Arch/"}],"tags":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/tags/Arch/"},{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"}]},{"title":"Linux 系统操作进阶（知其所以然）","slug":"Linux 系统操作进阶（知其所以然）","date":"2025-03-13T02:00:00.000Z","updated":"2025-03-13T10:04:11.349Z","comments":true,"path":"Linux 系统操作进阶（知其所以然）/","permalink":"https://wxwdaydayup.top/Linux%20%E7%B3%BB%E7%BB%9F%E6%93%8D%E4%BD%9C%E8%BF%9B%E9%98%B6%EF%BC%88%E7%9F%A5%E5%85%B6%E6%89%80%E4%BB%A5%E7%84%B6%EF%BC%89/","excerpt":"建议使用 Ubuntu 或者 Arch Linux。即使命令行在各个 Linux 发行版上基本通用，但是本文还是会针对 Arch Linux 添加更多内容，建议有能力的同学尽量使用 Arch Linux。","text":"文件（夹）管理本文学习的第一步，就是要找到 Linux 终端的所在位置。目前较常见的图形化终端有 Konsole、Gnome terminal、xterm 等几种。一般安装后在各个发行版的菜单中搜索即可找到。Gnome terminal 和 Konsole 基本是当前各大流行 Linux 发行版预装最多的终端应用，功能也非常强大好用。而 xterm 是世界上第一款图形化终端软件，xterm 软件包在 X Window 出现之前就有了。其对于老式哑终端的模仿非常到位，可以仿真各类老式哑终端的色彩等行为。所谓的哑终端就是传统的利用通信电缆（一般是一条多线束的串行电缆）连接到 Unix 系统上的一台显示器和一个键盘。关于各个图形化终端的各类配置，同学们可以自行慢慢摸索。 除了上述的图形化终端，在 Linux 出现的早期，没有图形化界面可供操作，当时通常的方式是使用一个简单的哑终端操作 Unix 系统。当今 2021 年，这种连接方式基本早已不存在了，但是你仍然可以模拟此种连接方式。Linux 系统启动后，它会自动创建出一些虚拟控制台。虚拟控制台是运行在 Linux 系统内存中的终端会话。通过按键组合ctrl + alt + (F1~F7)，可以分别切换到多个不同的虚拟控制台。这种模式称作 Linux 控制台，它仿真了早期的硬接线控制台终端，而且是一种同 Linux 系统交互的直接接口。虚拟控制台一般也被称为 tty。tty 代表电传打字机（teletypewriter）。这是一个古老的名词，指的是一台用于发送消息的机器。 在开始使用 tty 后，你可以看到首先会让你输入要登录的用户名，输入用户名回车后会提示输入密码，需要注意的是，密码的输入是不会显示在屏幕上的，盲输完回车即可完成登录，屏幕不显示密码是正常的，不要以为自己的键盘坏了。 起步在启动图形化终端后，你首先会看到一个待输入的命令提示符，类似 windows 系统中的 cmd。一般如下所示，显示了当前用户 ID 名 testuser，系统名为 archlinux。~这个波浪线代表你正处于 testuser 这个用户的个人目录下，路径为/home/testuser。$代表当前是已一个普通用户登陆，若为#则表示是以 root 帐户登陆。 1testuser@archlinux:~$ 你可能听说过 Linux 中有非常多的命令，都记住各个命令的用法是不现实的，所以第一步我们来学习的命令就是 man 命令：一个用来查询各个命令如何使用的命令。 在 ArchLinux 上，你首先需要安装man-db man-pages两个包，如果是第一次安装，最好执行一下如下命令，以便 man-db.service 建立-k 搜索参数需要使用的 db 索引。 1$ sudo systemctl enable --now man-db #第一次执行时间会较长，可能会有几分钟 耐心等待 sudo 命令代表可以让当前用户暂时使用 root 权限执行此条命令。 比如，现在想查询 ls 命令的使用方式，那么输入执行如下命令即可 1$ man ls 执行后你可以看到标题，描述，以及一大堆的信息。首先要知道，man 命令是用来速查某种命令使用方式的，不是用来各个详细阅读的(当然你有时间愿意读也没问题)。在这个界面你可以执行一些搜索操作，方式和在 vim 中类似，比如输入/斜杠加上你想搜索的单词进行搜索，n键跳到下一个匹配的位置等等。一般常规的查询一个命令的流程就是先看一下 Description 知道这个命令是干什么的，然后输入斜杠搜索一下你想查询的参数的含义，最后看完按q键退出。 在 man 页面的左上角，可以看到LS(1)的字样。这个(1)代表的是手册类型，下面列举一下各个数字所代表的类型意义。 1:可执行程序或 shell 命令 2:系统调用 3:库调用 4:特殊文件 5:文件格式与约定 6:游戏 7:概览、约定及杂项 8:超级用户和系统管理员命令 9:内核例程 上面有的部分现在看不懂也没关系，该懂的时候你自然就懂了。 一个命令偶尔会在多个内容区域都有对应的手册页。比如说，有个叫作 hostname(在 archlinux 中需要安装包inetutils) 的命令。手册页中既包括该命令的相关信息，也包括对系统主机名的概述。要想查看所需要的页面，对手册页中的第 1 部分而言，可以输入 man 1 hostname。对于手册页中的第 7 部分，就是输入 man 7 hostname。 除了 man 命令可以查询 Linux 命令的使用方式，info 命令也可以进行查询(在 archlinux 中需要安装包texinfo)。这里不再详细讲述 info 命令，因为 man 命令已经可以覆盖绝大多数内容。 另外，大多数命令都可以接受-help 或–help 选项。例如你可以输入 hostname –help 来查看帮助。 如果不记得命令名怎么办？可以使用关键字搜索手册页。语法是：man -k 关键字。例如，要查找与终端相关的命令，可以输入 man -k terminal。 除了万能的 man 命令，近几年还出现了一个非常流行的命令行帮助项目:tldr。其含义为太长不看的缩写。像它的名字一样，这个命令只输出某个命令的最简要的使用方式，对喜欢太长不看的人来说非常好用。在 archlinux 上可以直接通过 pacman -S tldr 进行安装。 1$ tldr tar #查看tar命令的简明使用方式 若你出现如下错误，说明你的网络环境下，tldr 命令查询的 github raw 网址已经被 GFW 墙掉了。请使用全局代理或 proxychains 前缀，或添加 https_proxy 环境变量。 1Error fetching from tldr: &lt;urlopen error [Errno 111] Connection refused&gt; cd 漫游文件系统当登录系统并获得 shell 命令提示符后，你通常位于自己的主目录中。一般情况下，你首先会想去逛逛主目录之外的其他地方。本节将告诉你如何使用 shell 命令来实现这个目标。 稍微了解 Linux 文件系统的话就会知道，一般来说一个完整的 Linux 文件路径可能是这样的: 1/home/testuser/Documents/test.cpp 这种完整的路径被称为绝对路径，即从根路径/到目标文件的完整路径结构，含义为 testuser 这个用户家路径下的 Documents 目录下，有一个名为 test.cpp 的文件。想查看当前所处的位置的绝对路径，可以使用命令pwd 12$ pwd/home/testuser/Documents/ 与此对应的，另一个概念为相对路径。其代表当前路径为基准起点，对应的一个相对位置。比如当前你所处的路径为/home/testuser/Documents，此时想要去到 testuser 用户的桌面 /home/testuser/Desktop 路径下，用相对路径即可表示为 1../Desktop 其中..为双点符，表示当前目录的父目录。另外一个常用标识符为.单点符，标识当前目录自身。 在文件系统中变更目录位置的命令为cd，可以接受绝对路径或相对路径作为参数 1234#绝对路径的例子$ cd /home/testuser/Documents/ #使用绝对路径的方式切换到/home/testuser/Documents/路径下#相对路径的例子$ cd ../Desktop #从/home/testuser/Documents/目录，使用相对路径的方式切换到/home/testuser/Desktop/路径下 一般来说，要视情况来使用相对路径或者绝对路径。在上述例子中，使用相对路径可以少输入很多内容。若此时想要切换到&#x2F;etc 路径下，则明显使用绝对路径较为方便 12$ cd /etc #如果使用绝对路径$ cd ../../../etc #如果使用相对路径 cd 命令可以直接使用，不加任何参数，此时会默认切换到当前用户的家目录下，如/home/testuser。在终端中，如果你能看到提示符最后有一个~波浪线，它代表的就是当前的路径是当前用户的家目录。 此外，另一个常用的用法是cd -。此命令可以切换到你上次所处的文件系统路径位置下。在需要返回上次路径的时候，此命令非常高效实用。 ls 查看文件信息本节首先来学习一下查看文件与目录信息的相关命令。ls 命令最基本的形式会显示当前目录下的文件和目录。 注意，ls 命令输出的列表是按字母排序的（按列排序而不是按行排序）。可用带 -F 参数的 ls 命令轻松区分文件和目录。 12345$ ls -FDocuments/ Videos/Music/ my_script.sh*Desktop/ Pictures/testfile F 参数在目录名后加了正斜线（&#x2F;），以方便用户在输出中分辨它们。类似地，它会在可执行文件（比如上面的 my_script 文件）的后面加个星号，以便用户找出可在系统上运行的文件。 Linux 经常采用隐藏文件来保存配置信息。在 Linux 上，隐藏文件通常是文件名以点号开始的文件。这些文件并没有在默认的 ls 命令输出中显示出来，因此我们称其为隐藏文件。要把隐藏文件和普通文件及目录一起显示出来，就得用到 -a 参数。，使用ls -a，所有以点号开头的隐藏文件现在都显示出来了。 -R 参数是 ls 命令可用的另一个参数，叫作递归选项。它列出了当前目录下包含的子目录中的文件。如果目录很多，这个输出就会很长。注意，首先 -R 参数显示了当前目录下的内容，也就是之前例子中用户 home 目录下的那些文件。另外，它还显示出了用户 home 目录下所有子目录及其内容。如果当前路径下的目录有更多的子目录，-R 参数会继续进行遍历。正如你尝试的，如果目录结构很庞大，输出内容会变得很长。 命令行的多个选项一般并不一定要分开输入：ls -F -R -a。它们可以进行如下合并：ls -FRa。 在基本的输出列表中，ls 命令并未输出太多每个文件的相关信息。要显示附加信息，另一个常用的参数是 -l。-l 参数会产生长列表格式的输出，包含了目录中每个文件的更多相关信息。这种长列表格式的输出在每一行中列出了单个文件或目录。除了文件名，输出中还有其他有用信息。输出的第一行显示了在目录中包含的总块数（block）。在此之后，每一行都包含了关于文件（或目录）的下述信息： 12345678910$ ls -l总用量 44drwxr-xr-x 3 testuser testuser 4096 Dec 13 21:09 Androiddrwx--x---+ 2 testuser testuser 4096 Dec 17 13:02 Desktop #多出的加号代表ACLdrwxr-xr-x 5 testuser testuser 4096 Dec 10 15:08 Documentsdrwxr-xr-x 4 testuser testuser 4096 Dec 17 11:06 Downloadsdrwxr-xr-x 3 testuser testuser 4096 Dec 10 22:50 Gamesdrwxr-xr-x 3 testuser testuser 4096 Dec 11 18:54 Musicdrwxr-xr-x 4 testuser testuser 4096 Dec 14 22:50 Picturesdrwxr-xr-x 2 testuser testuser 4096 Dec 13 11:28 Videos 文件类型，比如目录（d）、文件（-）、字符型文件（c）或块设备（b）； 文件的权限； 文件的硬链接总数； 文件属主的用户名； 文件属组的组名； 文件的大小（以字节为单位）； 文件的上次修改时间； 文件名或目录名。 -l 参数是一个强大的工具。有了它，你几乎可以看到系统上任何文件或目录的大部分信息。在进行文件管理时，ls 命令的很多参数都能派上用场。如果在 shell 提示符中输入 man ls，就能看到可用来修改 ls 命令输出的参数有好几页。别忘了可以将多个参数结合起来使用。你不时地会发现一些参数组合不仅能够显示出所需的内容，而且还容易记忆，例如 ls -alF。 由前面的例子可知，默认情况下，ls 命令会输出目录下的所有非隐藏文件。有时这个输出会显得过多，当你只需要查看单个或者少数文件信息时更是如此。幸而 ls 命令还支持在命令行中定义过滤器（filter）。它会用过滤器来决定应该在输出中显示哪些文件或目录。这个过滤器就是一个进行简单文本匹配的字符串。可以在要用的命令行参数之后添加这个过滤器：当用户指定特定文件的名称作为过滤器时，ls 命令只会显示该文件的信息。有时你可能不知道要找的那个文件的确切名称。ls 命令能够识别标准通配符，并在过滤器中用它们进行模式匹配： 问号（?）代表一个字符； 星号（*）代表零个或多个字符。 在过滤器中使用星号和问号被称为文件扩展匹配（file globbing），指的是使用通配符进行模式匹配的过程。通配符正式的名称叫作元字符通配符（metacharacter wildcards）。除了星号和问号之外，还有更多的元字符通配符可用于文件扩展匹配，例如可以使用中括号： 123$ ls -l my_scr[ai]pt-rw-rw-r-- 1 christine christine 0 May 21 13:25 my_scrapt-rwxrw-r-- 1 christine christine 54 May 21 11:26 my_script 在这个例子中，我们使用了中括号以及在特定位置上可能出现的两种字符：a 或 i。中括号表示一个字符位置并给出多个可能的选择。可以像上面的例子那样将待选的字符列出来，也可以指定字符范围，例如字母范围[a - i]： 1234$ ls -l f[a-i]ll-rw-rw-r-- 1 christine christine 0 May 21 13:44 fall-rw-rw-r-- 1 christine christine 0 May 21 13:44 fell-rw-rw-r-- 1 christine christine 0 May 21 13:44 fill 另外，可以使用感叹号（!）将不需要的内容排除在外： 1234$ ls -l f[!a]ll-rw-rw-r-- 1 christine christine 0 May 21 13:44 fell-rw-rw-r-- 1 christine christine 0 May 21 13:44 fill-rw-rw-r-- 1 christine christine 0 May 21 13:44 full 在进行文件搜索时，文件扩展匹配是一个功能强大的特性。它也可以用于 ls 以外的其他 shell 命令。随后的部分会有更多相关的例子。 文件的处理touch 创建文件touch 命令用于创建空白文件。如果作用于一个已有文件，可以更改其修改时间。如果只想改变访问时间，可用-a参数： 12$ touch -a test_onels -l --time=atime test_one 如果只使用 ls -l 命令，并不会显示访问时间。这是因为默认显示的是修改时间。要想查看文件的访问时间，需要加入另外一个参数：–time&#x3D;atime。有了这个参数，就能够显示出已经更改过的文件的访问时间。 cp 复制文件复制文件的格式为： 1$ cp source destination 当 source 和 destination 参数都是文件名时，cp 命令将源文件复制成一个新文件，并且以 destination 命名。新文件就像全新的文件一样，有新的修改时间。 如果目标文件已经存在，cp 命令并不会提醒这一点。最好是加上-i选项，强制 shell 询问是否需要覆盖已有文件。 也可以将文件复制到现有目录中。 1$ cp -i test_one /home/christine/Documents/ 新文件就出现在目录 Documents 中了，和源文件同名。 上面的例子在目标目录名尾部加上了一个正斜线（&#x2F;），这表明 Documents 是目录而非文件。这有助于明确目的，而且在复制单个文件时非常重要。如果没有使用正斜线，子目录&#x2F;home&#x2F;christine&#x2F;Documents 又不存在，就会有麻烦。在这种情况下，试图将一个文件复制到 Documents 子目录反而会创建一个名为 Documents 的文件，连错误消息都不会显示！ 上一个例子采用了绝对路径，不过也可以使用相对路径。 本章在前面介绍了特殊符号可以用在相对文件路径中。其中的单点符（.）就很适合用于 cp 命令。记住，单点符表示当前工作目录。如果需要将一个带有很长的源对象名的文件复制到当前工作目录中时，单点符能够简化该任务。如果你的源对象名很长，使用单点符要比输入完整的目标对象名省事得多。 1$ cp -i /etc/NetworkManager/NetworkManager.conf . cp 命令的 -R 参数威力强大。可以用它在一条命令中递归地复制整个目录的内容： 12$ ls -Fd *Scripts #-d选项只列出目录本身的信息，不列出其中的内容。一般可与 l 选项搭配显示目录自身详情$ cp -R Scripts/ Mod_Scripts 在执行 cp -R 命令之前，目录 Mod_Scripts 并不存在。它是随着 cp -R 命令被创建的，整个 Scripts 目录中的内容都被复制到其中。注意，在新的 Mod_Scripts 目录中，所有的文件都有对应的新日期。Mod_Scripts 目录现在已经成为了 Scripts 目录的完整副本。 也可以在 cp 命令中使用通配符： 1$ cp *script Mod_Scripts/ 该命令将所有以 script 结尾的文件复制到 Mod_Scripts 目录中。 [Tab]键 自动补全如果你需要操作的文件&#x2F;文件夹的名字很长，这正是制表键(Tab 键)自动补全挺身而出的时候。制表键自动补全允许你在输入文件名或目录名时按一下制表键，让 shell 帮忙将内容补充完整。 1$ cp really_ridiculously_long_file_name Mod_Scripts/ 在上面的例子中，我们输入了命令 cp really，然后按制表键，shell 就将剩下的文件名自动补充完整了。 使用制表键自动补全的的技巧在于要给 shell 足够的文件名信息，使其能够将需要文件同其他文件区分开。假如有另一个文件名也是以 really 开头，那么就算按了制表键，也无法完成文件名的自动补全。如果你的电脑有蜂鸣器，这时候你会听到蜂鸣器嘟的一声。要是再连按一下制表键，shell 就会列出所有以 really 开头的文件名。这个特性可以让你观察究竟应该输入哪些内容才能完成自动补全。 以上是对文件&#x2F;文件夹的自动补全处理。如果希望对于 linux 命令也可以使用自动补全，在 Archlinux 上则需要额外安装包bash-completion。 mv 移动&#x2F;重命名文件在 Linux 中，重命名文件称为移动（moving）。mv 命令可以将文件和目录移动到另一个位置或重新命名。 12$ mv fall fzll #重命名$ mv fzll Pictures/ #把文件fzll从/home/testuser移动到了/home/testuser/Pirctures 注意，mv 将文件名从 fall 更改为 fzll，但 inode 编号和时间戳保持不变。这是因为 mv 只影响文件名。和 cp 命令类似，也可以在 mv 命令中使用-i参数。这样在命令试图覆盖已有的文件时，你就会得到提示。 也可以使用 mv 命令移动文件位置并修改文件名称，这些操作只需一步就能完成： 1$ mv /home/testuser/Pictures/fzll /home/testuser/fall 也可以使用 mv 命令移动整个目录及其内容： 1$ mv Mod_Scripts Old_Scripts rm 删除文件bash shell 中删除文件的命令是 rm。rm 命令的基本格式非常简单。 1$ rm -i fall 注意，-i 命令参数提示你是不是要真的删除该文件。bash shell 中没有回收站或垃圾箱，文件一旦删除，就无法再找回。因此，在使用 rm 命令时，要养成总是加入-i 参数的好习惯。也可以使用通配符删除成组的文件。别忘了使用-i 选项保护好自己的文件。 1234$ rm -i f?llrm: remove regular empty file &#x27;fell&#x27;? yrm: remove regular empty file &#x27;fill&#x27;? yrm: remove regular empty file &#x27;full&#x27;? y rm 命令的另外一个特性是，如果要删除很多文件且不受提示符的打扰，可以用-f 参数强制删除。小心为妙！ ln 链接文件链接文件是 Linux 文件系统的一个优势。如需要在系统上维护同一文件的两份或多份副本，除了保存多份单独的物理文件副本之外，还可以采用保存一份物理文件副本和多个虚拟副本的方法。这种虚拟的副本就称为“链接”。链接是目录中指向文件真实位置的占位符。在 Linux 中有两种不同类型的文件链接： 符号链接(symbolic link) 硬链接(hard link) “符号链接”就是一个实实在在的文件，它指向存放在虚拟目录结构中某个地方的另一个文件。这两个通过符号链接在一起的文件，彼此的内容并不相同。 要为一个文件创建符号链接，原始文件必须事先存在。然后可以使用 ln 命令以及-s选项来创建符号链接： 123$ ln -s data_file sl_data_file-rw-rw-r-- 1 christine christine 1092 May 21 17:27 data_filelrwxrwxrwx 1 christine christine 9 May 21 17:29 sl_data_file -&gt; data_file 在上面的例子中，注意符号链接的名字 sl_data_file 位于 ln 命令中的第二个参数位置上。显示在长列表中符号文件名后的-&gt;符号表明该文件是链接到文件 data_file 上的一个符号链接。 另外，还要注意的是符号链接的文件大小与数据文件的文件大小。符号链接 sl_data_file 只有 9 个字节，而 data_file 有 1092 个字节。这是因为 sl_data_file 仅仅只是指向 data_file 而已。它们的内容并不相同，是两个完全不同的文件。 另一种证明链接文件是独立文件的方法是查看 inode 编号。文件或目录的 inode 编号是一个用于标识的唯一数字，这个数字由内核分配给文件系统中的每一个对象。要查看文件或目录的 inode 编号，可以给 ls 命令加入-i 参数。 123$ ls -i *data_file296890 data_file296891 sl_data_file 从这个例子中可以看出数据文件的 inode 编号是 296890，而 sl_data_file 的 inode 编号则是 296891，所以说它们是不同的文件。 当含有一连串符号链接的链接串时，不必一个一个用 ls 查看其链接关系，可以直接使用 readlink -f filename 指令查到当前符号链接串的原始文件是什么。 “硬链接”会创建独立的虚拟文件，其中包含了原始文件的信息及位置。但是它们从根本上而言是同一个文件。引用硬链接文件等同于引用了源文件。要创建硬链接，原始文件也必须事先存在，只不过这次使用 ln 命令时不再需要加入额外的参数了。 1234$ ln code_file hl_code_file$ ls -li *code_file296892 -rw-rw-r-- 2 christine christine 189 May 21 17:56 code_file296892 -rw-rw-r-- 2 christine christine 189 May 21 17:56 hl_code_file 在上面的例子中，我们使用 ls -li 命令显示了*code_files 的 inode 编号以及长列表。注意，带有硬链接的文件共享 inode 编号。这是因为它们终归是同一个文件。还要注意的是，链接计数（列表中第三项）显示这两个文件都有两个链接。另外，它们的文件大小也一模一样。 只能对处于同一存储媒体的文件创建硬链接。要想在不同存储媒体的文件之间创建链接，只能使用符号链接。 复制链接文件的时候一定要小心。如果使用 cp 命令复制一个文件，而该文件又已经被链接(不论是符号链接还是硬链接)到了另一个源文件上，那么你得到的其实是源文件的一个副本。这很容易让人犯晕。其实用不着复制链接文件，可以创建原始文件的另一个链接。同一个文件拥有多个链接，这完全没有问题。但是，尽可能不要创建符号链接文件的符号链接。这会形成混乱的链接链，不仅容易断裂，还会造成各种麻烦。 文件夹的处理在 Linux 中创建目录很简单，用 mkdir 命令即可： 1$ mkdir New_Dir 要想同时创建父目录和其下的子目录，需要加入-p 参数： 1$ mkdir -p New_Dir/Sub_Dir/Under_Dir mkdir 命令的-p 参数可以根据需要创建缺失的父目录。父目录是包含目录树中下一级目录的目录。 删除目录的基本命令是 rmdir。默认情况下，rmdir 命令只删除空目录。如果在一个目录下创建了内容， rmdir 命令会拒绝删除目录。要解决这一问题，得先把目录中的文件删掉，然后才能在空目录上使用 rmdir 命令。rmdir 并没有-i 选项来询问是否要删除目录。这也是为什么说 rmdir 只能删除空目录还是有好处的原因。 也可以在整个非空目录上使用 rm 命令。使用-r 选项使得命令可以向下进入目录，删除其中的文件，然后再删除目录本身。 1$ rm -ri My_Dir #i用来确认是否删除每个文件/目录 对 rm 命令而言，-r 参数和-R 参数的效果是一样的。-R 参数同样可以递归地删除目录中的文件。shell 命令很少会就相同的功能采用不同大小写的参数。 一口气删除目录及其所有内容的终极大法就是使用带有-r 参数和-f 参数的 rm 命令。rm -rf 命令既没有警告信息，也没有声音提示。这肯定是一个危险的工具，尤其是在拥有超级用户权限的时候。务必谨慎使用，请再三检查你所要进行的操作是否符合预期。 12$ tree Small_Dir$ rm -rf Small_Dir 在上面的例子中，我们使用了 tree 工具。它能够以一种美观的方式展示目录、子目录及其中的文件。如果需要了解目录结构，尤其是在删除目录之前，这款工具正好能派上用场。不过它可能并没有默认安装在你所使用的 Linux 发行版中。ArchLinux 用户需要安装tree包来使用。 文件的查看可用 file 命令确定文件的文件类型。 12$ file 1.txt1.txt: ASCII text #file命令不仅能确定文件中包含的文本信息，还能确定该文本文件的字符编码，ASCII 常见的文件类型还有很多类型，比如下面几种 directory 目录 symbolic link to ‘data_file’ 符号链接 Bourne-Again shell script，ASCII text executable 脚本文件 &#x2F;usr&#x2F;bin&#x2F;ls: ELF 64-bit LSB executable，x86-64，version 1 (SYSV)，dynamically linked (uses shared libs)，for GNU&#x2F;Linux 2.6.24二进制可执行程序。file 命令能够确定该程序编译时所面向的平台以及需要何种类型的库。如果你有从未知源处获得的二进制文件，这会是个非常有用的特性 JSON data 知道如何查看文件类型后，接下来学习如何查看文件内容。几个常见的命令是 cat，more 与 less。more 命令目前已经和 less 一样支持上下翻页，基本没有区别了。对于查看单个完整文件，群主更偏向直接使用 vim 查看。 有时存在一些巨型文件，如有些日志文件可以达到几十 GB 之大，这时候如果还整体查看文件，可能直接把 vim 等程序卡死了。此时需要的就是查看部分文件。常用的命令为 tail 和 head。 更常见的场景是查看文件的末尾，如日志的末尾，查看最新产生的内容。默认情况是查看此文件最后十行的内容。 1$ tail log_file 可以向 tail 命令中加入-n 参数来修改所显示的行数。在下面的例子中，通过加入-n 2 使 tail 命令只显示文件的最后两行： 1$ tail -n 2 log_file -f 参数是 tail 命令的一个突出特性。它允许你在其他进程使用该文件时查看文件的内容。tail 命令会保持活动状态，并不断显示添加到文件中的内容。这是实时监测系统日志的绝妙方式。 head 命令，顾名思义，会显示文件开头那些行的内容。默认情况下，它会显示文件前 10 行的文本。类似于 tail 命令，它也支持-n 参数，这样就可以指定想要显示的内容了。 这两个命令都允许你在破折号后面直接输入想要显示的行数： 12$ head log_file$ head -5 log_file 文件的编辑在命令行中编辑文件最常用的三个程序分别为 emacs，vim，以及 nano。其中 emacs 以及 vim 的功能较为丰富，nano 较为简单。个人的意见是掌握 vim 一种即可。原因是 vim 应用广泛，且是很多 Linux 发行版的预装程序。对于 vim 的学习，也只是适度即可，有很多 linux 爱好者把 vim 玩的炉火纯青，花费很多时间精力将 vim 打造成 IDE 级别的程序，个人认为是没有必要的。 对于 vim 的学习，有一个命令是vimtutor。这是一个非常好的边操作边学的教程，大家学习几遍，即可很好的掌握 vim 的大多数基础功能了。如果想看中文的版本，可以执行vimtutor -g zh。 进程、磁盘、数据、系统信息管理进程相关当程序运行在系统上时，我们称之为进程（process）。想监测这些进程，需要熟悉 ps&#x2F;top 等命令的用法。ps 命令好比工具中的瑞士军刀，它能输出运行在系统上的所有程序的许多信息。而 top 可以监控当前各个进程的运行状态，以及占用 cpu，内存等系统资源的情况。 ps 查看进程默认情况下，ps 命令只会显示运行在当前控制台下的属于当前用户的进程。直接执行 ps 命令，可以发现我们只运行了 bash shell（注意，shell 也只是运行在系统上的另一个程序而已）以及 ps 命令本身。可以看到基本输出显示了程序的进程 ID（Process ID，PID）、它们运行在哪个终端（TTY）以及进程已用的 CPU 时间。 Linux 系统中使用的 GNU ps 命令支持 3 种不同类型的命令行参数： Unix 风格的参数，前面加单破折线；Unix 风格的参数是从贝尔实验室开发的 AT&amp;T Unix 系统上原有的 ps 命令继承下来的。 BSD 风格的参数，前面不加破折线；伯克利软件发行版（Berkeley software distribution，BSD）是加州大学伯克利分校开发的一个 Unix 版本。它和 AT &amp; T Unix 系统有许多细小的不同 GNU 风格的长参数，前面加双破折线。 Unix 风格一些常用的参数组合： 1234$ ps -ef #查看系统上运行的所有进程 -e参数指定显示所有运行在系统上的进程；-f参数则扩展了输出，这些扩展的列包含了有用的信息。UID PID PPID C STIME TTY TIME CMDroot 1 0 0 11:29 ? 00:00:01 /sbin/init... UID：启动这些进程的用户。 PID：进程的进程 ID。 PPID：父进程的进程号（如果该进程是由另一个进程启动的）。 C：进程生命周期中的 CPU 利用率。 STIME：进程启动时的系统时间。 TTY：进程启动时的终端设备。 TIME：运行进程需要的累计 CPU 时间。 CMD：启动的程序名称。 如果想要获得更多的信息，可采用-l 参数，它会产生一个长格式输出。 1234$ ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD0 S 500 3081 3080 0 80 0 - 1173 wait pts/0 00:00:00 bash0 R 500 4463 3081 1 80 0 - 1116 - pts/0 00:00:00 ps 注意使用了-l 参数之后多出的那些列。 F：内核分配给进程的系统标记。1 代表 进程被 fork 但没有被执行。4 代表使用了超级管理员的权限。5 代表 1 和 4 都做了。0 没有任何特殊含义，含义为进程被 fork 了，也确实执行了，并且没有超级用户权限。 S：进程的状态（S 代表在休眠；R 代表正在运行，或正等待运行；Z 代表僵化，进程已结束但父进程已不存在；T 代表停止，I 代表 idle 进程）。 PRI：进程的优先级（越大的数字代表越低的优先级）。 NI：谦让度值用来参与决定优先级。越大优先级越低。 ADDR：进程的内存地址。正在运行的任务将在此列中显示一个破折号（’-‘） SZ：所需物理内存页面的大致大小。详情看 vsz 与 rss WCHAN：进程休眠的内核函数的地址。 在使用 BSD 参数时，ps 命令会自动改变输出以模仿 BSD 格式。大部分的输出列跟使用 Unix 风格参数时的输出是一样的，只有一小部分不同。 1234$ ps lF UID PID PPID PRI NI VSZ RSS WCHAN STAT TTY TIME COMMAND0 500 3081 3080 20 0 4692 1432 wait Ss pts/0 0:00 -bash0 500 5104 3081 20 0 4468 844 - R+ pts/0 0:00 ps l VSZ：进程的虚拟内存大小，以千字节（KB）为单位。 RSS：常驻集大小，进程在未换出时占用的物理内存。 STAT：代表当前进程状态的双字符状态码。 许多系统管理员都喜欢 BSD 风格的 l 参数。它能输出更详细的进程状态码（STAT 列）。双字符状态码能比 Unix 风格输出的单字符状态码更清楚地表示进程的当前状态。第一个字符采用了和 Unix 风格 S 列相同的值，表明进程是在休眠、运行还是等待。第二个参数进一步说明进程的状态。 &lt;：该进程运行在高优先级上。 N：该进程运行在低优先级上。 L：该进程有页面锁定在内存中。 s：该进程是控制进程。 l：该进程是多线程的。 +：该进程运行在前台。 从前面的例子可以看出，bash 命令处于休眠状态，但同时它也是一个控制进程（在我的会话中，它是主要进程），而 ps 命令则运行在系统的前台。 最后，GNU 开发人员在这个新改进过的 ps 命令中加入了另外一些参数。其中一些 GNU 长参数复制了现有的 Unix 或 BSD 类型的参数，而另一些则提供了新功能。 可以将 GNU 长参数和 Unix 或 BSD 风格的参数混用来定制输出。GNU 长参数中一个着实让人喜爱的功能就是–forest 参数。它会显示进程的层级信息，并用 ASCII 字符绘出可爱的图表。这种格式让跟踪子进程和父进程变得十分容易。 top 监控进程ps 命令虽然在收集运行在系统上的进程信息时非常有用，但也有不足之处：它只能显示某个特定时间点的信息。如果想观察那些频繁换进换出的内存的进程趋势，用 ps 命令就不方便了。而 top 命令刚好适用这种情况。top 命令跟 ps 命令相似，能够显示进程信息，但它是实时显示的。 123456789101112xbren@archlinux:~$ toptop - 00:01:04 up 38 min, 0 users, load average: 0.52, 0.58, 0.59Tasks: 4 total, 1 running, 3 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.5 us, 0.8 sy, 0.0 ni, 98.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stMiB Mem : 16042.5 total, 8472.3 free, 7346.2 used, 224.0 buff/cacheMiB Swap: 49152.0 total, 49099.5 free, 52.5 used. 8565.7 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 9216 660 320 S 0.0 0.0 0:00.18 init 5115 root 20 0 9308 240 176 S 0.0 0.0 0:00.00 init 5116 xbren 20 0 19280 4808 4704 S 0.0 0.0 0:00.81 bash 5606 xbren 20 0 18920 2148 1528 R 0.0 0.0 0:00.04 top 输出的分上下两部分。第一部分显示的是系统的概况。第二部分显示了进程的实时概要信息。 第一部分的第一行显示了当前时间、系统的运行时间、登录的用户数以及系统的平均负载。平均负载有 3 个值：最近 1 分钟的、最近 5 分钟的和最近 15 分钟的平均负载。值越大说明系统的负载越高。由于进程短期的突发性活动，出现最近 1 分钟的高负载值也很常见，但如果近 15 分钟内的平均负载都很高，就说明系统可能有问题。 Linux 系统管理的要点在于定义究竟到什么程度才算是高负载。这个值取决于系统的硬件配置以及系统上通常运行的程序。对某个系统来说是高负载的值可能对另一系统来说就是正常值。在单核机器上，负载的意义是这样的，比如最近十五分钟的负载值为 5.09，含义为计算机的平均过载为 409％。平均而言，有 4.09 个进程在等待 CPU。通常对于单核机器来说，如果系统的负载值超过了 2，就说明系统比较繁忙了。但是对于多核机器来说，就不是这样计算的了。例如，如果在单 CPU 系统上的平均负载为 2，则意味着系统过载了 100％，在整个时间段内，一个进程正在使用 CPU，而另一个进程正在等待。在具有两个 CPU 的系统上，含义为两个不同的进程始终使用两个不同的 CPU。在具有四个 CPU 的系统上，这将代表只有 50%的使用率-两个进程使用两个 CPU，而两个 CPU 处于空闲状态。 第二行显示了进程概要信息——top 命令的输出中将进程叫作任务（task）：有多少进程处在运行、休眠、停止或是僵化状态（僵化状态是指进程完成了，但父进程没有响应）。 下一行显示了 CPU 使用的概要信息。由前到后分别为：用户态使用率，内核态使用率，用做 nice 加权的进程分配的用户态 cpu 使用率，空闲的 cpu 使用率，等待磁盘写入完成时间比，硬件中断消耗时间，软件中断消耗时间，为处理其他进程而从虚拟机中偷走的 cpu 时间（仅虚拟机）。 紧跟其后的两行说明了系统内存的状态。第一行说的是系统的物理内存：总共有多少内存，还有多少空闲，当前用了多少，缓存占用了多少。后一行说的是同样的信息，不过是针对系统交换空间（如果分配了的话）的状态而言的。 第二部分显示了当前运行中的进程的详细列表，有些列跟 ps 命令的输出类似。给出一些未出现过的列的解释 USER：进程属主的名字。 PR：进程的优先级。 NI：进程的谦让度值。 VIRT：进程占用的虚拟内存总量。 RES：进程占用的物理内存总量。 SHR：进程和其他进程共享的内存总量。 S：进程的状态（D 代表可中断的休眠状态，R 代表在运行状态，S 代表休眠状态，T 被任务控制信号终止的停止状态，t 代表被 debugger 在跟踪时终止的停止状态，Z 代表僵化状态，I 代表 idle 空闲）。 %CPU：进程使用的 CPU 时间比例。 %MEM：进程使用的内存占可用内存的比例。 TIME+：自进程启动到目前为止的 CPU 时间总量。 COMMAND：进程所对应的命令行名称，也就是启动的程序名 默认情况下，top 命令在启动时会按照 %CPU 值对进程排序。可以在 top 运行时使用多种交互命令重新排序。每个交互式命令都是单字符，在 top 命令运行时键入可改变 top 的行为。键入 f 允许你选择对输出进行排序的字段，键入 d 允许你修改轮询间隔。键入 q 可以退出 top。用户在 top 命令的输出上有很大的控制权。用这个工具就能经常找出占用系统大部分资源的罪魁祸首。当然了，一旦找到，下一步就是结束这些进程。这也正是接下来的话题。 kill 发送信号作为系统管理员，很重要的一个技能就是知道何时以及如何结束一个进程。有时进程挂起了，只需要动动手让进程重新运行或结束就行了。但有时，有的进程会耗尽 CPU 且不释放资源。在这两种情景下，你就需要能控制进程的命令。Linux 沿用了 Unix 进行进程间通信的方法。 在 Linux 中，进程之间通过信号来通信。进程的信号就是预定义好的一个消息，进程能识别它并决定忽略还是作出反应。进程如何处理信号是由开发人员通过编程来决定的。大多数编写完善的程序都能接收和处理标准 Unix 进程信号。这些信号列举如下。 信号 名称 描述 1 HUP 挂起 2 INT 中断 3 QUIT 结束运行 9 KILL 无条件终止 11 SEGV 段错误 15 TERM 尽可能终止 17 STOP 无条件停止运行，但不终止 18 TSTP 停止或暂停，但继续在后台运行 19 CONT 在 STOP 或 TSTP 之后恢复执行 在 Linux 上有两个命令可以向运行中的进程发出进程信号。 kill 命令可通过进程 ID（PID）给进程发信号。默认情况下，kill 命令会向命令行中列出的全部 PID 发送一个 TERM 信号。遗憾的是，你只能用进程的 PID 而不能用命令名，所以 kill 命令有时并不好用。要发送进程信号，你必须是进程的属主或登录为 root 用户。否则会提示Operation not permitted。 TERM 信号告诉进程可能的话就停止运行。不过，如果有不服管教的进程，那它通常会忽略这个请求。如果需要强制终止，可以指定广为人知的-9 参数，即 KILL 信号。 同时，-s 参数支持指定其他信号（用信号名或信号值）。 1$ kill -s HUP 3940 要检查 kill 命令是否有效，可再运行 ps 或 top 命令，看看问题进程是否已停止。 第二个是 killall 命令，它非常强大，它支持通过进程名而不是 PID 来结束进程。killall 命令也支持通配符，这在系统因负载过大而变得很慢时很有用。 1$ killall http* 上例中的命令结束了所有以 http 开头的进程，比如 Apache Web 服务器的 httpd 服务。以 root 用户身份登录系统时，使用 killall 命令要特别小心，因为很容易就会误用通配符而结束了重要的系统进程。这可能会破坏文件系统。 磁盘相关在 Linux 系统上有几个命令行命令可以用来帮助管理存储媒体。本节将介绍在日常系统管理中经常用到的核心命令。 mount 挂载磁盘Linux 文件系统将所有的磁盘都并入一个虚拟目录下。在使用新的存储媒体之前，需要把它放到虚拟目录下。这项工作称为挂载（mounting）。在今天的图形化桌面环境里，大多数 Linux 发行版都能自动挂载特定类型的可移动存储媒体。可移动存储媒体指的是可从 PC 上轻易移除的媒体，比如 CD-ROM、软盘和 U 盘。如果用的发行版不支持自动挂载和卸载可移动存储媒体，就必须手动完成。本节将介绍一些可以帮你管理可移动存储设备的 Linux 命令行命令。 Linux 上用来挂载媒体的命令叫作 mount。默认情况下，mount 命令会输出当前系统上挂载的设备列表。 12345$ mount/dev/nvme0n1p1 on / type ext4 (rw,relatime)/dev/nvme0n1p2 on /home type ext4 (rw,relatime)/dev/nvme0n1p3 on /boot/EFI type vfat (rw,relatime,fmask=0022,dmask=0022,codepage=437,iocharset=iso8859-1,shortname=mixed,utf8,errors=remount-ro)/dev/sda1 on /run/media/testuser/My Ultra type fuseblk (rw,nosuid,nodev,relatime,user_id=0,group_id=0,default_permissions,allow_other,blksize=4096,uhelper=udisks2) mount 命令提供如下四部分信息： 媒体的设备文件名 媒体挂载到虚拟目录的挂载点 文件系统类型 已挂载媒体的访问状态 上面例子的最后一行输出中，移动硬盘被 KDE 桌面自动挂载到了挂载点&#x2F;run&#x2F;media 下。这个移动硬盘本身是 NTFS 格式，但是显示为 fuseblk。fuse 意为 file system in user space，在 archlinux 下，需要使用 ntfs-3g 来识别 NTFS 硬盘。ntfs-3g 并不是内核模块，而是调用 fuse 来挂载的，所以 df -hT 以及 mount 的结果会认为是 fuseblk(blk&#x3D;block)。 要手动在虚拟目录中挂载设备，需要以 root 用户身份登录，或是以 root 用户身份运行 sudo 命令。下面是手动挂载媒体设备的基本命令： 1$ mount -t type device directory type 参数指定了磁盘被格式化的文件系统类型。Linux 可以识别非常多的文件系统类型。如果是和 Windows PC 共用这些存储设备，通常得使用下列文件系统类型。 vfat：Windows 长文件系统。缺点是单文件 4GB 的限制。 ntfs：Windows NT、XP、Vista、Win 7 以及 Win10 中广泛使用的高级文件系统。 iso9660：标准 CD-ROM 文件系统。 exFAT:vfat 升级版，突破了 4GB 的限制。 大多数 U 盘和软盘会被格式化成 vfat&#x2F;NTFS&#x2F;exFAT 文件系统。而数据 CD 则必须使用 iso9660 文件系统类型。 后面两个参数定义了该存储设备的设备文件的位置以及挂载点在虚拟目录中的位置。比如说，手动将 U 盘&#x2F;dev&#x2F;sdb1 挂载到&#x2F;media&#x2F;disk，可用下面的命令： 1$ sudo mount -t vfat /dev/sdb1 /media/disk 媒体设备挂载到了虚拟目录后，root 用户就有了对该设备的所有访问权限，而其他用户的访问则会被限制。你可以通过目录权限（后文将介绍权限）指定用户对设备的访问权限。 -o 参数允许在挂载文件系统时添加一些以逗号分隔的额外选项。以下为常用的选项。 ro：以只读形式挂载。 rw：以读写形式挂载。 user：允许普通用户挂载文件系统。 check&#x3D;none：挂载文件系统时不进行完整性校验。 loop：挂载一个文件。 从 Linux 系统上移除一个可移动设备时，不能直接从系统上移除，而应该先卸载。Linux 上不能直接弹出已挂载的 CD。如果你在从光驱中移除 CD 时遇到麻烦，通常是因为该 CD 还挂载在虚拟目录里。先卸载它，然后再去尝试弹出。 卸载设备的命令是 umount（是的，你没看错，命令名中并没有字母 n，这一点有时候很让人困惑）。umount 命令的格式非常简单： 1umount [directory | device ] umount 命令支持通过设备文件或者是挂载点来指定要卸载的设备。如果有任何程序正在使用设备上的文件，系统就不会允许你卸载它： 123456$ sudo umount: /home/rich/mntumount: /home/rich/mnt: device is busy$ cd /home/rich$ sudo umount /home/rich/mnt$ ls -l mnttotal 0 上例中，命令行提示符仍然在挂载设备的文件系统目录中，所以 umount 命令无法卸载该镜像文件。一旦命令提示符移出该镜像文件的文件系统，umount 命令就能卸载该镜像文件。 如果在卸载设备时，系统提示设备繁忙，无法卸载设备，通常是有进程还在访问该设备或使用该设备上的文件。这时可用 lsof 命令获得使用它的进程信息，然后在应用中停止使用该设备或停止该进程。lsof 命令的用法很简单：lsof &#x2F;path&#x2F;to&#x2F;device&#x2F;node，或者 lsof &#x2F;path&#x2F;to&#x2F;mount&#x2F;point df 查看磁盘空间有时你需要知道在某个设备上还有多少磁盘空间。df 命令可以让你很方便地查看所有已挂载磁盘的使用情况 123456$ dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/sda2 18251068 7703964 9605024 45% //dev/sda1 101086 18680 77187 20% /boottmpfs 119536 0 119536 0% /dev/shm/dev/sdb1 127462 113892 13570 90% /media/disk df 命令会显示每个有数据的已挂载文件系统。如你在前例中看到的，有些已挂载设备仅限系统内部使用。可以注意到，默认大小均为 1024 字节，不利于直观查看，可附加-h 参数进行更直观的查看。它会把输出中的磁盘空间按照用户易读的形式显示，通常用 M 来替代兆字节，用 G 替代吉字节。 123456$ df -hFilesystem Size Used Avail Use% Mounted on/dev/sdb2 18G 7.4G 9.2G 45% //dev/sda1 99M 19M 76M 20% /boottmpfs 117M 0 117M 0% /dev/shm/dev/sdb1 125M 112M 14M 90% /media/disk du 查看目录空间通过 df 命令很容易发现哪个磁盘的存储空间快没了。系统管理员面临的下一个问题是，发生这种情况时要怎么办。另一个有用的命令是 du 命令。du 命令可以显示某个特定目录（默认情况下是当前目录）的磁盘使用情况。这一方法可用来快速判断系统上某个目录下是不是有超大文件。默认情况下，du 命令会显示当前目录下所有的文件、目录和子目录的磁盘使用情况，它会以磁盘块为单位来表明每个文件或目录占用了多大存储空间。对标准大小的目录来说，这个输出会是一个比较长的列表。 每行输出左边的数值是每个文件或目录占用的磁盘块数。注意，这个列表是从目录层级的最底部开始，然后按文件、子目录、目录逐级向上。这么用 du 命令（不加参数，用默认参数）作用并不大。我们更想知道每个文件和目录占用了多大的磁盘空间，但如果还得逐页查找的话就没什么意义了。下面是能让 du 命令用起来更方便的几个命令行参数。 -s：同时查询多目录时，依次只显示每个输出参数(目录)的总大小。 -c：同时查询多目录时，显示所有已列出文件总的大小。 -h：按用户易读的格式输出大小，即用 K 替代千字节，用 M 替代兆字节，用 G 替代吉字节。 1234567$ du -sh ./Documents/ ./Desktop/3.4G ./Documents/58G ./Desktop/$ du -shc ./Documents/ ./Desktop/3.4G ./Documents/58G ./Desktop/62G 总用量 文件数据相关sort 排序处理大量数据时的一个常用命令是 sort 命令。顾名思义，sort 命令是对数据进行排序的。默认情况下，sort 命令按照会话指定的默认语言的排序规则对文本文件中的数据行排序。 对数字排序时，如果你本期望这些数字能按值排序，就要失望了。默认情况下，sort 命令会把数字当做字符来执行标准的字符排序，产生的输出可能根本就不是你要的。解决这个问题可用-n 参数，它会告诉 sort 命令把数字识别成数字而不是字符，并且按值排序。 另一个常用的参数是-M，按月排序。Linux 的日志文件经常会在每行的起始位置有一个时间戳，用来表明事件是什么时候发生的，下面是一个例子。 1Sep 13 07:10:09 testbox smartd[2718]: Device: /dev/sda, opened 如果将含有时间戳日期的文件按默认的排序方法来排序，并不会得到想要的结果。如果用-M 参数，sort 命令就能识别三字符的月份名，并相应地排序。 -k 和-t 参数在对按字段分隔的数据进行排序时非常有用，例如&#x2F;etc&#x2F;passwd 文件。可以用-t 参数来指定字段分隔符，然后用-k 参数来指定排序的字段。举个例子，对密码文件&#x2F;etc&#x2F;passwd 根据用户 ID 进行数值排序，可以这么做： 12345678$ sort -t &#x27;:&#x27; -k 3 -n /etc/passwdroot:x:0:0::/root:/bin/bashbin:x:1:1::/:/usr/bin/nologindaemon:x:2:2::/:/usr/bin/nologinmail:x:8:12::/var/spool/mail:/usr/bin/nologinftp:x:14:11::/srv/ftp:/usr/bin/nologinhttp:x:33:33::/srv/http:/usr/bin/nologinuuidd:x:68:68::/:/usr/bin/nologin 现在数据已经按第三个字段——用户 ID 的数值排序。 最后给出一个综合的例子： 1234567891011$ du -s * | sort -nr4649672 Android2726928 Desktop2224812 Documents1139980 Games47172 Downloads29072 Pictures560 ThunderNetwork8 Music4 下载4 Videos 注意，-r 参数将结果按降序输出，这样就更容易看到目录下的哪些文件占用空间最多。本例中用到的管道命令（|）将 du 命令的输出重定向到 sort 命令。我们将在本文后面进一步讨论。 grep 搜索你会经常需要在大文件中找一行数据，而这行数据又埋藏在文件的中间。这时并不需要手动翻看整个文件，用 grep 命令来帮助查找就行了。grep 命令的命令行格式如下： 1grep [options] pattern [file] grep 命令会在输入或指定的文件中查找包含匹配指定模式的字符的行。grep 的输出就是包含了匹配模式的行。 12345$ grep three file1three$ grep t file1twothree 第一个例子在文件 file1 中搜索能匹配模式 three 的文本。grep 命令输出了匹配了该模式的行。第二个例子在文件 file1 中搜索能匹配模式 t 的文本。这个例子里，file1 中有两行匹配了指定的模式，两行都输出了。由于 grep 命令非常流行，它经历了大量的更新。有很多功能被加进了 grep 命令。如果查看一下它的手册页面，你会发现它是多么的无所不能。 如果要进行反向搜索（输出不匹配该模式的行），可加-v 参数。 1234$ grep -v t file1onefourfive 如果要显示匹配模式的行所在的行号，可加-n 参数 123$ grep -n t file12:two3:three 如果只要知道有多少行含有匹配的模式，可用-c 参数。 12$ grep -c t file12 如果要指定多个匹配模式，可用-e 参数来指定每个模式。这个例子输出了含有字符 t 或字符 f 的所有行。 12345$ grep -e t -e f file1twothreefourfive 默认情况下，grep 命令用基本的 Unix 风格正则表达式来匹配模式。Unix 风格正则表达式采用特殊字符来定义怎样查找匹配的模式。以下是在 grep 搜索中使用正则表达式的简单例子。 12345$ grep [tf] file1twothreefourfive 正则表达式中的方括号表明 grep 应该搜索包含 t 或者 f 字符的匹配。如果不用正则表达式，grep 就会搜索匹配字符串 tf 的文本。 egrep 命令是 grep 的一个衍生，支持 POSIX 扩展正则表达式。POSIX 扩展正则表达式含有更多的可以用来指定匹配模式的字符（后文会讲）。fgrep 则是另外一个版本，支持将匹配模式指定为用换行符分隔的一列固定长度的字符串。这样就可以把这列字符串放到一个文件中，然后在 fgrep 命令中用其在一个大型文件中搜索字符串了。egrep 与 grep -E 相同。 fgrep 与 grep -F 相同，所以掌握好 grep 就好。 tar 压缩与归档gzip 是非常流行的压缩工具软件包，使用方式也很简单，这个软件包含有下面的工具。 gzip：用来压缩文件。 gzcat：用来查看压缩过的文本文件的内容。 gunzip：用来解压文件 123$ gzip myprog #压缩文件ls -l my*-rwxrwxr-x 1 rich rich 2197 2007-09-13 11:29 myprog.gz gzip 命令会压缩你在命令行指定的文件。也可以在命令行指定多个文件名甚至用通配符来一次性批量压缩文件。 1$ gzip my* 虽然 gzip 命令能够很好地将数据压缩和归档进单个文件，但它不是 Unix 和 Linux 中的标准归档工具。目前，Unix 和 Linux 上最广泛使用的归档工具是 tar 命令。tar 命令最开始是用来将文件写到磁带设备上归档的，然而它也能把输出写到文件里，这种用法在 Linux 上已经普遍用来归档数据了。关于 tar 的用法由于历史原因也有三种使用方式，较为复杂，记住常用方式即可。此时使用tldr tar命令，即可很方便的查看常用用法。 系统信息相关dmidecode 信息大全dmidecode 命令 可以让你在 Linux 系统下获取有关硬件方面的信息。dmidecode 的作用是将 DMI 数据库中的信息解码，以可读的文本方式显示。由于 DMI 信息可以人为修改，因此里面的信息不一定是系统准确的信息。dmidecode 遵循 SMBIOS&#x2F;DMI 标准，其输出的信息包括 BIOS、系统、主板、处理器、内存、缓存等等。 DMI（Desktop Management Interface,DMI）就是帮助收集电脑系统信息的管理系统，DMI 信息的收集必须在严格遵照 SMBIOS 规范的前提下进行。SMBIOS（System Management BIOS）是主板或系统制造者以标准格式显示产品管理信息所需遵循的统一规范。SMBIOS 和 DMI 是由行业指导机构 Desktop Management Task Force(DMTF)起草的开放性的技术标准，其中 DMI 设计适用于任何的平台和操作系统。 DMI 充当了管理工具和系统层之间接口的角色。它建立了标准的可管理系统更加方便了电脑厂商和用户对系统的了解。DMI 的主要组成部分是 Management Information Format(MIF)数据库。这个数据库包括了所有有关电脑系统和配件的信息。通过 DMI，用户可以获取序列号、电脑厂商、串口信息以及其它系统配件信息。 一个小技巧是，在笔记本售后网站一般需要输入序列号查询，以下命令可以直接显示出。不用把笔记本翻过来到背面去记序列号再查询了。 1$ sudo dmidecode -s system-serial-number 同时，也可以很方便的查看 BIOS 版本、内存频率(也许是唯一查看内存频率的方法)等信息。 upower 电池信息upower 可以查看电池相关信息，使用如下命令获取详情。可以看到电池损耗，充电比率等实用信息： 1$ upower -i `upower -e | grep &#x27;BAT&#x27;` 理解 Shell 父子关系、内建命令shell 的父子关系用于登录的某个虚拟控制器终端，或在 GUI 中运行终端仿真器时所启动的默认的交互 shell，是一个父 shell。本文到目前为止都是父 shell 提供 CLI 提示符，然后等待命令输入。 查看父子结构在 CLI 提示符后输入&#x2F;bin&#x2F;bash 命令或其他等效的 bash 命令时，会创建一个新的 shell 程序。这个 shell 程序被称为子 shell（child shell）。子 shell 也拥有 CLI 提示符，同样会等待命令输入。当输入 bash、生成子 shell 的时候，你是看不到任何相关的信息的，因此需要另一条命令帮助我们理清这一切。在之前讲过的 ps 命令能够派上用场，在生成子 shell 的前后配合选项-f 来观察不同。 123456789101112$ ps -fUID PID PPID C STIME TTY TIME CMD501 1841 1840 0 11:50 pts/0 00:00:00 -bash501 2429 1841 4 13:44 pts/0 00:00:00 ps -f$$ bash$ ps -fUID PID PPID C STIME TTY TIME CMD501 1841 1840 0 11:50 pts/0 00:00:00 -bash501 2430 1841 0 13:44 pts/0 00:00:00 bash501 2444 2430 1 13:44 pts/0 00:00:00 ps -f$ 第一次使用 ps -f 的时候，显示出了两个进程。其中一个进程的进程 ID 是 1841（第二列），运行的是 bash shell 程序（最后一列）。另一个进程（进程 ID 为 2429）对应的是命令 ps -f。 输入命令 bash 之后，一个子 shell 就出现了。第二个 ps -f 是在子 shell 中执行的。可以从显示结果中看到有两个 bash shell 程序在运行。第一个 bash shell 程序，也就是父 shell 进程，其原始进程 ID 是 1814。第二个 bash shell 程序，即子 shell 进程，其 PID 是 2430。注意，子 shell 的父进程 ID（PPID）是 1841，指明了这个父 shell 进程就是该子 shell 的父进程。 进程就是正在运行的程序。bash shell 是一个程序，当它运行的时候，就成为了一个进程。一个运行着的 shell 就是某种进程而已。因此，在说到运行一个 bash shell 的时候，你经常会看到“shell”和“进程”这两个词交换使用。 在生成子 shell 进程时，只有部分父进程的环境被复制到子 shell 环境中。这会对包括变量在内的一些东西造成影响，我们会在后续谈及相关的内容。 同样的，你也可以在子 shell 中不停的继续创建子 shell,它们最终会形成一个嵌套结构，可以用 ps –forest 命令展示了这些子 shell 间的嵌套结构。可以利用 exit 命令有条不紊地退出各个子 shell。 另一个创建子 shell 的方式是使用进程列表。命令列表要想成为进程列表，这些命令必须包含在括号里。 1$ (pwd ; ls ; cd /etc ; pwd ; cd ; pwd ; ls) 括号的加入使一串命令变成了进程列表，生成了一个子 shell 来执行对应的命令。 进程列表是一种命令分组（command grouping）。另一种命令分组是将命令放入花括号中，并在命令列表尾部加上分号（;），前后的空格均不可省略。语法为{ command; }。使用花括号进行命令分组并不会像进程列表那样创建出子 shell。 要想知道是否生成了子 shell，得借助一个使用了环境变量的命令。（环境变量会在后续详述。）这个命令就是 echo $BASH_SUBSHELL。如果该命令返回 0，就表明没有子 shell。如果返回 1 或者其他更大的数字，就表明存在一个或多个子 shell。 下面的例子中使用了一串命令列表，列表尾部是 echo $BASH_SUBSHELL 123$ pwd ; ls ; cd /etc ; pwd ; cd ; pwd ; ls ; echo $BASH_SUBSHELL...0 在命令输出的最后，显示的是数字 0。这就表明这些命令不是在子 shell 中运行的。要是使用进程列表的话，结果就不一样了。在列表最后加入 echo $BASH_SUBSHELL。 123$ (pwd ; ls ; cd /etc ; pwd ; cd ; pwd ; ls ; echo $BASH_SUBSHELL)...1 这次在命令输入的最后显示出了数字 1。这表明的确创建了子 shell，并用于执行这些命令。所以说，进程列表就是使用括号包围起来的一组命令，它能够创建出子 shell 来执行这些命令。你甚至可以在进程列表中嵌套括号来创建子 shell 的子 shell。 123$ ( pwd ; echo $BASH_SUBSHELL)/home/Christine1 123$ ( pwd ; (echo $BASH_SUBSHELL))/home/Christine2 注意，在第一个进程列表中，数字 1 表明了一个子 shell，这个结果和预期的一样。但是在第二个进程列表中，在命令 echo $BASH_SUBSHELL 外面又多出了一对括号。这对括号在子 shell 中产生了另一个子 shell 来执行命令。因此数字 2 表明的就是这个子 shell。 后台模式在 shell 脚本中，经常使用子 shell 进行多进程处理。但是采用子 shell 的成本不菲，会明显拖慢处理速度。在交互式的 CLI shell 会话中，子 shell 同样存在问题。它并非真正的多进程处理，因为终端控制着子 shell 的 I&#x2F;O。 在交互式的 shell CLI 中，还有很多更富有成效的子 shell 用法。进程列表、协程和管道（后续会讲到）都利用了子 shell。它们都可以有效地在交互式 shell 中使用。在交互式 shell 中，一个高效的子 shell 用法就是使用后台模式。在讨论如何将后台模式与子 shell 搭配使用之前，你得先搞明白什么是后台模式。 在后台模式中运行命令可以在处理命令的同时让出 CLI，以供他用。演示后台模式的一个经典命令就是 sleep。sleep 命令接受一个参数，该参数是你希望进程等待（睡眠）的秒数。这个命令在脚本中常用于引入一段时间的暂停。命令 sleep 10 会将会话暂停 10 秒钟，然后返回 shell CLI 提示符。 1$ sleep 10 要想将命令置入后台模式，可以在命令末尾加上字符&amp;。把 sleep 命令置入后台模式可以让我们利用 ps 命令来小窥一番。 12345678$ sleep 3000 &amp;[1] 2396$ ps -fUID PID PPID C STIME TTY TIME CMDchristi+ 2338 2337 0 10:13 pts/9 00:00:00 -bashchristi+ 2396 2338 0 10:17 pts/9 00:00:00 sleep 3000christi+ 2397 2338 0 10:17 pts/9 00:00:00 ps -f$ sleep 命令会在后台（&amp;）睡眠 3000 秒（50 分钟）。当它被置入后台，在 shell CLI 提示符返回之前，会出现两条信息。第一条信息是显示在方括号中的后台作业（background job）号（1）。第二条是后台作业的进程 ID（2396）。 ps 命令用来显示各种进程。我们可以注意到命令 sleep 3000 已经被列出来了。在第二列显示的进程 ID（PID）和命令进入后台时所显示的 PID 是一样的，都是 2396。 除了 ps 命令，你也可以使用 jobs 命令来显示后台作业信息。jobs 命令可以显示出当前运行在后台模式中的所有用户的进程（作业）。 123$ jobs[1]+ Running sleep 3000 &amp;$ jobs 命令在方括号中显示出作业号（1）。它还显示了作业的当前状态（running）以及对应的命令（sleep 3000 &amp;） 利用 jobs 命令的-l 选项，你还能够看到更多的相关信息。除了默认信息之外，-l 选项还能够显示出命令的 PID。一旦后台作业完成，就会显示出结束状态。 123$ jobs -l[1]+ 28331 Done sleep 3000 &amp;$ 需要提醒的是：后台作业的结束状态可未必会一直等待到合适的时候才现身。当作业结束状态突然出现在屏幕上的时候，你可别吃惊啊。 之前说过，进程列表是运行在子 shell 中的一条或多条命令。使用包含了 sleep 命令的进程列表，并显示出变量 BASH_SUBSHELL，结果和期望的一样。 12$ (sleep 2 ; echo $BASH_SUBSHELL ; sleep 2)1 在上面的例子中，有一个 2 秒钟的暂停，接着显示出的数字 1 表明只有一个子 shell，在返回提示符之前又经历了另一个 2 秒钟的暂停，没什么特别的。 将相同的进程列表置入后台模式会在命令输出上表现出些许不同。 1234$ (sleep 2 ; echo $BASH_SUBSHELL ; sleep 2)&amp;[2] 2401$ 1[2]+ Done ( sleep 2; echo $BASH_SUBSHELL; sleep 2 ) 把进程列表置入后台会产生一个作业号和进程 ID，然后返回到提示符。不过奇怪的是表明单一级子 shell 的数字 1 显示在了提示符的旁边！不要不知所措，只需要按一下回车键，就会得到另一个提示符。 在 CLI 中运用子 shell 的创造性方法之一就是将进程列表置入后台模式。你既可以在子 shell 中进行繁重的处理工作，同时也不会让子 shell 的 I&#x2F;O 受制于终端。 当然了，sleep 和 echo 命令的进程列表只是作为一个示例而已。使用 tar 创建备份文件是有效利用后台进程列表的一个更实用的例子。 12$ (tar -cf Rich.tar /home/rich ; tar -cf My.tar /home/christine)&amp;[3] 2423 协程的使用将进程列表置入后台模式并不是子 shell 在 CLI 中仅有的创造性用法。协程就是另一种方法。协程可以同时做两件事。它在后台生成一个子 shell，并在这个子 shell 中执行命令。要进行协程处理，得使用 coproc 命令，还有要在子 shell 中执行的命令。 123$ coproc sleep 10[1] 2544$ 除了会创建子 shell 之外，协程基本上就是将命令置入后台模式。当输入 coproc 命令及其参数之后，你会发现启用了一个后台作业。屏幕上会显示出后台作业号（1）以及进程 ID（2544）。jobs 命令能够显示出协程的处理状态 12$ jobs[1]+ Running coproc COPROC sleep 10 &amp; 在上面的例子中可以看到在子 shell 中执行的后台命令是 coproc COPROC sleep 10。COPROC 是 coproc 命令给进程起的名字。你可以使用命令的扩展语法自己设置这个名字。 12345$ coproc My_Job &#123; sleep 10; &#125;[1] 2570$$ jobs [1]+ Running coproc My_Job &#123; sleep 10; &#125; &amp;$ 通过使用扩展语法，协程的名字被设置成 My_Job。这里要注意的是，扩展语法写起来有点麻烦。必须确保在第一个花括号（{）和命令名之间有一个空格。还必须保证命令以分号（;）结尾。另外，分号和闭花括号（}）之间也得有一个空格。 协程能够让你尽情发挥想象力，发送或接收来自子 shell 中进程的信息。只有在拥有多个协程的时候才需要对协程进行命名，因为你得和它们进行通信。否则的话，让 coproc 命令将其设置成默认的名字 COPROC 就行了。 你可以发挥才智，将协程与进程列表结合起来产生嵌套的子 shell。只需要输入进程列表，然后把命令 coproc 放在前面就行了。 123456789$ coproc ( sleep 10; sleep 2 )[1] 143311$ jobs[1]+ Running coproc COPROC ( sleep 10; sleep 2 ) &amp;$ ps -f --foresttestuser 142848 142839 0 18:00 pts/1 00:00:00 /bin/bashtestuser 143311 142848 0 18:01 pts/1 00:00:00 \\_ /bin/bashtestuser 143312 143311 0 18:01 pts/1 00:00:00 | \\_ sleep 10testuser 143776 142848 0 18:02 pts/1 00:00:00 \\_ ps -f --forest 理解 shell 的内建命令在学习 GNU bash shell 期间，你可能听到过“内建命令”这个术语。搞明白 shell 的内建命令和非内建（外部）命令非常重要。内建命令和非内建命令的操作方式大不相同。 外部命令，有时候也被称为文件系统命令，是存在于 bash shell 之外的程序。它们并不是 shell 程序的一部分。外部命令程序通常位于&#x2F;bin、&#x2F;usr&#x2F;bin、&#x2F;sbin 或&#x2F;usr&#x2F;sbin 中。 ps 就是一个外部命令。你可以使用 which 和 type 命令找到它。 123456789$ which ps/bin/ps$$ type -a psps is /bin/ps$$ ls -l /bin/ps-rwxr-xr-x 1 root root 93232 Jan 6 18:32 /bin/ps$ 当外部命令执行时，会创建出一个子进程。这种操作被称为衍生（forking）。外部命令 ps 很方便显示出它的父进程以及自己所对应的衍生子进程。 12345$ ps -fUID PID PPID C STIME TTY TIME CMDchristi+ 2743 2742 0 17:09 pts/9 00:00:00 -bashchristi+ 2801 2743 0 17:16 pts/9 00:00:00 ps -f$ 作为外部命令，ps 命令执行时会创建出一个子进程。在这里，ps 命令的 PID 是 2801，父 PID 是 2743。作为父进程的 bash shell 的 PID 是 2743。 当进程必须执行衍生操作时，它需要花费时间和精力来设置新子进程的环境。所以说，外部命令多少还是有代价的。 就算衍生出子进程或是创建了子 shell，你仍然可以通过发送信号与其沟通，这一点无论是在命令行还是在脚本编写中都是极其有用的。发送信号（signaling）使得进程间可以通过信号进行通信。信号及其发送会在后续章节中讲到。 内建命令和外部命令的区别在于前者不需要使用子进程来执行。它们已经和 shell 编译成了一体，作为 shell 工具的组成部分存在。不需要借助外部程序文件来运行 cd 和 exit 命令都内建于 bash shell。可以利用 type 命令来了解某个命令是否是内建的。 123456$ type cdcd is a shell builtin$$ type exitexit is a shell builtin$ 因为既不需要通过衍生出子进程来执行，也不需要打开程序文件，内建命令的执行速度要更快，效率也更高。 要注意，有些命令有多种实现。例如 echo 和 pwd 既有内建命令也有外部命令。两种实现略有不同。要查看命令的不同实现，使用 type 命令的-a 选项。 1234567891011121314$ type -a echoecho is a shell builtinecho is /bin/echo$$ which echo/bin/echo$$ type -a pwdpwd is a shell builtinpwd is /bin/pwd$$ which pwd/bin/pwd$ 命令 type -a 显示出了每个命令的两种实现。注意，which 命令只显示出了外部命令文件。 对于有多种实现的命令，如果想要使用其外部命令实现，直接指明对应的文件就可以了。例如，要使用外部命令 pwd，可以输入&#x2F;bin&#x2F;pwd。 history 历史记录一个有用的内建命令是 history 命令。bash shell 会跟踪你用过的命令。你可以唤回这些命令并重新使用。要查看最近用过的命令列表，可以输入不带选项的 history 命令。通常历史记录中会保存最近的 500&#x2F;1000 条命令。这个数量可是不少的！你可以设置保存在 bash 历史记录中的命令数。要想实现这一点，你需要修改名为 HISTSIZE 的环境变量。 你可以唤回并重用历史列表中最近的命令。这样能够节省时间和击键量。输入!!，然后按回车键就能够唤出刚刚用过的那条命令来使用。或者点击方向键中的向上键，也能使用刚刚用过的那条命令，连续点击还能向上翻阅执行历史命令。 你可以唤回历史列表中任意一条命令。只需输入惊叹号和命令在历史列表中的编号即可。如执行!20 命令历史记录被保存在隐藏文件.bash_history 中，它位于用户的主目录中。这里要注意的是，bash 命令的历史记录是先存放在内存中，当 shell 退出时才被写入到历史文件中。 可以在退出 shell 会话之前强制将命令历史记录写入.bash_history 文件。要实现强制写入，需要使用 history 命令的-a 选项。 如果你打开了多个终端会话，仍然可以使用 history -a 命令在打开的会话中向.bash_history 文件中添加记录。但是对于其他打开的终端会话，历史记录并不会自动更新。这是因为.bash_history 文件只有在打开首个终端会话时才会被读取。要想强制重新读取.bash_history 文件，更新终端会话的历史记录，可以使用 history -n 命令。 使用 bash shell 命令历史记录能够大大地节省时间。利用内建的 history 命令能够做到的事情远不止这里所描述的。可以通过输入 man history 来查看 history 命令的 bash 手册页面。 alias 命令别名alias 命令是另一个 shell 的内建命令。命令别名允许你为常用的命令（及其参数）创建另一个名称，从而将输入量减少到最低。你所使用的 Linux 发行版很有可能已经为你设置好了一些常用命令的别名。要查看当前可用的别名，使用 alias 命令以及选项-p。 12345678$ alias -palias egrep=&#x27;egrep --color=auto&#x27;alias fgrep=&#x27;fgrep --color=auto&#x27;alias grep=&#x27;grep --color=auto&#x27;alias l=&#x27;ls -CF&#x27;alias la=&#x27;ls -A&#x27;alias ll=&#x27;ls -alF&#x27;alias ls=&#x27;ls --color=auto&#x27; #表明终端支持彩色模式的列表 可以使用 alias 命令创建属于自己的别名。 1alias li=&#x27;ls -li&#x27; 在定义好别名之后，你随时都可以在 shell 中使用它，就算在 shell 脚本中也没问题。要注意，因为命令别名属于内部命令，一个别名仅在它所被定义的 shell 进程中才有效。 1234$ alias li=&#x27;ls -li&#x27;$ bash$ libash: li: command not found 不过好在有办法能够让别名在不同的子 shell 中都奏效。下一章中就会讲到具体的做法。shell、子 shell、进程和衍生进程都会受到环境变量的影响。下一章，我们会探究环境变量的影响方式以及如何在不同的上下文中使用环境变量。 Linux 环境变量Linux 环境变量能帮你提升 Linux shell 体验。很多程序和脚本都通过环境变量来获取系统信息、存储临时数据和配置信息。在 Linux 系统上有很多地方可以设置环境变量，了解去哪里设置相应的环境变量很重要。 认识环境变量bash shell 用环境变量（environment variable）的特性来存储有关 shell 会话和工作环境的信息（这也是它们被称作环境变量的原因）。这项特性允许你在内存中存储数据，以便程序或 shell 中运行的脚本能够轻松访问到它们。这也是存储持久数据的一种简便方法。在 bash shell 中，环境变量分为两类： 全局变量 局部变量 全局环境变量对于 shell 会话和所有生成的子 shell 都是可见的。局部变量则只对创建它们的 shell 可见。这让全局环境变量对那些所创建的子 shell 需要获取父 shell 信息的程序来说非常有用。Linux 系统在你开始 bash 会话时就设置了一些全局环境变量。系统环境变量基本上都是使用全大写字母，以区别于普通用户的环境变量。要查看全局变量，可以使用 env 或 printenv 命令。 系统为 bash shell 设置的全局环境变量数目众多，我们不得不在展示的时候进行删减。其中有很多是在登录过程中设置的，另外，你的登录方式也会影响到所设置的环境变量。 要显示个别环境变量的值，可以使用 printenv 命令，但是不要用 env 命令。 123456$ printenv HOME/home/Christine$$ env HOMEenv: HOME: No such file or directory$ 也可以使用 echo 显示变量的值。在这种情况下引用某个环境变量的时候，必须在变量前面加上一个美元符（$）。 123$ echo $HOME/home/Christine$ 在变量名前加上$也可在其他命令中作为参数使用 1$ ls $HOME # 等价与ls ~ 正如前面提到的，全局环境变量可用于进程的所有子 shell。 12345678910111213$ bash$$ ps -fUID PID PPID C STIME TTY TIME CMD501 2017 2016 0 16:00 pts/0 00:00:00 -bash501 2082 2017 0 16:08 pts/0 00:00:00 bash501 2095 2082 0 16:08 pts/0 00:00:00 ps -f$$ echo $HOME/home/Christine$$ exit$ 在这个例子中，用 bash 命令生成一个子 shell 后，显示了 HOME 环境变量的当前值，这个值和父 shell 中的一模一样，都是&#x2F;home&#x2F;Chrisine。 局部环境变量,顾名思义只能在定义它们的进程中可见。尽管它们是局部的，但是和全局环境变量一样重要。事实上，Linux 系统也默认定义了标准的局部环境变量。不过你也可以定义自己的局部变量，如你所想，这些变量被称为用户定义局部变量。 查看局部环境变量的列表有点复杂。遗憾的是，在 Linux 系统并没有一个只显示局部环境变量的命令。set 命令会显示为某个特定进程设置的所有环境变量，包括局部变量、全局变量以及用户定义变量。 所有通过 printenv 命令能看到的全局环境变量都出现在了 set 命令的输出中。但在 set 命令的输出中还有其他一些环境变量，即局部环境变量和用户定义变量。 命令 env、printenv 和 set 之间的差异很细微。set 命令会显示出全局变量、局部变量以及用户定义变量。它还会按照字母顺序对结果进行排序。env 和 printenv 命令同 set 命令的区别在于前两个命令不会对变量排序，也不会输出局部变量和用户定义变量。在这种情况下，env 和 printenv 的输出是重复的。不过 env 命令除了查看环境变量外还有一些其他功能。 操作环境变量一旦启动了 bash shell（或者执行一个 shell 脚本），就能创建在这个 shell 进程内可见的局部变量了。可以通过等号给环境变量赋值，值可以是数值或字符串 12345$ echo $my_variable$ my_variable=Hello$$ echo $my_variableHello 非常简单！现在每次引用 my_variable 环境变量的值，只要通过$my_variable 引用即可。如果要给变量赋一个含有空格的字符串值，必须用引号来界定字符串的首和尾。没有单引号的话，bash shell 会以为下一个词是另一个要执行的命令。注意，你定义的局部环境变量用的是小写字母，而到目前为止你所看到的系统环境变量都是大写字母。 所有的环境变量名均使用大写字母，这是 bash shell 的标准惯例。如果是你自己创建的局部变量或是 shell 脚本，请使用小写字母。变量名区分大小写。在涉及用户定义的局部变量时坚持使用小写字母，这能够避免重新定义系统环境变量可能带来的灾难。 设置了局部环境变量后，就能在 shell 进程的任何地方使用它了。但是，如果生成了另外一个 子 shell，它在子 shell 中就不可用。当你退出子 shell 并回到原来的 shell 时，这个局部环境变量依然可用。 类似地，如果你在子进程中设置了一个局部变量，那么一旦你退出了子进程，那个局部环境变量就不可用。 这种时候可以设置全局环境变量。在设定全局环境变量的进程所创建的子进程中，该变量都是可见的。创建全局环境变量的方法是先创建一个局部环境变量，然后再把它导出到全局环境中。这个过程通过 export 命令来完成。 12$ my_variable=&quot;I am Global now&quot;$ export my_variable 在定义并导出局部环境变量 my_variable 后，可通过 bash 命令启动一个子 shell。在这个子 shell 中能够正确的显示出变量 my_variable 的值。该变量能够保留住它的值是因为 export 命令使其变成了全局环境变量。 修改子 shell 中全局环境变量并不会影响到父 shell 中该变量的值。除此之外，子 shell 甚至无法使用 export 命令改变父 shell 中全局环境变量的值。 当然，既然可以创建新的环境变量，自然也能删除已经存在的环境变量。可以用 unset 命令完成这个操作。在 unset 命令中引用环境变量时，记住不要使用$。 1234567$ echo $my_variableI am Global now$$ unset my_variable$$ echo $my_variable$ 在涉及环境变量名时，什么时候该使用$，什么时候不该使用$，实在让人摸不着头脑。记住一点就行了：如果要用到变量，使用$；如果要操作变量，不使用$。这条规则的一个例外就是使用 printenv 显示某个变量的值 在处理全局环境变量时，事情就有点棘手了。如果你是在子进程中删除了一个全局环境变量，这只对子进程有效。该全局环境变量在父进程中依然可用。和修改变量一样，在子 shell 中删除全局变量后，你无法将效果反映到父 shell 中。 默认的环境变量默认情况下，bash shell 会用一些特定的环境变量来定义系统环境。这些变量在你的 Linux 系统上都已经设置好了，只管放心使用。bash shell 源自当初的 Unix Bourne shell，因此也保留了 Unix Bourne shell 里定义的那些环境变量。除了默认的 Bourne 的环境变量，bash shell 还提供一些自有的变量。你可能已经注意到，不是所有的默认环境变量都会在运行 set 命令时列出。尽管这些都是默认环境变量，但并不是每一个都必须有一个值。 其中最重要的一个环境变量为 PATH。当你在 shell 命令行界面中输入一个外部命令时，shell 必须搜索系统来找到对应的程序。PATH 环境变量定义了用于进行命令和程序查找的目录。在本文所用的 Arch Linux 系统中，PATH 环境变量的内容是这样的： 12$ echo $PATH/usr/local/sbin:/usr/local/bin:/usr/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl 输出中显示了多个可供 shell 用来查找命令和程序的目录。PATH 中的目录使用冒号分隔。如果命令或者程序的位置没有包括在 PATH 变量中，那么如果不使用绝对路径的话，shell 是没法找到的。如果 shell 找不到指定的命令或程序，它会产生一个经典的错误信息：command not found。 一般来说，默认环境变量有很多，在需要用到时查阅用法即可，不必全部记忆。 可以把新的搜索目录添加到现有的 PATH 环境变量中，无需从头定义。PATH 中各个目录之间是用冒号分隔的。你只需引用原来的 PATH 值，然后再给这个字符串添加新目录就行了。 1$ PATH=$PATH:/home/christine/Scripts 一些程序员习惯将单点符也加入 PATH 环境变量。该单点符代表当前目录 1$ PATH=$PATH:. 如此对 PATH 变量的修改只能持续到终端退出或重启系统。这种效果并不能一直持续。在下一节中，你会学到如何永久保持环境变量的修改效果。 定位系统环境变量在你登入 Linux 系统启动一个 bash shell 时，默认情况下 bash 会在几个文件中查找命令。这些文件叫作启动文件或环境文件。bash 检查的启动文件取决于你启动 bash shell 的方式。启动 bash shell 有 3 种方式： 登录时作为默认登录 shell 作为非登录 shell 的交互式 shell 作为运行脚本的非交互 shell 下面几节介绍了 bash shell 在不同的方式下启动文件。 登录 shell当你登录 Linux 系统时，bash shell 会作为登录 shell 启动。登录 shell 会从 5 个不同的启动文件里读取命令： &#x2F;etc&#x2F;profile $HOME&#x2F;.bash_profile $HOME&#x2F;.bashrc $HOME&#x2F;.bash_login $HOME&#x2F;.profile &#x2F;etc&#x2F;profile 文件是系统上默认的 bash shell 的主启动文件。系统上的每个用户登录时都会执行这个启动文件 要留意的是有些 Linux 发行版使用了可拆卸式认证模块（Pluggable Authentication Modules ，PAM）。在这种情况下，PAM 文件会在 bash shell 启动之前处理，这些文件中可能会包含环境变量。PAM 文件包括&#x2F;etc&#x2F;environment 文件和$HOME&#x2F;.pam_environment 文件。PAM 更多的相关信息可以在 http://linux-pam.org 中找到。 另外 4 个启动文件是针对用户的，可根据个人需求定制。注意，这四个文件都以点号开头，这说明它们是隐藏文件（不会在通常的 ls 命令输出列表中出现）。它们位于用户的 HOME 目录下，所以每个用户都可以编辑这些文件并添加自己的环境变量，这些环境变量会在每次启动 bash shell 会话时生效。 Linux 发行版在环境文件方面存在的差异非常大。本节中所列出的$HOME下的那些文件并非每个用户都有。例如有些用户可能只有一个$HOME&#x2F;.bash_profile 文件。这很正常。 &#x2F;etc&#x2F;profile 文件 &#x2F;etc&#x2F;profile 文件是 bash shell 默认的的主启动文件。只要你登录了 Linux 系统，bash 就会执行&#x2F;etc&#x2F;profile 启动文件中的命令。不同的 Linux 发行版在这个文件里放了不同的命令。每个发行版的&#x2F;etc&#x2F;profile 文件都有不同的设置和命令。例如，在 Arch Linux 的&#x2F;etc&#x2F;profile 文件中，涉及了一个叫作&#x2F;etc&#x2F;bash.bashrc 的文件。这个文件包含了系统环境变量等其他内容。但是，&#x2F;etc&#x2F;profile 各个发行版有所不同，在 CentOS 发行版的&#x2F;etc&#x2F;profile 文件中，并没有出现这个文件。 许多发行版的&#x2F;etc&#x2F;profile 文件都用到了同一个特性：for 语句。它用来迭代&#x2F;etc&#x2F;profile.d 目录下的所有文件（该语句会在后续章节详述）。这为 Linux 系统提供了一个放置特定应用程序启动文件的地方，当用户登录时，shell 会执行这些文件。在本文所用的 Arch Linux 系统中，&#x2F;etc&#x2F;profile.d 目录下包含以下文件： 123456789$ ls -l /etc/profile.d总用量 36-rw-r--r-- 1 root root 545 Oct 20 17:10 freetype2.sh-rw-r--r-- 1 root root 1107 Apr 15 2020 gawk.csh-rw-r--r-- 1 root root 757 Apr 15 2020 gawk.sh-rwxr-xr-x 1 root root 105 Sep 25 21:52 gpm.sh-rw-r--r-- 1 root root 766 Sep 3 06:30 locale.sh-rw-r--r-- 1 root root 468 Sep 18 05:12 perlbin.csh-rw-r--r-- 1 root root 464 Sep 18 05:12 perlbin.sh 不难发现，有些文件与系统中的特定应用有关。大部分应用都会创建两个启动文件：一个供 bash shell 使用（使用.sh 扩展名），一个供 c shell 使用（使用.csh 扩展名）。locale.sh 文件会尝试去判定系统上所采用的默认语言字符集，然后设置对应的 LANG 环境变量。 $HOME 目录下的启动文件 这些启动文件都起着同一个作用：提供一个用户专属的启动文件来定义该用户所用到的环境变量。大多数 Linux 发行版只用这四个启动文件中的一到两个： $HOME&#x2F;.bash_profile $HOME&#x2F;.bashrc $HOME&#x2F;.bash_login $HOME&#x2F;.profile shell 会按照按照下列顺序，运行第一个被找到的文件，余下的则被忽略： $HOME&#x2F;.bash_profile $HOME&#x2F;.bash_login $HOME&#x2F;.profile 注意，这个列表中并没有$HOME&#x2F;.bashrc 文件。这是因为该文件通常通过其他文件运行的。 记住，$HOME 表示的是某个用户的主目录。它和波浪号（~）的作用一样。 Arch Linux 系统中的.bash_profile 文件的内容如下 123456$ cat $HOME/.bash_profile## ~/.bash_profile#[[ -f ~/.bashrc ]] &amp;&amp; . ~/.bashrc .bash_profile 启动文件会先去检查 HOME 目录中是不是还有一个叫.bashrc 的启动文件。如果有的话，会先执行启动文件里面的命令。 交互式 shell 进程如果你的 bash shell 不是登录系统时启动的（比如是在命令行提示符下敲入 bash 时启动），那么你启动的 shell 叫作交互式 shell。交互式 shell 不会像登录 shell 一样运行，但它依然提供了命令行提示符来输入命令。 如果 bash 是作为交互式 shell 启动的，它就不会访问&#x2F;etc&#x2F;profile 文件，只会检查用户 HOME 目录中的.bashrc 文件。 在本文所用的 Arch Linux 系统上，这个文件看起来如下： 12345678910$ cat .bashrc## ~/.bashrc## If not running interactively, don&#x27;t do anything[[ $- != *i* ]] &amp;&amp; returnalias ls=&#x27;ls --color=auto&#x27;PS1=&#x27;[\\u@\\h \\W]\\$&#x27; .bashrc 文件有两个作用：一是查看并执行&#x2F;etc 目录下通用的 bashrc 文件(&#x2F;etc&#x2F;bashrc)，在 Arch Linux 上无此表现，但是在 Centos 上是存在的。二是为用户提供一个定制自己的命令别名和私有脚本函数（将在后文讲到）的地方。 上面的 PS1 值就是终端下提示符的格式，如[testuser@archlinux ~]$ 非交互式 shell最后一种 shell 是非交互式 shell。系统执行 shell 脚本时用的就是这种 shell。不同的地方在于它没有命令行提示符。但是当你在系统上运行脚本时，也许希望能够运行一些特定启动的命令。 脚本能以不同的方式执行。只有其中的某一些方式能够启动子 shell。你会在后续学习到 shell 不同的执行方式。 为了处理这种情况，bash shell 提供了 BASH_ENV 环境变量。当 shell 启动一个非交互式 shell 进程时，它会检查这个环境变量来查看要执行的启动文件。如果有指定的文件，shell 会执行该文件里的命令，这通常包括 shell 脚本变量设置。 在本文所用的 Arch Linux 发行版中，变量 BASH_ENV 没有被设置。记住，如果变量未设置，echo 命令会显示一个空行，然后返回 CLI 提示符： 123$ printenv BASH_ENV$ 那如果 BASH_ENV 变量没有设置，shell 脚本到哪里去获得它们的环境变量呢？别忘了有些 shell 脚本是通过启动一个子 shell 来执行的。子 shell 可以继承父 shell 导出过的变量。 举例来说，如果父 shell 是登录 shell，在&#x2F;etc&#x2F;profile、&#x2F;etc&#x2F;profile.d&#x2F;*.sh 和$HOME&#x2F;.bashrc 文件中设置并导出了变量，用于执行脚本的子 shell 就能够继承这些变量。 要记住，由父 shell 设置但并未导出的变量都是局部变量。子 shell 无法继承局部变量。 对于那些不启动子 shell 的脚本，变量已经存在于当前 shell 中了。所以就算没有设置 BASH_ENV，也可以使用当前 shell 的局部变量和全局变量。 环境变量持久化现在你已经了解了各种 shell 进程以及对应的环境文件，找出永久性环境变量就容易多了。也可以利用这些文件创建自己的永久性全局变量或局部变量。 对全局环境变量来说（Linux 系统中所有用户都需要使用的变量），可能更倾向于将新的或修改过的变量设置放在&#x2F;etc&#x2F;profile 文件中，但这可不是什么好主意。如果你升级了所用的发行版，这个文件也会跟着更新，那你所有定制过的变量设置可就都没有了。 最好是在&#x2F;etc&#x2F;profile.d 目录中创建一个以.sh 结尾的文件。把所有新的或修改过的全局环境变量设置放在这个文件中。 在大多数发行版中，存储个人用户永久性 bash shell 变量的地方是$HOME&#x2F;.bashrc文件。这一点适用于所有类型的shell进程。但如果设置了BASH_ENV变量，那么记住，除非它指向的是$HOME&#x2F;.bashrc，否则你应该将非交互式 shell 的用户变量放在别的地方。 图形化界面组成部分（如 GUI 客户端）的环境变量可能需要在另外一些配置文件中设置，这和设置 bash shell 环境变量的地方可能不一样。 想想之前讲过的 alias 命令设置就是不能持久的。你可以把自己的 alias 设置放在$HOME&#x2F;.bashrc 启动文件中，使其效果永久化。 数组变量环境变量有一个很酷的特性就是，它们可作为数组使用。数组是能够存储多个值的变量。这些值可以单独引用，也可以作为整个数组来引用。要给某个环境变量设置多个值，可以把值放在括号里，值与值之间用空格分隔。 1mytest=(one two three four five) 没什么特别的地方。如果你想把数组像普通的环境变量那样显示，你会失望的。 12$ echo $mytestone 只有数组的第一个值显示出来了。要引用一个单独的数组元素，就必须用代表它在数组中位置的数值索引值。索引值要用方括号括起来。 12$ echo $&#123;mytest[2]&#125;three 环境变量数组的索引值都是从零开始。这通常会带来一些困惑。 要显示整个数组变量，可用星号作为通配符放在索引值的位置。 12$ echo $&#123;mytest[*]&#125;one two three four five 甚至能用 unset 命令删除数组中的某个值，但是要小心，这可能会有点复杂。看下面的例子。 12345678910$ unset mytest[2]$$ echo $&#123;mytest[*]&#125;one two four five$$ echo $&#123;mytest[2]&#125;$ echo $&#123;mytest[3]&#125;four$ 这个例子用 unset 命令删除在索引值为 2 的位置上的值。显示整个数组时，看起来像是索引里面已经没这个索引了。但当专门显示索引值为 2 的位置上的值时，就能看到这个位置是空的。 最后，可以在 unset 命令后跟上数组名来删除整个数组。 12345$ unset mytest$$ echo $&#123;mytest[*]&#125;$ 有时数组变量会让事情很麻烦，所以在 shell 脚本编程时并不常用。对其他 shell 而言，数组变量的可移植性并不好，如果需要在不同的 shell 环境下从事大量的脚本编写工作，这会带来很多不便。有些 bash 系统环境变量使用了数组（比如 BASH_VERSINFO），但总体上不会太频繁用到。 Linux 文件权限缺乏安全性的系统不是完整的系统。系统中必须有一套能够保护文件免遭非授权用户浏览或修改的机制。Linux 沿用了 Unix 文件权限的办法，即允许用户和组根据每个文件和目录的安全性设置来访问文件。本章将介绍如何在必要时利用 Linux 文件安全系统保护和共享数据。 Linux 的安全性Linux 安全系统的核心是用户账户。每个能进入 Linux 系统的用户都会被分配唯一的用户账户。用户对系统中各种对象的访问权限取决于他们登录系统时用的账户。用户权限是通过创建用户时分配的用户 ID（User ID，通常缩写为 UID）来跟踪的。UID 是数值，每个用户都有唯一的 UID，但在登录系统时用的不是 UID，而是登录名。 Linux 系统使用特定的文件和工具来跟踪和管理系统上的用户账户。在我们讨论文件权限之前，先来看一下 Linux 是怎样处理用户账户的。本节会介绍管理用户账户需要的文件和工具，这样在处理文件权限问题时，你就知道如何使用它们了。 &#x2F;etc&#x2F;passwd 文件Linux 系统使用一个专门的文件来将用户的登录名匹配到对应的 UID 值。这个文件就是&#x2F;etc&#x2F;passwd 文件，它包含了一些与用户有关的信息。下面是 Linux 系统上典型的&#x2F;etc&#x2F;passwd 文件的一个例子。 123456789101112$ cat /etc/passwdroot:x:0:0::/root:/bin/bashbin:x:1:1::/:/usr/bin/nologindaemon:x:2:2::/:/usr/bin/nologinhttp:x:33:33::/srv/http:/usr/bin/nologinnobody:x:65534:65534:Nobody:/:/usr/bin/nologindbus:x:81:81:System Message Bus:/:/usr/bin/nologinsystemd-journal-remote:x:982:982:systemd Journal Remote:/:/usr/bin/nologinsystemd-network:x:981:981:systemd Network Management:/:/usr/bin/nologintestuser:x:1000:985::/home/testuser:/bin/bashcups:x:209:209:cups helper user:/:/usr/bin/nologindhcpcd:x:969:969:dhcpcd privilege separation:/var/lib/dhcpcd:/usr/bin/nologin root 用户账户是 Linux 系统的管理员，固定分配给它的 UID 是 0。就像上例中显示的，Linux 系统会为各种各样的功能创建不同的用户账户，而这些账户并不是真的用户。这些账户叫作系统账户，是系统上运行的各种服务进程访问资源用的特殊账户。所有运行在后台的服务都需要用一个系统用户账户登录到 Linux 系统上。 在安全成为一个大问题之前，这些服务经常会用 root 账户登录。遗憾的是，如果有非授权的用户攻陷了这些服务中的一个，他立刻就能作为 root 用户进入系统。为了防止发生这种情况，现在运行在 Linux 服务器后台的几乎所有的服务都是用自己的账户登录。这样的话，即使有人攻入了某个服务，也无法访问整个系统。 Linux 为系统账户预留了 1000 以下的 UID 值。有些服务甚至要用特定的 UID 才能正常工作。为普通用户创建账户时，大多数 Linux 系统会从 1000 开始，将第一个可用 UID 分配给这个账户（并非所有的 Linux 发行版都是这样）。你可能已经注意到&#x2F;etc&#x2F;passwd 文件中还有很多用户登录名和 UID 之外的信息。&#x2F;etc&#x2F;passwd 文件的字段包含了如下信息： 登录用户名 用户密码 用户账户的 UID（数字形式） 用户账户的组 ID（GID）（数字形式） 用户账户的文本描述（称为备注字段） 用户 HOME 目录的位置 用户的默认 shell &#x2F;etc&#x2F;passwd 文件中的密码字段都被设置成了 x，这并不是说所有的用户账户都用相同的密码。在早期的 Linux 上，&#x2F;etc&#x2F;passwd 文件里有加密后的用户密码。但鉴于很多程序都需要访问&#x2F;etc&#x2F;passwd 文件获取用户信息，这就成了一个安全隐患。随着用来破解加密密码的工具的不断演进，用心不良的人开始忙于破解存储在&#x2F;etc&#x2F;passwd 文件中的密码。Linux 开发人员需要重新考虑这个策略。 现在，绝大多数 Linux 系统都将用户密码保存在另一个单独的文件中（叫作 shadow 文件，位置在&#x2F;etc&#x2F;shadow）。只有特定的程序（比如登录程序）才能访问这个文件。 &#x2F;etc&#x2F;passwd 是一个标准的文本文件。你可以用任何文本编辑器在&#x2F;etc&#x2F;password 文件里直接手动进行用户管理（比如添加、修改或删除用户账户）。但这样做极其危险。如果&#x2F;etc&#x2F;passwd 文件出现损坏，系统就无法读取它的内容了，这样会导致用户无法正常登录（即便是 root 用户）。用标准的 Linux 用户管理工具去执行这些用户管理功能就会安全许多。 &#x2F;etc&#x2F;shadow 文件&#x2F;etc&#x2F;shadow 文件对 Linux 系统密码管理提供了更多的控制。只有 root 用户才能访问&#x2F;etc&#x2F;shadow 文件，这让它比起&#x2F;etc&#x2F;passwd 安全许多。 &#x2F;etc&#x2F;shadow 文件为系统上的每个用户账户都保存了一条记录。记录就像下面这样： 1testuser:$6$inJRhswsgTqYbpOp$Tjas9zGdk/lLovn4M1xxczsZF/5ZlJlqnjyDiaRuTTs.:18361:0:99999:7::: 在&#x2F;etc&#x2F;shadow 文件的每条记录中都有 9 个字段 与&#x2F;etc&#x2F;passwd 文件中的登录名字段对应的登录名 加密后的密码 自上次修改密码后过去的天数（自 1970 年 1 月 1 日开始计算） 多少天后才能更改密码 多少天后必须更改密码 密码过期前提前多少天提醒用户更改密码 密码过期后多少天禁用用户账户 用户账户被禁用的日期（用自 1970 年 1 月 1 日到当天的天数表示） 预留字段给将来使用 使用 shadow 密码系统后，Linux 系统可以更好地控制用户密码。它可以控制用户多久更改一次密码，以及什么时候禁用该用户账户，如果密码未更新的话。 添加新用户用来向 Linux 系统添加新用户的主要工具是 useradd。这个命令简单快捷，可以一次性创建新用户账户及设置用户 HOME 目录结构。useradd 命令使用系统的默认值以及命令行参数来设置用户账户。系统默认值被设置在&#x2F;etc&#x2F;default&#x2F;useradd 文件中。 12345678910$ sudo cat /etc/default/useradd# useradd defaults file for ArchLinux# original changes by TomKGROUP=usersHOME=/homeINACTIVE=-1EXPIRE=SHELL=/bin/bashSKEL=/etc/skelCREATE_MAIL_SPOOL=no 在创建新用户时，如果你不在命令行中指定具体的值，useradd 命令就会使用那些默认值。这个例子列出的默认值如下： 新用户会被添加到 users 的公共组； 新用户的 HOME 目录将会位于&#x2F;home&#x2F;loginname； 新用户账户密码在过期后不会被禁用； 新用户账户未被设置过期日期； 新用户账户将 bash shell 作为默认 shell； 系统会将&#x2F;etc&#x2F;skel 目录下的内容复制到用户的 HOME 目录下； 系统不会为该用户账户在 mail 目录下创建一个用于接收邮件的文件。 倒数第二个值很有意思。useradd 命令允许管理员创建一份默认的 HOME 目录配置，然后把它作为创建新用户 HOME 目录的模板。这样就能自动在每个新用户的 HOME 目录里放置默认的系统文件。在 Arch Linux 系统上，&#x2F;etc&#x2F;skel 目录有下列文件： 12345678$ ls -al /etc/skel总用量 20drwxr-xr-x 2 root root 4096 Aug 20 13:32 .drwxr-xr-x 99 root root 4096 Nov 26 13:03 ..-rw-r--r-- 1 root root 21 Aug 10 00:27 .bash_logout-rw-r--r-- 1 root root 57 Aug 10 00:27 .bash_profile-rw-r--r-- 1 root root 141 Aug 10 00:27 .bashrc 它们是 bash shell 环境的标准启动文件。系统会自动将这些默认文件复制到你创建的每个用户的 HOME 目录。 可以用默认系统参数创建一个新用户账户，然后检查一下新用户的 HOME 目录。 1$ sudo useradd -m test 默认情况下，useradd 命令不会创建 HOME 目录，但是-m 命令行选项会使其创建 HOME 目录。你能在此例中看到，useradd 命令创建了新 HOME 目录，并将&#x2F;etc&#x2F;skel 目录中的文件复制了过来。 运行本章中提到的用户账户管理命令，需要以 root 用户账户登录或者通过 sudo 命令以 root 用户账户身份运行这些命令。 要想在创建用户时改变默认值或默认行为，可以使用 useradd 的额外命令行参数，具体可参见 man。 你会发现，在创建新用户账户时使用命令行参数可以更改系统指定的默认值。但如果总需要修改某个值的话，最好还是修改一下系统的默认值。可以在-D 选项后跟上一个指定的值来修改系统默认的新用户设置。如下示例 1$ sudo useradd -D -s /bin/tsch 现在，useradd 命令会将 tsch shell 作为所有新建用户的默认登录 shell。 删除用户如果你想从系统中删除用户，userdel 可以满足这个需求。默认情况下，userdel 命令会只删除&#x2F;etc&#x2F;passwd 文件中的用户信息，而不会删除系统中属于该账户的任何文件。 如果加上-r 参数，userdel 会删除用户的 HOME 目录以及邮件目录。然而，系统上仍可能存有已删除用户的其他文件。这在有些环境中会造成问题。 下面是用 userdel 命令删除已有用户账户的一个例子。 1$ sudo userdel -r test 在有大量用户的环境中使用-r 参数时要特别小心。你永远不知道用户是否在其 HOME 目录下存放了其他用户或其他程序要使用的重要文件。记住，在删除用户的 HOME 目录之前一定要检查清楚！ 修改用户Linux 提供了一些不同的工具来修改已有用户账户的信息。如下列出了这些工具。 usermod: 修改用户账户的字段，还可以指定主要组以及附加组的所属关系 passwd: 修改已有用户的密码 chpasswd: 从文件中读取登录名密码对，并更新密码 chage: 修改密码的过期日期 chfn: 修改用户账户的备注信息 chsh: 修改用户账户的默认登录 shell 每种工具都提供了特定的功能来修改用户账户信息。下面将具体介绍这些工具 usermodusermod 命令是用户账户修改工具中最强大的一个。它能用来修改&#x2F;etc&#x2F;passwd 文件中的大部分字段，只需用与想修改的字段对应的命令行参数就可以了。参数大部分跟 useradd 命令的参数一样（比如，-c 修改备注字段，-e 修改过期日期，-g 修改默认的登录组）。除此之外，还有另外一些可能派上用场的选项。 -l 修改用户账户的登录名。 -L 锁定账户，使用户无法登录。 -p 修改账户的密码。 -U 解除锁定，使用户能够登录。 -L 选项尤其实用。它可以将账户锁定，使用户无法登录，同时无需删除账户和用户的数据。要让账户恢复正常，只要用-U 选项就行了。 passwd 和 chpasswd改变用户密码的一个简便方法就是用 passwd 命令 1234$ sudo passwd test新的密码：重新输入新的密码：passwd：已成功更新密码 如果只用 passwd 命令，它会改你自己的密码。系统上的任何用户都能改自己的密码，但只有 root 用户才有权限改别人的密码。 -e 选项能强制用户下次登录时修改密码。你可以先给用户设置一个简单的密码，之后再强制在下次登录时改成他们能记住的更复杂的密码。 如果需要为系统中的大量用户修改密码，chpasswd 命令可以事半功倍。chpasswd 命令能从标准输入自动读取登录名和密码对（由冒号分割）列表，给密码加密，然后为用户账户设置。你也可以用重定向命令来将含有 userid:passwd 对的文件重定向给该命令。 1$ sudo chpasswd &lt; users.txt chsh、chfn 和 chagechsh、chfn 和 chage 工具专门用来修改特定的账户信息。chsh 命令用来快速修改默认的用户登录 shell。使用时必须用 shell 的全路径名作为参数，不能只用 shell 名。 123$ sudo chsh -s /bin/csh testChanging shell for test.Shell changed. chfn 命令提供了在&#x2F;etc&#x2F;passwd 文件的备注字段中存储信息的标准方法。chfn 命令会将用于 Unix 的 finger 命令的信息存进备注字段，而不是简单地存入一些随机文本（比如名字或昵称之类的），或是将备注字段留空。finger 命令可以非常方便地查看 Linux 系统上的用户信息。 12345678910111213$ sudo finger testuserLogin: testuser Name: (null)Directory: /home/testuser Shell: /bin/bashOn since Thu Nov 26 13:02 (CST) on tty1 from :0 8 hours 54 minutes idleOn since Thu Nov 26 13:02 (CST) on pts/0 from :0 8 hours 53 minutes idleOn since Thu Nov 26 21:17 (CST) on pts/1 from :0 5 seconds idle (messages off)No mail.No Plan. 出于安全性考虑，很多 Linux 系统管理员会在系统上禁用 finger 命令，不少 Linux 发行版甚至都没有默认安装该命令。在 Arch Linux 上，需要通过 AUR 安装netkit-bsd-finger包来使用 finger 命令 如果在使用 chfn 命令时没有参数，它会向你询问要将哪些适合的内容加进备注字段。 1234567$ sudo chfn testChanging finger information for test.Name []: Ima TestOffice []: Director of Technology OfficePhone []: (123)555-1234Home Phone []: (123)555-9876Finger information changed. 查看&#x2F;etc&#x2F;passwd 文件中的记录，你会看到下面这样的结果。 12$ grep test /etc/passwdtest:x:504:504:Ima Test,Director of Technology,(123)555- 1234,(123)555-9876:/home/test:/bin/csh 所有的指纹信息现在都存在&#x2F;etc&#x2F;passwd 文件中了。 最后，chage 命令用来帮助管理用户账户的有效期。 -d: 设置上次修改密码到现在的天数 -E: 设置密码过期的日期 -I: 设置密码过期到锁定账户的天数 -m: 设置修改密码之间最少要多少天 -W: 设置密码过期前多久开始出现提醒信息 chage 命令的日期值可以用下面两种方式中的任意一种： YYYY-MM-DD 格式的日期 代表从 1970 年 1 月 1 日起到该日期天数的数值 chage 命令中有个好用的功能是设置账户的过期日期。有了它，你就能创建在特定日期自动过期的临时用户，再也不需要记住删除用户了！过期的账户跟锁定的账户很相似：账户仍然存在，但用户无法用它登录。 使用 Linux 组用户账户在控制单个用户安全性方面很好用，但涉及在共享资源的一组用户时就捉襟见肘了。为了解决这个问题，Linux 系统采用了另外一个安全概念——组（group） 组权限允许多个用户对系统中的对象（比如文件、目录或设备等）共享一组共用的权限。 Linux 发行版在处理默认组的成员关系时略有差异。有些 Linux 发行版会创建一个组，把所有用户都当作这个组的成员。遇到这种情况要特别小心，因为一个用户的文件很有可能对其他用户也是可读的。有些发行版会为每个用户创建单独的一个组，这样可以更安全一些。例如，在 KDE 中创建用户， 就会为每个用户创建一个单独的与用户账户同名的组。在添加用户前后可用 grep 命令或 tail 命令查看&#x2F;etc&#x2F;group 文件的内容进行比较。 每个组都有唯一的 GID——跟 UID 类似，在系统上这是个唯一的数值。除了 GID，每个组还有唯一的组名。Linux 系统上有一些组工具可以创建和管理你自己的组。本节将细述组信息是如何保存的，以及如何用组工具创建新组和修改已有的组。 &#x2F;etc&#x2F;group 文件与用户账户类似，组信息也保存在系统的一个文件中。&#x2F;etc&#x2F;group 文件包含系统上用到的每个组的信息。下面是一些来自 Linux 系统上&#x2F;etc&#x2F;group 文件中的典型例子。 1234567891011121314151617181920$ cat /etc/grouproot:x:0:rootsys:x:3:binlog:x:19:proc:x:26:polkitdwheel:x:998:testuser,test,test2tty:x:5:systemd-journal:x:984:bin:x:1:daemondaemon:x:2:binhttp:x:33:nobody:x:65534:dbus:x:81:systemd-network:x:981:systemd-timesync:x:979:git:x:970:cups:x:209:dhcpcd:x:969:sddm:x:968:testuser:x:1000: 和 UID 一样，GID 在分配时也采用了特定的格式。系统账户用的组通常会分配低于 1000 的 GID 值，而用户组的 GID 则会从 1000 开始分配。&#x2F;etc&#x2F;group 文件有 4 个字段： 组名 组密码 GID 属于该组的用户列表 组密码允许非组内成员通过它临时成为该组成员。这个功能并不很普遍，但确实存在。 千万不能通过直接修改&#x2F;etc&#x2F;group 文件来添加用户到一个组，要用 usermod 命令。在添加用户到不同的组之前，首先得创建组(创建用户时，默认生成的与用户名同名的组除外)。 用户账户列表某种意义上有些误导人。你会发现，在列表中，有些组并没有列出用户,如 testuser 组。这并不是说这些组没有成员。当一个用户在&#x2F;etc&#x2F;passwd 文件中指定某个组作为默认组时，用户账户不会作为该组成员再出现在&#x2F;etc&#x2F;group 文件中。多年以来，被这个问题难倒的系统管理员可不是一两个呢。如果想要严谨的查看一个组所有的全部用户，可以先取&#x2F;etc&#x2F;passwd 下以该组为默认组的用户，再加上&#x2F;etc&#x2F;group 下该组的用户，合并这两部分，就能得到该组全部的用户列表了。除此之外，以用户的维度，可以使用id命令查看一个用户所属的组的情况。 创建新组groupadd 命令可在系统上创建新组。 1$ sudo groupadd shared 在创建新组时，默认没有用户被分配到该组。groupadd 命令没有提供将用户添加到组中的选项，但可以用 usermod 命令来弥补这一点。 1$ sudo usermod -G shared test usermod 命令的-G 选项会用这个新组覆盖该用户的附加属组列表。 如果更改了已登录系统账户所属的用户组，该用户必须登出系统后再登录，组关系的更改才能生效。 为用户账户分配组时要格外小心。如果加了-g 选项，指定的组名会替换掉该账户的默认组。-G 选项的值将覆盖用户附加属组列表，不会影响默认组。如果想向附加属组列表中追加组，需要使用-aG 选项。 修改组在&#x2F;etc&#x2F;group 文件中可以看到，需要修改的组信息并不多。groupmod 命令可以修改已有组的 GID（加-g 选项）或组名（加-n 选项）。 1$ groupmod -n sharing shared 原 shared 组被更名为 sharing。 修改组名时，GID 和组成员不会变，只有组名改变。由于所有的安全权限都是基于 GID 的，你可以随意改变组名而不会影响文件的安全性。 理解文件权限现在你已经了解了用户和组，是时候解读 ls 命令输出时所出现的谜一般的文件权限了。本节将会介绍如何对权限进行分析以及它们的来历。 使用文件权限符使用 ls -l 可以查看到文件的权限情况 1234567891011121314$ ls -l总用量 600-rw-r--r-- 1 testuser users 540878 Nov 20 00:10 &#x27;2020-11-20 00-10-20.flv&#x27;-rw-r--r-- 1 testuser users 9 Oct 29 12:44 222drwxr-xr-x 5 testuser users 12288 Nov 27 01:55 Desktopdrwxr-xr-x 7 testuser users 4096 Oct 30 02:03 Documentsdrwxr-xr-x 21 testuser users 16384 Nov 7 17:25 Downloadsdrwxr-xr-x 5 testuser users 4096 Nov 23 23:21 Gamesdrwxr-xr-x 3 testuser users 4096 Apr 10 2020 Musicdrwxr-xr-x 4 testuser users 4096 Nov 18 17:32 &#x27;Nutstore Files&#x27;drwxr-xr-x 3 testuser users 4096 Nov 2 14:11 Picturesdrwxr-xr-x 6 testuser users 4096 Sep 9 19:01 ThunderNetworkdrwxr-xr-x 3 testuser users 4096 Sep 5 22:33 Videosdrwxr-xr-x 7 testuser users 4096 Nov 18 18:18 &#x27;VirtualBox VMs&#x27; 输出结果的第一个字段就是描述文件和目录权限的编码。这个字段的第一个字符代表了对象的类型： -代表文件 d 代表目录 l 代表链接 c 代表字符型设备 b 代表块设备 n 代表网络设备 之后有 3 组三字符的编码。每一组定义了 3 种访问权限 r 代表对象是可读的 w 代表对象是可写的 x 代表对象是可执行的 若没有某种权限，在该权限位会出现单破折线。这 3 组权限分别对应对象的 3 个安全级别。 对象的属主 对象的属组 系统其他用户 讨论这个问题的最简单的办法就是找个例子，然后逐个分析文件权限。 1-rwxrwxr-x 1 rich rich 4882 2010-09-18 13:58 myprog 文件 myprog 有下面 3 组权限。 rwx：文件的属主（设为登录名 rich）。 rwx：文件的属组（设为组名 rich）。 r-x：系统上其他人 这些权限说明登录名为 rich 的用户可以读取、写入以及执行这个文件（可以看作有全部权限）。类似地，rich 组的成员也可以读取、写入和执行这个文件。然而不属于 rich 组的其他用户只能读取和执行这个文件：w 被单破折线取代了，说明这个安全级别没有写入权限。 默认文件权限你可能会问这些文件权限从何而来，答案是 umask。umask 命令用来设置所创建文件和目录的默认权限。 123$ touch newfile$ ls -al newfile-rw-r--r-- 1 rich rich 0 Sep 20 19:16 newfile touch 命令用分配给我的用户账户的默认权限创建了这个文件。umask 命令可以显示和设置这个默认权限。 123$ umask0022$ 遗憾的是，umask 命令设置没那么简单明了，想弄明白其工作原理就更混乱了。第一位仅代表 c 语言习惯的前导八进制 0,并不起实际作用。实际上，umask 会忽略任何一个前导 0(很多资料，如鸟哥私房菜、Linux bible 等，将第一位 0 解释为设置特殊权限位，即 SUID SGID 以及 SBIT，这是错误的。更多可参考 man 2 umask)。 后面的 3 位表示文件或目录对应的 umask 八进制值。要理解 umask 是怎么工作的，得先理解八进制模式的安全性设置。 八进制模式的安全性设置先分别获取文件的属主、文件的属组、系统上其他人 3 组 rwx 权限的二进制值，然后将其转换成 对于应的 3 个八进制值，连成一个长度为 3 的数值。举例来说，如果读权限是唯一置位的权限，权限值就是 r–，转换成二进制值就是 100，代表的八进制值是 4。如果拥有全部权限，权限值就是 rwx，转换成二进制值就是 111，代表的八进制值是 7。 八进制模式先取得权限的八进制值，然后再把这三组安全级别（属主、属组和其他用户）的八进制值顺序列出。因此，八进制模式的值 664 代表属主和属组成员都有读取和写入的权限，而其他用户都只有读取权限。 了解八进制模式权限是怎么工作的之后，umask 值反而更叫人困惑了。我的 Linux 系统上默认的八进制的 umask 值是 0022，而我所创建的文件的八进制权限却是 644，这是如何得来的呢？ umask 值只是个掩码。它会屏蔽掉不想授予该安全级别的权限。接下来我们还得再多进行一些八进制运算才能搞明白来龙去脉。 下一步要把 umask 值从对象的全权限值中减掉。对文件来说，全权限的值是 666（所有用户都有读和写的权限）；而对目录来说，则是 777（所有用户都有读、写、执行权限）。 所以在上例中，文件一开始的权限是 666，减去 umask 值 022 之后，剩下的文件权限就成了 644。 在大多数 Linux 发行版中，umask 值通常会设置在&#x2F;etc&#x2F;profile 启动文件中，不过有一些是设置在&#x2F;etc&#x2F;login.defs 文件中的（如 Ubuntu）。可以用 umask 命令为默认 umask 设置指定一个新值。 1234$ umask 026$ touch newfile2$ ls -l newfile2-rw-r----- 1 rich rich 0 Sep 20 19:46 newfile2 在把 umask 值设成 026 后，默认的文件权限变成了 640，因此新文件现在对组成员来说是只读的，而系统里的其他成员则没有任何权限。 umask 值同样会作用在创建目录上。 123$ mkdir newdir$ ls -ldrwxr-x--x 2 rich rich 4096 Sep 20 20:11 newdir/ 由于目录的默认权限是 777，umask 作用后生成的目录权限不同于生成的文件权限。umask 值 026 会从 777 中减去，留下来 751 作为目录权限设置。 时刻记住，这里的减去描述的意思为按位去除 umask 的权限，并不是真正的减法。比如文件的全权限是 666,umask 为 003，如果直接进行真正的减法操作，结果为 663，也即为-rw-rw--wx，原本没有执行权限的文件反而有执行权限了，这明显是错误的。正确的结果为转换为对应的权限，进行去除权限的操作，正确的结果为 664。 隐藏文件权限属性文件可以存在一些隐藏属性，对其权限进行额外的控制，较为常见的为 i 与 a 这两个属性。隐藏属性可通过如下方式查询和设置。 1234$ sudo chattr +i testfile$ lsattr attrtest----i----------- attrtest$ chattr -i testfile 隐藏属性 i 设置后，可以让一个文件不能被删除、改名、设置链接，也无法写入或新增数据。对于系统安全性有相当大的助益。只有 root 能设置此属性。 当设置 a 之后，这个文件将只能增加数据，而不能删除也不能修改数据，只有 root 才能设置这属性。 在执行 lsattr 后，你可能还会看到一个 e 属性，查阅 man 手册可知，e 属性表示文件正在使用范围扩展数据块来映射磁盘上的块。不能使用 chattr 将其删除。范围扩展是文件系统中为文件保留的连续存储区域。当进程创建文件时，文件系统管理软件会分配整个范围。当再次写入文件时（可能在执行其他写入操作之后），数据将从上次写入停止的地方继续。这减少或消除了文件碎片以及可能的文件分散。 改变安全性设置如果你已经创建了一个目录或文件，需要改变它的安全性设置，在 Linux 系统上有一些工具能够完成这项任务。本节将告诉你如何更改文件和目录的已有权限、默认文件属主以及默认属组。 改变权限chmod 命令用来改变文件和目录的安全性设置。该命令的格式如下： chmod options mode file mode 参数可以使用八进制模式或符号模式进行安全性设置。八进制模式设置非常直观，直接用期望赋予文件的标准 3 位八进制权限码即可。 123$ chmod 760 newfile$ ls -l newfile-rwxrw---- 1 rich rich 0 Sep 20 19:16 newfile 八进制文件权限会自动应用到指定的文件上。符号模式的权限就没这么简单了。与通常用到的 3 组三字符权限字符不同，chmod 命令采用了另一种方法。下面是在符号模式下指定权限的格式。 [ugoa…][+-&#x3D;][rwxxstugo…] 第一组字符定义了权限作用的对象： u 代表用户 g 代表组 o 代表其他 a 代表上述所有 下一步，后面跟着的符号表示你是想在现有权限基础上增加权限（+），还是在现有权限基础上移除权限（-），或是将权限设置成后面的值（&#x3D;）。 最后，第三组符号代表作用到设置上的权限。通常是 rwx 三种，你也会看到其余几种特殊的标志位，如 u,g,o。 u：将权限设置为跟属主一样。 g：将权限设置为跟属组一样。 o：将权限设置为跟其他用户一样。 像这样使用这些权限。 123$ chmod o+r newfile$ ls -lF newfile-rwxrw-r-- 1 rich rich 0 Sep 20 19:16 newfile* 不管其他用户在这一安全级别之前都有什么权限，o+r 都给这一级别添加读取权限。 123$ chmod u-x newfile$ ls -lF newfile-rw-rw-r-- 1 rich rich 0 Sep 20 19:16 newfile u-x 移除了属主已有的执行权限。注意 ls 命令的-F 选项，它能够在具有执行权限的文件名后加一个星号。 options 为 chmod 命令提供了另外一些功能。-R 选项可以让权限的改变递归地作用到文件和子目录。你可以使用通配符指定多个文件，然后利用一条命令将权限更改应用到这些文件上。 特殊标志位 SUID SGID 以及 SBIT除了常见的 rwx 权限，还有一些特殊的标志位，这让很多人迷惑，它们就是 SUID SGID 以及 SBIT。 Linux 为每个文件和目录存储了 3 个额外的信息位。 设置用户 ID（SUID）：当 s 这个标志出现在文件拥有者的 x 权限上时，此时就被称为 Set UID。当文件被用户使用时，程序会以文件属主的权限运行。举一个直观的例子，用户的密码存储在&#x2F;etc&#x2F;shadow 下，这个文件只有 root 用户才能进行写入，但是一个用户是可以通过 passwd 命令对自身的密码进行变更的，这里便用到了 SUID。通过 ls 查看，可以看到&#x2F;usr&#x2F;bin&#x2F;passwd 这个文件被赋予了 SUID 标志位，其拥有者是 root,那么执行 passwd 的过程中，普通用户会“暂时”获得 root 的权限，以便对自身密码进行修改。注意，SUID 仅在 binary program 二进制文件上生效，SUID 对于目录也是不生效的。 设置组 ID（SGID）：当 s 标志在文件拥有者的 x 位置为 SUID，同理，s 在群组的 x 时则称为 Set GID。对文件来说，程序会以文件属组的权限运行，SGID 也仅在 binary program 二进制文件上生效；对目录来说，目录中创建的新文件会以目录的默认属组作为默认属组。 粘着位（SBIT）：受限删除位。作用于其他组权限的位置,标志为 t。当使用者在该目录下创建文件或目录时，仅有自己与 root 才有权力删除该文件，他人无法删除。SBIT 目前只针对目录有效，对于文件已经没有效果了。 SGID 位对文件共享非常重要。启用 SGID 位后，你可以强制在一个共享目录下创建的新文件都属于该目录的属组，这个组也就成为了每个用户的属组 特殊标志位们可通过 chmod 命令设置。它会加到标准 3 位八进制值之前（组成 4 位八进制值），或者在符号模式下用符号 s&#x2F;t。 如果你用的是八进制模式，你需要知道这些位的位置，如下表所示。 二进制值 八进制值 描述 000 0 所有位都清零 001 1 粘着位置位 010 2 SGID 位置位 011 3 SGID 位和粘着位都置位 100 4 SUID 位置位 101 5 SUID 位和粘着位都置位 110 6 SUID 位和 SGID 位都置位 111 7 所有位都置位 举例来说，想要一个文件权限为-rwsr-xr-x，那么使用chmod 4755 filename进行设置。除了数字法之外，你也可以通过符号法来处理。其中 SUID 为 u+s ，而 SGID 为 g+s ，SBIT 则是 o+t。 此外，你有时还会看到大写的 X&#x2F;S&#x2F;T,它们的含义如下： X：如果对象是目录或者文件已有执行权限，则赋予执行权限。在批量设置文件夹和文件的权限时，此项很有用，用于保证批量执行时可执行权限的正确赋予。它避免了必须区分文件和目录。比如需要清除全部可执行标志位时，可以进行a-x,a=rwX的权限操作，而不用刻意区分目录和文件。 S&#x2F;T: 空的，没有执行权限的 UID&#x2F;GID 和黏置位。小写的 s 与 t 都是取代 x 这个权限的，但是当下达 7666 权限时，也就是说,user,group 以及 others 都没有 x 这个可执行的标志时(因为是 666)，特殊权限位也不可能有权限执行，7666 的结果为-rwSrwSrwT。所以，这个 S, T 代表的就是“空的”执行权限，不具有执行权限。换个说法， SUID +s 是表示“该文件在执行的时候，具有文件拥有者的权限”，但是文件拥有者都无法执行时，也就不存在权限给其他人使用了。 改变所属关系有时你需要改变文件的属主，比如有人离职或开发人员创建了一个在产品环境中需要归属在系统账户下的应用。Linux 提供了两个命令来实现这个功能：chown 命令用来改变文件的属主，chgrp 命令用来改变文件的默认属组。 chown 命令的格式如下。 chown options owner[.group] file 可用登录名或 UID 来指定文件的新属主 123$ sudo chown dan newfile$ ls -l newfile-rw-rw-r-- 1 dan rich 0 Sep 20 19:16 newfile 非常简单。chown 命令也支持同时改变文件的属主和属组。 123$ sudo chown dan.shared newfile$ ls -l newfile-rw-rw-r-- 1 dan shared 0 Sep 20 19:16 newfile 如果你不嫌麻烦，可以只改变一个目录的默认属组。 123$ sudo chown .rich newfile$ ls -l newfile-rw-rw-r-- 1 dan rich 0 Sep 20 19:16 newfile 最后，如果你的 Linux 系统采用和用户登录名匹配的组名，可以只用一个条目就改变二者。 123$ sudo chown test. newfile$ ls -l newfile-rw-rw-r-- 1 test test 0 Sep 20 19:16 newfile chown 命令采用一些不同的选项参数。-R 选项配合通配符可以递归地改变子目录和文件的所属关系。-h 选项可以改变该文件的所有符号链接文件的所属关系。 只有 root 用户能够改变文件的属主。任何属主都可以改变文件的属组，但前提是属主必须是原属组和目标属组的成员。 chgrp 命令可以更改文件或目录的默认属组。 123$ chgrp shared newfile$ ls -l newfile-rw-rw-r-- 1 rich shared 0 Sep 20 19:16 newfile 用户账户必须是这个文件的属主，除了能够更换属组之外，还得是新组的成员。现在 shared 组的任意一个成员都可以写这个文件了。这是 Linux 系统共享文件的一个途径。然而，在系统中给一组用户共享文件也会变得很复杂。下一节会介绍如何实现。 共享文件可能你已经猜到了，Linux 系统上共享文件的方法是创建组。但在一个完整的共享文件的环境中，事情会复杂得多。 你已经看到，创建新文件时，Linux 会用你默认的 UID 和 GID 给文件分配权限。想让其他人也能访问文件，要么改变其他用户所在安全组的访问权限，要么就给文件分配一个包含其他用户的新默认属组。 如果你想在大范围环境中创建文档并将文档与人共享，这会很烦琐。幸好有一种简单的方法可以解决这个问题。要创建一个共享目录，使目录里的新文件都能沿用目录的属组，只需将该目录的 SGID 位置位。 12345678910111213$ mkdir testdir$ ls -ldrwxrwxr-x 2 rich rich 4096 Sep 20 23:12 testdir/$ chgrp shared testdir$ chmod g+s testdir$ ls -ldrwxrwsr-x 2 rich shared 4096 Sep 20 23:12 testdir/$ umask 002$ cd testdir$ touch testfile$ ls -ltotal 0-rw-rw-r-- 1 rich shared 0 Sep 20 23:13 testfile 首先，用 mkdir 命令来创建希望共享的目录。然后通过 chgrp 命令将目录的默认属组改为包含所有需要共享文件的用户的组（你必须是该组的成员）。最后，将目录的 SGID 位置位，以保证目录中新建文件都用 shared 作为默认属组。 为了让这个环境能正常工作，所有组成员都需把他们的 umask 值设置成文件对属组成员可写。在前面的例子中，umask 改成了 002，所以文件对属组是可写的。 做完了这些，组成员就能到共享目录下创建新文件了。跟期望的一样，新文件会沿用目录的属组，而不是用户的默认属组。现在 shared 组的所有用户都能访问这个文件了。 管理文件系统使用 Linux 系统时，需要作出的决策之一就是为存储设备选用什么文件系统。大多数 Linux 发行版在安装时会非常贴心地提供默认的文件系统，大多数入门级用户想都不想就用了默认的那个。 使用默认文件系统未必就不好，但了解一下可用的选择有时也会有所帮助。本章将探讨 Linux 世界里可选用的不同文件系统，并向你演示如何在命令行上进行创建和管理。 探索 Linux 文件系统之前讨论了 Linux 如何通过文件系统来在存储设备上存储文件和目录。Linux 的文件系统为我们在硬盘中存储的 0 和 1 和应用中使用的文件与目录之间搭建起了一座桥梁。Linux 支持多种类型的文件系统管理文件和目录。每种文件系统都在存储设备上实现了虚拟目录结构，仅特性有所不同。本章将带你逐步了解 Linux 环境中较常用的文件系统的优点和缺陷。 基本的 Linux 文件系统Linux 最初采用的是一种简单的文件系统，它模仿了 Unix 文件系统的功能。本节将讨论这种文件系统的演进过程。 ext 文件系统 Linux 操作系统中引入的最早的文件系统叫作扩展文件系统（extended filesystem，简记为 ext）。它为 Linux 提供了一个基本的类 Unix 文件系统：使用虚拟目录来操作硬件设备，在物理设备上按定长的块来存储数据。 ext 文件系统采用名为索引节点的系统来存放虚拟目录中所存储文件的信息。索引节点系统在每个物理设备中创建一个单独的表（称为索引节点表）来存储这些文件的信息。存储在虚拟目录中的每一个文件在索引节点表中都有一个条目。ext 文件系统名称中的 extended 部分来自其跟踪的每个文件的额外数据，包括： 文件名 文件大小 文件的属主 文件的属组 文件的访问权限 Linux 通过唯一的数值（称作索引节点号）来引用索引节点表中的每个索引节点，这个值是创建文件时由文件系统分配的。文件系统通过索引节点号而不是文件全名及路径来标识文件。 ext2 文件系统 最早的 ext 文件系统有不少限制，比如文件大小不得超过 2 GB。在 Linux 出现后不久，ext 文件系统就升级到了第二代扩展文件系统，叫作 ext2。 如你所猜测的，ext2 文件系统是 ext 文件系统基本功能的一个扩展，但保持了同样的结构。ext2 文件系统扩展了索引节点表的格式来保存系统上每个文件的更多信息。 ext2 的索引节点表为文件添加了创建时间值、修改时间值和最后访问时间值来帮助系统管理员追踪文件的访问情况。ext2 文件系统还将允许的最大文件大小增加到了 2 TB（在 ext2 的后期版本中增加到了 32 TB），以容纳数据库服务器中常见的大文件。 除了扩展索引节点表外，ext2 文件系统还改变了文件在数据块中存储的方式。ext 文件系统常见的问题是在文件写入到物理设备时，存储数据用的块很容易分散在整个设备中（称作碎片化，fragmentation）。数据块的碎片化会降低文件系统的性能，因为需要更长的时间在存储设备中查找特定文件的所有块。 保存文件时，ext2 文件系统通过按组分配磁盘块来减轻碎片化。通过将数据块分组，文件系统在读取文件时不需要为了数据块查找整个物理设备。多年来，ext 文件系统一直都是 Linux 发行版采用的默认文件系统。但它也有一些限制。索引节点表虽然支持文件系统保存有关文件的更多信息，但会对系统造成致命的问题。文件系统每次存储或更新文件，它都要用新信息来更新索引节点表。问题在于这种操作并非总是一气呵成的。 如果计算机系统在存储文件和更新索引节点表之间发生了什么，这二者的内容就不同步了。ext2 文件系统由于容易在系统崩溃或断电时损坏而臭名昭著。即使文件数据正常保存到了物理设备上，如果索引节点表记录没完成更新的话，ext2 文件系统甚至都不知道那个文件存在！很快开发人员就开始尝试开发不同的 Linux 文件系统了。 日志文件系统日志文件系统为 Linux 系统增加了一层安全性。它不再使用之前先将数据直接写入存储设备再更新索引节点表的做法，而是先将文件的更改写入到临时文件（称作日志，journal）中。在数据成功写到存储设备和索引节点表之后，再删除对应的日志条目。 如果系统在数据被写入存储设备之前崩溃或断电了，日志文件系统下次会读取日志文件并处理上次留下的未写入的数据。 Linux 中有 3 种广泛使用的日志方法，每种的保护等级都不相同 数据模式: 索引节点和文件都会被写入日志；丢失数据风险低，但性能差 有序模式: 只有索引节点数据会被写入日志，在对应的元数据标记为提交前，强制写入文件内容。只有数据成功写入后才删除；在性能和安全性之间取得了良好的折中 回写模式: 只有索引节点数据会被写入日志，但不控制文件数据何时写入；丢失数据风险高，但仍比不用日志好 数据模式日志方法是目前为止最安全的数据保护方法，但同时也是最慢的。所有写到存储设备上的数据都必须写两次：第一次写入日志，第二次写入真正的存储设备。这样会导致性能很差，尤其是对要做大量数据写入的系统而言。 这些年来，在 Linux 上还出现了一些其他日志文件系统。下面将会讲述常见的 Linux 日志文件系统。 ext3 文件系统 2001 年，ext3 文件系统被引入 Linux 内核中。它采用和 ext2 文件系统相同的索引节点表结构，但给每个存储设备增加了一个日志文件，以将准备写入存储设备的数据先记入日志。 默认情况下，ext3 文件系统用有序模式的日志功能——只将索引节点信息写入日志文件，直到数据块都被成功写入存储设备才删除。你可以在创建文件系统时用简单的一个命令行选项将 ext3 文件系统的日志方法改成数据模式或回写模式。 虽然 ext3 文件系统为 Linux 文件系统添加了基本的日志功能，但它仍然缺少一些功能。例如 ext3 文件系统无法恢复误删的文件，它没有任何内建的数据压缩功能（虽然有个需单独安装的补丁支持这个功能），ext3 文件系统也不支持加密文件。鉴于这些原因，Linux 项目的开发人员选择再接再厉，继续改进 ext3 文件系统。 ext4 文件系统 扩展 ext3 文件系统功能的结果是 ext4 文件系统（你可能也猜出来了）。ext4 文件系统在 2008 年受到 Linux 内核官方支持，现在已是大多数流行的 Linux 发行版采用的默认文件系统。 除了支持数据压缩和加密，ext4 文件系统还支持一个称作区段（extent）的特性。区段在存储设备上按块分配空间，但在索引节点表中只保存起始块的位置。由于无需列出所有用来存储文件中数据的数据块，它可以在索引节点表中节省一些空间。 ext4 还引入了块预分配技术（block preallocation）。如果你想在存储设备上给一个你知道要变大的文件预留空间，ext4 文件系统可以为文件分配所有需要用到的块，而不仅仅是那些现在已经用到的块。ext4 文件系统用 0 填满预留的数据块，不会将它们分配给其他文件。 Reiser 文件系统 2001 年，Hans Reiser 为 Linux 创建了第一个称为 ReiserFS 的日志文件系统。ReiserFS 文件系统只支持回写日志模式——只把索引节点表数据写到日志文件。ReiserFS 文件系统也因此成为 Linux 上最快的日志文件系统之一。 有两个有意思的特性被引入了 ReiserFS 文件系统：一个是你可以在线调整已有文件系统的大小；另一个是被称作尾部压缩（tailpacking）的技术，该技术能将一个文件的数据填进另一个文件的数据块中的空白空间。如果你必须为已有文件系统扩容来容纳更多的数据，在线调整文件系统大小功能非常好用。 JFS 文件系统 作为可能依然在用的最老的日志文件系统之一，JFS（Journaled File System）是 IBM 在 1990 年为其 Unix 衍生版 AIX 开发的。然而直到第 2 版，它才被移植到 Linux 环境中。 IBM 官方称 JFS 文件系统的第 2 版为 JFS2，但大多数 Linux 系统提到它时都只用 JFS。 JFS 文件系统采用的是有序日志方法，即只在日志中保存索引节点表数据，直到真正的文件数据被写进存储设备时才删除它。这个方法在 ReiserFS 的速度和数据模式日志方法的完整性之间的采取的一种折中。 JFS 文件系统采用基于区段的文件分配，即为每个写入存储设备的文件分配一组块。这样可以减少存储设备上的碎片。 除了用在 IBM Linux 上外，JFS 文件系统并没有流行起来，但你有可能在同 Linux 打交道的日子中碰到它。 XFS 文件系统 XFS 日志文件系统是另一种最初用于商业 Unix 系统而如今走进 Linux 世界的文件系统。美国硅图公司（SGI）最初在 1994 年为其商业化的 IRIX Unix 系统开发了 XFS。2002 年，它被发布到了适用于 Linux 环境的版本。 XFS 文件系统采用回写模式的日志，在提供了高性能的同时也引入了一定的风险，因为实际数据并未存进日志文件。XFS 文件系统还允许在线调整文件系统的大小，这点类似于 ReiserFS 文件系统，除了 XFS 文件系统只能扩大不能缩小。 写时复制文件系统采用了日志式技术，你就必须在安全性和性能之间做出选择。尽管数据模式日志提供了最高的安全性，但是会对性能带来影响，因为索引节点和数据都需要被日志化。如果是回写模式日志，性能倒是可以接受，但安全性就会受到损害。 就文件系统而言，日志式的另一种选择是一种叫作写时复制（copy-on-write，COW）的技术。COW 利用快照兼顾了安全性和性能。如果要修改数据，会使用克隆或可写快照。修改过的数据并不会直接覆盖当前数据，而是被放入文件系统中的另一个位置上。即便是数据修改已经完成，之前的旧数据也不会被重写。COW 文件系统已日渐流行，接下来会简要概览其中最流行的两种（Btrf 和 ZFS）。 ZFS 文件系统 COW 文件系统 ZFS 是由 Sun 公司于 2005 年研发的，用于 OpenSolaris 操作系统，从 2008 年起开始向 Linux 移植，最终在 2012 年投入 Linux 产品的使用。 ZFS 是一个稳定的文件系统，与 Resier4、Btrfs 和 ext4 势均力敌。它最大的弱项就是没有使用 GPL 许可。自 2013 年发起的 OpenZFS 项目有可能改变这种局面。但是，在获得 GPL 许可之前，ZFS 有可能终无法成为 Linux 默认的文件系统。 Btrfs 文件系统 Btrfs 文件系统是 COW 的新人，也被称为 B 树文件系统。它是由 Oracle 公司于 2007 年开始研发的。Btrfs 在 Reiser4 的诸多特性的基础上改进了可靠性。另一些开发人员最终也加入了开发过程，帮助 Btrfs 快速成为了最流行的文件系统。究其原因，则要归于它的稳定性、易用性以及能够动态调整已挂载文件系统的大小。OpenSUSE Linux 发行版将 Btrfs 作为其默认文件系统。除此之外，该文件系统也出现在了其他 Linux 发行版中（如 RHEL），Fedora 在 2020 年将 Btrfs 作为其默认文件系统。 操作文件系统Linux 提供了一些不同的工具，我们可以利用它们轻松地在命令行中进行文件系统操作。可使用键盘随心所欲地创建新的文件系统或者修改已有的文件系统。本节将会带你逐步了解命令行下的文件系统交互的命令。 创建分区一开始，你必须在存储设备上创建分区来容纳文件系统。分区可以是整个硬盘，也可以是部分硬盘，以容纳虚拟目录的一部分。此部分推荐使用的终端中好用的图形化 cfdisk 工具，除此之外，fdisk 也是一个使用广泛的传统工具，不过使用较为麻烦，不推荐使用。 要启动 cfdisk 命令，你必须指定要分区的存储设备的设备名，另外还得有超级用户权限。如果在没有对应权限的情况下使用该命令，你会得到类似于下面这种错误提示。 123$ cfdisk /dev/sdbUnable to open /dev/sdb 有时候，创建新磁盘分区最麻烦的事情就是找出安装在 Linux 系统中的物理磁盘。Linux 采用了一种标准格式来为硬盘分配设备名称，但是你得熟悉这种格式。对于老式的 IDE 驱动器，Linux 使用的是&#x2F;dev&#x2F;hdx。其中 x 表示一个字母，具体是什么要根据驱动器的检测顺序（第一个驱动器是 a，第二个驱动器是 b，以此类推）。对于较新的 SATA 驱动器和 SCSI 驱动器，Linux 使用&#x2F;dev&#x2F;sdx。其中的 x 具体是什么也要根据驱动器的检测顺序（和之前一样，第一个驱动器是 a，第二个驱动器是 b，以此类推）。最新的 SSD 固态硬盘一般以&#x2F;dev&#x2F;nvme0nx 来标识。在格式化分区之前，最好再检查一下是否正确指定了驱动器。 如果你拥有超级用户权限并指定了正确的驱动器，那就可以进入 cfdisk 工具的操作界面了。 cfdisk 可以看到目前磁盘的详情，在界面下方有各类操作，可用方向键和回车进行选择，非常方便。一般的步骤是新建分区，输入大小，选择类型，最后写入退出即可。 创建文件系统在将数据存储到分区之前，你必须用某种文件系统对其进行格式化，这样 Linux 才能使用它。每种文件系统类型都用自己的命令行程序来格式化分区。如下列出了本章中讨论的不同文件系统所对应的工具。 mkefs 创建 ext 文件系统 mke2fs 创建 ext2 文件系统 mkfs.ext3 创建 ext3 文件系统 mkfs.ext4 创建 ext4 文件系统 mkreiserfs 创建 ReiserFS 文件系统 jfs_mkfs 创建 JFS 文件系统 mkfs.xfs 创建 XFS 文件系统 mkfs.zfs 创建 ZFS 文件系统 mkfs.btrfs 创建 Btrfs 文件系统 并非所有文件系统工具都已经默认安装了。要想知道某个文件系统工具是否可用，可以使用 type 命令。 1234$ type mkfs.ext4mkfs.ext4 是 /usr/bin/mkfs.ext4$ type mkfs.btrfs-bash: type: mkfs.btrfs: not found 据上面这个取自 Ubuntu 系统的例子显示，mkfs.ext4 工具是可用的。而 Btrfs 工具则不可用。不可用的工具请按发行版自行安装。 每个文件系统命令都有很多命令行选项，允许你定制如何在分区上创建文件系统。要查看所有可用的命令行选项，可用 man 命令来显示该文件系统命令的手册页面。所有的文件系统命令都允许通过不带选项的简单命令来创建一个默认的文件系统。 1234567891011$ sudo mkfs.ext4 /dev/sdb1mke2fs 1.45.6 (20-Mar-2020)创建含有 3891192 个块（每块 4k）和 972944 个inode的文件系统文件系统UUID：3f916991-2368-4d43-8b10-90b6a7c13445超级块的备份存储于下列块： 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208正在分配组表： 完成正在写入inode表： 完成*创建日志*（16384 个块）完成写入超级块和文件系统账户统计信息： 已完成 这个新的文件系统采用 ext4 文件系统类型，这是 Linux 上的日志文件系统。注意，创建过程中有一步是创建新的日志。 为分区创建了文件系统之后，下一步是将它挂载到虚拟目录下的某个挂载点，这样就可以将数据存储在新文件系统中了。你可以将新文件系统挂载到虚拟目录中需要额外空间的任何位置。 12345678910$ ls /mnt$ sudo mkdir /mnt/my_partition$ ls -al /mnt/my_partition/$ #啥也没有$ sudo mount -t ext4 /dev/sdb1 /mnt/my_partition$ ls -al /mnt/my_partition/total 24drwxr-xr-x. 3 root root 4096 Jun 11 09:53 .drwxr-xr-x. 3 root root 4096 Jun 11 09:58 ..drwx------. 2 root root 16384 Jun 11 09:53 lost+found mkdir 命令在虚拟目录中创建了挂载点，mount 命令将新的硬盘分区添加到挂载点。mount 命令的-t 选项指明了要挂载的文件系统类型（ext4）。现在你可以在新分区中保存新文件和目录了！ 这种挂载文件系统的方法只能临时挂载文件系统。当重启 Linux 系统时，文件系统并不会自动挂载。要强制 Linux 在启动时自动挂载新的文件系统，可以将其添加到&#x2F;etc&#x2F;fstab 文件。 现在文件系统已经被挂载了到虚拟目录中，可以投入日常使用了。遗憾的是，在日常使用过程中有可能会出现一些严重的问题，例如文件系统损坏。下一节将演示如何应对这种问题。 文件系统的检查与修复就算是现代文件系统，碰上突然断电或者某个不规矩的程序在访问文件时锁定了系统，也会出现错误。幸而有一些命令行工具可以帮你将文件系统恢复正常 每个文件系统都有各自可以和文件系统交互的恢复命令。这可能会让局面变得不太舒服，随着 Linux 环境中可用的文件系统变多，你也不得不去掌握大量对应的命令。好在有个通用的前端程序，可以决定存储设备上的文件系统并根据要恢复的文件系统调用适合的文件系统恢复命令。 fsck 命令能够检查和修复大部分类型的 Linux 文件系统，包括本章早些时候讨论过的 ext、ext2、ext3、ext4、ReiserFS、JFS、XFS、ZFS 以及 Btrfs。该命令的格式是： 1fsck options /dev/sdX 你可以在命令行上列出多个要检查的文件系统。文件系统可以通过设备名、在虚拟目录中的挂载点以及分配给文件系统的唯一 UUID 值来引用。 fsck 命令使用&#x2F;etc&#x2F;fstab 文件来自动检查文件系统类型。如果存储设备从未被挂载（比如你刚刚在新的存储设备上创建了个文件系统，&#x2F;etc&#x2F;fstab 并无其信息），你需要用-t 命令行选项来指定文件系统类型。使用 man 或 tldr 查看其他可用的命令行选项。在使用 fsck 时，被检查的文件系统应该处在未挂载状态。 你可能注意到了，有些命令行选项是重复的。这是为多个命令实现通用的前端带来的部分问题。有些文件系统修复命令有一些额外的可用选项。如果要做更高级的错误检查，就需要查看这个文件系统修复工具的手册页面来确定是不是有该文件系统专用的扩展选项。 只能在未挂载的文件系统上运行 fsck 命令。对大多数文件系统来说，你只需卸载文件系统来进行检查，检查完成之后重新挂载就好了。但因为根文件系统含有所有核心的 Linux 命令和日志文件，所以你无法在处于运行状态的系统上卸载它。这正是亲手体验 Linux LiveCD 的好时机！只需用 LiveCD 启动系统即可，然后在根文件系统上运行 fsck 命令。 到目前为止，本章讲解了如何处理物理存储设备中的文件系统。Linux 还有另一些方法可以为文件系统创建逻辑存储设备。下一节将告诉你如何使用逻辑存储设备。 逻辑卷管理如果用标准分区在硬盘上创建了文件系统，为已有文件系统添加额外的空间多少是一种痛苦的体验。你只能在同一个物理硬盘的可用空间范围内调整分区大小。如果硬盘上没有地方了，你就必须弄一个更大的硬盘，然后手动将已有的文件系统移动到新的硬盘上。 这时候可以通过将另外一个硬盘上的分区加入已有文件系统，动态地添加存储空间。Linux 逻辑卷管理器（logical volume manager，LVM）软件包正好可以用来做这个。它可以让你在无需重建整个文件系统的情况下，轻松地管理磁盘空间。 逻辑卷管理布局逻辑卷管理的核心在于如何处理安装在系统上的硬盘分区。在逻辑卷管理的世界里，物理硬盘的各个分区称作物理卷（physical volume，PV）。每个物理卷都会映射到硬盘上特定的物理分区。 多个物理卷集中在一起可以形成一个卷组（volume group，VG）。逻辑卷管理系统将卷组视为一个物理硬盘，但事实上卷组可能是由分布在多个物理硬盘上的多个物理分区组成的。卷组提供了一个创建逻辑分区的平台，而这些逻辑分区则包含了文件系统。 整个结构中的最后一层是逻辑卷（logical volume，LV）。逻辑卷基于卷组之上，为 Linux 提供了创建文件系统的分区环境，作用类似于到目前为止我们一直在探讨的 Linux 中的物理硬盘分区。Linux 系统将逻辑卷视为物理分区。 可以使用任意一种标准 Linux 文件系统来格式化逻辑卷，然后再将它加入 Linux 虚拟目录中的某个挂载点 卷组横跨多个不同的物理硬盘，覆盖了多个独立的物理分区。在卷组上层可有多个独立的逻辑卷。Linux 系统将每个逻辑卷视为一个物理分区。每个逻辑卷可以被格式化成 ext4 文件系统，然后挂载到虚拟目录中某个特定位置。 某个物理硬盘也可以有一些未使用的分区。通过逻辑卷管理，你随后可以轻松地将这个未使用分区分配到已有卷组：要么用它创建一个新的逻辑卷，要么在需要更多空间时用它来扩展已有的逻辑卷。 类似地，如果你给系统添加了一块硬盘，逻辑卷管理系统允许你将它添加到已有卷组，为某个已有的卷组创建更多空间，或是创建一个可用来挂载的新逻辑卷。这种扩展文件系统的方法要好用得多！ Linux 中的 LVMLinux LVM 是由 Heinz Mauelshagen 开发的，于 1998 年发布到了 Linux 社区。它允许你在 Linux 上用简单的命令行命令管理一个完整的逻辑卷管理环境。 Linux LVM 有两个可用的版本。 LVM1: 最初的 LVM 包于 1998 年发布，只能用于 Linux 内核 2.4 版本。它仅提供了基本的逻辑卷管理功能。 LVM2: LVM 的更新版本，可用于 Linux 内核 2.6 版本。它在标准的 LVM 1 功能外提供了额外的功能。 大部分采用 2.6 或更高内核版本的现代 Linux 发行版都提供对 LVM 2 的支持。除了标准的逻辑卷管理功能外，LVM 2 还提供了另外一些好用的功能。 快照 最初的 Linux LVM 允许你在逻辑卷在线的状态下将其复制到另一个设备。这个功能叫作快照。在备份由于高可靠性需求而无法锁定的重要数据时，快照功能非常给力。传统的备份方法在将文件复制到备份媒体上时通常要将文件锁定。快照允许你在复制的同时，保证运行关键任务的 Web 服务器或数据库服务器继续工作。遗憾的是，LVM 1 只允许你创建只读快照。一旦创建了快照，就不能再写入东西了。LVM 2 允许你创建在线逻辑卷的可读写快照。有了可读写的快照，就可以删除原先的逻辑卷，然后将快照作为替代挂载上。这个功能对快速故障转移或涉及修改数据的程序试验（如果失败，需要恢复修改过的数据）非常有用。 条带化 LVM 2 提供的另一个引人注目的功能是条带化（striping）。有了条带化，可跨多个物理硬盘创建逻辑卷。当 Linux LVM 将文件写入逻辑卷时，文件中的数据块会被分散到多个硬盘上。每个后继数据块会被写到下一个硬盘上。 条带化有助于提高硬盘的性能，因为 Linux 可以将一个文件的多个数据块同时写入多个硬盘，而无需等待单个硬盘移动读写磁头到多个不同位置。这个改进同样适用于读取顺序访问的文件，因为 LVM 可同时从多个硬盘读取数据。 LVM 条带化不同于 RAID 条带化。LVM 条带化不提供用来创建容错环境的校验信息。事实上，LVM 条带化会增加文件因硬盘故障而丢失的概率。单个硬盘故障可能会造成多个逻辑卷无法访问。 镜像 通过 LVM 安装文件系统并不意味着文件系统就不会再出问题。和物理分区一样，LVM 逻辑卷也容易受到断电和磁盘故障的影响。一旦文件系统损坏，就有可能再也无法恢复。 LVM 快照功能提供了一些安慰，你可以随时创建逻辑卷的备份副本，但对有些环境来说可能还不够。对于涉及大量数据变动的系统，比如数据库服务器，自上次刚刚快照之后可能又要新增存储成百上千条记录。 这个问题的一个解决办法就是 LVM 镜像。镜像是一个实时更新的逻辑卷的完整副本。当你创建镜像逻辑卷时，LVM 会将原始逻辑卷同步到镜像副本中。根据原始逻辑卷的大小，这可能需要一些时间才能完成。 一旦原始同步完成，LVM 会为文件系统的每次写操作执行两次写入,一次写入到主逻辑卷，一次写入到镜像副本。可以想到，这个过程会降低系统的写入性能。就算原始逻辑卷因为某些原因损坏了，你手头也已经有了一个完整的最新副本 使用 Linux LVM现在你已经知道 Linux LVM 可以做什么了，本节将讨论如何创建 LVM 来帮助组织系统上的硬盘空间。Linux LVM 包只提供了命令行程序来创建和管理逻辑卷管理系统中所有组件。有些 Linux 发行版则包含了命令行命令对应的图形化前端，但为了完全控制你的 LVM 环境，最好习惯直接使用这些命令。 定义物理卷创建过程的第一步就是将硬盘上的物理分区转换成 Linux LVM 使用的物理卷区段。这里可以直接使用 cfdisk 进行操作。类型中选择 Linux LVM 即可。 下一步是用分区来创建实际的物理卷。这可以通过 pvcreate 命令来完成。pvcreate 定义了用于物理卷的物理分区。它只是简单地将分区标记成 Linux LVM 系统中的分区而已。 如果下一步中的 pvcreate 命令不能正常工作，很可能是因为 LVM 2 软件包没有默认安装。可以使用软件包名 lvm2 进行安装 12$ sudo pvcreate /dev/sdb1Physical volume &quot;/dev/sdb1&quot; successfully created 如果你想查看创建情况的话，可以使用 pvdisplay 命令来显示已创建的物理卷列表。 123456789101112$ sudo pvdisplay /dev/sdb1&quot;/dev/sdb1&quot; is a new physical volume of &quot;2.01 GiB&quot;--- NEW Physical volume ---PV Name /dev/sdb1VG NamePV Size 2.01 GiBAllocatable NOPE Size 0Total PE 0Free PE 0Allocated PE 0PV UUID 0FIuq2-LBod-IOWt-8VeN-tglm-Q2ik-rGU2w7 pvdisplay 命令显示出&#x2F;dev&#x2F;sdb1 现在已经被标记为物理卷。注意，输出中的 VG Name 内容为空，因为物理卷还不属于某个卷组。 PE Size(physical extent)：物理区域是物理卷中可用于分配的最小存储单元，物理区域大小在建立卷组时指定，一旦确定不能更改，同一卷组所有物理卷的物理区域大小需一致，新的 pv 加入到 vg 后，pe 的大小自动更改为 vg 中定义的 pe 大小。 创建卷组下一步是从物理卷中创建一个或多个卷组。究竟要为系统创建多少卷组并没有既定的规则，你可以将所有的可用物理卷加到一个卷组，也可以结合不同的物理卷创建多个卷组。 123$ sudo vgcreate Vol1 /dev/sdb1 Volume group &quot;Vol1&quot; successfully created$ 输出结果平淡无奇。如果你想看看新创建的卷组的细节，可用 vgdisplay 命令。 123456789101112131415161718192021$ sudo vgdisplay Vol1--- Volume group ---VG Name Vol1System IDFormat lvm2Metadata Areas 1Metadata Sequence No 1VG Access read/writeVG Status resizableMAX LV 0Cur LV 0Open LV 0Max PV 0Cur PV 1Act PV 1VG Size 2.00 GiBPE Size 4.00 MiBTotal PE 513Alloc PE / Size 0 / 0Free PE / Size 513 / 2.00 GiBVG UUID oe4I7e-5RA9-G9ti-ANoI-QKLz-qkX4-58Wj6e 这个例子使用&#x2F;dev&#x2F;sdb1 分区上创建的物理卷，创建了一个名为 Vol1 的卷组。创建一个或多个卷组后，就可以创建逻辑卷了。 创建逻辑卷Linux 系统使用逻辑卷来模拟物理分区，并在其中保存文件系统。Linux 系统会像处理物理分区一样处理逻辑卷，允许你定义逻辑卷中的文件系统，然后将文件系统挂载到虚拟目录上。 要创建逻辑卷，使用 lvcreate 命令。虽然你通常不需要在其他 Linux LVM 命令中使用命令行选项，但 lvcreate 命令要求至少输入一些选项。具体选项详见 man,大多数情况下你用到的只是少数几个选项。 12$ sudo lvcreate -l 100%FREE -n lvtest Vol1Logical volume &quot;lvtest&quot; created 如果想查看你创建的逻辑卷的详细情况，可用 lvdisplay 命令 1234567891011121314151617$ sudo lvdisplay Vol1--- Logical volume ---LV Path /dev/Vol1/lvtestLV Name lvtestVG Name Vol1LV UUID 4W2369-pLXy-jWmb-lIFN-SMNX-xZnN-3KN208LV Write Access read/writeLV Creation host, time archlinux, 2021-02-02 13:23:03 +0800LV Status available# open 0LV Size 2.00 GiBCurrent LE 513Segments 1Allocation inheritRead ahead sectors auto- currently set to 256Block device 253:2 现在可以看到你刚刚创建的逻辑卷了！注意，卷组名（Vo l 1）用来标识创建新逻辑卷时要使用的卷组。-l 选项定义了要为逻辑卷指定多少可用的卷组空间。注意，你可以按照卷组空闲空间的百分比来指定这个值。本例中为新逻辑卷使用了所有的空闲空间。你可以用-l 选项来按可用空间的百分比来指定这个大小，或者用-L 选项以字节、千字节（KB）、兆字节（MB）或吉字节（GB）为单位来指定实际的大小。-n 选项允许你为逻辑卷指定一个名称（在本例中称作 lvtest）。 LE(logical extent)：逻辑区域是逻辑卷中可用于分配的最小存储单元，逻辑区域的大小取决于逻辑卷所在卷组中的物理区域的大小。 创建文件系统运行完 lvcreate 命令之后，逻辑卷就已经产生了，但它还没有文件系统。你必须使用相应的命令行程序来创建所需要的文件系统 1$ sudo mkfs.ext4 /dev/Vol1/lvtest 在创建了新的文件系统之后，可以用标准 Linux mount 命令将这个卷挂载到虚拟目录中，就跟它是物理分区一样。唯一的不同是你需要用特殊的路径来标识逻辑卷。 1$ sudo mount /dev/Vol1/lvtest /mnt/my_partition 注意，mkfs.ext4 和 mount 命令中用到的路径都有点奇怪。路径中使用了卷组名和逻辑卷名，而不是物理分区路径。文件系统被挂载之后，就可以访问虚拟目录中的这块新区域了。 修改 LVMLinux LVM 的好处在于能够动态修改文件系统，在 Linux 有一些工具允许你修改现有的逻辑卷管理配置。 如果你无法通过一个很炫的图形化界面来管理你的 Linux LVM 环境，也不是什么都干不了。在本章中你已经看到了一些 Linux LVM 命令行程序的实际用法。还有一些其他的常见命令可以用来管理 LVM 的设置。 vgchange 激活和禁用卷组 vgremove 删除卷组 vgextend 将物理卷加到卷组中 vgreduce 从卷组中删除物理卷 lvextend 增加逻辑卷的大小 lvreduce 减小逻辑卷的大小 通过使用这些命令行程序，就能完全控制你的 Linux LVM 环境。更详细的用法可使用 man 或 tldr 查看。 在手动增加或减小逻辑卷的大小时，要特别小心。逻辑卷中的文件系统需要手动修整来处理大小上的改变。大多数文件系统都包含了能够重新格式化文件系统的命令行程序，比如用于 ext2、ext3 和 ext4 文件系统的 resize2fs 程序。","categories":[{"name":"Shell","slug":"Shell","permalink":"https://wxwdaydayup.top/categories/Shell/"}],"tags":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/tags/Arch/"},{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"}],"author":null},{"title":"给新手的关于如何不去弄坏 Arch Linux 系统的建议","slug":"给新手的关于如何不去弄坏 Arch Linux 系统的建议","date":"2025-03-12T02:00:00.000Z","updated":"2025-03-09T09:34:54.725Z","comments":true,"path":"给新手的关于如何不去弄坏 Arch Linux 系统的建议/","permalink":"https://wxwdaydayup.top/%E7%BB%99%E6%96%B0%E6%89%8B%E7%9A%84%E5%85%B3%E4%BA%8E%E5%A6%82%E4%BD%95%E4%B8%8D%E5%8E%BB%E5%BC%84%E5%9D%8F%20Arch%20Linux%20%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BB%BA%E8%AE%AE/","excerpt":"背离通常的操作手段导致系统故障是正常的，因而我们在此处列出常见的导致系统故障的操作，以期帮助大家避免这些问题。不过，若有充分的知识和谨慎的操作，即使出了问题，通常也是可以妥当解决的。","text":"原始页面来自 Debian Wiki。 Arch Linux 是滚动更新的系统。从单独的时刻上去看，其即使可能会在更新后出现问题，但由于滚动更新，这些问题也可以被快速修复，因而总体上依然稳定可靠。除去上游引入的问题，用户手上持有的系统最高权限——root 权限——也通常是导致系统损坏的导火索。背离通常的操作手段导致系统故障是正常的，因而我们在此处列出常见的导致系统故障的操作，以期帮助大家避免这些问题。不过，若有充分的知识和谨慎的操作，即使出了问题，通常也是可以妥当解决的。 在此之前，需要知道一点的是，来自官方仓库的软件包受到官方支持，且来自 core 仓库的软件包更是会先进行严格的审核。而在其他系统中，你可能会从各个网站下载安装包，但无论在哪个系统上，这通常都伴随风险。在 Arch Linux 上，还有很多第三方软件的安装脚本来自 AUR。这些脚本相较于用户手动使用命令编译安装来说，可以让通过脚本安装的软件受到本系统的包管理软件，pacman 管理，这可以极大的减小自行安装与包管理冲突的风险，但这些脚本亦可能包含恶意代码（这曾经发生过，虽然不常见）。因此，请尽量选用来自官方仓库的软件包，并在使用来自 AUR 的安装脚本前对它们做仔细检查（比如检查包含的网址，可能包含的破坏性命令等）。 中文用户可能会选用来自非官方用户仓库，[archlinuxcn] 的软件包。同样，你也应该谨慎选用这些软件包，在非官方软件包出问题时也请向相应的人员报告问题。 01. 数据无价，分区操作需谨慎根据安装指南#分区方案示例，您可能会将除 /boot 和 swap 之外的所有系统所需内容（这包括 /home，您的很多个人数据会存储在这里）放在一个单独的分区。这样的配置对新用户相对友好，但是在您进行某些可能会损害数据的操作（如调整磁盘分区大小）时，由于个人数据和系统文件存放在同一个分区内，若是因为相关操作导致分区损毁，则您很可能会同时失去珍贵的个人数据。 因此，分区操作需谨慎，在安装系统的时候就应当通盘考虑如何分配磁盘，因为稍后再修改所要花费的精力会更大。比如，参考“不要把鸡蛋放在同一个篮子里”的道理，您可以在安装时，将一些目录（如 /home）作为单独的挂载点，将这些目录下的内容放在其他分区。这样，即使系统分区出了问题，您的数据也在其他分区内完好无损，并且您可以快速恢复您的工作环境。具体请参阅 fstab。 02. 不要混用测试仓库如果你使用桌面环境，你有可能想提前尝试测试版本的桌面环境，比如 KDE 和 GNOME，并相应启用 gnome-unstable 和 kde-unstable。需要注意的是，这些仓库需要同时与测试仓库，也就是 core-testing 和 extra-testing 同时启用（如果有启用更多的官方仓库也要启用相应的测试仓库），否则可能导致部分升级，简单来说就是新旧软件包不兼容的情况。要提前尝试，就都要提前尝试。一旦产生错误，则必须尽快解决问题。 通常，只要 pacman 可以运行，完整地启用测试仓库后，进行 pacman -Syu 就能修复这些问题。 03. 不要“下载”显卡驱动显卡制造商的官网可能会提供显卡驱动的安装脚本，但是也请用来自软件仓库的驱动软件包。Arch Linux 的软件仓库已经（基本上）提供了这些驱动，并且可以伴随 Linux 内核升级而升级，这比单独的安装脚本要可靠和安全得多。通常情况下，查阅 OpenGL、Vulkan 以及 VA-API 这三个 wiki 页面足以引导你安装并配置好运行桌面所需的显卡驱动。 即使是臭名昭著的 NVIDIA，近年来的表现也在逐渐稳定。要查阅与具体硬件品牌相关的更多信息，请参考 NVIDIA、AMDGPU、Xorg#AMD 或 Intel 图形处理器等文。本 wiki 同时提供其他软件在 Arch Linux 上的使用说明，其中也可能包含相关软件在与特定显卡配合使用时需要单独采取的措施。 04. 小心 make install 和其他类似命令pacman 包管理通过统一的方式管理系统软件及其文件，但 make install、ninja install 等安装的文件不受 pacman 管理，且可能与 pacman 管理的文件相冲突。同样，如果需要卸载由这些命令安装的文件，也需要花费一番功夫。 同样，直接运行这些命令会需要你自行管理这些软件的升级等，事实上十分不便。来自 AUR 的安装脚本实际上采用与软件仓库打包相一致的过程，因而这样安装的软件受到pacman管理。在了解相应风险后，您也可以使用 AUR 助手帮助你升级来自 AUR 的软件包。如果AUR也实在没有，也可以考虑自己创建软件包（当然这并不轻松），让 pacman 管理。还有一些常见的类似建议列在下方。 不要直接 pip install Python 有相当多的库并不在 Arch Linux 仓库内，如果你不想使用 Arch 构建系统亲自打包 Python 程序的话，使用 pip install 是个折中的办法。但是，请一定在 venv（或类似的虚拟环境）中运行。如果你 # pip install，那么你安装的文件会与 pacman 管理的文件产生冲突。然而，即使使用 pip install --user 将程序安装到 ~/.local 下，也可能安装了与系统软件包重复但版本不同的库，从而导致系统上安装的某些依赖该 Python 库的程序因库版本不正确而出错。 如果你需要用的 Python 程序支持用命令行启动运行，而无需在 Python 代码中 import 调用的话，推荐使用 python-pipx包 来安装它。pipx 会自动为你创建 venv，并自动在 venv 中安装你需要的程序。 有时候一些 Python 程序会依赖一些重量级库，比如 PyQt&#x2F;PySide&#x2F;PyGObject 等，如果在 venv 这样的隔离环境中安装则需要在 venv 中安装所需的 Qt&#x2F;glib 库，这通常无法与系统上的其它软件良好集成。这种时候，你可以用 python -m venv --system-site-packages 来创建 venv 并在其中安装你需要的软件包。这样创建的 venv 不是与系统环境完全隔离的，venv 之内的 Python 能够导入系统范围安装的包，而系统环境的包则看不到 venv 内的包，因此不会干扰系统软件包正常工作，相当于获得了 pip install --user 的优点而规避了它的缺点。 不要默认启用 anaconda 环境 anaconda 是个不错的管理 Python 软件的方式。然而，它自带了包括 curl 和 ncurses 在内的许多库文件，其版本可能与系统所需要的版本冲突。因此，请不要默认启用 anaconda 环境，仅在需要使用的时候启用。 05. 不要盲从教程标题不是在说不要看任何教程，而是说，应该同时比对几份同主题的教程（对于 ArchWiki，则也可以是中英文，甚至其他语言），以及参考说明文档。同样，教程也有时效性，如果是五年前的教程，可能现在已经完全不适用。 但，无论是在跟随教程之前，还是在对比几份教程之前，都应该搞清楚教程中的命令到底会做出哪些操作。这样可能会帮助你及时发现错误，当然，即使未能发现，也能更迅速地帮助你恢复系统正常。 除了 ArchWiki 外，man 命令等是已经存在于你系统上的文档。这些也是参考来源。 06. 不要盲目照抄配置文件与脚本盲目照抄配置文件和脚本对于系统的危害是深远且多方面的。 每个系统或应用都有其独特的运行环境和需求。盲目照抄配置文件、脚本，往往忽略了这些差异，可能导致配置不兼容，进而引发系统错误或崩溃。 当您使用别人提供的脚本时，应当知道它是用来做什么的、它依赖什么软件包、它应当被何 shell 执行等。 点文件一文中提到的其他用户提供的配置文件、各大代码托管平台上的用户点文件仓库以及 AUR 中类似于 ml4w-hyprlandAUR 的包，都是针对那些用户自身，而非您的习惯或设备来设计的。比如说，假如您喜欢某人的终端增强配置，就草率地将其 ~/.bashrc 直接抄进了您的 ~/.config/fish/config.fish，这样的话，出现问题时，无论是您要向社区询问，还是他人试图解决您的问题，都会因为这其中积累的无数个“未知”，给您自己和社区带来莫大的麻烦。 07. 移除软件包需谨慎软件包之间有依赖关系，也就是一个软件包必须和另一些软件包一起存在。因此，移除一个软件包可能会需要相关的其他软件包也被一同移除。 移除软件包前，pacman 会显示要移除的包的列表。一定要仔细查看每个即将被删除的包，它们有的可能是你仍需要使用的软件包。如果不清楚，除了询问其他人以外，你还可以通过 pacman 的查询命令来查看每个软件包的简介与相关信息。 08. 记得自己做过什么记得自己做过什么在出问题的时候可以帮助你或者是让其他人帮你快速解决问题。比如，改动配置文件时，也许可以原地留一下注释和日期，标注原因，之类的。本文先前所提及的“不要照抄其他配置文件”也是同理，充分把握自己的系统这件事对解决之后可能发生的问题而言十分重要。 总的来说，要维持 Arch Linux 系统的稳定，你自然要付出一定的精力。 09. 谨慎对待 LLM 给出的内容LLM，大型语言模型（也就是 OpenAI 的 ChatGPT，Anthropic 的 Claude，Google 的 Gemini，深度求索的 DeepSeek 等 “AI”），看似是人类可以向 AI 询问任何问题，AI 就会给出看着非常可信的答案。有人可能会觉得如获至宝，看到有人问问题就把问题丢给它们问，再把回答随便贴上去。 但是，现阶段的通用大型语言模型，即便是在有联网工具能力的情况下（比如 ChatGPT 的搜索模式），也只能基本确保它们组出的是语法语气没有问题的句子，而不是事实正确的句子。即便是现在推理用的大模型，也并没有对现实的认知能力，自然没有其他社区成员的经验，询问它们是不大可能获得诸如“你电脑在更新的时候大写锁定键忽然闪灯，是因为闭源 NVIDIA 驱动和内核互作导致更新时内核崩溃，根据你的显卡型号，你应该换用 nvidia-open包 这个包”之类的详细结果的。 好吧，LLM 似乎确实不适合询问莫名其妙的疑难杂症——那如果是让它帮我写一个特定用途的小工具呢？不是说它们很擅长写电脑程序吗？ 在你准备问出更多问题之前，再次强调一遍：现阶段的 AI 没有对现实的认知能力，它不能保证自己写的符合你的要求，甚至可能因为阴差阳错写出有害的东西出来（虽然更多时候是前者）。 因此，总结一下：如果一段文字看着是 AI 生成的，或者你打算向 AI 问问题，请先认为你看到的内容一个字都不能信。也请不要把“它说的对不对啊”的工作推给别人，因为比起对 LLM 缝缝补补，人类自己早就能把问题解决掉了。 10. 寻求他人帮助Arch Linux 用户通常对 Arch Linux 上的问题更为熟悉。在遵循行为准则的前提下，向官方社区和非官方的国际社区（中文用户可以看看 Arch Linux 中文社区）通常是个好主意。 行为准则#常识有言： 使用 Arch Linux，先要接受 Arch 之道 先看文档，搜索网站，做好功课，再行提问 寻求帮助，耐心委婉 乐于奉献，止于损害 遵循基本前提，提供尽可能多的细节，保持耐心多等待，不要宣泄情绪。 当然，每个社区都会有自己的建议。但通常，使用即时通讯软件时，不要频繁换行发言，尽可能一次发完。上传日志建议使用外部网站（比如 Pastebin 和每个群组自行设置的类 Pastebin 网站），并且注意删掉私人信息。询问问题时待在有问题的设备前，不要“离线提问”，避免在他人给出建议的时候你却“暂时给不出日志”又或是“暂时摸不到电脑”而消耗其他社区用户的耐心。 最后，祝你的 Arch Linux 使用之旅顺利且愉快！","categories":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/categories/Arch/"}],"tags":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/tags/Arch/"},{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"}]},{"title":"Arch Linux 常见问题排除与解决","slug":"Arch Linux 常见问题排除与解决","date":"2025-03-11T02:00:00.000Z","updated":"2025-03-09T09:23:07.182Z","comments":true,"path":"Arch Linux 常见问题排除与解决/","permalink":"https://wxwdaydayup.top/Arch%20Linux%20%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%8E%92%E9%99%A4%E4%B8%8E%E8%A7%A3%E5%86%B3/","excerpt":"本节描述一些在日常使用过程中你有很大概率可能遇到的问题，并提供解决方法。","text":"本节描述一些在日常使用过程中你有很大概率可能遇到的问题，并提供解决方法。 01. 使用 BIOS+GPT 模式安装 Arch Linux虽然使用传统 BIOS 模式安装的场景已经越来越少，但是在某些特殊场景，如在 VPS 上安装 Arch Linux,可能依然需要使用到 BIOS 模式。本小节讲述在使用 BIOS+GPT 模式安装时，与 UEFI+GPT 模式安装的不同点，其中绝大多数步骤是相同的。 安装前，在主板的 BIOS 设置中，或在 VPS 的启动设置中(如有)，将启动模式调整为传统 BIOS 模式启动。 在分区时，需要额外分出一个 2M 大小的 BIOS boot 模式的分区，此分区无需进行格式化与挂载。 在安装引导程序时，对应的命令修改为: grub-install --target=i386-pc /dev/vda 以及 grub-mkconfig -o /boot/grub/grub.cfg。其中，第一条命令中的/dev/vda为安装 GRUB 的磁盘，而非分区。具体的名字根据安装者的实际情况进行更改。 02. 静态 IP 设置虽然使用可以自动获取 ip 地址的工具可以覆盖绝大多数场景，但是仍有部分特殊场景，如校园网，VPS 等环境下需要进行静态 IP 的设置。本小节给出一个简略的设置静态 IP 的方式。如需要设置静态 IP,需要首先禁用 dhcpcd 或 NetworkManager 等自动获取 ip 的工具。 12sudo systemctl stop dhcpcd NetworkManagersudo systemctl disable dhcpcd NetworkManager 接下来启用 systemd-networkd 1sudo systemctl enable --now systemd-networkd 使用ip ad命令查看当前网卡的名字，如这里使用名字 ens3。随后创建配置文件/etc/systemd/network/10-static-ens3.network。接下来在其中填入内容。其中的 ip 地址和网关需要从你的网络提供商处获取。其中的 DNS 设置同样需要在/etc/resolv.conf中按照前文中的方式进行设置。 123456789101112[Match]Name=ens3[Network]Address=YOUR_IPV4_ADDRESS/MASKGateway=YOUR_IPV4_GATEWAYDNS=8.8.8.8[Network]Address=YOUR_IPV6_ADDRESS/MASKGateway=YOUR_IPV6_GATEWAYDNS=2001:4860:4860::8888 最后，重启服务即可。 1sudo systemctl restart systemd-networkd 03. 鼠标出现按键不灵敏或失灵的现象一般来说大多数鼠标都是即插即用的，但 5.14 内核前后更新后可能遇到失灵的情况。根据自身鼠标品牌安装对应的驱动即可解决。相关资料 04. 关机时卡住很久才能关机一般屏幕会出现形如A stop job is running for...(1m30s)的信息，这是经常会遇到的关机卡住 1 分 30 秒的问题，一般来说这种情况是出现了某个进程在关机时不愿停止，需要等到超时时间到达强行停止。通用的解决办法是调整缩短这个等待时间，建议从 1 分 30 秒调整至 30 秒，30 秒已经足够几乎所有进程正常结束。 编辑 /etc/systemd/system.conf 1sudo vim /etc/systemd/system.conf 找到其中DefaultTimeoutStopSec一项，将其前方的井号去掉，并赋值为 30s 即可。最后执行 daemon-reload 使其生效。 1sudo systemctl daemon-reload 上述解决方案其实只是将这个等待时间缩小了，并没有解决实际问题。如果你想排查问题真正的原因所在，在关机时如果出现了A stop job is running for...(1m30s)的信息，耐心等待其结束关机，然后重新启动电脑，执行以下命令： 1journalctl -p5 按&#x2F;(斜杠键)搜索Killing关键字，找到你关机的时间附近所在的匹配行，你可以在附近看到到底是哪一个进程导致了 timeout,然后再去排查这个进程有什么问题即可。 05. 磁盘容量不足的处理方式一般使用 LVM 安装 Linux 系统则不用担心这种情况发生。但是我们使用的是传统的 ext4 经典分区方式。这种情况下一般建议在安装的开始就将根目录设置的大一些，如 100G。如果&#x2F;home 分区大小不够了，可以新安装一块硬盘，将其挂载到你想要的位置，再按照基础安装的步骤中重新 genfstab 一下就行了。 除此之外，如果根目录容量不足，可以不定期清理一下 pacman 的缓存，详见archwiki。太长不看的可以直接用下面这一行命令清理没有安装的所有缓存的包，和没有被使用的同步数据库。 1sudo pacman -Sc 06. 软件的降级在 archlinux 上 偶尔会出现某一个包的最新版本有各种问题的情况，如某些软件过新, 而一些依赖并没有支持,比如virtualbox 在 linux5.18 内核下的崩溃，此时需要降级该包以正常使用。包可以是普通软件，也可以是内核。 1yay -S downgrade 安装此包即可，使用方法也很简单，downgrade 后加上需要降级的包名即可，随后会提示你选择需要降级到的版本，点选即可。 07. 升级系统时出现形如 unable to lock database 的错误可能存在升级系统时异常关机或程序异常退出的情况，或者多个 pacman 的相关程序在同时执行。移除 pacman 的 db 锁即可。 1sudo rm /var/lib/pacman/db.lck 08. 手动开关混成器有时混成器会因为某些原因需要手动开启或关闭，但是目前在 KDE 下混成器在设置里无法在不关机的情况下直接关闭，下面命令提供手动开关混成器的效果。相关资料 123qdbus org.kde.KWin /Compositor suspend #禁用qdbus org.kde.KWin /Compositor resume #开启 09. 屏幕溢出：overscan在连接一些老式的显示设备时，可能与出现overscan的现象，简单来说就是电视屏幕四圈会有一圈溢出了，不显示出来。对于英特尔核芯显卡，可以选择 intel panel fitter 的方式[1]。最后就是要加入到一个 service 里开机自动启动，并且是在 DE 加载完成后执行[2]。 1sudo intel_panel_fitter -p A -x 1230 -y 700","categories":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/categories/Arch/"}],"tags":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/tags/Arch/"},{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"}]},{"title":"Arch Linux 系统美化","slug":"Arch Linux 系统美化","date":"2025-03-10T02:00:00.000Z","updated":"2025-03-09T09:20:29.586Z","comments":true,"path":"Arch Linux 系统美化/","permalink":"https://wxwdaydayup.top/Arch%20Linux%20%E7%B3%BB%E7%BB%9F%E7%BE%8E%E5%8C%96/","excerpt":"本文讲述如何配置以让 KDE 桌面环境看起来更加拥有美感。 原则：美化不应该付出大量的时间折腾，既没有实际用处，也没有意义。花最少的时间完成性价比最高的美化始终是第一原则。","text":"本文讲述如何配置以让 KDE 桌面环境看起来更加拥有美感。 原则：美化不应该付出大量的时间折腾，既没有实际用处，也没有意义。花最少的时间完成性价比最高的美化始终是第一原则。 在 KDE 相关软件更新前后，出现过第三方主题不稳定&#x2F;卡顿的问题，再次强调不要美化魔改的太过，这会添加更多的不确定性，让你的桌面稳定性下降。 01. 壁纸在桌面右键，选择配置桌面。在新出现的窗口中右下角选择添加图片可以选择你想要的图片。其中位置一项选择’缩放，保持比例’，背景一项选择’模糊’。这样你就可以拥有一个成比例，且边缘带有高斯模糊的漂亮的桌面壁纸。 02. 系统主题使用一个高质量的系统主题可以直线提升系统的美观程度。系统设置 &gt; 外观 &gt; 全局主题 &gt; 获取新的全局主题 ，搜索主题 layan，进行设置即可。 顺便说一句，这个主题的作者 vinceliuice 是一位中国大佬，是一位设计师，他设计的主题以及图标的质量都很高，你可以去他的主页为他打分和点赞。 如果切换主题后，windows 键不能呼出菜单，可在左下角右键，配置程序启动器，在键盘快捷键中重新设置windows+F1键，windows 键会显示为 Meta 键。 03. 窗口装饰在 系统设置 &gt; 外观 &gt; 窗口装饰 中，获取新窗口装饰，搜索 layan，并应用即可。 04. 系统图标如果主题中的图标不能满足你，那么可以选择一些自定义的图标。系统设置 &gt; 外观 &gt; 图标 &gt; 获取新图标主题 ，搜索图标名 Tela-icon-theme，进行安装设置即可。 05. SDDM 主题你应该注意得到，输入密码时默认的登录界面是很丑的，这里也可以替换掉。系统设置 &gt; 开机和关机 &gt; 登录屏幕(SDDM) &gt; 获取新登录屏幕 ，搜索 SDDM 主题 layan 并设置即可。 06. 欢迎屏幕（splashscreen）可以对在登录界面后的欢迎屏幕进行美化。 系统设置 &gt; 外观 &gt; 欢迎屏幕 &gt; 获取新欢迎屏幕 ，搜索 miku 进行设置即可。这个Snowy Night Miku是我们搜索到的最好看的二刺猿属性的初始界面了。另外，还有一个大佬做了一些二次元主题的欢迎屏幕，但是质量一般，这里是他的主页。 07. 桌面插件在任务栏空白处右键，选择编辑面板，添加部件。 Netspeed widget 网速组件，这个很实用 todolist 任务组件 然后把你经常使用的软件固定在任务栏即可。 KDE Plasma 5.22.1 更新后，需要额外安装 ksysguard 才能确保桌面插件的正常运行。相关资料 08. 混成器系统设置 &gt; 显示和监控 &gt; 混成器 开启混成器 09. 终端样式设置打开 konsole， 设置 &gt; 编辑当前方案 &gt; 外观 ，选择Red-Black 应用确认即可。 10. Kvantum Manager主题配合 Kvantum Manager 可以达到更好的效果。 1sudo pacman -S kvantum 在这里下载 Layan 的 Kvantum 主题，并解压。打开 Kvantum Manager,选择主题并安装，接下来在Change/Delete Theme中选择 Layan,Use this theme。最后在系统设置，外观中的应用程序风格中选择 kvantum 即可。 如果透明的效果没有显示，确保 KDE 的全局缩放比例为整数倍。或者尝试切换混成器中 openGL 的设置。 11. GRUB 主题官方文档 在pling选择下载你想要的 GRUB 主题，比如这个二刺螈主题。接下来 cd 进解压出来的文件夹，打开 konsole 输入 1sudo cp -r . /usr/share/grub/themes/Nino 以将主题放置在系统的 GRUB 默认文件夹内。 接着编辑 /etc/default/grub 文件，找到 #GRUB_THEME= 一行，将前面的注释去掉，并指向主题的 theme.txt 文件。即 12#GRUB_THEME=GRUB_THEME=&quot;/usr/share/grub/themes/Nino/theme.txt&quot; #修改后 然后再在终端输入 1sudo grub-mkconfig -o /boot/grub/grub.cfg 更新 GRUB ，并重启即可。 12. 开机动画Plymouth 是一个来自于 Fedora 社区的提供美化启动图形界面的功能的项目，如有需要，可以参考官方文档进行配置。不建议新手在此项配置上花费太多时间。","categories":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/categories/Arch/"}],"tags":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/tags/Arch/"},{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"}]},{"title":"Arch Linux 成为不合格的系统管理员","slug":"Arch Linux 成为不合格的系统管理员","date":"2025-03-09T02:00:00.000Z","updated":"2025-03-09T08:31:50.075Z","comments":true,"path":"Arch Linux 成为不合格的系统管理员/","permalink":"https://wxwdaydayup.top/Arch%20Linux%20%E6%88%90%E4%B8%BA%E4%B8%8D%E5%90%88%E6%A0%BC%E7%9A%84%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%91%98/","excerpt":"KDE 桌面环境提供了强大的 GUI 以供普通用户使用。按 Win 键呼出菜单栏，找到 设置 > 系统设置，可以找到绝大多数系统设置项，本章介绍的知识足够你来应付日常的使用。","text":"阅读完上述章节，你的系统已完全可以使用，KDE 桌面环境提供了强大的 GUI 以供普通用户使用。按 Windows 键（Linux 下也常被叫做 Meta 键）呼出菜单栏，找到设置&#x3D;&gt;系统设置，可以找到绝大多数系统设置项。 但如果想要游刃有余的掌控你的系统，你还需要阅读掌握本文的内容。 如果你想进一步详细了解本文各部分的详细知识，可以点击在各个小节给出的拓展链接进行学习。 如果你不想详细了解，本章介绍的知识也足够你来应付日常的使用。 01. 必须掌握的 Linux 知识此处只介绍最基本的，最必要的 Linux 知识点与小技巧 。 在 Linux 中，文件目录结构与 Windows 完全不同。Windows 存在 C 盘、D 盘等盘符，而在 Linux 中不存在这些划分，最上层的目录是根目录，路径为 &#x2F; ，并以一个树形结构从此向下一级一级区分。 对于 Linux 的树形文件结构，存在相对路径与绝对路径之分。绝对路径是代表从根路径 &#x2F; 开始的完整路径，如/home/testuser/Download。相对路径代表从当前目录，到目标目录的一个部分路径。比如当前你所在的目录为/home/testuser，那么切换到绝对路径/home/testuser/Download的相对路径即为./Download。其中./代表从当前目录，再向下寻找。另外，..这种两个句点代表的是向上层寻找，比如你当前所在的路径为/home/testuser/Download，向上寻找到/home/testuser/Desktop的相对路径即为../Desktop。 简单来说，Linux 中存在两类用户。第一类用户即为 root 用户，也称为超级用户，它拥有系统中最高的权限。第二类用户就是除了 root 用户的普通用户，他们可以拥有不同等级的权限。使用 root 权限时需要十分小心。 理论上来说，任何图形化界面中的操作都可以用对应的命令行命令完成。如果你打开某个程序报错，不妨试试找到它的对应启动命令，在终端中执行此命令，并观察它运行时的错误日志输出，查阅相关资料，解决问题。 02. 终端操作系统如果想要熟练掌握 Linux，就必须掌握终端的常见命令与使用方式。 123456789ls /some_path # 查看某个文件夹下的文件与子文件夹 /代表根目录，是Linux最顶端的路径，是绝对路径pwd # 查看当前终端所在路径cd /home/testuser # 切换目录命令，将当前终端切换到某一个路径下cp ./a.cpp ./b.cpp # 复制命令 将当前路径下的a.cpp复制一份为b.cpp ./代表当前文件夹所在路径，是相对路径cp -r ./a ./b # 复制整体文件夹rm b.cpp # 删除命令 删除b.cppmv a.cpp b.cpp # 移动(重命名)命令 将a.cpp更名为b.cppmkdir new_folder # 新建文件夹new_foldersudo some command # 使普通用户以root权限执行某些命令 bash 终端设置路径为 ~/.bashrc 1234$include /etc/inputrc # 引入全局bash配置set completion-ignore-case on # 补全路径忽略大小写set horizontal-scroll-mode Off # 允许提示换行set bell-style none # 关闭提示警告音 03. Pacman 包管理Pacman 是 Arch Linux 的包管理器，它用于安装、删除、查询软件等。 12345678910sudo pacman -S package_name # 安装软件包sudo pacman -Syu package_name # 升级系统并安装软件包，Arch Linux 不支持部分升级，建议用此命令先升级再安装sudo pacman -Syu # 升级系统sudo pacman -Syyu # 升级系统 yy标记强制刷新 u标记升级动作sudo pacman -R package_name # 删除软件包sudo pacman -Rs package_name # 删除软件包，及其所有没有被其他已安装软件包使用的依赖包sudo pacman -Qdt # 找出孤立包 Q为查询本地软件包数据库 d标记依赖包 t标记不需要的包 dt合并标记孤立包sudo pacman -Rs $(pacman -Qtdq) # 删除孤立软件包sudo pacman -Fy # 更新命令查询文件列表数据库sudo pacman -F xxx # 当不知道某个命令属于哪个包时，用来查询某个xxx命令属于哪个包 一个好用的图形化包管理软件 1yay -S octopi #包管理器前端界面 拓展链接: 官方文档 04. 系统服务的操作与介绍Linux 系统中运行着各种服务，你需要掌握查询，变更服务状态的方式。同时对创建服务最好也有大致的了解。这里讲述命令systemctl的用法。以 dhcpcd 为例 123456789systemctl start dhcpcd # 启动服务systemctl stop dhcpcd # 停止服务systemctl restart dhcpcd # 重启服务systemctl reload dhcpcd # 重新加载服务以及它的配置文件systemctl status dhcpcd # 查看服务状态systemctl enable dhcpcd # 设置开机启动服务systemctl enable --now dhcpcd # 设置服务为开机启动并立即启动这个单元:systemctl disable dhcpcd # 取消开机自动启动systemctl daemon-reload dhcpcd # 重新载入 systemd 配置 扫描新增或变更的服务单元 不会重新加载变更的配置 加载变更的配置用 reload 拓展链接: systemctl 官方文档 systemd 配置文件样例解释 05. 编辑系统配置文件 用 sudoedit 编辑配置文件 在前面的 “桌面环境安装与基础设置” 一节中，我们已经多次编辑了系统配置文件。它们的特点是对系统中的所有用户生效、归 root 用户所有、并且只有 root 用户才拥有写入的权限，这就需要我们用 sudo 提升到 root 权限才能编辑它们。很容易想到用 sudo 命令去运行文本编辑器，以 vim 为例： 1sudo vim 你要编辑的文件的路径 但是这样却不是最好的方式，因为它违反了“最小权限原则”。因为当我们用 sudo 执行一个命令时，整个进程都会获得 root 权限。也就是说，vim 的所有操作、甚至包括所有的 vim 插件都会在 root 权限下运行，这通常来说是非常危险的。有的文本编辑器甚至会在检测到自身以 root 权限运行的时候拒绝运行，以避免做出危险的操作。 反过来考虑，只是编辑一个文件不需要那么强大的权限，我们只需要拥有对这一个配置文件的读写权限就足够了。而 sudoedit（或 sudo -e，二者是完全等效的）是编辑一个系统配置文件的最佳实践。 1EDITOR=vim sudoedit 要编辑的文件 sudoedit 命令大致是这样工作的：它会先创建一份普通用户有权编辑的临时文件，把要编辑的文件以 root 权限复制到这个临时文件中，接着根据 EDITOR 等环境变量，以普通用户的权限运行文本编辑器。在文本编辑器编辑完成并退出后，它会再次以 root 权限用这个编辑好的临时文件去覆盖掉原先的配置文件。 关于 sudoedit 的更多信息，详见 sudo 的手册。 配置文件的语法高亮 严格来说这不是一个关于 sudoedit 的问题，而是一个关于文本编辑器的问题，但是它经常在用 sudoedit 编辑文件时遇到。 因为 sudoedit 会创建一个随机名称的临时文件，文本编辑器可能不认识这个文件名，不知道该启用什么语法的高亮显示。这时候就需要我们主动告诉文本编辑器该使用什么语法，以 vim 为例，可以在命令行模式下用如下设置语法： 1:set syntax=文件的语法 另一个问题是如何知道语法的名称。一方面我们可以用搜索引擎搜索，或者在 vim 的内置插件里寻找，不过对于那些普通用户也能读取的配置文件，可以直接用 vim 去查看它，这时候 vim 会以只读模式打开文件，但是会根据文件名启用语法高亮。这样只需要在命令行模式下运行： 1:set syntax 即可查看当前 vim 所使用的高亮语法。 编辑 sudoers 配置文件 在前面我们编辑过 sudoers 配置文件。sudoers 算是系统配置文件中的一个特例，编辑它的最佳实践不是使用 sudoedit，而是 visudo 命令。 12sudo visudo # visudo 需要使用 root 权限运行。默认编辑 /etc/sudoerssudo visudo -f 要编辑的sudoers文件的路径 # 也可以指定文件路径 visudo 与 sudoedit 类似的是，它也会把要编辑的配置文件先复制到一个临时文件，再调用文本编辑器编辑，而不同的是，在开始编辑之前 visudo 还会锁定正在编辑的 sudoers 文件，以此避免两个人同时对它编辑；并且会在编辑完成之后检查 sudoers 的语法，如果发现错误则会拒绝这次编辑的结果。 这是因为，如果在 sudoers 文件中遇到语法错误，sudo 为了安全性，会让整个 sudoers 配置文件都不生效。这样的话，如果普通用户不慎改坏了 sudoers 文件，则有可能失去使用 sudo 命令的权限，就好像“关上了大门并把自己关在了外面”，这时候就需要直接用 root 用户登录甚至需要 live USB 急救才行。而 visudo 检查 sudoers 语法就可以很大程度上避免这种情况发生。 另一方面，visudo 需要使用 root 身份运行，这意味着它的文本编辑器实际上也是以 root 身份运行的，这一点与 sudoedit 不同。为了安全，可以配置为只使用某些受限制的“安全的”文本编辑器来编辑 sudoers 文件。详见 ArchWiki 以及 sudoers 手册中的 editor 一节和 env_editor 一节。 关于 visudo 的更多内容详见手册。 06. 文件传输与系统备份有一点 Linux 经验读者应该知道scp这个命令。它常被用来在服务器间传输文件。但是目前它应该被更现代的工具rsync替代，其拥有即时压缩，差量传输等新特性。同时，rsync也被用来进行备份操作。 12rsync foo.txt me@server:/home/me/ # 最基础的复制文件 与scp的操作完全相同rsync -a bar/ me@server:/home/me/ # -a 标记实现目录复制等 比scp -r 能更好的处理符号链接等情况 关于全盘备份，请阅读官方文档。 07. 文件解压缩除了众所周知的 tar 命令，我们在之前安装过的 ark 包可以配合 dolphin 文件管理器轻松的右键直接解压缩，其可选依赖提供了各个压缩格式的支持，可以自行选择安装。需要注意的是解压 windows 下的压缩包，可能会乱码，安装 ark 的可选依赖之一 unarchiver，使用 unar 可以避免这个问题。 12sudo pacman -S unarchiverunar xxx.zip 08. 系统硬件信息检测磁盘检测可使用 smartmontools 12sudo smartctl -A /dev/sda #硬盘sudo smartctl -d sat -A /dev/sdc #usb设备 磁盘空间分析可直接使用 df 命令，也可使用 Filelight图形化界面直观查看磁盘占用情况 1df -h cpu 与显卡的信息查看可使用如下两款软件 12yay -S cpu-xyay -S gpu-viewer 使用 dmidecode 可以完整查看系统绝大部分硬件信息，包括较难得到的内存频率，主板 BIOS 等等。 1sudo dmidecode 09. 制作 Win10 启动盘你可能在 linux 下，有时需要制作 win10 的启动盘。在以往，在 linux 下制作一个 win10 启动盘还是很简单的，但是随着近几年微软的更新，其 iso 安装镜像中存在一个名为install.wim的文件，其大小已经超出了 4GB，超出了 fat32 所要求的单个文件最大 4GB 的限制。这使得必须用额外的步骤才能制作一个启动盘。这里依旧使用 fat32 格式是因为其兼容性是最好的，ntfs 的 uefi 启动盘很多情况下不被识别。 首先和基础安装中的部分步骤类似，首先用 parted 命令创建 U 盘的分区 label 为 gpt。接下来用 cfdisk 命令创建新分区，在 Type 中选择 Microsoft basic data。接下来使用 mkfs.vfat 命令格式化所创建的分区。这样 U 盘就准备好了。 接下来下载 win10 的 iso 镜像并解压。在某些文件管理器中，你会得到如下错误。 12This disc contains a &quot;UDF&quot; file system and requires an operating systemthat supports the ISO-13346 &quot;UDF&quot; file system specification.w 这种情况下则需要手动挂载并复制出来 1mount -o loop /path/of/windows10.iso /mnt/your/mountpoint 得到复制出来的文件后，最后要进行的就是压缩 install.wim 文件，这里需要首先安装一个包 1sudo pacman -S wimlib 接下来进行压缩，这一步会持续较长时间，耐心等待。完成后可以看到文件已经被压缩到了 3.x GB。 1sudo wimlib-imagex optimize install.wim --solid 最后把全部文件复制到 U 盘中即可。","categories":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/categories/Arch/"}],"tags":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/tags/Arch/"},{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"}]},{"title":"Arch Linux 桌面环境安装和基础设置","slug":"Arch Linux 桌面环境安装和基础设置","date":"2025-03-03T02:00:00.000Z","updated":"2025-03-09T09:46:36.445Z","comments":true,"path":"Arch Linux 桌面环境安装和基础设置/","permalink":"https://wxwdaydayup.top/Arch%20Linux%20%E6%A1%8C%E9%9D%A2%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E5%92%8C%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE/","excerpt":"本文将介绍 Arch Linux 桌面环境和一些必要应用的安装。","text":"本文将介绍 Arch Linux 桌面环境和一些必要应用的安装，直入正题： 01. 确保系统为最新1pacman -Syyu #升级系统中全部包 02. 准备非 root 用户添加用户，比如新增加的用户叫 testuser 1useradd -m -G wheel -s /bin/bash testuser #wheel附加组可sudo，以root用户执行命令 -m同时创建用户家目录 设置新用户 testuser 的密码 1passwd testuser 编辑 sudoers 配置文件 1vim /etc/sudoers # 需要以 root 用户运行命令 找到下面这样的一行，把前面的注释符号 # 去掉，:wq 保存并退出即可 1#%wheel ALL=(ALL:ALL) NOPASSWD: ALL 这里稍微解释一下 %wheel 代表是 wheel 组，百分号是前缀 ALL&#x3D; 代表在所有主机上都生效(如果把同样的sudoers文件下发到了多个主机上) (ALL) 代表可以成为任意目标用户 ALL 代表可以执行任意命令 一个更详细的例子: 12%mailadmin snow,rain=(root) /usr/sbin/postfix, /usr/sbin/postsuper, /usr/bin/doveadmnobody ALL=(root) NOPASSWD: /usr/sbin/rndc reload 组 mailadmin 可以作为 root 用户，执行一些邮件服务器控制命令。可以在 “snow” 和 “rain”这两台主机上执行 用户 nobody 可以以 root 用户执行rndc reload命令。可以在所有主机上执行。同时可以不输入密码。（正常来说 sudo 都是要求输入调用方的密码的） 03. 安装 KDE Plasma 桌面环境1pacman -S plasma-meta konsole dolphin #安装plasma-meta元软件包以及终端和文件管理器 04. 配置 greeter sddmSDDM 是一个显示管理器，它是 Plasma 的官方组成部分 1systemctl enable sddm 05. 设置交换文件 swap （可选）在桌面环境中，交换分区或文件用来实现休眠(hibernate)的功能，即将当前环境保存在磁盘的交换文件或分区部分。除此之外，某些特定软件需要 swap 才可以正确运行。交换文件与分区性能相同，且交换文件更为灵活，可随时变更大小，增加与删除。 待机，指系统将当前状态保存于内存中，进入的低能耗状态（保持开机）。 休眠，与待机有所不同，是将当前状态保存于硬盘中，然后可以完全断电。 1234dd if=/dev/zero of=/swapfile bs=1M count=4096 status=progress #创建4G的交换空间 大小根据需要自定chmod 600 /swapfile #设置正确的权限mkswap /swapfile #格式化swap文件swapon /swapfile #启用swap文件 若你在之前将硬盘格式化为 btrfs 文件系统，由于 btrfs 不支持常规 swapon 操作，你需要使用 btrfs 专用的方法创建 swap 文件，此时应： 12345rm /swapfile #删除你已经使用 dd 创建的 /swapfilebtrfs filesystem mkswapfile --size 4G /swapfile #使用 btrfs 专用方式创建 swapswapon /swapfile #启用 swapswapon --show #确认 swap 是否成功挂载free -h #确认 swap 是否成功挂载 这是因为 btrfs 具有 COW（写时复制）特性，直接使用 dd 创建的 /swapfile 可能导致碎片化，swapon 也不支持 COW 文件。因此，我们必须使用 btrfs filesystem mkswapfile 命令，它会自动创建一个正确的、非 COW 的 swap 文件。 最后，向&#x2F;etc&#x2F;fstab 中追加如下内容： 1/swapfile none swap defaults 0 0 KDE 自身提供开箱即用的待机功能(suspend)，即将系统挂起到内存，消耗少量的电量。休眠(hibernate)会将系统挂起到交换分区或文件，几乎不消耗电量。待机功能已可满足绝大多数人的需求，如果你一定需要休眠功能，可以参考官方文档（https://wiki.archlinux.org/title/Power_management/Suspend_and_hibernate）设置休眠相关步骤。 06. 开启 32 位支持库1vim /etc/pacman.conf 去掉[multilib]一节中两行的注释，来开启 32 位库支持。 最后:wq 保存退出，刷新 pacman 数据库 1pacman -Syyu 重启电脑，即可看到欢迎界面，输入新用户的密码即可登录桌面 07. 安装基础功能包进入桌面后，搜索 konsole。它是 KDE 桌面环境默认的命令行终端。 首先检查桌面环境中的网络设置： 接下来安装一些基础功能包 12345678910sudo pacman -S sof-firmware alsa-firmware alsa-ucm-conf #一些可能需要的声音固件sudo pacman -S ntfs-3g #识别NTFS格式的硬盘sudo pacman -S adobe-source-han-serif-cn-fonts wqy-zenhei #安装几个开源中文字体 一般装上文泉驿就能解决大多wine应用中文方块的问题sudo pacman -S noto-fonts-cjk noto-fonts-emoji noto-fonts-extra #安装谷歌开源字体及表情sudo pacman -S firefox chromium #安装常用的火狐（有Bug）、谷歌浏览器sudo pacman -S ark #与dolphin同用右键解压sudo pacman -S p7zip unrar unarchiver lzop lrzip #安装ark可选依赖sudo pacman -S packagekit-qt5 packagekit appstream-qt appstream #确保Discover(软件中心）可用 需重启sudo pacman -S gwenview #图片查看器sudo pacman -S git wget kate bind #一些工具 不要安装过多字体：在字体超过 255 种时，某些 QT 程序可能无法正确显示某些表情和符号 08. 设置 DNS一般来说，如今大多电脑连接的路由器是可以自动处理 DNS 的，如果你的路由器不能处理，则需要额外进行 DNS 的设置。同时，如果使用 ISP 提供的默认 DNS，你的网络访问记录将存在更大的，被泄露或被当局存储记录的风险。除此之外，使用 ISP 提供的 DNS 还有可能将某些服务解析至一些已经失效或劣化的服务器。即使你的网络环境可以自动处理 DNS 设置，我们还是建议你使用可信的国际通用 DNS 设置。如下的配置将固定使用谷歌的 DNS，但是网络访问延迟可能增加。在阅读完随后的代理设置一节后，你的 DNS 请求将均通过代理发送，这将在 DNS 发送方面最大限度的保障你的隐私和安全。 vim 编辑 /etc/resolv.conf，删除已有条目，并将如下内容加入其中 1234nameserver 8.8.8.8nameserver 2001:4860:4860::8888nameserver 8.8.4.4nameserver 2001:4860:4860::8844 如果你的路由器可以自动处理 DNS，resolvconf 会在每次网络连接时用路由器的设置覆盖本机&#x2F;etc&#x2F;resolv.conf 中的设置，执行如下命令加入不可变标志，使其不能覆盖如上加入的配置 1sudo chattr +i /etc/resolv.conf 09. 设置系统为中文打开 System Settings &gt; _Regional Settings 在语言中添加中文加入，应用即可 接下来编辑 ~/.config/plasma-localerc ，将其中的 LANG 值更改为 zh_CN.UTF-8 10. 安装 Yay AUR 助手AUR 为 archlinux user repository。任何用户都可以上传自己制作的 AUR 包，这也是 Arch Linux 可用软件众多的原因。由于任何人都可上传，也存在对应的风险，一般选用大众认可的包即可。 可以使用 yay 或 paru 安装 AUR 中的包。首先切换至普通用户： 1su - nailclipper 刷新包缓存并更新系统 1sudo pacman -Syu 安装所需的 base-devel（包含 makepkg 等工具）和 git（克隆 yay 的 Git 仓库所需的） 1sudo pacman -S --needed base-devel git 使用 --needed 标志，它不会重新安装已经安装的软件包 使用 git 命令克隆 Yay 仓库。你可以在系统中的任何位置执行此操作，无论是主目录还是其他目录。 1git clone https://aur.archlinux.org/yay.git 完成后，切换到克隆的目录 1cd yay 事实上，你是在构建它。ls 后你将在此处看到 PKGBUILD 文件。使用以下命令从此处构建包 1makepkg -si 按照屏幕上的说明进行操作。当系统要求你确认时，按 Y 若你在此时遇到网络问题，显示为：&#x3D;&#x3D;&gt; 错误： 在 build() 中发生一个错误。 正在放弃… 我们需要打开文件夹下的 PKGBUILD 文件，找到 build() 函数，在其多条 export 语句下添加： 12345678910build() &#123; export GOPATH=&quot;$srcdir&quot;/gopath export CGO_CPPFLAGS=&quot;$&#123;CPPFLAGS&#125;&quot; export CGO_CFLAGS=&quot;$&#123;CFLAGS&#125;&quot; ... ... ... #下面这两条是你需要添加的内容 export GO111MODULE=on export GOPROXY=https://goproxy.cn 该过程完成后，通过检查其版本来验证 Yay 是否已成功安装 1yay --version 使用 Yay AUR 助手进行包管理: 搜索软件包：yay search_term 安装软件包：yay -S package_name 删除软件包：yay -R package_name 要删除包及其依赖项：yay -Rns package_name 仅升级 AUR 包：yay -Sua 将 Yay 升级到新版本：yay -Sua 从 Arch 系统中删除 Yay：sudo pacman -Rs yay 11. 安装输入法Fcitx5 官方文档 中文及日文输入法均体验良好 123456sudo pacman -S fcitx5-im #基础包组sudo pacman -S fcitx5-chinese-addons #官方中文输入引擎sudo pacman -S fcitx5-anthy #日文输入引擎yay -S fcitx5-pinyin-moegirl #萌娘百科词库 你可能在此卡住。如卡住，可根据后文设置好代理后再安装sudo pacman -S fcitx5-pinyin-zhwiki #中文维基百科词库sudo pacman -S fcitx5-material-color #主题 设置环境变量：编辑文件 sudo vim /etc/environment 加入以下内容。konsole 以及 dolphin 都需要这些环境变量，倒是 chrome 和 firefox 都不需要就可以输入中文 1234GTK_IM_MODULE=fcitxQT_IM_MODULE=fcitxXMODIFIERS=@im=fcitxSDL_IM_MODULE=fcitx 打开 系统设置 &gt; 区域设置 &gt; 输入法，先点击运行Fcitx，拼音为默认添加项。如你还需要更多输入法如五笔，则再点击添加输入法，找到简体中文下的五笔 ，点击添加即可加入五笔输入法。 接下来点击 拼音 右侧的配置按钮，点选云拼音和在程序中显示预编辑文本 最后应用。 回到输入法设置，点击配置附加组件，找到 经典用户界面 在主题里选择一个你喜欢的颜色，最后应用。 注销，重新登陆，就可以发现已经可以在各个软件中输入中文了 RIME 中州韵输入法引擎（英语：Rime Input Method Engine，又称 Rime 输入法）是由佛振编写的开源中文输入法，目前项目网站、源代码均托管在 GitHub。基于同一个核心架构，该输入法分为三个官方发行版：Linux 发行版中州韵（ibus-rime）、Windows 发行版小狼毫（Weasel）、macOS 发行版鼠须管（Squirrel）。另有数个第三方发行版：Linux 发行版 fcitx-rime、Windows 发行版 PRIME、macOS 发行版 XIME、Android 发行版同文输入法（Trime）、iOS 发行版 iRime。 这里介绍一下 fcitx5-rime 的安装方式 ‘’’bash sudo pacman -S fcitx5-rime #不是 fcitx-rime，因为 fcitx 与 fcitx5 有版本冲突 ‘’’ 然后打开 打开 系统设置 &gt; 区域设置 &gt; 输入法 &gt;，点击添加输入法，找到 RIME，即可添加 RIME 输入法。 RIME 输入法默认是繁体字按 Ctrl+~，即可打开选单，使用键盘上的←→，选择朙月拼音·简化字,回车。 12. 配置系统默认编辑器默认情况下，Arch Linux 在一些终端编辑场景使用 vi 编辑器，但是我们使用 vim。如果不做一个额外配置，在 git 等场景下，在终端调用编辑器会出错。编辑 sudo vim /etc/profile 文件，在文件的末尾加入如下内容，将 vim 设置为默认 EDITOR 1export EDITOR=&#x27;vim&#x27; 这样就不用在每次执行命令时都指定一遍 EDITOR=vim 了 13. 启用蓝牙相关功能对于蓝牙及无线网卡，在 Linux 下推荐使用英特尔产品。博通以及瑞昱产品在兼容性，稳定性方面在 Linux 中表现很差，会带来很多不必要的麻烦，如在驱动，BLE 方面的支持很差或者没有。 如果你有蓝牙设备，需要安装蓝牙软件包并启用蓝牙服务。随后在系统设置中进行添加设备与连接即可。注意，文件传输功能现在需要额外安装包bluez-obex，其功能与 2024 年已从 bluez 包中分离出来。 12sudo pacman -S bluez bluez-utils bluez-obexsudo systemctl enable --now bluetooth 设置开机自动启用蓝牙设备，编辑/etc/bluetooth/main.conf文件，将AutoEnable设置为 true 即可。如果一些设备依然无法实现开机自动连接，尝试继续将Experimental以及KernelExperimental两项的值设置为 true。 博通（Broadcom）网卡在 Linux 下的支持度很差，无论是无线还是蓝牙模块。对于无线功能来说，一般直接安装 broadcom-wl 包即可。 1sudo pacman -S broadcom-wl 对于蓝牙模块，需要查阅broadcom-bt-firmware仓库，在 brcm 文件夹中找到适合于自己网卡型号的 hcd 文件，将其下载并置于 /lib/firmware/brcm 文件夹中后重启即可。如果你无法确认自己的网卡型号对应哪一个 hcd 文件，那就全部下载并置于文件夹中。","categories":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/categories/Arch/"}],"tags":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/tags/Arch/"},{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"}]},{"title":"Arch Linux 无图形化操作系统安装指南","slug":"Arch Linux 无图形化操作系统安装指南","date":"2025-03-02T02:00:00.000Z","updated":"2025-03-09T07:34:23.378Z","comments":true,"path":"Arch Linux 无图形化操作系统安装指南/","permalink":"https://wxwdaydayup.top/Arch%20Linux%20%E6%97%A0%E5%9B%BE%E5%BD%A2%E5%8C%96%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/","excerpt":"首先允许我提前声明一点，Arch Linux的安装并不算难，但是绝对也算不上简单，中间的安装可能会遇到很多问题，本篇文章不能保证完全贴合你的真实机器环境，但是我会在我安装过程中遇到的一点点小问题都说出来，给大家避个坑。","text":"在本文开始之前，首先允许我提前声明一点，Arch Linux的安装并不算难，但是绝对也算不上简单，中间的安装可能会遇到很多问题，本篇文章不能保证完全贴合你的真实机器环境，但是我会在我安装过程中遇到的一点点小问题都说出来，给大家避个坑，那么接下来，介绍一下本文用到的安装环境： Windows VMware虚拟机 Vmware的NAT网络连接模式 至于在个人电脑上安装 Arch Linux 与虚拟机安装不同的地方，我会当前步骤前后标注出来。 毕竟是安装操作系统，第一步肯定获得Arch Linux操作系统的镜像包，关于其镜像包，由于官网给我们的是磁链和BT文件，所以网络环境和软件环境好的同学可以使用官网的下载方式。条件不允许的同志，可以选择使用镜像站来下载；这里贴出官网的下载方式和镜像站： 官网BT：https://archlinux.org/releng/releases/2025.03.01/torrent/ 清华源镜像站：https://mirrors.tuna.tsinghua.edu.cn/archlinux/iso/2025.03.01/ 下载完成后，还需要在 archlinux 下载页面（https://archlinux.org/iso/2025.03.01/archlinux-2025.03.01-x86_64.iso.sig）下载`PGP signature&#96;签名文件(不要从镜像源下载签名文件)，将签名文件和 iso 镜像置于同一文件夹，随后进行对镜像的签名校验，以保证下载的镜像是完整，无错误的，未被篡改的。若你使用 Linux，执行以下命令，确保输出完好的签名。具体镜像名根据名字自行修改。 1gpg --keyserver-options auto-key-retrieve --verify archlinux-2025.03.01-x86_64.iso.sig 如果你使用 Windows 系统，可使用 7-zip 工具验证哈希校验和，首先下载官网提供的 sha256sums.txt 文件，然后选择你所下载完成的 ISO 镜像文件，右键 &gt; 7-zip &gt; CRC SHA &gt; SHA-256，验证其结果是否与 sha256sums.txt 文件内容相同。 注意，这里的签名校验非常重要，这可以保证你的安装镜像是未被篡改的，同时也能及时发现文件是否损坏。 01. 新建虚拟机新建虚拟机的过程很简单，这里不过多赘述，主要注意的几个点已经在下图中标注，这里磁盘的大小仅为参考，一般来说个人日常使用的 linux 分配 100G 已经够用了。如果你的存储资源有限，那么最小建议不小于 50G，磁盘过小会造成无法更新系统软件包等问题。 注意：在安装之前，首先不要急着启动 Arch，我们先到 Arch 虚拟机的设置中修改一下，使用UEFI来引导系统启动。（由于当前 UEFI 已普及十余年，安装将全部以 UEFI+GPT 的形式进行，传统 BIOS 方式不再赘述。） 看到这里，使用虚拟机的同学就可以准备启动 Arch 进行接下来的安装了。而对于需要在 PC 端安装的同学还需要以下准备： 确保网络环境如果你可以使用路由器分接出来的网线，以 dhcp 的方式直接上网，那么不用准备什么。如果你的环境只能使用无线网络安装，需要事先把自己所用的 wifi 名称改成自己能记住的英文名称。因为安装时无法显示和输入中文名的 wifi，你会看到一堆不知道是什么的方块，并且在安装过程中你将没有办法输入中文的无线名称进行连接。虽然通过一些繁琐的步骤可以解决终端中文的问题，但是显然这么做在安装 Arch Linux 时毫无必要。其次，有些笔记本电脑上存在无线网卡的硬件开关或者键盘控制，开机后安装前需要确保你的无线网卡硬件开关处于打开状态。 刻录启动优盘准备一个 2G 以上的优盘，刻录一个安装启动盘。Windows 下推荐使用 ventoy 或者 Rufus 或者 etcher 进行优盘刻录。三者皆为自由软件。Linux 下可以直接用 dd 命令进行刻录。注意 of 的参数为 sdx,不是 sdx1 sdx2 等。 1sudo dd bs=4M if=/path/to/archlinux.iso of=/dev/sdx status=progress oflag=sync bs&#x3D;4M 指定一个较为合理的文件输入输出块大小。status&#x3D;progress 用来输出刻录过程总的信息。oflag&#x3D;sync 用来控制写入数据时的行为特征。确保命令结束时数据及元数据真正写入磁盘，而不是刚写入缓存就返回。 进入主板 BIOS 进行设置插入优盘并开机。在开机的时候，按下 F2&#x2F;F8&#x2F;F10&#x2F;DEL 等(取决与你的主板型号，具体请查阅你主板的相关信息，我的微星主板使用的是 DEL)按键，进入主板的 BIOS 设置界面。 关闭主板设置中的 Secure Boot在类似名为 security 的选项卡中，找到一项名为 Secure Boot(名称可能略有差异)的选项，选择 Disable 将其禁用。 调整启动方式为 UEFI在某些旧的主板里，需要调整启动模式为 UEFI，而非传统的 BIOS&#x2F;CSM。在类似名为 boot 的选项卡中，找到类似名为 Boot Mode 的选项，确保将其调整为 UEFI only，而非 legacy&#x2F;CSM。 调整硬盘启动顺序在类似名为 boot 的选项卡中，找到类似名为 Boot Options(名称可能略有差异)的设置选项，将 USB 优盘的启动顺序调至首位。对于微星主板，可以在计算机启动加电自检时（出现那个MSI logo 时）按下 F11 选择优盘作为启动盘。 准备安装最后保存 BIOS 设置并退出，一般的按键是 F10。此时系统重启，不出意外你应该已经进入 archlinux 的安装界面。 02. Arch Linux 基础安装本节从安装最基础的无图形化 ArchLinux 系统开始。 （官方指南：https://wiki.archlinux.org/title/Installation_guide） 开机后应显示如下界面：您将会以 root 身份登录进入一个虚拟控制台，默认的 Shell 是 Zsh。 如果您觉得用命令行安装过于繁琐，可以试试官方的安装脚本 archinstall。详情可参见 archinstall SSH 远程连接 我们安装 Arch 的时候是完全被允许使用 SSH 来远程连接的，关于我为什么要提这个问题，因为我们安装的时候是无法在虚拟机或物理机中粘贴的，如果我们能够使用 Shell 工具远程连接到Arch的安装进程上，就可以正常的来粘贴命令了，这样的话将会起到事半功倍的效果。 在物理机上安装时，此时要先连接网络，否则无法建立 SSH 连接，对于有线网络无需任何设置（安装环境中 DHCP 服务是默认开启的）。对于 WIFI 网络，需要执行以下命令： 1234567iwctl #执行iwctl命令，进入交互式命令行device list #列出设备名，比如无线网卡看到叫 wlan0station wlan0 scan #扫描网络station wlan0 get-networks #列出网络 比如想连接YOUR-WIRELESS-NAME这个无线station wlan0 connect YOUR-WIRELESS-NAME #进行连接 输入密码即可exit #成功后exit退出ping www.baidu.com #测试网络 如果你没有相关的工具，那么也不影响后续的操作；如果你有，请使用root@xxx.xxx.xxx.xxx来进行连接，ip a 命令可以查看 Arch 的 IP，passwd 可以修改 root 的密码（记得检查小键盘数字锁是否打开）。闲话少说，基本的配置完成，我们还是步入正轨来安装Arch吧。 1234#查看 IPip a#修改 root 密码passwd root 禁用 reflector reflector 会为你选择速度合适的镜像源，但其结果并不准确，同时会清空配置文件中的内容，对于新人来讲并不适用，我们首先对其进行禁用。 1systemctl stop reflector.service 再次确保是否为 UEFI 模式 在一系列的信息刷屏后，可以看到已经以 root 登陆安装系统了，此时可以执行的命令： 1ls /sys/firmware/efi/efivars 若输出了一堆东西，即 efi 变量，则说明已在 UEFI 模式。否则请确认你的启动方式是否为 UEFI。 连接网络 对于使用虚拟机的同学，curl 百度进行测试，如果能够输出东西，有一堆HTML标签等等，说明网络无异常。对于在物理机安装的同学，一般来说，你连接的网络几乎均可以通过 DHCP 的方式来进行 IP 地址和 DNS 的相关设置（由 systemd-networkd 和 systemd-resolved 提供功能），无需进行额外操作。在没有合适网络的情况下，使用手机的移动热点也是很方便的选择。如果你的网络环境需要配置静态 IP 和 DNS，请自行参考网络配置#静态 IP 地址进行操作。 对于有线连接来说，直接插入网线即可。 对于无线连接（已经在 SSH 远程连接章节完成网络配置的同学请忽略），则需进行如下操作进行网络连接。 无线连接使用 iwctl 命令进行，按照如下步骤进行网络连接： 123456iwctl #执行iwctl命令，进入交互式命令行device list #列出设备名，比如无线网卡看到叫 wlan0station wlan0 scan #扫描网络station wlan0 get-networks #列出网络 比如想连接YOUR-WIRELESS-NAME这个无线station wlan0 connect YOUR-WIRELESS-NAME #进行连接 输入密码即可exit #成功后exit退出 可以等待几秒等网络建立链接后再进行下面测试网络的操作。 1ping www.baidu.com 如果你不能正常连接网络，首先确认系统已经启用网络接口 12ip link #列出网络接口信息，如不能联网的设备叫wlan0ip link set wlan0 up #比如无线网卡看到叫 wlan0 如果随后看到类似Operation not possible due to RF-kill的报错，继续尝试rfkill命令来解锁无线网卡。 1rfkill unblock wifi **注意：**默认情况下，安装映像在启动时已经预先配置好并启用了 systemd-networkd、systemd-resolved、iwd 和 ModemManager。但在已经安装完成了的系统之中并非如此。 更新系统时钟 系统时间的准确是十分重要的，我们的 SSL 证书等等以及例如 OTP 等等很多服务，都是要建立在时间准确的前提下的，所以这一步是至关重要的。使用命令同步系统时间： 12timedatectl set-ntp true #将系统时间与网络时间进行同步timedatectl status #检查服务状态 由于我们国家处于东八区，这里的Time zone给出的是UTC+0，所以只要将其时间加上8H即可得出我们的时间，如果计算后的时间和我们的实际时间基本相吻合，那么这里就可以继续操作了。 分区 由于这里我们是使用新开虚拟机操作，顾虑不用很多，不会刷写到我们物理机的磁盘。但是在这里我还是提一嘴，数据无价！ 这里总共设置三个分区，是一个我们认为较为通用的方案。此步骤会清除磁盘中全部内容，请事先确认。 EFI 分区： /efi 800M（建议 1 GiB） Swap 分区：4GiB（Swap 交换空间也可以在 Swap#交换文件 上为支持它的文件系统设置） 根分区： / 剩余全部（至少 50 GiB） 首先将磁盘转换为 gpt 类型，这里假设比如你想安装的磁盘名称为 sdx。如果你使用 NVME 的固态硬盘，你看到的磁盘名称可能为 nvme0n1。 12345lsblk #显示分区情况 找到你想安装的磁盘名称parted /dev/sdx #执行parted，进入交互式命令行，进行磁盘类型变更(parted)mktable #输入mktableNew disk label type? gpt #输入gpt 将磁盘类型转换为gpt 如磁盘有数据会警告，输入yes即可(parted)quit #最后quit退出parted命令行交互 接下来使用 cfdisk 命令对磁盘分区。进入 cfdisk 后的操作很直观，用键盘的方向键、Tab 键、回车键配合即可操作分配各个分区的大小与格式。一般建议将 EFI 分区设置为磁盘的第一个分区，据说有些主板如果不将 EFI 设置为第一个分区，可能有不兼容的问题。其中 EFI 分区选择EFI System类型，Swap 分区选择Linux swap 类型，根分区选择Linux filesystem类型。 12cfdisk /dev/sdx #来执行分区操作,分配各个分区大小，类型fdisk -l #分区结束后， 复查磁盘情况 注意：最后一定要点击Write，以更改分区表，当下方提示 “The partition table has been altered.” ，说明修改成功，选择 Quit 退出。 格式化 建立好分区后，需要对分区用合适的文件系统进行格式化。这里用mkfs.vfat命令格式化 EFI 分区，使用mkswap命令格式化 swap 分区，用mkfs.btrfs命令格式化根分区，。如下命令中的 sdax 中，x 代表分区的序号。格式化命令要与上一步分区中生成的分区名字对应才可以。 磁盘若事先有数据，会提示你: ‘proceed any way?’ 按 y 回车继续即可。 1234mkfs.vfat /dev/sda1 #格式化efi分区mkswap /dev/sda2 #格式化swap分区mkfs.btrfs /dev/sda3 #格式化根分区lsblk -f #查看分区结果 挂载分区 在挂载时，挂载是有顺序的，先挂载根分区，再挂载 EFI 分区。 这里的 sdax 只是例子，具体根据你自身的实际分区情况来。 1234mount /dev/sda3 /mntmkdir /mnt/boot #创建efi目录mount /dev/sda1 /mnt/boot/efiswapon /dev/sda2 镜像源选择 使用如下命令编辑镜像列表： 1vim /etc/pacman.d/mirrorlist 其中的首行是将会使用的镜像源。添加中科大或者清华的放在最上面即可。 12Server = https://mirrors.ustc.edu.cn/archlinux/$repo/os/$archServer = https://mirrors.tuna.tsinghua.edu.cn/archlinux/$repo/os/$arch 如果其速度不佳，可以手动指定其他镜像源。完整的镜像源列表可参考官方镜像源生成器。 这里使用中国境内的镜像源以提高访问速度。然而这存在问题，镜像源(如 arch linux 清华镜像源)以及第三方源(如 archlinux-cn)可以知道你的 ip 是什么，什么时候更新了系统，什么时候检查了系统，什么时候更新了什么软件，你安装的软件列表是什么。在威权国家的镜像源维护者完全有可能根据威权当局的要求提供这些数据，很多维护者在网络上几乎是实名上网的，他们没有任何抵抗能力，进一步的，威权国家可以根据这些元数据与你产生的其他元数据进行比对，从而对你进行进一步的定位与辨识。简单举一个例子，要求维护者提供或监视安装了 v2ray&#x2F;qv2ray 等软件包的使用者的 ip,以及安装时间，以及其全部软件列表。 如果你在安装 arch linux 时的网络已经处于代理模式下，可以选择一个与你代理位置较近的，非威权国家的镜像源来使用。如果你在安装 arch linux 时的网络环境没有代理，那么在安装结束后，需要尽快更换一个非威权国家的镜像源来使用。如下列举一些较为优质的国际源。 12345Server = https://mirror.archlinux.tw/ArchLinux/$repo/os/$arch #东亚地区:中华民国Server = https://mirror.0xem.ma/arch/$repo/os/$arch #北美洲地区:加拿大Server = https://mirror.aktkn.sg/archlinux/$repo/os/$arch #东南亚地区:新加坡Server = https://archlinux.uk.mirror.allworldit.com/archlinux/$repo/os/$arch #欧洲地区:英国Server = https://mirrors.cat.net/archlinux/$repo/os/$arch #东亚地区:日本 安装系统 必须的基础包 1pacstrap /mnt base base-devel linux linux-headers linux-firmware 注意，目前需要首先确保等待 pacman-init.service 服务启动后，才能执行 pacstrap 或 pacman 命令安装包，否则会引发错误使得安装过程无法进行。使用systemctl status pacman-init.service命令来检查当前服务状态。 必须的功能性软件 12pacstrap /mnt dhcpcd iwd vim bash-completion btrfs-progs #一个有线所需(iwd也需要dhcpcd) 一个无线所需 一个编辑器 一个补全工具 一个Btrfs文件系统工具集 生成 fstab 文件 fstab 用来定义磁盘分区 1genfstab -U /mnt &gt;&gt; /mnt/etc/fstab 复查一下 &#x2F;mnt&#x2F;etc&#x2F;fstab 确保没有错误，此时可以手动修改 /mnt/etc/fstab 添加挂载选项 1cat /mnt/etc/fstab change root 把环境切换到新安装的系统 1arch-chroot /mnt 时区设置 设置时区，在 &#x2F;etc&#x2F;localtime 下用 &#x2F;usr 中合适的时区创建符号连接。如下设置上海时区 1ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 随后进行硬件时间设置，将当前的正确 UTC 时间写入硬件时间 1hwclock --systohc 设置 Locale 进行本地化 Locale 决定了地域、货币、时区日期的格式、字符排列方式和其他本地化标准。 首先使用 vim 编辑 &#x2F;etc&#x2F;locale.gen，去掉 en_US.UTF-8 所在行以及 zh_CN.UTF-8 所在行的注释符号（#）。 1vim /etc/locale.gen 然后使用如下命令生成 locale 1locale-gen 最后向 &#x2F;etc&#x2F;locale.conf 导入内容 1echo &#x27;LANG=en_US.UTF-8&#x27; &gt; /etc/locale.conf 设置主机名 首先在/etc/hostname设置主机名 1vim /etc/hostname 加入你想为主机取的主机名，这里比如叫 myarch。 接下来在/etc/hosts设置与其匹配的条目。 1vim /etc/hosts 加入如下内容 123127.0.0.1 localhost::1 localhost127.0.1.1 myarch 某些情况下如不设置主机名，在 KDE 下可能会存在网络情况变更时无法启动 GUI 应用的问题，在终端中出现形如No protocol specified qt.qpa.xcb: could not connect to display的错误，这种情况较为少见。 安装微码 12pacman -S intel-ucode #Intelpacman -S amd-ucode #AMD 安装引导程序 1234pacman -S grub efibootmgr #安装引导程序。grub 是启动引导器，efibootmgr 被 grub 脚本用来将启动项写入 NVRAM 。grub-install --target=x86_64-efi --efi-directory=/boot --bootloader-id=GRUB#将 GRUB 安装到 EFI 分区 接下来编辑&#x2F;etc&#x2F;default&#x2F;grub 文件，去掉GRUB_CMDLINE_LINUX_DEFAULT一行中最后的 quiet 参数，同时把 log level 的数值从 3 改成 5。这样是为了后续如果出现系统错误，方便排错。同时在同一行加入 nowatchdog 参数，这可以显著提高开关机速度。 1vim /etc/default/grub 最后生成 GRUB 所需的配置文件 1grub-mkconfig -o /boot/grub/grub.cfg 若在物理机安装： 使用 N 卡的同学需要注意，KDE6 默认使用 wayland session 为默认，如果你需要使用 wayland,则需开启 DRM。同样编辑 &#x2F;etc&#x2F;default&#x2F;grub 文件，在GRUB_CMDLINE_LINUX_DEFAULT一行中最后的加入参数：nvidia_drm.modeset&#x3D;1 我们在之前的命令中指定了 bootloader-id 为 GRUB，这一般不会出现问题。然而在某些主板安装完成后，你会发现没有 nvme 启动条目。这是因为某些主板的 UEFI 固件在显示 UEFI NVRAM 引导条目之前，需要在特定的位置存放可引导文件，不支持自定义存放 efi 文件。解决方式是使用--removable 参数解决一些主板 NVRAM 的兼容性问题。 12grub-install --target=x86_64-efi --efi-directory=/boot/efi --removablegrub-mkconfig -o /boot/grub/grub.cfg 除此之外，如果你的主板是一些较老的型号，如 intel 9 系列以下或者较老 AMD 的主板，它们很可能不支持从 nvme 启动系统，虽然可以通过修改 BIOS 加入 NVME 支持模块来解决，但这不在本文讨论范围内。 添加 root 密码 1passwd 安装 openssh 服务和 networkmanager 服务并设置开机自启 1234pacman -S opensshpacman -S networkmanagersystemctl enable sshdsystemctl enable NetworkManager 完成安装 123exit # 退回安装环境#umount -R /mnt # 卸载新分区reboot # 重启 至此，无图形化 ArchLinux 系统安装完成。 在物理机安装的同学注意，重启前要先拔掉优盘，否则你重启后还是进安装程序而不是安装好的系统。重启后，开启 dhcp 服务，即可连接网络 12systemctl start dhcpcd #立即启动dhcpping www.gnu.org #测试网络连接 若为无线链接，则还需要启动 iwd 才可以使用 iwctl 连接网络 1234567systemctl start iwd #立即启动iwdiwctl #和之前的方式一样，连接无线网络device list #列出设备名，比如无线网卡看到叫 wlan0station wlan0 scan #扫描网络station wlan0 get-networks #列出网络 比如想连接YOUR-WIRELESS-NAME这个无线station wlan0 connect YOUR-WIRELESS-NAME #进行连接 输入密码即可exit #成功后exit退出 archlinux 在 2021 年 4 月在安装镜像中内置了一个安装脚本，提供一些选项，即可快速安装。其和所有一键安装脚本类似，提供自动化，且不灵活的安装过程。不建议使用这种安装脚本，除了不灵活的原因，初学者也无法在这种安装过程中学到任何东西。如果你的确需要快速启动一个基础的 archlinux 环境，那么可以尝试此脚本。 示例：使用 pacman 安装 fastfetch 12pacman -S fastfetch #安装fastfetch #运行","categories":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/categories/Arch/"}],"tags":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/tags/Arch/"},{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"}]},{"title":"Shell 编程快速上手（知其然）","slug":"Shell 编程快速上手（知其然）","date":"2025-02-27T02:00:00.000Z","updated":"2025-03-13T09:48:37.748Z","comments":true,"path":"Shell 编程快速上手（知其然）/","permalink":"https://wxwdaydayup.top/Shell%20%E7%BC%96%E7%A8%8B%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%EF%BC%88%E7%9F%A5%E5%85%B6%E7%84%B6%EF%BC%89/","excerpt":"Shell是一个命令行解释器，它接收应用程序（用户）命令，然后调用操作系统内核。Shell还是一个功能相当强大的编程语言，易编写，易调试，灵活性强。","text":"1.概述Shell是一个命令行解释器，它接收应用程序（用户）命令，然后调用操作系统内核。Shell还是一个功能相当强大的编程语言，易编写，易调试，灵活性强。 1.1 Fedora Linux 提供的Shell解释器有1234567[root@hadoop100 ~]# cat /etc/shells/bin/sh/bin/bash/usr/bin/sh/usr/bin/bash/usr/bin/tmux/bin/tmux 1.2 bash 和 sh 的关系123[root@hadoop100 ~]# cd /usr/bin; ll | grep bash-rwxr-xr-x. 1 root root 1414688 Aug 11 2024 bashlrwxrwxrwx. 1 root root 4 Aug 11 2024 sh -&gt; bash 1.3 Fedora 默认的解释器是 bash12[root@hadoop100 ~]# echo $SHELL/bin/bash 2. Shell脚本入门2.1 脚本格式脚本以 #!/bin/bash 开头（指定解释器） 2.2 第一个 Shell 脚本: helloworld.sh（1）需求：创建一个 Shell 脚本，输出 Hello World （2）案例实操： 123456789[root@hadoop100 ~]# mkdir scripts[root@hadoop100 ~]# cd scripts/[root@hadoop100 scripts]# touch helloworld.sh[root@hadoop100 scripts]# vim helloworld.sh #------------------------------#在 helloworld.sh 中输入如下内容:#!/bin/bashecho &quot;Hello World&quot;#------------------------------- （3）脚本的常用执行方式 第一种：采用 bash 或 sh + 脚本的相对路径或绝对路径（不用赋予脚本 +x 权限） ​ sh + 脚本的相对路径 12[root@hadoop100 scripts]# sh ./helloworld.sh Hello World ​ sh + 脚本的绝对路径 12[root@hadoop100 scripts]# sh /root/scripts/helloworld.sh Hello World ​ bash + 脚本的相对路径 12[root@hadoop100 scripts]# bash ./helloworld.sh Hello World ​ bash + 脚本的绝对路径 12[root@hadoop100 scripts]# bash /root/scripts/helloworld.sh Hello World 第二种：采用输入脚本的绝对路径或相对路径执行脚本（必须具有 +x 权限） 1. 首先要赋予 helloworld.sh 脚本的 +x 权限 1[root@hadoop100 scripts]# chmod +x helloworld.sh 2. 执行脚本 ​ 相对路径 12[root@hadoop100 scripts]# ./helloworld.sh Hello World ​ 绝对路径 12[root@hadoop100 scripts]# /root/scripts/helloworld.sh Hello World 注意：第一种执行方法，本质是bash解释器帮你执行脚本，所以脚本本身不需要执行权限。第二种执行方法，本质是脚本需要自己执行，所以需要执行权限。 第三种：在脚本的路径前加上 “.” 或者 source 1. 创建以下脚本： 12345[root@hadoop100 scripts]# vim test.sh[root@hadoop100 scripts]# cat test.sh #!bin/bashA=5echo $A 2. 分别使用 sh, bash, ./ 和 &quot;.&quot; 的方式来执行，结果如下： 12345678910111213141516[root@hadoop100 scripts]# bash test.sh 5[root@hadoop100 scripts]# echo $A[root@hadoop100 scripts]# sh test.sh 5[root@hadoop100 scripts]# echo $A[root@hadoop100 scripts]# ./test.sh 5[root@hadoop100 scripts]# echo $A[root@hadoop100 scripts]# . test.sh 5[root@hadoop100 scripts]# echo $A5 &lt;--使脚本内容在当前shell中执行，而不是子shell 原因： ​ 前三种方式都是在当前shell中打开一个子shell来执行脚本内容，当脚本内容结束，则子shell关闭，回到父shell中。 ​ 第四种，也就是在脚本路径前加 “.” 或 source 的方式，可以使脚本内容在当前 shell 中执行，而无需打开子 shell ，这也是为什么我们每次要修改完 etc/profile 文件后，需要 source 一下的原因。 ​ 开子 shell 和不开子 shell 的区别就在于，环境变量的继承关系，如在子 shell 中设置的当前变量，父 shell 是不可见的。 3. 变量3.1 系统预定义变量（1）常用系统变量 `$HOME` `$PWD` `$SHELL` `$USER` 等 （2）案例实操 ​ 1）查看系统变量的值 12345678[root@hadoop100 scripts]# echo $HOME/root[root@hadoop100 scripts]# echo $PWD/root/scripts[root@hadoop100 scripts]# echo $SHELL/bin/bash[root@hadoop100 scripts]# echo $USERroot ​ 2）显示系统环境变量： env 123456789101112131415[root@hadoop100 scripts]# envSHELL=/bin/bashHISTCONTROL=ignoredupsHISTSIZE=1000HOSTNAME=hadoop100GPG_TTY=/dev/pts/0EDITOR=/usr/bin/nanoPWD=/root/scriptsLOGNAME=rootXDG_SESSION_TYPE=ttyMOTD_SHOWN=pamHOME=/rootSSH_ASKPASS=/usr/bin/ksshaskpassLANG=en_US.UTF-8... ​ 3）显示当前 Shell 中所有变量：set 1234567891011[root@hadoop100 scripts]# set | headA=5BASH=/bin/bashBASHOPTS=checkwinsize:cmdhist:complete_fullquote:expand_aliases:extglob:extquote:force_fignore:globasciiranges:globskipdots:histappend:interactive_comments:login_shell:patsub_replacement:progcomp:promptvars:sourcepathBASHRCSOURCED=YBASH_ALIASES=()BASH_ARGC=([0]=&quot;0&quot;)BASH_ARGV=()BASH_CMDS=()BASH_COMPLETION_VERSINFO=([0]=&quot;2&quot; [1]=&quot;13&quot; [2]=&quot;0&quot;)BASH_LINENO=() 3.2 自定义变量​ （1）基本语法 ​ 1）定义变量：变量名&#x3D;变量值，注意：&#x3D;号前后不能有空格 ​ 2）撤销变量：unset 变量名 ​ 3）声明静态变量：readonly 变量，注意：不能unset ​ （2）变量定义规则 ​ 1）变量名称可以由字母，数字和下划线组成，但是不能以数字开头，环境变量名建议大写 ​ 2）等号两侧不能由空格 ​ 3）在 bash 中，变量默认类型都是字符串类型，无法直接进行数值计算 ​ 4）变量的值如果有空格，需要使用双引号或单引号括起来 ​ （3）案例实操 ​ 1）定义变量 A 123[root@hadoop100 scripts]# A=5[root@hadoop100 scripts]# echo $A5 ​ 2）给变量 A 重新赋值 123[root@hadoop100 scripts]# A=8[root@hadoop100 scripts]# echo $A8 ​ 3）撤销变量 A 123[root@hadoop100 scripts]# unset A[root@hadoop100 scripts]# echo $A ​ 4）声明静态变量 B&#x3D;2，不能 unset 1234567[root@hadoop100 scripts]# readonly B=2[root@hadoop100 scripts]# echo $B2[root@hadoop100 scripts]# B=9-bash: B: readonly variable[root@hadoop100 scripts]# unset B-bash: unset: B: cannot unset: readonly variable ​ 5）在 bash 中，变量默认类型都是字符串类型，无法直接进行数值计算 123[root@hadoop100 scripts]# C=1+2[root@hadoop100 scripts]# echo $C1+2 ​ 6）变量的值如果有空格，需要使用双引号或单引号括起来 12345[root@hadoop100 scripts]# D=I love shellbash: love: command not found...[root@hadoop100 scripts]# D=&quot;I love shell&quot;[root@hadoop100 scripts]# echo $DI love shell ​ 7）可以把变量提升为全局环境变量，可供其他 Shell 程序使用 123456789101112131415[root@hadoop100 scripts]# E=11[root@hadoop100 scripts]# vim ./helloworld.sh #--------------------------#在helloworld中添加如下内容#!/bin/bashecho &quot;Hello World&quot;echo $E#--------------------------[root@hadoop100 scripts]# ./helloworld.sh Hello World[root@hadoop100 scripts]# export E[root@hadoop100 scripts]# ./helloworld.sh Hello World11 3.3 特殊变量3.3.1 $n​ （1）基本语法 ​ $n（功能描述：n 为数字，$0 代表该脚本名称，$1 - $9 代表第一到第九个参数，十以上的参数需要用大括号包含，如 ${10}） ​ （2）案例实操 1234567891011121314151617181920[root@hadoop100 scripts]# touch paremeter.sh[root@hadoop100 scripts]# vim paremeter.sh #------------------------#!/bin/bashecho &#x27;=========$n===========&#x27;echo $0echo $1echo $2#-------------------------[root@hadoop100 scripts]# chmod 755 paremeter.sh [root@hadoop100 scripts]# ./paremeter.sh =========$n===========./paremeter.sh[root@hadoop100 scripts]# ./paremeter.sh cls top=========$n===========./paremeter.shclstop 3.3.2 $#​ （1）基本语法 ​ $# （功能描述：获取所有输入参数个数，常用于循环，判断参数的个数是否正确以及加强脚本的健壮性） ​ （2）案例实操 1234567891011121314151617[root@hadoop100 scripts]# vim paremeter.sh #------------------------#!/bin/bashecho &#x27;=========$n===========&#x27;echo $0echo $1echo $2echo &#x27;=========$#===========&#x27;echo $##-------------------------[root@hadoop100 scripts]# ./paremeter.sh cls top=========$n===========./paremeter.shclstop=========$#===========2 3.3.3 $*、$@​ （1）基本语法 ​ $* （功能描述：这个变量代表命令行中所有的参数，$* 把所有的参数看成一个整体） ​ $@ （功能描述：这个变量也代表命令行中所有的参数，不过 $@ 把每个参数区分对待） ​ （2）案例实操 12345678910111213141516171819202122232425[root@hadoop100 scripts]# vim paremeter.sh #------------------------#!/bin/bashecho &#x27;=========$n===========&#x27;echo $0echo $1echo $2echo &#x27;=========$#===========&#x27;echo $#echo &#x27;=========$*===========&#x27;echo $*echo &#x27;=========$@===========&#x27;echo $@#-------------------------[root@hadoop100 scripts]# ./paremeter.sh a b c d e f g=========$n===========./paremeter.shab=========$#===========7=========$*===========a b c d e f g=========$@===========a b c d e f g 3.3.4 $?​ （1）基本语法 ​ $? （功能描述：最后一次执行的命令的返回状态。如果这个变量的值为0，证明上一个命令正确执行；如果这个变量的值为非0（具体是哪个数，由命令自己来决定），则证明上一个命令执行不正确） ​ （2）案例实操 ​ 判断 helloworld.sh 脚本是否正确执行 123456789[root@hadoop100 scripts]# ./helloworld.sh Hello World11[root@hadoop100 scripts]# echo $?0[root@hadoop100 scripts]# abcbash: abc: command not found...[root@hadoop100 scripts]# echo $?127 4. 运算符​ （1）基本语法 ​ $((运算式)) 或 $[运算式] ​ （2）案例实操： ​ 计算（2+3）*4 的值 123456[root@hadoop100 scripts]# S=$(((2+3)*4))[root@hadoop100 scripts]# echo $S20[root@hadoop100 scripts]# S=$[(2+3)*4][root@hadoop100 scripts]# echo $S20 5. 条件判断​ （1）基本语法 ​ 1）test condition ​ 2）[ condition ] （注意 condition 前后要有空格） ​ 注意：条件非空即为 true，如 [ abc ] 返回 true，[ ] 返回false ​ （2）常用判断条件 ​ 1）两个整数之间比较 ​ -eq 等于（equal） -ne 不等于（not equal） ​ -lt 小于（less than） -le 小于等于（less equal） ​ -gt 大于（greater than） -ge 大于等于（greater equal） ​ 注：如果是字符串之间的比较，用 “&#x3D;” 判断相等，用 “!&#x3D;” 判断不等 ​ 2）按照文件权限进行判断 ​ -r 有读的权限（read） ​ -w 有写的权限（write） ​ -x 有执行的权限（execute） ​ 3）按照文件类型进行判断 ​ -e 文件存在（existence） ​ -f 文件存在并且是一个常规文件（file） ​ -d 文件存在并且是一个目录（directory） ​ （3）案例实操 ​ 1）23 是否大于等于 22 123[root@hadoop100 scripts]# [ 23 -ge 22 ][root@hadoop100 scripts]# echo $?0 ​ 2）helloworld 是否具有写权限 123[root@hadoop100 scripts]# [ -w helloworld.sh ][root@hadoop100 scripts]# echo $?0 ​ 3）/home/nailclipper/cls.txt 目录中的文件是否存在 123[root@hadoop100 scripts]# [ -e /home/nailclipper/cls.txt ][root@hadoop100 scripts]# echo $?0 ​ 4）多条件判断（&amp;&amp; 表示前一条命令执行成功时，才执行后一条命令，|| 表示上一条命令执行失败后，才执行下一条命令） 1234[root@hadoop100 scripts]# [ abc ] &amp;&amp; echo OK || echo notOKOK[root@hadoop100 scripts]# [ ] &amp;&amp; echo OK || echo notOKnotOK 6. 流程控制6.1 if 判断​ （1）基本语法 ​ 1）单分支 123if [ 条件判断式 ];then 程序fi ​ 或者 1234if [ 条件判断式 ]then 程序fi ​ 2）多分支 123456789if [ 条件判断式 ]then 程序elif [ 条件判断式 ]then 程序else 程序fi 注意事项： 1. [ 条件判断式 ]，中括号和条件判断式之间必须有空格 2. fi 后要有空格 ​ （2）案例实操 ​ 输入一个数字，如果是1，则输出 shuai，如果是2，则输出 mei，如果是其他，什么也不输出 1234567891011121314151617181920[root@hadoop100 scripts]# vim if.sh#-------------------------------#!/bin/bashif [ $1 -eq 1 ]then echo &quot;shuai&quot;elif [ $1 -eq 2 ]then echo &quot;mei&quot;else echofi #--------------------------------[root@hadoop100 scripts]# chmod 755 if.sh [root@hadoop100 scripts]# ./if.sh 1shuai[root@hadoop100 scripts]# ./if.sh 2mei[root@hadoop100 scripts]# ./if.sh 3 6.2 case 语句​ （1）基本语法 123456789101112case $变量名 in&quot;值 1&quot;) 如果变量的值等于值 1 ，则执行程序 1 ;;&quot;值 2&quot;) 如果变量的值等于值 2 ，则执行程序 2 ;; ...省略其他分支*) 如果变量的值都不是以上的值，则执行此程序;;esac 注意事项： 1. case行尾必须为单词 &quot;in&quot; ，每一个模式匹配必须以右括号 &quot;)&quot; 结束 1. 双分号 &quot;;;&quot; 表示命令序列结束，相当于 java 中的 break 1. 最后的 &quot;*)&quot; 表示默认模式，相当于 java 中的 default ​ （2）案例实操 ​ 输入一个数字，如果是 1，则输出 one ，如果是 2 ，则输出 two ，如果是其他，则输出 big 12345678910111213141516171819202122232425[root@hadoop100 scripts]# vim case.sh#------------------------------#!/bin/bashcase $1 in&quot;1&quot;) echo &quot;one&quot;;;&quot;2&quot;) echo &quot;two&quot;;;*) echo &quot;big&quot;;;esac#------------------------------[root@hadoop100 scripts]# chmod 755 case.sh [root@hadoop100 scripts]# ./case.sh 1one[root@hadoop100 scripts]# ./case.sh 2two[root@hadoop100 scripts]# ./case.sh 3big 6.3 for 循环​ （1）基本语法1 1234for ((初始值;循环控制条件;变量变化))do 程序done ​ （2）案例实操 ​ 从 1 加到 100 1234567891011121314[root@hadoop100 scripts]# vim for1.sh#----------------------#!/bin/bashfor ((i=0;i&lt;=100;i++))do sum=$[ $sum+$i ]doneecho $sum#----------------------[root@hadoop100 scripts]# chmod 755 for1.sh [root@hadoop100 scripts]# ./for1.sh 5050 ​ （3）基本语法2 1234for 变量 in 值1 值2 值3...do 程序done ​ （4）案例实操 ​ 1）打印所有输入参数 1234567891011121314[root@hadoop100 scripts]# vim for2.sh#---------------------------#!/bin/bashfor i in java python shelldo echo &quot;I love $i&quot;done #----------------------------[root@hadoop100 scripts]# chmod 755 for2.sh [root@hadoop100 scripts]# ./for2.shI love javaI love pythonI love shell ​ 2）比较 “$*” 和 “$@” 的区别 ​ “$*” 和 “$@” 都表示传递给函数或脚本的所有参数，不被双引号 “” 包含时，都以 $1 $2 … $n 的形式输出所有参数 1234567891011121314151617181920212223242526[root@hadoop100 scripts]# vim for3.sh#----------------------------------#!/bin/bashecho &#x27;=========$*===========&#x27;for i in $*do echo &quot;I love $i&quot;done echo &#x27;=========$@===========&#x27;for j in $@do echo &quot;I love $j&quot;done #-----------------------------------[root@hadoop100 scripts]# chmod 755 for3.sh [root@hadoop100 scripts]# ./for3.sh java python shell=========$*===========I love javaI love pythonI love shell=========$@===========I love javaI love pythonI love shell ​ 当它们被双引号 “” 包含时，$* 会将所有的参数作为一个整体，以 “$1 $2 $3 … $n” 的形式输出所有参数；$@ 会将各个参数分开，以 “$1” “$2” “$3” … “$n” 的形式输出所有参数 123456789101112131415161718192021222324[root@hadoop100 scripts]# vim for4.sh#-------------------------------------#!/bin/bashecho &#x27;=========$*===========&#x27;for i in &quot;$*&quot;do echo &quot;I love $i&quot;done echo &#x27;=========$@===========&#x27;for j in &quot;$@&quot;do echo &quot;I love $j&quot;done #-------------------------------------[root@hadoop100 scripts]# chmod 755 for4.sh [root@hadoop100 scripts]# ./for4.sh java python shell=========$*===========I love java python shell=========$@===========I love javaI love pythonI love shell 6.4 while 循环​ （1）基本语法 1234while [ 条件判断式 ]do 程序done ​ （2）案例实操 ​ 从 1 加到 100 1234567891011121314151617181920[root@hadoop100 scripts]# vim while.sh#---------------------------&quot;while.sh&quot; [New] 0,0-1 All#!/bin/bashsum=0i=1while [ $i -le 100 ]do sum=$[ $sum+$i ] i=$[ $1+1 ]done echo $sum#---------------------------[root@hadoop100 scripts]# chmod 755 while.sh [root@hadoop100 scripts]# ./while.sh 5050 7. read 读取控制台输入​ （1）基本语法 ​ read （选项） （参数） ​ 1）选项： ​ -p：指定读取值时的提示符 ​ -t：指定读取值时等待的时间（秒），如果 -t 不加表示一直等待 ​ 2）参数： ​ 变量：指定读取值的变量名 ​ （2）案例实操 ​ 提示 7 秒内，读取控制台输入的名称 1234567891011[root@hadoop100 scripts]# vim read.sh#-----------------------------#!/bin/bashread -t 7 -p &quot;Enter your name in 7 seconds:&quot; NNecho $NN#-----------------------------[root@hadoop100 scripts]# chmod 755 read.sh [root@hadoop100 scripts]# ./read.shEnter your name in 7 seconds:nailclippernailclipper 8. 函数8.1 系统函数8.1.1 basename​ （1）基本语法 ​ basename [string / pathname] [suffix] （功能描述：basename 命令会删掉所有的前缀，包括最后一个（’&#x2F;‘）字符，然后将字符串显示出来） ​ basename 可以理解为取路径里的文件名称 ​ 选项： ​ suffix 为后缀，如果 suffix 被指定了，basename 会将 pathname 或 string 中的 suffix 去掉 ​ （2）案例实操 ​ 截取该 /home/nailclipper/xuexi.txt 路径的文件名称 1234567[root@hadoop100 scripts]# touch /home/nailclipper/xuexi.txt[root@hadoop100 scripts]# basename /home/nailclipper/xuexi.txtxuexi.txt[root@hadoop100 scripts]# basename /home/nailclipper/nailclipper[root@hadoop100 scripts]# basename /home/nailclipper/xuexi.txt .txtxuexi 8.1.2 dirname​ （1）基本语法 ​ dirname 文件绝对路径 （功能描述：从给定的包含绝对路径的文件名中去除文件名（非目录部分），然后返回剩下的路径（目录的部分）） ​ diename 可以理解为取文件路径的绝对路径名称 ​ （2）案例实操 ​ 获取 xuexi.txt 文件的路径 1234[root@hadoop100 scripts]# dirname /home/nailclipper/xuexi.txt/home/nailclipper[root@hadoop100 scripts]# dirname ../../home/nailclipper/xuexi.txt../../home/nailclipper 8.2 自定义函数​ （1）基本语法 123456[ function ]funname[()]&#123; Action; [return int;]&#125;#[]表示可选项 ​ （2）经验技巧 ​ 1）必须在调用函数地方之前声明函数，shell 脚本是逐行运行，不会像其他语言一样先编译 ​ 2）函数返回值只能通过 $? 系统变量获得，可以显示加：return 返回，如果不加，将以最后一条命令运行结果作为返回值，作为返回值 return 后跟数值 n （0-255） ​ （3）案例实操 ​ 计算两个输入参数的和 12345678910111213141516171819202122[root@hadoop100 scripts]# vim fun.sh#---------------------------&quot;fun.sh&quot; 8L, 62B 6,12-19 All#!/bin/bashfunction sum()&#123; s=0 s=$[ $1+$2 ] echo &quot;$s&quot;&#125;read -p &quot;Please input the number1:&quot; n1;read -p &quot;Please input the number2:&quot; n2;sum $n1 $n2;#----------------------------[root@hadoop100 scripts]# chmod 755 fun.sh [root@hadoop100 scripts]# ./fun.sh Please input the number1:345Please input the number2:6781023 9. 正则表达式入门​ 正则表达式是使用单个字符串来描述，匹配一系列符合某个语法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些符合某个模式的文本。在 Linux 中，grep，sed，awk 等文本处理工具都支持通过正则表达式进行模式匹配 9.1 常规匹配​ 一串不包含特殊字符的正则表达式匹配它自己，如 12[root@hadoop100 scripts]# cat /etc/passwd | grep nailclippernailclipper:x:1000:1000:nailclipper:/home/nailclipper:/bin/bash ​ 就会匹配所有包含 nailclipper 的行 9.2 常用特殊字符​ （1）特殊字符：^ ​ ^ 匹配一行的开头，例如 12[root@hadoop100 scripts]# cat /etc/passwd | grep ^nanailclipper:x:1000:1000:nailclipper:/home/nailclipper:/bin/bash ​ 会匹配出所有以 na 开头的行 ​ （2）特殊字符：$ ​ “$” 匹配一行的结束，例如 123[root@hadoop100 scripts]# cat /etc/passwd | grep bash$root:x:0:0:Super User:/root:/bin/bashnailclipper:x:1000:1000:nailclipper:/home/nailclipper:/bin/bash ​ 会匹配出所有以 bash 结尾的行 ^$ 会匹配所有的空行 ​ （3）特殊字符：. ​ “.” 匹配一个任意的字符，例如 1234[root@hadoop100 scripts]# cat /etc/passwd | grep r..troot:x:0:0:Super User:/root:/bin/bashoperator:x:11:0:operator:/root:/usr/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/usr/sbin/nologin ​ （4）特殊字符：* ​ “*” 不单独使用，它和上一个字符连用，表示匹配上一个字符 0 次或多次，例如 12345[root@hadoop100 scripts]# cat /etc/passwd | grep ro*troot:x:0:0:Super User:/root:/bin/bashoperator:x:11:0:operator:/root:/usr/sbin/nologinrtkit:x:172:172:RealtimeKit:/:/sbin/nologinabrt:x:173:173::/etc/abrt:/sbin/nologin ​ 会匹配 rt，rot，root，rooor 等所有行 .* 会匹配所有的行 ​ （5）字符区间（中括号）：[] ​ [ ] 表示匹配某个范围内的一个字符，例如 ​ [6,8]——匹配 6 或者 8 ​ [0-9]——匹配一个 0-9 的数字 ​ [0-9]*——匹配任意长度的数字字符串 ​ [a-z]——匹配一个 a-z 之间的字符 ​ [a-z]* ——匹配任意长度的字母字符串 ​ [a-c, e-f]-匹配一个 a-c 或者 e-f 之间的任意字符 123456[root@hadoop100 scripts]# cat /etc/passwd | grep r[a,b,c,o]*troot:x:0:0:Super User:/root:/bin/bashoperator:x:11:0:operator:/root:/usr/sbin/nologinrtkit:x:172:172:RealtimeKit:/:/sbin/nologinabrt:x:173:173::/etc/abrt:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/usr/share/empty.sshd:/usr/sbin/nologin ​ 会匹配 rt，rat，rbt，rabt，rabct，root，rabcbcoat 等等所有行 ​ （6）特殊字符：\\ ​ “\\“ 表示转义，并不会单独使用。由于所有特殊字符都有其特定匹配模式，当我们想匹配某一特殊字符本身时（例如，找出所有包含 $ 的行），就会碰到困难，此时我们就要将转义字符和特殊字符连用，来表示特殊字符本身，例如 1234[root@hadoop100 scripts]# cat /etc/passwd | grep &#x27;\\:&#x27;grep: warning: stray \\ before :root:x:0:0:Super User:/root:/bin/bashbin:x:1:1:bin:/bin:/usr/sbin/nologin 10. 文本处理工具10.1 cut​ cut 的工作就是”剪”，具体的说就是在文件中负责剪切数据用的。cut 命令从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段输出。 ​ （1）基本用法 ​ cut [选项参数] filename ​ 说明：默认分隔符是制表符 ​ （2）选项参数说明 ​ -f 列号，提取第几列 ​ -d 分隔符 ，按照指定分隔符分隔列，默认是制表符 “\\t” ​ -c 按字符进行切割，后面加 n 表示取第几列，比如 -c 1 ​ （3）案例实操 ​ 1）数据准备 12345678[root@hadoop100 scripts]# vim cut.txt#------------------------------dong shenguan zhenwo wolai laile le#------------------------------ ​ 2）切割 cut.txt 第一、二列 123456789101112131415161718[root@hadoop100 scripts]# cut -d &quot; &quot; -f 1 cut.txtdongguanwolaile[root@hadoop100 scripts]# cut -d &quot; &quot; -f 2 cut.txtshenzhenwolaile[root@hadoop100 scripts]# cut -d &quot; &quot; -f 1,2 cut.txtdong shenguan zhenwo wolai laile le ​ 3）在 cut.txt 文件中切割出 guan 12[root@hadoop100 scripts]# cat cut.txt | grep guan | cut -d &quot; &quot; -f 1guan ​ 4）选取系统 PATH 变量值第 2 个 “:” 开始后的所有路径 1234[root@hadoop100 scripts]# echo $PATH/root/.local/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin[root@hadoop100 scripts]# echo $PATH | cut -d &quot;:&quot; -f 3-/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin ​ 5）切割 nmcli 后打印的 IP 地址 123456789101112131415161718192021222324252627[root@hadoop100 scripts]# nmcliens160: connected to Wired connection 1 &quot;VMware VMXNET3&quot; ethernet (vmxnet3), 00:0C:29:F3:6E:24, hw, mtu 1500 ip4 default inet4 192.168.26.100/24 route4 192.168.26.0/24 metric 100 route4 default via 192.168.26.2 metric 100 inet6 fe80::30ab:e710:aa2c:3ab0/64 route6 fe80::/64 metric 1024lo: connected (externally) to lo &quot;lo&quot; loopback (unknown), 00:00:00:00:00:00, sw, mtu 65536 inet4 127.0.0.1/8 inet6 ::1/128DNS configuration: servers: 192.168.26.2 interface: ens160Use &quot;nmcli device show&quot; to get complete information about known d&gt;&quot;nmcli connection show&quot; to get an overview on active connection p&gt;Consult nmcli(1) and nmcli-examples(7) manual pages for complete &gt;[root@hadoop100 scripts]# nmcli | grep -m 1 inet4 | cut -d &quot;/&quot; -f1 | cut -d &quot; &quot; -f 2192.168.26.100 10.2 awk​ 一个强大的文本分析工具，把文件逐行的输入，以空格为默认分隔符将每行切片，切开的部分再进行分析处理 ​ （1）基本用法 ​ awk [选项参数] &#39;/pattern1/&#123;action&#125; /pattern2/&#123;action&#125;...&#39; filename ​ pattern：表示 awk 在数据中查找的内容，就是匹配模式 ​ action：在找到匹配内容时所执行的一系列命令 ​ （2）选项参数说明 ​ -F 指定输入文件分隔符 ​ -v 赋值一个用户定义变量 ​ （3）案例实操 ​ 1）数据准备 123[root@hadoop100 scripts]# cp /etc/passwd /root/scripts/#文件内容#用户名:密码(加密过后的):用户 id:组 id:注释:用户家目录:shell 解析器 ​ 2）搜索 passwd 文件以 root 关键字开头的所有行，并输出该行的第 7 列 12[root@hadoop100 scripts]# awk -F &quot;:&quot; &#x27;/^root/&#123;print $7&#125;&#x27; passwd/bin/bash ​ 3）搜索 passwd 文件以 root 关键字开头的所有行，并输出该行的第 1 列和第 7 列，中间以 “,” 号分隔 12[root@hadoop100 scripts]# awk -F &quot;:&quot; &#x27;/^root/&#123;print $1&quot;,&quot;$7&#125;&#x27; passwdroot,/bin/bash ​ 注意：只有匹配了 pattern 的行才会执行 action ​ 4）只显示 passwd 的第一列和第七列，以逗号 “,” 分隔，且在所有行前面添加列名 user,shell，在最后一行添加 “hanli, &#x2F;bin&#x2F;hanpaopao” 12345678[root@hadoop100 scripts]# awk -F &quot;:&quot; &#x27;BEGIN&#123;print &quot;user,shell&quot;&#125; &#123;print $1&quot;,&quot;$7&#125; END&#123;print &quot;hanli,/bin/hanpaopao&quot;&#125;&#x27; passwduser,shellroot,/bin/bashbin,/usr/sbin/nologindaemon,/usr/sbin/nologin...user,/bin/bashhanli,/bin/hanpaopao ​ 注意：BEGIN 在所有数据读取行之前执行；END 在所有数据执行之后执行 ​ 5）将 passwd 文件中的用户 id 增加数值 1 并输出 12345678910111213[root@hadoop100 scripts]# cut -d &quot;:&quot; -f 3 passwd01234...[root@hadoop100 scripts]# awk -v i=1 -F &quot;:&quot; &#x27;&#123;print $3+i&#125;&#x27; passwd12345 ​ （4）awk 的内置变量 ​ FILENAME 文件名 ​ NR 已读的记录数（行号） ​ NF 浏览记录的域的个数（切割后，列的个数） ​ （5）案例实操 ​ 1）统计 passwd 文件名，每行的行号，每行的列数 12345[root@hadoop100 scripts]# awk -F &quot;:&quot; &#x27;&#123;print &quot;filename:&quot;FILENAME &quot;,linenum:&quot;NR &quot;,col:&quot;NF&#125;&#x27; passwdfilename:passwd,linenum:1,col:7filename:passwd,linenum:2,col:7filename:passwd,linenum:3,col:7 ​ 2）查询 nmcli 命令输出结果中的空行所在的行号 123456789101112131415161718192021222324252627282930[root@hadoop100 scripts]# nmcliens160: connected to Wired connection 1 &quot;VMware VMXNET3&quot; ethernet (vmxnet3), 00:0C:29:F3:6E:24, hw, mtu 1500 ip4 default inet4 192.168.26.100/24 route4 192.168.26.0/24 metric 100 route4 default via 192.168.26.2 metric 100 inet6 fe80::30ab:e710:aa2c:3ab0/64 route6 fe80::/64 metric 1024lo: connected (externally) to lo &quot;lo&quot; loopback (unknown), 00:00:00:00:00:00, sw, mtu 65536 inet4 127.0.0.1/8 inet6 ::1/128DNS configuration: servers: 192.168.26.2 interface: ens160Use &quot;nmcli device show&quot; to get complete information about known d&gt;&quot;nmcli connection show&quot; to get an overview on active connection p&gt;Consult nmcli(1) and nmcli-examples(7) manual pages for complete &gt;[root@hadoop100 scripts]# nmcli | awk &#x27;/^$/&#123;print NR&#125;&#x27;10162023 ​ 3）切割 IP 12[root@hadoop100 scripts]# nmcli | grep -m 1 inet4 | awk &#x27;&#123;print $2&#125;&#x27; | awk -F &quot;/&quot; &#x27;&#123;print $1&#125;&#x27;192.168.26.100 11. 综合应用案例11.1 归档文件​ 实际生产应用中，往往需要对重要数据进行归档备份 ​ 需求：实现一个每天对指定目录归档备份的脚本，输入一个目录名称（末尾不带 &#x2F; ），将目录下所有文件按天归档保存，并将归档日期附加在归档文件名上，放在 /root/archive 下 ​ 这里用到了归档命令：tar ​ 后面可以加上 -c 选项表示归档，加上 -z 选项表示同时进行压缩，得到的文件后缀名为 tar.gz ​ 脚本实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@hadoop100 scripts]# mkdir /root/archive#--------------------------------------------#!/bin/bash#首先判断输入参数个数是否为1if [ $# -ne 1 ]then echo &quot;参数个数错误！应输入一个参数，作为归档目录名&quot; exitfi #从参数中获取目录名称if [ -d $1 ]then echo $1else echo echo &quot;目录不存在！&quot; echo exitfi DIR_NAME=$(basename $1)DIR_PATH=$(cd $(dirname $1);pwd)#获取当前日期DATE=$(date +%y%m%d)#定义生成的归档文件名称FILE=archive_$&#123;DIR_NAME&#125;_$DATE.tar.gzDEST=/root/archive/$FILE#开始归档目录文件echo &quot;开始归档...&quot;echotar -czf $DEST $DIR_PATH/$DIR_NAMEif [ $? -eq 0 ]then echo echo &quot;归档成功！&quot; echo &quot;归档文件为：$DEST&quot; echoelse echo &quot;归档出现问题！&quot; echofiexit#------------------------------------------- 11.2 发送消息​ 我们可以利用 Linux 自带的 mesg 和 write 工具，向其他用户发送消息 ​ 需求：实现一个向某个用户快速发送消息的脚本，输入用户名作为第一个参数，后面直接跟要发送的消息。脚本需要检测用户是否登陆在系统中、是否打开消息功能，以及当前发送消息是否为空 ​ 脚本实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980[root@hadoop100 scripts]# whoroot pts/0 2025-02-28 10:03 (192.168.26.1)root pts/1 2025-02-28 10:03 (192.168.26.1)[root@hadoop100 scripts]# who -Troot + pts/0 2025-02-28 10:03 (192.168.26.1)root + pts/1 2025-02-28 10:03 (192.168.26.1)#---------------------------------------------#!/bin/bashlogin_user=$(who | grep -i -m 1 $1 | awk &#x27;&#123;print $1&#125;&#x27;)if [ -z $login_user ]then echo &quot;$1 不在线&quot; echo &quot;脚本退出&quot; exitfiis_allowed=$(who -T | grep -i -m 1 $1 | awk -F &quot; &quot; &#x27;&#123;print $2&#125;&#x27;)if [ $is_allowed != &quot;+&quot; ]then echo &quot;$1没有开启消息功能&quot; echo &quot;脚本退出..&quot; exitfiif [ -z $2 ]then echo &quot;没有消息发出&quot; echo &quot;脚本退出&quot; exitfiwhole_msg=$(echo $* | cut -d &quot; &quot; -f 2-)user_terminal=$(who | grep -i -m 1 $1 | awk -F &quot; &quot; &#x27;&#123;print $2&#125;&#x27;)echo &quot;$whole_msg,$login_user,$user_terminal&quot;echo $whole_msg | write $login_user $user_terminalif [ $? -ne 0 ]then&quot;sendmessage.sh&quot; 40L, 669B 30,44 Top#!/bin/bash echo &quot;$1 不在线&quot; echo &quot;脚本退出&quot; exitfiis_allowed=$(who -T | grep -i -m 1 $1 | awk -F &quot; &quot; &#x27;&#123;print $2&#125;&#x27;)if [ $is_allowed != &quot;+&quot; ]then echo &quot;$1没有开启消息功能&quot; echo &quot;脚本退出..&quot; exitfiif [ -z $2 ]then echo &quot;没有消息发出&quot; echo &quot;脚本退出&quot; exitfiwhole_msg=$(echo $* | cut -d &quot; &quot; -f 2-)user_terminal=$(who | grep -i -m 1 $1 | awk -F &quot; &quot; &#x27;&#123;print $2&#125;&#x27;)echo &quot;$whole_msg,$login_user,$user_terminal&quot;echo $whole_msg | write $login_user $user_terminalif [ $? != 0 ]then echo &quot;发送失败&quot;else echo &quot;发送成功&quot;fiexit#-------------------------------------------- mesg y ：允许接收消息 mesg n ：拒绝接收消息","categories":[{"name":"Shell","slug":"Shell","permalink":"https://wxwdaydayup.top/categories/Shell/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"},{"name":"Fedora","slug":"Fedora","permalink":"https://wxwdaydayup.top/tags/Fedora/"}],"author":null},{"title":"Linux 系统操作基础（知其然）","slug":"Linux 系统操作基础（知其然）","date":"2025-02-10T02:00:00.000Z","updated":"2025-03-13T09:44:49.420Z","comments":true,"path":"Linux 系统操作基础（知其然）/","permalink":"https://wxwdaydayup.top/Linux%20%E7%B3%BB%E7%BB%9F%E6%93%8D%E4%BD%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E7%9F%A5%E5%85%B6%E7%84%B6%EF%BC%89/","excerpt":"Linux是一种自由和开放源码的类UNIX操作系统。该操作系统的内核由林纳斯·托瓦兹在1991年10月5日首次发布，再加上用户空间的应用程序之后，就成为了Linux操作系统。Linux严格来说是单指操作系统的内核，因操作系统中包含了许多用户图形接口和其他实用工具。如今Linux常用来指基于Linux的完整操作系统，内核则改以Linux内核称之。","text":"01 【介绍和安装】1.Linux基本介绍1.1 学习方向 linux运维工程师： 维护linux的服务器（一般大型企业） linux嵌入式工程师： linux做驱动开发，或者linux的嵌入式 linux下开发项目 1.2 应用领域 个人桌面 服务器应用 免费，稳定，高效 侵入式应用 机顶盒，手机，数字电视，智能家居等 1.3 学习进阶 学习基本指令 文件操作指令 编辑工具 用户管理 linux系统配置 环境变量，网络配置，服务配置 linux环境下搭建开发环境 大数据 JavaEE Python 等 编写shell脚本，对Linux服务器维护 安全设置，防止攻击，保证服务器正常运行，系统调优 深入理解Linux，对内核有研究，掌握大型网站架构、熟悉各环节部署方法 2.Linux起源2.1 Linux介绍 Linux 是一款免费，开源，安全，高效，稳定，处理高并发很强悍的操作系统 Linux创始人——linux（林纳斯） Linux主要发行版本 2.2 Unix与Linux的关系Unix来源 Linux来源 Linux与Unix关系 Linux与Windows关系 2.3 Fedora的安装2.3.1 安装VMware Workstation 2.3.2 编辑VMware Workstation 的虚拟网卡2.3.2.1 进行便捷的远程开发需要满足的两个条件 2.3.2.2 三种类型的网卡的含义 桥接模式：虚拟机电脑在网络环境中的地位和宿主环境（开发电脑）是一样的，虚拟机可以上网，但是ip地址会变来变去，因为虚拟机的ip地址是由DHCP动态分配的 NAT模式：开发电脑（宿主环境）会通过虚拟网卡构建一个局域网，虚拟机电脑作为局域网中一个成员，由于局域网受开发电脑的控制，因此虚拟机电脑的ip地址可以是固定的，局域网中的成员（虚拟机）可以通过开发电脑（宿主环境）间接的连到外面的互联网 仅主机模式：虚拟机相当于黑户，完全和外界隔绝，因此不能上网 这三种网卡的编辑暂时先不用管，在后面的网络配置小节中，我们会详细介绍。 2.3.3 安装fedora的linux操作系统2.3.3.1 创建一个虚拟机（虚拟电脑） ▶创建一个虚拟机 2.3.3.2 在虚拟机上安装Fedora的操作系统 ▶在虚拟机上安装Fedora 41操作系统 安装完成后重启电脑至此安装完成 3.Linux基本目录机构3.1 基本介绍 Linux的文件系统采用树状目录结构， 最上层是根目录“&#x2F;” Linux世界里，一切皆文件。 3.2 目录用途 /afs: AFS 挂载点，被用来访问存储在 AFS 文件系统中的共享数据或目录。AFS 是一个分布式文件系统，允许多个计算机共享文件和目录，并提供高效的文件存取机制，通常用于跨网络访问存储资源。 /boot：存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。 /etc：所有的系统管理所需要的配置文件。 /lib或/lib64：系统开机所需要最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。 /lost+found：这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。 /mnt：系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将外部的存储挂载在&#x2F;mnt&#x2F;上，然后进入该目录就可以查看里面的内容了。 /proc：这个目录是一个虚拟的目录，它是系统内存的映射，访问这个目录来获取系统信息。 /run： 目录是一个临时文件系统，用于存储系统启动时生成的运行时数据。 比较常见的用途是daemon进程将自己的pid保存到这个目录。该目录下的文件和目录是在每次系统启动时创建的，并且在系统关机时会被清理 /srv：service的缩写，该目录存放一些服务启动之后需要提供的数据。 /tmp：这个目录是用来存放一些临时文件的。 /var：这个目录中存放着在不断扩充着的东西，习惯将经常被修改的目录放在这个目录下，包括各种日志文件。 /bin： 是Binary的缩写，用于存放系统的基本用户命令（二进制可执行文件）的目录。它包含了一些最常用的命令，这些命令可以被所有用户直接执行，无需指定路径。 /dev：类似windows的设备管理器，把所有的硬件用文件的形式存储。 /home：存放普通用户的主目录，在Linux中每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。 /media：linux系统会自动识别一些设备，例如U盘光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。 /opt：这是给主机额外安装软件所摆放的目录，如安装ORACLE数据库就可放到该目录下。默认为空。 /root：该目录为系统管理员，也称作超级权限者的用户主目录。 /sbin：s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。 /sys：这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统sysfs。 /usr：这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似与windows下的program files目录。 3.3 总结 Linux的目录中有且只有一个根目录。 Linux的各个目录存放的内容已经规划好，不用乱放文件。 Linux是以文件的形式管理我们的设备，因此linux系统，一切皆为文件。 Linux的各个文件目录下存放什么内容，必须有一个认识。 02 【vim编辑器 网络配置 远程登录】1.vi和vim编辑器1.1 vi和vim的基本介绍 所有Linux系统都会内置vi文本编辑器 vim是vi的升级版，可以主动以字体颜色分辨语法的正确性，代码补完和编译，错误跳转等功能。 1.2 vi和vim的三种模式基本上 vi&#x2F;vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。 这三种模式的作用分别是： 1.2.1 正常模式 用户刚刚启动 vi&#x2F;vim，便进入了正常模式。 此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。 以下是常用的几个命令： i 切换到输入模式，以输入字符。 x 删除当前光标所在处的字符。 : 切换到底线命令模式，以在最底一行输入命令。 若想要编辑文本：启动Vim，进入了命令模式，按下i，切换到输入模式。 命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。 1.2.2 插入&#x2F;编辑模式 在命令模式下按下i就进入了输入模式。 在输入模式中，可以使用以下按键： 字符按键以及Shift组合，输入字符 ENTER，回车键，换行 BACK SPACE，退格键，删除光标前一个字符 DEL，删除键，删除光标后一个字符 方向键，在文本中移动光标 HOME&#x2F;END，移动光标到行首&#x2F;行尾 Page Up&#x2F;Page Down，上&#x2F;下翻页 Insert，切换光标为输入&#x2F;替换模式，光标将变成竖线&#x2F;下划线 ESC，退出输入模式，切换到命令模式 1.2.3 命令行模式 在命令模式下按下:（英文冒号）就进入了底线命令模式。 底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。 在底线命令模式中，基本的命令有（已经省略了冒号）： q 退出程序 w 保存文件 按ESC键可随时退出底线命令模式。 1.2.4 三种模式转换示意图 1.3 vi&#x2F;vim 使用实例使用 vi&#x2F;vim 进入一般模式 如果你想要使用 vi 来新建一个名为 runoob.txt 的文件时，你可以这样做： 1$ vim runoob.txt 直接输入 vim 文件名 就能够进入 vim 的一般模式了。请注意，记得 vim 后面一定要加文件名，不管该文件存在与否！ 按下 i 进入输入模式(也称为编辑模式)，开始编辑文字 在一般模式之中，只要按下 i, o, a 等字符就可以进入输入模式了！ 在编辑模式当中，你可以发现在左下角状态栏中会出现 –INSERT- 的字样，那就是可以输入任意字符的提示。 这个时候，键盘上除了 Esc 这个按键之外，其他的按键都可以视作为一般的输入按钮了，所以你可以进行任何的编辑。 按下 ESC 按钮回到一般模式 好了，假设我已经按照上面的样式给他编辑完毕了，那么应该要如何退出呢？是的！没错！就是给他按下 Esc 这个按钮即可！马上你就会发现画面左下角的 – INSERT – 不见了！ 在一般模式中按下 :wq 储存后离开 vim OK，我们要存档了，存盘并离开的指令很简单，输入 :wq 即可保存离开！ 1.4 Vim 按键说明除了上面简易范例的 i, Esc, :wq 之外，其实 vim 还有非常多的按键可以使用。 1.4.1 一般模式的光标移动、搜索替换、复制粘贴 移动光标的方法 h 或 向左箭头键(←) 光标向左移动一个字符 j 或 向下箭头键(↓) 光标向下移动一个字符 k 或 向上箭头键(↑) 光标向上移动一个字符 l 或 向右箭头键(→) 光标向右移动一个字符 [Ctrl] + [f] 屏幕『向下』移动一页，相当于 [Page Down]按键 (常用) [Ctrl] + [b] 屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用) [Ctrl] + [d] 屏幕『向下』移动半页 [Ctrl] + [u] 屏幕『向上』移动半页 + 光标移动到非空格符的下一行 - 光标移动到非空格符的上一行 n&lt;space&gt; 那个 n 表示『数字』，例如 20 。按下数字后再按空格键，光标会向右移动这一行的 n 个字符。例如 20&lt;space&gt; 则光标会向后面移动 20 个字符距离。 0 或 ^ 或功能键[Home] 这是数字『 0 』：移动到这一行的最前面字符处 (常用) $ 或功能键[End] 移动到这一行的最后面字符处 (常用) H 光标移动到这个屏幕的最上方那一行的第一个字符 M 光标移动到这个屏幕的中央那一行的第一个字符 L 光标移动到这个屏幕的最下方那一行的第一个字符 G 移动到这个档案的最后一行 (常用) nG n 为数字。移动到这个档案的第 n 行。例如 20G 则会移动到这个档案的第 20 行(可配合 :set nu) gg 移动到这个档案的第一行，相当于 1G ！ (常用) n&lt;Enter&gt; n 为数字。光标向下移动 n 行 (常用) 搜索 /word 向光标之下寻找一个名称为 word 的字符串。例如要在档案内搜寻 vbird 这个字符串，就输入 &#x2F;vbird 即可！ (常用) ?word 向光标之上寻找一个字符串名称为 word 的字符串。 /^abc 查找以 abc 为行首的行 /abc$ 查找以 abc 为行尾的行 n 这个 n 是英文按键。代表重复前一个搜寻的动作。举例来说， 如果刚刚我们执行 &#x2F;vbird 去向下搜寻 vbird 这个字符串，则按下 n 后，会向下继续搜寻下一个名称为 vbird 的字符串。如果是执行 ?vbird 的话，那么按下 n 则会向上继续搜寻名称为 vbird 的字符串！ (常用) N 这个 N 是英文按键。与 n 刚好相反，为『反向』进行前一个搜寻动作。 例如 &#x2F;vbird 后，按下 N 则表示『向上』搜寻 vbird 。 在查找过程中需要注意的是，要查找的字符串是严格区分大小写的，如查找 “shenchao” 和 “ShenChao” 会得到不同的结果。 如果想忽略大小写，则输入命令 “:set ic”；调整回来输入”:set noic”。 如果在字符串中出现特殊符号，则需要加上转义字符 “&quot;。常见的特殊符号有 \\、*、?、$ 等。如果出现这些字符，例如，要查找字符串 “10$”，则需要在命令模式中输入 “&#x2F;10 \\ $”。 替换文本 功能描述 r 替换光标所在位置的字符 R 从光标所在位置开始替换字符，其输入内容会覆盖掉后面等长的文本内容，按“Esc”可以结束 :s/a1/a2/g 将当前光标所在行中的所有 a1 用 a2 替换 :n1,n2 s/a1/a2/g 将文件中 n1 到 n2 行中所有 a1 都用 a2 替换 (常用) :g/a1/a2/g 将文件中所有的 a1 都用 a2 替换例如，要将某文件中所有的 “root” 替换为 “liudehua”，则有两种输入命令，分别为： 123:1,$ s/root/liudehua/g或:%s/root/liudehua/g 上述命令是在编辑模式下操作的，表示的是从第一行到最后一行，即全文查找 “root”，然后替换成 “liudehua”。 如果刚才的命令变成 :10,20 s/root/liudehua/g，则只替换从第 10 行到第 20 行的 “root”。 复制粘贴 功能描述 p 将剪贴板中的内容粘贴到光标后 (常用) P（大写） 将剪贴板中的内容粘贴到光标前 y 复制已选中的文本到剪贴板 yy 将光标所在行复制到剪贴板，此命令前可以加数字 n，可复制多行 (常用) yw 将光标位置的单词复制到剪贴板 删除文本 功能描述 x 删除光标所在位置的字符 (常用) dd 删除光标所在行 (常用) ndd 删除当前行（包括此行）后 n 行文本 dG 删除光标所在行一直到文件末尾的所有内容 D 删除光标位置到行尾的内容 :n1,n2 d 删除从 n1 行到 n2 行的文本内容 (常用) 注意，被删除的内容并没有真正删除，都放在了剪贴板中。将光标移动到指定位置处，按下 “p” 键，就可以将刚才删除的内容又粘贴到此处。 1.4.2 一般模式切换到编辑模式 进入输入或取代的编辑模式 i, I 进入输入模式(Insert mode)： i 为『从目前光标所在处输入』， I 为『在目前所在行的第一个非空格符处开始输入』。 (常用) a,A 进入输入模式(Insert mode)： a 为『从目前光标所在的下一个字符处开始输入』， A 为『从光标所在行的最后一个字符处开始输入』。 (常用) o, O 进入输入模式(Insert mode)： 这是英文字母 o 的大小写。o 为在目前光标所在的下一行处输入新的一行； O 为在目前光标所在的上一行处输入新的一行！ (常用) r, R 进入取代模式(Replace mode)： r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止； (常用) [Esc] 退出编辑模式，回到一般模式中 (常用) 1.4.3 一般模式切换到指令行模式 指令行的储存、离开等指令 :w 将编辑的数据写入硬盘档案中 (常用) :w! 若文件属性为『只读』时，强制写入该档案。不过，到底能不能写入， 还是跟你对该档案的权限有关！ :q 离开 vi (常用) :q! 若曾修改过档案，又不想储存，使用 ! 为强制离开不储存档案。 注意一下啊，那个惊叹号 (!) 在 vi 当中，常常具有『强制』的意思～ :wq 储存后离开，若为 :wq! 则为强制储存后离开 (常用) ZZ 这是大写的 Z 喔！如果修改过，保存当前文件，然后退出！效果等同于(保存并退出) ZQ 不保存，强制退出。效果等同于 :q!。 :w [filename] 将编辑的数据储存成另一个档案（类似另存新档） :r [filename] 在编辑的数据中，读入另一个档案的数据。亦即将 『filename』 这个档案内容加到游标所在行后面 :n1,n2 w [filename] 将 n1 到 n2 的内容储存成 filename 这个档案。 :! command 暂时离开 vi 到指令行模式下执行 command 的显示结果！例如 『:! ls &#x2F;home』即可在 vi 当中察看 &#x2F;home 底下以 ls 输出的档案信息！ vim 环境的变更 :set nu 显示行号，设定之后，会在每一行的前缀显示该行的行号 :set nonu 与 set nu 相反，为取消行号！ 1.5 总结Vim 的常见指令 必须掌握yy：复制光标当前一行5yy：拷贝当前5行p：箭头移动到目的行粘贴u：撤销上一步dd：删除当前行5dd：删除当前行向下的5行x：剪切一个字母，相当于delX：剪切一个字母，相当于退格键yw：复制一个词dw：删除一个词在文件中查找某个单词：命令行输入 &#x2F;（查找内容），按n查找下一个设置文件行号：set nu，取消文件行号：set nonu编辑文件，正常模式下使用快捷键到达文档最末行：G，最首行：gg编辑文件，光标移动到某行：shift+g显示行号：set nu输入行号这个数输入shift+gw：向后移动一个单词（光标停在单词首部）b：向前移动一个单词 ，2b 向前移动2个单词 ▶一些其他的常见指令 插入命令指令说明i在当前位置生前插入I在当前行首插入a在当前位置后插入A在当前行尾插入o在当前行之后插入一行O在当前行之前插入一行游标移动指令说明gg移动到文件头。 &#x3D; [[G（shift + g）移动到文件尾。 &#x3D; ]]行数 → G移动到第 n 行冒号+行号，回车比如跳到240行就是 :240回车h左移一个字符l右移一个字符，这个命令很少用，一般用w代替。k上移一个字符j下移一个字符w向后移动一个单词（光标停在单词首部）b向前移动一个单词 2b 向前移动2个单词e同w，只不过是光标停在单词尾部ge同b，光标停在单词尾部。^移动到本行第一个非空白字符上。0移动到本行第一个字符上HOME移动到本行第一个字符。同0健。$移动到行尾 ，3$ 移动到下面3行的行尾f（find）fx将找到光标后第一个为x的字符，3fd将找到第三个为d的字符。F同f，反向查找撤销和重做指令说明u撤销（Undo）U撤销对整行的操作Ctrl + r重做（Redo），即撤销的撤销。删除命令指令说明x删除当前字符3x删除当前光标开始向后三个字符X删除当前字符的前一个字符。X&#x3D;dhdl删除当前字符， dl&#x3D;xdh删除前一个字符dd删除当前行dj删除上一行dk删除下一行10d删除当前行开始的10行。D删除当前字符至行尾。D&#x3D;d$d$删除当前字符之后的所有字符（本行）kdgg删除当前行之前所有行（不包括当前行）jdG（jd shift + g）删除当前行之后所有行（不包括当前行）:1,10d删除1-10行:11,$d删除11行及以后所有的行:1,$d删除所有行J(shift + j)删除两行之间的空行，实际上是合并两行。拷贝，剪贴和粘贴指令说明yy拷贝当前行nyy拷贝当前后开始的n行，比如2yy拷贝当前行及其下一行。p在当前光标后粘贴,如果之前使用了yy命令来复制一行，那么就在当前行的下一行粘贴。shift+p在当前行前粘贴:1,10 co 20将1-10行复制一份插入到第20行之后。:1,$ co $将整个文件复制一份并添加到文件尾部。ddp交换当前行和其下一行xp交换当前字符和其后一个字符ndd剪切当前行之后的n行。利用p命令可以对剪切的内容进行粘贴:1,10d将1-10行剪切。利用p命令可将剪切后的内容进行粘贴。:1, 10 m 20将第1-10行移动到第20行之后。（11-20行的内容会向前递进）正常模式下按v（逐字）或V（逐行）进入可视模式，然后用jklh命令移动光标选择某些行或字符，再按y即可复制退出命令指令说明:wq保存并退出ZZ保存并退出:q!强制退出并忽略所有更改:e!放弃所有修改，并打开原来文件。:q未修改直接退出 2.网络配置2.1 三种网络模式详解vmware为我们提供了三种网络工作模式，它们分别是：Bridged（桥接模式）、NAT（网络地址转换模式）、Host-Only（仅主机模式）。 打开vmware虚拟机，我们可以在选项栏的“编辑”下的“虚拟网络编辑器”中看到VMnet0（桥接模式）、VMnet1（仅主机模式）、VMnet8（NAT模式），那么这些都是有什么作用呢？其实，我们现在看到的VMnet0表示的是用于桥接模式下的虚拟交换机；VMnet1表示的是用于仅主机模式下的虚拟交换机；VMnet8表示的是用于NAT模式下的虚拟交换机。 同时，在主机上对应的有VMware Network Adapter VMnet1和VMware Network Adapter VMnet8两块虚拟网卡，它们分别作用于仅主机模式与NAT模式下。在“网络连接”中我们可以看到这两块虚拟网卡，如果将这两块卸载了，可以在vmware的“编辑”下的“虚拟网络编辑器”中点击“还原默认设置”，可重新将虚拟网卡还原。 小伙伴看到这里，肯定有疑问，为什么在真机上没有VMware Network Adapter VMnet0虚拟网卡呢？那么接下来，我们就一起来看一下这是为什么。 初次使用fedora操作系统需要设置root密码：1234567891011121314151617nailclipper@fedora:~$ sudo su -We trust you have received the usual lecture from the local SystemAdministrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility.For security reasons, the password you type will not be visible.[sudo] password for nailclipper: root@fedora:~# passwd rootNew password: BAD PASSWORD: The password is shorter than 8 charactersRetype new password: passwd: password updated successfully 2.1.1 Bridged（桥接模式）什么是桥接模式？桥接模式就是将主机网卡与虚拟机虚拟的网卡利用虚拟网桥进行通信。在桥接的作用下，类似于把物理主机虚拟为一个交换机，所有桥接设置的虚拟机连接到这个交换机的一个接口上，物理主机也同样插在这个交换机当中，所以所有桥接下的网卡与网卡都是交换模式的，相互可以访问而不干扰。在桥接模式下，虚拟机ip地址需要与主机在同一个网段，如果需要联网，则网关DNS需要与主机网卡一致。其网络结构如下图所示： 点击“网络适配器”，选择“桥接模式”，然后“确定” 在进入系统之前，我们先确认一下主机的ip地址、网关、DNS等信息。 然后，设置虚拟机网卡，在终端输入命令： 123456789101112131415# 查看自己的虚拟网卡名称，本机为：Wired connection 1root@fedora:~# nmcli conNAME UUID TYPE DEVICE Wired connection 1 fc58b13b-0bd8-38b8-acd3-4f8ed3da7763 ethernet ens160 lo 3bbbdae0-9ce2-4da8-9b5c-7a413653c26a loopback lo #设置IP,在桥接模式下该IP需要和主机IP在同一网段内，如：192.168.212.xxxroot@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.addresses 192.168.212.100/24#设置网关,在桥接模式下网关需要和主机网关相同root@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.gateway 192.168.212.143#设置DNS,在桥接模式下DNS需要和主机DNS相同root@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.dns &quot;192.168.212.143&quot;#设置 method 为 manual 表示使用静态 IProot@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.method manual#重启虚拟网卡root@fedora:~# nmcli con down &quot;Wired connection 1&quot; &amp;&amp; nmcli con up &quot;Wired connection 1&quot; 使用ping命令ping外网ip，测试能否联网。 基本语法: ping [主机地址] 例如： ping www.baidu.com 能ping通外网ip，证明桥接模式设置成功。 在fedora 41版本中，使用远程登陆需要先做如下设置:切换到root用户下，启动sshd服务：设置开机自启：systemctl enable sshd即刻启动：systemctl start sshd查看sshd的启动状态：systemctl status sshd使用finalshell进行远程登陆时发现重复提示输入密码，说明sshd服务拒绝我们使用密码登陆，打开sshd配置文件进行查看：vim /etc/ssh/sshd_configprohibit-password 是一个 PermitRootLogin 配置选项的值，它表示禁止使用密码进行 root 用户的登录。也就是说，即使允许 root 用户登录，也不能使用密码认证方式，通常需要使用其他认证方式（如 SSH 密钥认证）,于是，我们在这里把prohibit-password改为yes即可，保存退出后，重启sshd服务:systemctl restart sshd即可正常远程登陆。 那主机与虚拟机之间的通信是否正常呢？我们就用远程工具来测试一下。 主机与虚拟机通信正常。 这就是桥接模式的设置步骤，相信大家应该学会了如何去设置桥接模式了。桥接模式配置简单，但如果你的网络环境是ip资源很缺少或对ip管理比较严格的话，那桥接模式就不太适用了。这时，我们就来认识vmware的另一种网络模式：NAT模式。 2.1.2 NAT（地址转换模式）如果你的网络ip资源紧缺，但是你又希望你的虚拟机能够联网，这时候NAT模式是最好的选择。NAT模式借助虚拟NAT设备和虚拟DHCP服务器，使得虚拟机可以联网。其网络结构如下图所示： 在NAT模式中，主机网卡直接与虚拟NAT设备相连，然后虚拟NAT设备与虚拟DHCP服务器一起连接在虚拟交换机VMnet8上，这样就实现了虚拟机联网。那么我们会觉得很奇怪，为什么需要虚拟网卡VMware Network Adapter VMnet8呢？原来我们的VMware Network Adapter VMnet8虚拟网卡主要是为了实现主机与虚拟机之间的通信。在之后的设置步骤中，我们可以加以验证。 首先，设置虚拟机中NAT模式的选项，打开vmware，点击“编辑”下的“虚拟网络编辑器”，设置NAT参数。 将虚拟机的网络连接模式修改成NAT模式。 点击“网络适配器”，选择“NAT模式” 然后，设置虚拟机网卡，在终端输入命令： 123456789101112131415# 查看自己的虚拟网卡名称，本机为：Wired connection 1root@fedora:~# nmcli conNAME UUID TYPE DEVICE Wired connection 1 fc58b13b-0bd8-38b8-acd3-4f8ed3da7763 ethernet ens160 lo 3bbbdae0-9ce2-4da8-9b5c-7a413653c26a loopback lo #设置IP, 如：192.168.26.xxxroot@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.addresses 192.168.26.100/24#设置网关root@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.gateway 192.168.212.2#设置DNSroot@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.dns &quot;192.168.212.2&quot;#设置 method 为 manual 表示使用静态 IProot@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.method manual#重启虚拟网卡root@fedora:~# nmcli con down &quot;Wired connection 1&quot; &amp;&amp; nmcli con up &quot;Wired connection 1&quot; 使用ping命令ping外网ip，测试能否联网。 之前，我们说过VMware Network Adapter VMnet8虚拟网卡的作用，那我们现在就来测试一下。 如此看来，虚拟机能联通外网，确实不是通过VMware Network Adapter VMnet8虚拟网卡，那么为什么要有这块虚拟网卡呢？ 之前我们就说VMware Network Adapter VMnet8的作用是主机与虚拟机之间的通信，接下来，我们就用远程连接工具来测试一下。 然后，将VMware Network Adapter VMnet8启用之后，发现远程工具可以连接上虚拟机了。 那么，这就是NAT模式，利用虚拟的NAT设备以及虚拟DHCP服务器来使虚拟机连接外网，而VMware Network Adapter VMnet8虚拟网卡是用来主机与虚拟机通信的。 2.1.3 Host-Only（仅主机模式）Host-Only模式其实就是NAT模式去除了虚拟NAT设备，然后使用VMware Network Adapter VMnet1虚拟网卡连接VMnet1虚拟交换机来与虚拟机通信的，Host-Only模式将虚拟机与外网隔开，使得虚拟机成为一个独立的系统，只与主机相互通讯。其网络结构如下图所示： 通过上图，我们可以发现，如果要使得虚拟机能联网，我们可以将主机网卡共享给VMware Network Adapter VMnet1网卡，从而达到虚拟机联网的目的。接下来，我们就来测试一下。 首先设置“虚拟网络编辑器”，可以设置DHCP的起始范围。 设置虚拟机为Host-Only模式。 先查看主机上虚拟网卡VMnet1的IP信息： 然后，设置虚拟机网卡，在终端输入命令： 123456789101112131415# 查看自己的虚拟网卡名称，本机为：Wired connection 1root@fedora:~# nmcli conNAME UUID TYPE DEVICE Wired connection 1 fc58b13b-0bd8-38b8-acd3-4f8ed3da7763 ethernet ens160 lo 3bbbdae0-9ce2-4da8-9b5c-7a413653c26a loopback lo #设置IP, 在仅主机模式下，虚拟机IP地址要和虚拟网卡VMnet1的IP在一个网段内，如：192.168.137.xxxroot@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.addresses 192.168.137.100/24#设置网关，在仅主机模式下，虚拟机的网关要和虚拟网卡VMnet1的IP保持一致root@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.gateway 192.168.137.1#设置DNS，在仅主机模式下，虚拟机的DNS要和虚拟网卡VMnet1的IP保持一致root@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.dns 192.168.137.1#设置 method 为 manual 表示使用静态 IProot@fedora:~# nmcli con mod &quot;Wired connection 1&quot; ipv4.method manual#重启虚拟网卡root@fedora:~# nmcli con down &quot;Wired connection 1&quot; &amp;&amp; nmcli con up &quot;Wired connection 1&quot; 利用远程工具测试能否与主机通信。 主机与虚拟机之间可以通信，现在设置虚拟机联通外网。 使用ping命令ping外网ip，测试能否联网。 以上通过设置静态IP进行联网测试，如果需要动态获取IP进行联网测试，可以在虚拟网络编辑器中进行设置： 测试结果证明可以使得虚拟机连接外网。 2.2 修改 IP 地址后可能会遇到的问题（1）物理机能 ping 通虚拟机，但是虚拟机 ping 不通物理机,一般都是因为物理机的 防火墙问题,把防火墙关闭就行 （2）虚拟机能 Ping 通物理机,但是虚拟机 Ping 不通外网,一般都是因为 DNS 的设置有问题 （3）虚拟机 Ping www.baidu.com 显示域名未知等信息,一般查看 GATEWAY 和 DNS 设置是否正确 （4）如果以上全部设置完还是不行，需要关闭 NetworkManager 服务 systemctl stop NetworkManager 关闭 systemctl disable NetworkManager 禁用 2.3 配置主机名修改主机名称 hostname （功能描述：查看当前服务器的主机名称） 如果感觉此主机名不合适，我们可以进行修改。通过编辑vim /etc/hostname 文件 修改完成后重启生效。 如果想立即生效可以通过hostnamectl set-hostname xxx【要修改的主机名】这个命令，然后重启终端就可以看到效果了 修改 hosts 映射文件 1）修改 linux 的主机映射文件（hosts 文件） 后续在 hadoop 阶段，虚拟机会比较多，配置时通常会采用主机名的方式配置， 比较简单方便。 不用刻意记 ip 地址。vim /etc/hosts 添加如下内容 12345192.168.26.100 hadoop100192.168.26.101 hadoop101192.168.26.102 hadoop102192.168.26.103 hadoop103192.168.26.104 hadoop104 重启设备，重启后，查看主机名，已经修改成功 2）修改 windows 的主机映射文件（hosts 文件） ​ 进入 C:\\Windows\\System32\\drivers\\etc 路径 ​ 打开 hosts 文件并添加如下内容 12345192.168.26.100 hadoop100192.168.26.101 hadoop101192.168.26.102 hadoop102192.168.26.103 hadoop103192.168.26.104 hadoop104 先将该文件只读关闭，然后写入内容保存，最后恢复到只读状态 这时可以在windows通过ping hadoop100来测试是否连通虚拟机 3.远程登录通常在工作过程中，公司中使用的真实服务器或者是云服务器，都不允许除运维人员之 外的员工直接接触，因此就需要通过远程登录的方式来操作。所以，远程登录工具就是必不可少的，目前，比较主流的有 Xshell，SSH Secure Shell，SecureCRT，FinalShell 等，可以根据自己的习惯自行选择，以下以 FinalShell 为例。 03 【系统管理】1.Linux 中的进程和服务计算机中，一个正在执行的程序或命令，被叫做“进程”（process）。 启动之后一只存在、常驻内存的进程，一般被称作“服务”（service）。 2.systemctl 服务管理Fedora 41 使用 Systemd 管理守护进程，这些服务独立的运行在内存中，响应速度快，但占用更多内存，它们的启动脚本存放在目录 /usr/lib/systemd/system 中。 Systemd 的新特性： 系统引导时实现服务的并行启动； 按需激活进程； 系统实现快照； 基于依赖关系定义服务的控制逻辑； 2.1 systemctl参数说明 基本语法：systemctl start | stop | restart | status | reload 服务名 systemctl 指令管理的服务在 &#x2F;usr/lib/systemd/system 中 查看服务的方法：ls /usr/lib/systemd/system 1、使用语法 用法：systemctl [OPTIONS…] {COMMAND} … 2 、参数说明 参数 参数说明 start 立刻启动后面接的unit stop 立刻关闭后面接的unit restart 立刻关闭后启动后面接的unit，亦即执行stop再start的意思 reload 不关闭后面接的unit的情况下，重载配置文件，让设定生效 enable 设定下次开机时，后面接的unit会被启动 disable 设定下次开机时，后面接的unit 不会被启动 status 目前后面接的这个unit 的状态，会列出是否正在执行、是否开机启动等信息。 is-active 目前有没有正在运行中 is-enable 开机时有没有预设要启用这个unit kill 不要被kill这个名字吓着了,它其实是向运行unit的进程发送信号 show 列出unit的配置。 mask 注销unit,注销后你就无法启动这个unit了 unmask 取消对unit的注销 list-units 依据unit列出目前有启动的unit。若加上–all才会列出没启动的。（等价于无参数） list-unit-files 列出所有已安装unit以及他们的开机启动状态（enabled、disabled、static、mask）。 –type&#x3D;TYPE 就是unit type，主要有service，socket，target等 get-default 取得目前的 target set-default 设定后面接的 target 成为默认的操作模式 isolate 切换到后面接的模式 3、unit file结构 文件通常由三部分组成： Unit: 定义与Unit类型无关的通用选项；用于提供unit的描述信息，unit行为及依赖关系等。 Service：与特定类型相关的专用选项；此处为Service类型。 Install：定义由”systemctl enable”及”systemctl disable”命令在实现服务启用或禁用时用到的一些选项。 4、Unit段的常用选项 Description：描述信息，意义性描述； After：定义unit的启动次序；表示当前unit应晚于哪些unit启动；其功能与Before相反； Requies：依赖到其它的units；强依赖，被依赖的units无法激活时，当前的unit即无法激活； Wants：依赖到其它的units；弱依赖； Confilcts：定义units 的冲突关系； 5、Service段的常用选项 Type：用于定义影响ExecStart及相关参数的功能的unit进程类型；类型有：simple、forking、oneshot、dbus、notify、idle。 EnvironmentFile：环境配置文件； ExecStart：指明启动unit要运行的命令或脚本；ExecStart, ExecStartPost ExecStop：指明停止unit要运行的命令或脚本； Restart: 6、Install段的常用配置： Alias： RequiredBy：被哪些unit所依赖； WantBy：被哪些unit所依赖； 7、Unit文件样例 [root@s153 system]# cat chronyd.service[Unit]Description&#x3D;NTP client&#x2F;serverDocumentation&#x3D;man:chronyd(8) man:chrony.conf(5)After&#x3D;ntpdate.service sntp.service ntpd.serviceConflicts&#x3D;ntpd.service systemd-timesyncd.serviceConditionCapability&#x3D;CAP_SYS_TIME [Service]Type&#x3D;forkingPIDFile&#x3D;&#x2F;var&#x2F;run&#x2F;chronyd.pidEnvironmentFile&#x3D;-&#x2F;etc&#x2F;sysconfig&#x2F;chronydExecStart&#x3D;&#x2F;usr&#x2F;sbin&#x2F;chronyd $OPTIONSExecStartPost&#x3D;&#x2F;usr&#x2F;libexec&#x2F;chrony-helper update-daemonPrivateTmp&#x3D;yesProtectHome&#x3D;yesProtectSystem&#x3D;full [Install]WantedBy&#x3D;multi-user.target 2.2 systemctl使用示例1.查看开机启动列表: systemctl list-unit-files [ | grep 服务名] 123[root@hadoop100 ~]# systemctl list-unit-files[root@hadoop100 ~]# systemctl list-unit-files | grep firewalldfirewalld.service disabled 2.查看开机自启的服务列表: systemctl list-unit-files|grep enabled3.显示当前正在启动的服务: systemctl list-units --type=service 可以写一半再查看完整的服务名，一般也可以简写：firewalld.service = firewall 说明防火墙是一个自启的状态，Linux系统启动的时候防火墙也会自启。 2.设置开机启动 systemctl在enable、disable、mask子命令里面增加了–-now选项，可以激活同时启动服务，激活同时停止服务等。 1[root@hadoop100 ~]# systemctl enable --now firewalld 设置开机启动并现在启动, 相当于同时执行了systemctl start firewalld 和systemctl enable firewalld 查看服务启动状态 1[root@hadoop100 ~]# systemctl status firewalld 取消开机启动 取消开机启动并现在立即停止服务 1[root@hadoop100 ~]# systemctl disable --now firewalld 查看服务状态是否停止 1[root@hadoop100 ~]# systemctl status firewalld 使用 systemctl disable firewalld时，下次重启系统时防火墙还是处于关闭的状态 查看服务是否开机自启 1[root@hadoop100 ~]# systemctl is-enabled firewalld systemctl enable 服务名 (设置服务开机启动)，对 3 （无界面）和 5 （GUI）运行级别都生效 systemctl disable 服务名 (关闭服务开机启动)，对 3 （无界面）和 5 （GUI）运行级别都生效 4.开启服务 1[root@hadoop100 ~]# systemctl start firewall 5.关闭服务(但是下次开机还是会启动) 1[root@hadoop100 ~]# systemctl stop firewall 6.重启服务 1[root@hadoop100 ~]# systemctl restart firewall 7.重新加载配置 1[root@hadoop100 ~]# systemctl reload firewall 8.输出服务运行的状态 1[root@hadoop100 ~]# systemctl status firewalld 9.检查service是否在启动状态 systemctl is-active 服务名 写脚本时判断服务是否正在启动很好用 1[root@hadoop100 ~]# systemctl is-active NetworkManager 10.检测unit单元是否为自动启动 systemctl is-enabled 服务名 写脚本时判断服务是否开机自启很管用 1[root@hadoop100 ~]# systemctl is-enabled firewalld 11.注销一个服务(service) systemctl mask 服务名 注销服务意味着： 该服务在系统重启的时候不会启动 该服务无法进行做systemctl start&#x2F;stop操作 该服务无法进行systemctl enable&#x2F;disable操作 1[root@hadoop100 ~]# systemctl mask firewalld 12.取消注销服务(service) 1[root@hadoop100 ~]# systemctl unmask firewalld 13.显示单元的手册页（前提是由unit提供） 1[root@hadoop100 ~]# systemctl help firewalld 14.当新增或修改service单元文件时，需要系统重新加载所有修改过的配置文件 1[root@hadoop100 ~]# systemctl daemon-reload 15.查看systemd资源使用率 1[root@hadoop100 ~]# systemd-cgtop 16.杀死服务 systemctl kill 服务名 123[root@hadoop100 ~]# systemctl kill xinetd[root@hadoop100 ~]# systemctl is-failed xinetdinactive 3.系统运行级别1）Linux 运行级别 Fedora 41的启动流程图 Fedora 41中我们的初始化进程变为了systemd。执行默认target配置文件&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;default.target（这是一个软链接，与默认运行级别有关）。然后执行sysinit.target来初始化系统和basic.target来准备操作系统。接着启动multi-user.target下的本机与服务器服务，并检查&#x2F;etc&#x2F;rc.d&#x2F;rc.local文件是否有用户自定义脚本需要启动。最后执行multi-user下的getty.target及登录服务，检查default.target是否有其他的服务需要启动。 注意：&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;default.target指向了&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;目录下的graphical.target或multiuser.target。而graphical.target依赖multiuser.target，multiuser.target依赖basic.target，basic.target依赖sysinit.target，所以倒过来执行。 2）Fedora 41 的运行级别简化为: multi-user.target 等价于原运行级别 3（多用户有网，无图形界面） graphical.target 等价于原运行级别 5（多用户有网，有图形界面） 3） 查看当前运行级别: 12[root@hadoop100 ~]# systemctl get-defaultmulti-user.target 4）修改当前运行级别 1[root@hadoop100 ~]# systemctl set-default graphical.target Fedora 41 中取消了通过修改配置文件设置系统默认运行级别 1234567891011121314151617[root@hadoop100 ~]# cat /etc/inittab# inittab is no longer used.## ADDING CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM.## Ctrl-Alt-Delete is handled by /usr/lib/systemd/system/ctrl-alt-del.target## systemd uses &#x27;targets&#x27; instead of runlevels. By default, there are two main targets:## multi-user.target: analogous to runlevel 3 #相当于运行级别3# graphical.target: analogous to runlevel 5 #相当于运行级别5## To view current default target, run:# systemctl get-default #当前默认运行级别## To set a default target, run:# systemctl set-default TARGET.target #设置默认运行级别 4.关机重启命令4.1 关机重启命令汇总 halt 停机 root用户 halt：只关闭系统，电源还在运行halt -p：关闭系统，关闭电源（先执行halt，再执行poweroff） poweroff 关机 root用户 poweroff会发送一个关闭电源的信号给acpi reboot 重启 root用户 shutdown -h：关机-r：重启-c：取消shutdown操作 root用户 shutdown实际上是调用init 0, init 0会cleanup一些工作然后调用halt或者poweroffshutdown -r now：一分钟后重启shutdown -r 05:30：最近的5:30重启shutdown -r +10：十分钟后重启 init init 0：关机init 6：重启 root用户 init：切换系统的运行级别 systemctl systemctl halt [-i]：关机 systemctl poweroff [-i]：关机 systemctl reboot [-i]：重启 普通用户 超级用户 普通用户需要加-i， root用户不需要加-i （1）sync （功能描述：将数据由内存同步到硬盘中） （2）halt （功能描述：停机，关闭系统，但不断电） （3）poweroff （功能描述：关机，断电） （ (4）reboot （功能描述：就是重启，等同于 shutdown -r now） 在关机或者重启之前，执行3至4次sync，将在内存中还未保存到硬盘的数据更新到硬盘中，否则会造成数据的丢失。执行sync时要以管理员的身份运行，因为管理员具有所有文件的权限，而普通用户只具有自己的部分文件的权限。 最经常使用的关机重启的命令是shutdown，因此下面详细学习的使用。 4.2 shutdown命令基本格式：shutdown [选项] [时间] [警告信息] 选项： -h：关机 -r：重启 -c：取消shutdown执行的关机或者重启命令 -k：不关机，发出警告 时间： shutdown：一分钟后关机（默认） shutdown now：立刻关机 shutdown 10：10分钟后关机 shutdown 05:00：5点关机 示例： shutdown -r now：系统立马重启（等同于 rebootshutdown -r 05:30：最近的5:30重启shutdown -r 10：十分钟后重启 shutdown -h now：立马关机（等同于 poweroffshutdown -h 05:30：最近的5:30关机shutdown -h +10：十分钟后关机 shutdown -c：取消上面的关机重启操作 shutdown -k +10 “I will shutdown in 10 minutes”：10分钟后并不会真的关机，但是会把警告信息发给所有的用户。 4.3 sync命令sync ：linux同步数据命令，将数据由内存同步到硬盘中，包含已修改的 i-node、已延迟的块 I&#x2F;O 和读写映射文件。如果不去手动的输入sync命令来真正的去写磁盘，linux系统也会周期性的去sync数据。 1[root@hadoop100 ~]# sync 使用场景：1.在 关机或者开机之前最好多执行这个几次，以确保数据写入硬盘。2.挂载时，需要很长时间的操作动作（比如，cp 大文件，检测文件），在这个动作之后接sync。3.卸载U盘或其他存储设备，需要很长时间，使用sync。 经验技巧 ​ Linux 系统中为了提高磁盘的读写效率，对磁盘采取了 “预读迟写”操作方式。当用户保存文件时，Linux 核心并不一定立即将保存数据写入物理磁盘中，而是将数据保存在缓冲区中，等缓冲区满时再写入磁盘，这种方式可以极大的提高磁盘写入数据的效率。但是， 也带来了安全隐患，如果数据还未写入磁盘时，系统掉电或者其他严重问题出现，则将导致数据丢失。使用 sync 指令可以立即将缓冲区的数据写入磁盘。 04 【帮助命令 文件目录管理基础】1.帮助命令通常linux命令都十分简单，但是有些还是有些复杂度的。比如find，ps这种命令，如果要照顾到所有的场合，可能需要非常巨大的篇幅。但是，万一用到这种偏门的场合怎么办？ 全面了解一下是非常有必要的，以便在使用的时候能够唤起记忆中最浅显的印象。然后剩下的，就可以交给类似于man 的这种命令了。Linux上的每一个命令，都会有配套的帮助文件，这远比网络上那些转来转去的信息，正确的多。 正式介绍一下下面的两个命令： man 用来显示某个命令的文档信息。比如：man ls info 你可以认为和man是一样的，虽然有一些能够互补的内容。它们会在内容中进行提示的 --help 很多命令通过参数--help提供非常简短的帮助信息。这通常是最有用最快捷的用例展示。如果你根本就记不住一个非常拗口的单词，那就找找这些地方吧 注意：这些帮助信息，仅集中在命令的作用域本身。对于它的组合使用场景，并没有过多信息。也就是说，它教会了你怎么用，但并没有告诉你用它能够来做什么。 TAB补全现在，在终端里，输入ca，然后快速按2次&lt;TAB&gt;键盘，命令行会进入补全模式，显示以ca打头的所有命令。 1234[root@hadoop100 ~]# cacacertdir_rehash cache_dump cache_repair cache_writeback ca-legacy capsh case catchsegvcache_check cache_metadata_size cache_restore cal caller captoinfo cat catman 如果你对某个命令，只有模糊的印象，只记得前面的几个字母，这个功能是极好的，命令范围会一步步缩减。 2.文件和目录管理基础知识2.1 文件系统的层次结构平时打交道的都是文件，那么，应该如何找到它们呢？很简单，在 Linux 操作系统中，所有的文件和目录都被组织成以一个根节点“&#x2F;”开始的倒置的树状结构。 其中，目录就相当于 Windows 中的文件夹，目录中存放的既可以是文件，也可以是其他的子目录，而文件中存储的是真正的信息。 文件系统的最顶层是由根目录开始的，系统使用“&#x2F;”来表示根目录，在根目录之下的既可以是目录，也可以是文件，而每一个目录中又可以包含（子）目录或文件。如此反复就可以构成一个庞大的文件系统。 其实，使用这种树状、具有层次的文件结构主要目的是方便文件系统的管理和维护，想象一下，如果所有的文件都放在一个目录下，其文件系统的管理和维护将变成一场噩梦。 现实中也有许多类似的例子，例如在整个行政管理体制中，村民就相当于文件，他们住在一个村庄中，村庄就是存储村民的目录。许多村又组成了个乡，这个乡就相当于存储村的目录，依此类推，最终就构建出了一个庞大的行政区域管理结构图。 注意，目录名或文件名都是区分大小写的，如 dog、DOG 和 Dog 为 3 个不同的目录或文件。完整的目录或文件路径是由一连串的目录名所组成的，其中每一个目录由“&#x2F;”来分隔。如 cat 的完整路径是 &#x2F;home&#x2F;cat。 在文件系统中，有两个特殊的目录，一个是用户所在的工作目录，即当前目录，可用一个点“.”表示；另一个是当前目录的上一层目录，也叫父目录，用两个点“..”表示。 如果一个目录或文件名是以一个点开始，就表示这个目录或文件是一个隐藏目录或文件。即以默认方式査找（后续会讲查找命令）时，不显示该目录或文件。 为了方便管理和维护，Linux 系统采用了文件系统层次标准，也称为 FHS 标准，它规定了根目录下各个目录应该存在哪些类型的文件（或子目录），比如说，在 &#x2F;bin 和 &#x2F;sbin 目录中存放的应该是可执行文件，有关各个目录存放文件的类型。 2.2 绝对路径和相对路径详解在 Linux 中，简单的理解一个文件的路径，指的就是该文件存放的位置，例如， &#96;&#x2F;home&#x2F;cat 就表示的是 cat 文件所存放的位置。只要我们告诉 Linux 系统某个文件存放的准确位置，那么它就可以找到这个文件。 指明一个文件存放的位置，有 2 种方法，分别是使用绝对路径和相对路径。 我们知道，Linux 系统中所有的文件（目录）都被组织成以根目录“&#x2F;”开始的倒置的树状结构。 绝对路径一定是由根目录 &#x2F; 开始写起。例如，使用绝对路径的表示方式指明 bin 文件所在的位置，该路径应写为 &#x2F;usr&#x2F;bin，测试代码如下： 1234[root@hadoop100 ~]# binbash: bin: command not found... &lt;-- 没有找到[root@hadoop100 ~]# /usr/bin-bash: /usr/bin: Is a directory &lt;-- 是一个文件 可以看到，如果仅传递给 Linux 系统一个文件名，它无法找到指定文件；而当将 bin 文件的绝对路径传递 Linux 系统时，它就可以成功找到。 和绝对路径不同，相对路径不是从根目录 &#x2F; 开始写起，而是从当前所在的工作目录开始写起。使用相对路径表明某文件的存储位置时，经常会用到前面讲到的 2 个特殊目录，即当前目录（用 . 表示）和父目录（用 .. 表示）。 举个例子，当我们使用 root 身份登录 Linux 系统时，当前工作目录默认为 &#x2F;root，如果此时需要将当前工作目录调整到 root 用户的子目录 Desktop 中，当然可以使用绝对路径，示例代码如下： 12345[root@hadoop100 ~]# pwd &lt;-- 显示当前所在的工作路径/root[root@hadoop100 ~]# cd /root/Desktop[root@hadoop100 Desktop]# pwd/root/Desktop 注意，这里所使用的 pwd 和 cd 命令，目前只需知道它们的功能即可，具体用法会在后续文章中作详细讲解。 可以看到，通过使用绝对路径，我们成功地改变了当前工作路径。但除此之外，使用相对路径的方式会更简单。因为目前处于 &#x2F;root 的位置，而 Desktop 就位于当前目录下，所以： 12345[root@hadoop100 ~]# pwd &lt;-- 显示当前所在的工作路径/root[root@hadoop100 ~]# cd ./Desktop/[root@hadoop100 Desktop]# pwd/root/Desktop 此代码中，.&#x2F;Desktop 表示的就是 Destop 文件相对于 &#x2F;root 所在的路径。 再举一个例子，如果以 root 身份登录 Linux 系统，并实现将当前工作目录由 &#x2F;root 转换为 &#x2F;usr 目录，有以下 2 种方式： 123456789101112#使用绝对路径[root@hadoop100 ~]# pwd &lt;-- 显示当前所在的工作路径/root[root@hadoop100 ~]# cd /usr[root@hadoop100 ~]# pwd/usr#使用相对路径[root@hadoop100 ~]# pwd &lt;-- 显示当前所在的工作路径/root[root@hadoop100 ~]# cd ../usr &lt;-- 相对 root，usr 位于其父目录 /，因此这里要用到 ..[root@hadoop100 ~]# pwd/usr 总之，绝对路径是相对于根路径 &#x2F; 的，只要文件不移动位置，那么它的绝对路径是恒定不变的；而相对路径是相对于当前所在目录而言的，随着程序的执行，当前所在目录可能会改变，因此文件的相对路径不是固定不变的。 2.3 文件（目录）命名规则介绍完 Linux 系统中目录结构之后，读者一定想知道如何为文件或目录命名。 我们知道，在 Linux 系统中，一切都是文件，既然是文件，就必须要有文件名。同其他系统相比，Linux 操作系统对文件或目录命名的要求相对比较宽松。 Linux 系统中，文件和目录的命名规则如下： 除了字符“&#x2F;”之外，所有的字符都可以使用，但是要注意，在目录名或文件名中，使用某些特殊字符并不是明智之举。例如，在命名时应避免使用 &lt;、&gt;、？、* 和非打印字符等。如果一个文件名中包含了特殊字符，例如空格，那么在访问这个文件时就需要使用引号将文件名括起来。 目录名或文件名的长度不能超过 255 个字符。 目录名或文件名是区分大小写的。如 DOG、dog、Dog 和 DOg ，是互不相同的目录名或文件名，但使用字符大小写来区分不同的文件或目录，也是不明智的。 与 Windows 操作系统不同，文件的扩展名对 Linux 操作系统没有特殊的含义，换句话说，Linux 系统并不以文件的扩展名开分区文件类型。例如，dog.exe 只是一个文件，其扩展名 .exe 并不代表此文件就一定是可执行文件。需要注意的是，在 Linux 系统中，硬件设备也是文件，也有各自的文件名称。Linux 系统内核中的 udev 设备管理器会自动对硬件设备的名称进行规范，目的是让用户通过设备文件的名称，就可以大致猜测出设备的属性以及相关信息。 udev 设备管理器会一直以进程的形式运行，并侦听系统内核发出的信号来管理位于 &#x2F;dev 目录下的设备文件。 表 1 罗列出了Linux 系统中常见硬件设备的文件名。 硬件设备 文件名称 IDE设备 &#x2F;dev&#x2F;hd[a-d]，现在的 IDE设备已经很少见了，因此一般的硬盘设备会以 &#x2F;dev&#x2F;sd 开头。 SCSI&#x2F;SATA&#x2F;U盘 &#x2F;dev&#x2F;sd[a-p]，一台主机可以有多块硬盘，因此系统采用 a~p 代表 16 块不同的硬盘。 软驱 &#x2F;dev&#x2F;fd[0-1] 打印机 &#x2F;dev&#x2F;lp[0-15] 光驱 &#x2F;dev&#x2F;cdrom 鼠标 &#x2F;dev&#x2F;mouse 磁带机 &#x2F;dev&#x2F;st0 或 &#x2F;dev&#x2F;ht0 2.4 命令基本格式本节开始，我们不会再见到图形界面了，因为对服务器来讲，图形界面会占用更多的系统资源，而且会安装更多的服务、开放更多的端口，这对服务器的稳定性和安全性都有负面影响。其实，服务器是一个连显示器都没有的家伙，要图形界面干十么？ 说到这里，有很多人会很崩溃。笔者就经常听到抱怨 Linux 是落后于时代的老古董，就像笔者的白头发一样！但是，大家要理解，对服务器来讲，稳定性、可靠性、安全性才是最主要的。而简单易用不是服务器需要考虑的事情，所以学习 Linux，这些枯燥的命令是必须学习和记忆的内容。 2.5 命令提示符登录系统后，第一眼看到的内容是： [root@hadoop100 ~]# 这就是 Linux 系统的命令提示符。那么，这个提示符的含义是什么呢？ []：这是提示符的分隔符号，没有特殊含义。 root：显示的是当前的登录用户，笔者现在使用的是 root 用户登录。 @：分隔符号，没有特殊含义。 hadoop100：当前系统的主机名。 ~：代表用户当前所在的目录，此例中用户当前所在的目录是家目录。 #：命令提示符，Linux 用这个符号标识登录的用户权限等级。如果是超级用户，提示符就是 #；如果是普通用户，提示符就是 $。 家目录（又称主目录）是什么？ Linux 系统是纯字符界面，用户登录后，要有一个初始登录的位置，这个初始登录位置就称为用户的家： 超级用户的家目录：&#x2F;root。 普通用户的家目录：&#x2F;home&#x2F;用户名。 用户在自己的家目录中拥有完整权限，所以我们也建议操作实验可以放在家目录中进行。我们切换一下用户所在目录，看看有什么效果。 12[root@hadoop100 ~]# cd /usr/local[root@hadoop100 local]# 仔细看，如果切换用户所在目录，那么命令提示符中的会变成用户当前所在目录的最后一个目录（不显示完整的所在目录 &#x2F;usr&#x2F; local，只显示最后一个目录 local)。 2.6 命令的基本格式接下来看看 Linux 命令的基本格式: [root@hadoop100 ~]# 命令[选项][参数] 命令格式中的 [] 代表可选项，也就是有些命令可以不写选项或参数，也能执行。那么，我们就用 Linux 中最常见的 ls 命令来解释一下命令的格式（有关 ls 命令的具体用法，后续章节会详细介绍）。如果按照命令的分类，那么 ls 命令应该属于目录操作命令。 12[root@hadoop100 ~]# lsanaconda-ks.cfg Desktop Documents Downloads Music Pictures Public Templates Videos 2.6.1 选项的作用ls 命令之后不加选项和参数也能执行，不过只能执行最基本的功能，即显示当前目录下的文件名。那么加入一个选项，会出现什么结果？ 1234567891011[root@hadoop100 ~]# ls -ltotal 4-rw-------. 1 root root 450 Feb 20 07:09 anaconda-ks.cfgdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Desktopdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Documentsdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Downloadsdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Musicdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Picturesdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Publicdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Templatesdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Videos 如果加一个”-l”选项，则可以看到显示的内容明显增多了。”-l”是长列表（long list）的意思，也就是显示文件的详细信息。至于 “-l” 选项的具体含义，我们稍后再详细讲解。可以看到选项的作用是调整命令功能。如果没有选项，那么命令只能执行最基本的功能；而一旦有选项，则可以显示更加丰富的数据。 Linux 的选项又分为短格式选项（-l）和长格式选项（–all）。短格式选项是英文的简写，用一个减号调用，例如： 1[root@hadoop100 ~]# ls -l 而长格式选项是英文完整单词，一般用两个减号调用，例如： 1[root@hadoop100 ~]# ls --all 一般情况下，短格式选项是长格式选项的缩写，也就是一个短格式选项会有对应的长格式选项。当然也有例外，比如 ls 命令的短格式选项 -l 就没有对应的长格式选项。所以具体的命令选项可以通过后面我们要学习的帮助命令来进行査询。 2.6.2 参数的作用参数是命令的操作对象，一般文件、目录、用户和进程等可以作为参数被命令操作。例如： 12[root@hadoop100 ~]# ls -l anaconda-ks.cfg -rw-------. 1 root root 450 Feb 20 07:09 anaconda-ks.cfg 但是为什么一开始 ls 命令可以省略参数？那是因为有默认参数。命令一般都需要加入参数，用于指定命令操作的对象是谁。如果可以省略参数，则一般都有默认参数。例如： 12[root@hadoop100 ~]# lsanaconda-ks.cfg Desktop Documents Downloads Music Pictures Public Templates Videos 这个 ls 命令后面没有指定参数，默认参数是当前所在位置，所以会显示当前目录下的文件名。 总结一下：命令的选项用于调整命令功能，而命令的参数是这个命令的操作对象。 05【文件目录类命令】1.pwd 显示当前工作目录的绝对路径 pwd:print working directory 打印工作目录 到现在为止，我们还不知道自己在系统的什么地方。在浏览器上，我们能够通过导航栏上的url，了解到自己在互联网上的具体坐标。相似的功能，是由pwd命令提供的，它能够输出当前的工作目录。 pwd命令是非常常用的命令，尤其是在一些命令提示符设置不太友好的机器上。另外，它也经常用在shell脚本中，用来判断当前的运行目录是否符合需求。 有很多线上事故，都是由于没有确认当前目录所引起的。比如rm -rf *这种危险的命令。在执行一些高危命令时，随时确认当前目录，是个好的习惯。 1[root@hadoop100 ~]# pwd [-P] 选项与参数： -P ：显示出确实的路径，而非使用链接 (link) 路径。 实例：单纯显示出目前的工作目录： 12[root@hadoop100 ~]# pwd/root &lt;== 显示出目录了 我们使用root用户默认登陆后，就停留在/root目录中。Linux中的目录层次，是通过/进行划分的。 实例显示出实际的工作目录，而非链接档本身的目录名。 1234567[root@hadoop100 ~]# cd /var/mail &lt;==注意，/var/mail是一个链接档[root@hadoop100 mail]# pwd/var/mail &lt;==列出目前的工作目录[root@hadoop100 mail]# pwd -P/var/spool/mail &lt;==怎么回事？[root@hadoop100 mail]# ls -ld /var/maillrwxrwxrwx. 1 root root 10 Jul 16 2024 /var/mail -&gt; spool/mail 看到这里应该知道为啥了吧？因为 /var/mail 是链接档，链接到 /var/spool/mail。所以，加上 pwd -P 的选项后，会不以链接档的存放路径显示，而是显示正确的完整路径。 2.ls 列出目录的内容 ls:list 列出目录内容 ls命令，能够列出相关目录的文件信息。可以被评为linux下最勤劳的命令标兵。 语法： 123[root@hadoop100 ~]# ls [-aAdfFhilnrRSt] 目录名称[root@hadoop100 ~]# ls [--color=&#123;never,auto,always&#125;] 目录名称[root@hadoop100 ~]# ls [--full-time] 目录名称 选项与参数： -a ：全部的文件，连同隐藏文件( 开头为 . 的文件) 一起列出来 (常用) -d ：仅列出目录本身，而不是列出目录内的文件数据 (常用) -l ：长数据串列出，包含文件的属性与权限等等数据； (常用) 123456789101112131415161718192021222324252627# 注意：ls可以接受路径参数，不用先跳转，就可以输出相关信息[root@hadoop100 ~]# ls /afs bin boot dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var# 带上 -l参数，能够看到文件的一些权限信息已经更新日期等。[root@hadoop100 ~]# ls -l /total 20dr-xr-xr-x. 1 root root 0 Jul 16 2024 afslrwxrwxrwx. 1 root root 7 Jul 16 2024 bin -&gt; usr/bindr-xr-xr-x. 6 root root 4096 Feb 20 07:09 bootdrwxr-xr-x. 19 root root 3920 Feb 21 00:35 devdrwxr-xr-x. 1 root root 4714 Feb 20 02:53 etcdrwxr-xr-x. 1 root root 22 Feb 19 23:15 homelrwxrwxrwx. 1 root root 7 Jul 16 2024 lib -&gt; usr/liblrwxrwxrwx. 1 root root 9 Jul 16 2024 lib64 -&gt; usr/lib64drwx------. 1 root root 0 Oct 24 10:47 lost+founddrwxr-xr-x. 1 root root 0 Jul 16 2024 mediadrwxr-xr-x. 1 root root 0 Jul 16 2024 mntdrwxr-xr-x. 1 root root 0 Jul 16 2024 optdr-xr-xr-x. 330 root root 0 Feb 21 00:35 procdr-xr-x---. 1 root root 364 Feb 20 10:05 rootdrwxr-xr-x. 56 root root 1440 Feb 21 00:37 runlrwxrwxrwx. 1 root root 8 Jul 16 2024 sbin -&gt; usr/sbindrwxr-xr-x. 1 root root 0 Jul 16 2024 srvdr-xr-xr-x. 13 root root 0 Feb 21 00:35 sysdrwxrwxrwt. 20 root root 460 Feb 21 00:37 tmpdrwxr-xr-x. 1 root root 168 Oct 24 10:49 usrdrwxr-xr-x. 1 root root 200 Oct 24 10:57 var 每行列出的信息依次是： 文件类型与权限 链接数 文件属主 文件属组 文件大小用byte 来表示 建立或最近修改的时间 名字 直接在你的&#x2F;root目录里，执行ls -al，你会看到更多东西。这些额外的隐藏文件，都是以.开头，以配置文件居多。这就是参数a的作用。 1234567891011121314151617181920212223242526[root@hadoop100 ~]# ls -altotal 44dr-xr-x---. 1 root root 364 Feb 20 10:05 .dr-xr-xr-x. 1 root root 158 Oct 24 10:49 ..-rw-------. 1 root root 450 Feb 20 07:09 anaconda-ks.cfg-rw-------. 1 root root 3490 Feb 20 10:28 .bash_history-rw-r--r--. 1 root root 18 Jul 18 2024 .bash_logout-rw-r--r--. 1 root root 141 Jul 18 2024 .bash_profile-rw-r--r--. 1 root root 429 Jul 18 2024 .bashrcdrwx------. 1 root root 88 Feb 20 10:05 .cachedrwx------. 1 root root 276 Feb 20 10:28 .config-rw-r--r--. 1 root root 100 Jul 18 2024 .cshrcdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Desktopdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Documentsdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Downloads-rw-------. 1 root root 20 Feb 20 09:40 .lesshstdrwx------. 1 root root 20 Feb 20 10:05 .localdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Musicdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Picturesdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Publicdrwx------. 1 root root 0 Oct 24 10:50 .ssh-rw-r--r--. 1 root root 129 Jul 18 2024 .tcshrcdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Templatesdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Videos-rw-------. 1 root root 7130 Feb 20 02:53 .viminfo-rw-------. 1 root root 52 Feb 20 00:11 .Xauthority ls最常用的，就是加参数l或者参数a。 细心的同学，应该会注意到两个特殊的目录。.和..。前者表示的是当前目录，而后者表示的是上层目录。 使用cd命令，将在这些目录中，自由穿梭。 小技巧：如果你对英文日期阅读困难，可以使用ls -al --full-time查看可读的日期。 3.cd 切换目录 cd: Change Directory 切换路径 执行cd命令，可以将工作目录切换到目标文件夹。为了展示cd命令的效果。请在root用户下，执行下面的命令，这将创建一个7层的目录。 1[root@hadoop100 ~]# mkdir -p a1/b2/c3/d4/e5/f6/&#123;g1,g2,g3&#125; 我们使用cd命令，切换到最后一层。然后，我们使用..切换到上层目录。 1234567[root@hadoop100 ~]# cd a1/b2/c3/d4/e5/f6/g1[root@hadoop100 g1]# pwd/root/a1/b2/c3/d4/e5/f6/g1[root@hadoop100 g1]# cd ../[root@hadoop100 f6]# pwd/root/a1/b2/c3/d4/e5/f6 所以，切换到上面n层目录，只需使用多层级的../即可。有几个特殊的变量，需要说明一下。 ../ 指的是上层目录 ../../ 指的是上两层目录 ./ 指的是当前目录 ~ 指的是当前的用户目录，这是一个缩写符号 - 使用它，可以在最近两次的目录中来回切换 我们来使用命令把上面这些特殊变量验证一下。 123456789101112131415161718192021222324252627# 跳转到用户根目录[root@hadoop100 f6]# cd ~[root@hadoop100 ~]# pwd/root# 进入到第三层目录[root@hadoop100 ~]# cd a1/b2/c3[root@hadoop100 c3]# pwd/root/a1/b2/c3# 跳回到前三层目录[root@hadoop100 c3]# cd ../../../[root@hadoop100 ~]# pwd/root# 跳到上次访问的目录[root@hadoop100 ~]# cd -/root/a1/b2/c3[root@hadoop100 c3]# cd -/root# 进入当前目录：等于什么都没干[root@hadoop100 ~]# pwd/root[root@hadoop100 ~]# cd ./[root@hadoop100 ~]# pwd/root 4.mkdir 创建一个新的目录 mkdir: Make directory 建立目录 语法： 1mkdir [-mp] 目录名称 选项与参数： -m ：配置文件的权限！直接配置，不需要看默认权限 (umask) 的脸色～ -p ：帮助你直接将所需要的目录(包含上一级目录)递归创建起来！ 实例：请到&#x2F;tmp底下尝试创建数个新目录看看： 123456[root@hadoop100 ~]# cd /tmp[root@hadoop100 tmp]# mkdir test &lt;==创建一名为 test 的新目录[root@hadoop100 tmp]# mkdir test1/test2/test3/test4mkdir: cannot create directory `test1/test2/test3/test4&#x27;: No such file or directory &lt;== 无法直接创建此目录[root@hadoop100 tmp]# mkdir -p test1/test2/test3/test4 加了这个 -p 的选项，可以自行帮你创建多层目录！ 实例：创建权限为 rwx–x–x 的目录。 12345[root@hadoop100 tmp]# mkdir -m 711 test2[root@hadoop100 tmp]# ls -ldrwxr-xr-x. 2 root root 40 Feb 21 00:51 testdrwxr-xr-x. 3 root root 60 Feb 21 00:52 test1drwx--x--x. 2 root root 40 Feb 21 00:52 test2 上面的权限部分，如果没有加上 -m 来强制配置属性，系统会使用默认属性。 如果我们使用 -m ，如上例我们给予 -m 711 来给予新的目录 drwx–x–x 的权限。 5.rmdir 删除空的目录 rmdir: Remove directory 移除目录 语法： 1rmdir [-p] 目录名称 选项与参数： **-p ：**从该目录起，一次删除多级空目录 删除 test 目录 1[root@hadoop100 tmp]# rmdir test/ 将 mkdir 实例中创建的目录(&#x2F;tmp 底下)删除掉！ 12345678910[root@hadoop100 tmp]# ls -l &lt;==看看有多少目录存在？drwxr-xr-x. 2 root root 40 Feb 21 00:51 testdrwxr-xr-x. 3 root root 60 Feb 21 00:52 test1drwx--x--x. 2 root root 40 Feb 21 00:52 test2[root@hadoop100 tmp]# rmdir test &lt;==可直接删除掉，没问题[root@hadoop100 tmp]# rmdir test1 &lt;==因为尚有内容，所以无法删除rmdir: `test1&#x27;: Directory not empty[root@hadoop100 tmp]# rmdir -p test1/test2/test3/test4[root@hadoop100 tmp]# ls -l &lt;==底下的输出中test与test1不见了drwx--x--x. 2 root root 40 Feb 21 00:52 test2 利用 -p 这个选项，立刻就可以将 test1&#x2F;test2&#x2F;test3&#x2F;test4 一次删除。 删除完test4发现test3是空目录继续删除，以此类推。 不过要注意的是，这个 rmdir 仅能删除空的目录，你可以使用 rm 命令来删除非空目录。 6.touch 创建空文件1）基本语法 touch 文件名称 2）案例实操 1[root@hadoop100 ~]# touch xiyou/dssz/sunwukong.txt 7.cp 复制文件或目录cp 即拷贝文件和目录。 语法: cp [-adfilprsu] 来源档(source) 目标档(destination) cp [options] source1 source2 source3 .... directory 选项与参数： **-i：**若目标档(destination)已经存在时，在覆盖时会先询问动作的进行 (常用) **-p：**连同文件的属性一起复制过去，而非使用默认属性 (备份常用) **-r：**递归持续复制，用于目录的复制行为； (常用) **-f：**为强制(force)的意思，若目标文件已经存在且无法开启，则移除后再尝试一次； 用 root 身份，将 root 目录下的 .bashrc 复制到 &#x2F;tmp 下，并命名为 bashrc 123[root@hadoop100 ~]# cp ~/.bashrc /tmp/bashrc[root@hadoop100 ~]# cp -i ~/.bashrc /tmp/bashrccp: overwrite `/tmp/bashrc&#x27;? n &lt;==n不覆盖，y为覆盖 8.rm 删除文件或目录rm 是强大的删除命令，它可以永久性地删除文件系统中指定的文件或目录。在使用 rm 命令删除文件或目录时，系统不会产生任何提示信息。 语法： rm [-fir] 文件或目录 选项与参数： -f ：就是 force 的意思，忽略不存在的文件，不会出现警告信息； -i ：互动模式，在删除前会询问使用者是否动作 -r ：递归删除啊！最常用在目录的删除了！这是非常危险的选项！！！ 注意，rm 命令是一个具有破坏性的命令，因为 rm 命令会永久性地删除文件或目录，这就意味着，如果没有对文件或目录进行备份，一旦使用 rm 命令将其删除，将无法恢复，因此，尤其在使用 rm 命令删除目录时，要慎之又慎。 【例 1】基本用法。rm 命令如果任何选项都不加，则默认执行的是”rm -i 文件名”，也就是在删除一个文件之前会先询问是否删除。例如： 1234[root@hadoop100 ~]# touch cangls#删除前会询问是否删除[root@hadoop100 ~]# rm canglsrm:是否删除普通空文件&quot;cangls&quot;?y 【例 2】 删除目录。如果需要删除目录，则需要使用”-r”选项。例如: 12345678910111213[root@hadoop100 ~]# mkdir -p /test/lm/movie/jp#递归建立测试目录[root@hadoop100 ~]# rm /testrm:无法删除&quot;/test/&quot;: 是一个目录#如果不加&quot;-r&quot;选项，则会报错[root@hadoop100 ~]# rm -r /testrm:是否进入目录&quot;/test&quot;?yrm:是否进入目录&quot;/test/lm/movie&quot;?yrm:是否删除目录&quot;/test/lm/movie/jp&quot;?yrm:是否删除目录&quot;/test/lm/movie&quot;?yrm:是否删除目录&quot;/test/lm&quot;?yrm:是否删除目录&quot;/test&quot;?y#会分别询问是否进入子目录、是否删除子目录 大家会发现，如果每级目录和每个文件都需要确认，那么在实际使用中简直是灾难！ 【例 3】强制删除。如果要删除的目录中有 1 万个子目录或子文件，那么普通的 rm 删除最少需要确认 1 万次。所以，在真正删除文件的时候，我们会选择强制删除。例如： 1234[root@hadoop100 ~]# mkdir -p /test/lm/movie/jp#重新建立测试目录[root@hadoop100 ~]# rm -rf /test#强制删除，一了百了 加入了强制功能之后，删除就会变得很简单，但是需要注意，数据强制删除之后无法恢复，除非依赖第三方的数据恢复工具，如 extundelete 等。但要注意，数据恢复很难恢复完整的数据，一般能恢复 70%~80% 就很难得了。所以，与其把宝压在数据恢复上，不如养成良好的操作习惯。 虽然 “-rf” 选项是用来删除目录的，但是删除文件也不会报错。所以，为了使用方便，一般不论是删除文件还是删除目录，都会直接使用 “-rf” 选项。 9.mv 移动文件与目录或重命名语法： mv [-fiu] source destination mv [options] source1 source2 source3 .... directory 选项与参数： -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖； -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖！ -u ：若目标文件已经存在，且 source 比较新，才会更新 (update) 复制一文件，创建一目录，将文件移动到目录中 1234[root@hadoop100 ~]# cd /tmp[root@hadoop100 tmp]# cp ~/.bashrc bashrc[root@hadoop100 tmp]# mkdir mvtest[root@hadoop100 tmp]# mv bashrc mvtest 将某个文件移动到某个目录去，就是这样做！ 将刚刚的目录名称更名为 mvtest2 1[root@hadoop100 tmp]# mv mvtest mvtest2 10.cat 查看文件内容为了查看文件的生成效果，可以使用cat命令检测。cat命令将会把文件的内容，输出打印到终端上。如果加上参数n，甚至可以打印行号。效果如下： 123456789101112131415161718192021222324[root@hadoop100 ~]# cat spring1011121314151617181920[root@hadoop100 ~]# cat -n spring1 102 113 124 135 146 157 168 179 1810 1911 20 除了查看文件内容，cat命令通常用在更多的地方。只有和其他命令联合起来，它才会觉得有意义。 cat a b&gt;&gt; c: 合并a文件和b文件到c文件 cat a | cmd: 把a文件的内容作为输入，使用管道处理 写入内容到指定文件。在shell脚本中非常常用。我们在后面会多次用到这种写法 123456cat &gt; index.html &lt;&lt;EOF&lt;html&gt; &lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;/head&gt; &lt;body&gt;&lt;/body&gt;&lt;/html&gt;EOF 由于我们的文件不大，cat命令没有什么危害。但假如文件有几个GB，使用cat就危险的多，这只叫做猫的小命令，会在终端上疯狂的进行输出，你可以通过多次按ctrl+c来终止它。 11.less 分屏显示文件内容既然cat命令不适合操作大文件，那一定有替换的方案。less和more就是。由于less的加载速度比more快一些，所以现在一般都使用less。它最主要的用途，是用来分页浏览文件内容，并提供一些快速查找的方式。less是一个交互式的命令，你需要使用一些快捷键来控制它。 不仅如此，为了方面用户浏览文本内容，less 命令还提供了以下几个功能： 使用光标键可以在文本文件中前后（左后）滚屏； 用行号或百分比作为书签浏览文件； 提供更加友好的检索、高亮显示等操作； 兼容常用的字处理程序（如 Vim、Emacs）的键盘操作； 阅读到文件结束时，less 命令不会退出； 屏幕底部的信息提示更容易控制使用，而且提供了更多的信息。 less 命令的基本格式如下： [root@hadoop100 ~]# less [选项] 文件名 此命令可用的选项以及各自的含义如表所示。 选项 选项含义 -N 显示每行的行号。 -S 行过长时将超出部分舍弃。 -e 当文件显示结束后，自动离开。 -g 只标志最后搜索到的关键词。 -Q 不使用警告音。 -i 忽略搜索时的大小写。 -m 显示类似 more 命令的百分比。 -f 强迫打开特殊文件，比如外围设备代号、目录和二进制文件。 -s 显示连续空行为一行。 -b &lt;缓冲区大小&gt; 设置缓冲区的大小。 -o &lt;文件名&gt; 将 less 输出的内容保存到指定文件中。 -x &lt;数字&gt; 将【Tab】键显示为规定的数字空格。 在使用 less 命令查看文件内容的过程中，和 more 命令一样，也会进入交互界面，因此需要读者掌握一些常用的交互指令，如表所示。 空格 向下滚屏翻页 b 向上滚屏翻页 / 进入查找模式，比如/1111将查找1111字样 q 退出less g 到开头 G 去结尾 j 向下滚动 k 向上滚动，这两个按键和vim的作用非常像 【例 1】使用 less 命令查看 &#x2F;boot&#x2F;grub2&#x2F;grub.cfg 文件中的内容。 123456789101112131415161718192021222324[root@hadoop100 ~]# less /boot/grub2/grub.cfg## DO NOT EDIT THIS FILE## It is automatically generated by grub2-mkconfig using templates# from /etc/grub.d and settings from /etc/default/grub#### BEGIN /etc/grub.d/00_header ###set pager=1if [ -f $&#123;config_directory&#125;/grubenv ]; then load_env -f $&#123;config_directory&#125;/grubenvelif [ -s $prefix/grubenv ]; then load_envfiif [ &quot;$&#123;next_entry&#125;&quot; ] ; then set default=&quot;$&#123;next_entry&#125;&quot; set next_entry= save_env next_entry set boot_once=trueelse set default=&quot;$&#123;saved_entry&#125;&quot;: 可以看到，less 在屏幕底部显示一个冒号（：），等待用户输入命令，比如说，用户想向下翻一页，可以按空格键；如果想向上翻一页，可以按 b 键。 12.echo 输出内容到控制台echo 输出内容到控制台 基本语法 echo [选项] [输出内容] 选项： -e： 支持反斜线控制的字符转换 控制字符 作用 \\ 输出\\本身 \\n 换行符 \\t 制表符，也就是 Tab 案例实操 1234[root@hadoop100 ~]# echo &quot;hello\\tworld&quot;hello\\tworld[root@hadoop100 ~]# echo -e &quot;hello\\tworld&quot;hello world 13.head 显示文件头部内容取出文件前面几行 语法： head [-n number] 文件 选项与参数： -n ：后面接数字，代表显示几行的意思 1[root@hadoop100 ~]# head /etc/man_db.conf 默认的情况中，显示前面 10 行！若要显示前 20 行，就得要这样： 1[root@hadoop100 ~]# head -n 20 /etc/man_db.conf 14.tail 输出文件尾部内容取出文件后面几行 语法： tail [-n number] 文件 选项与参数： -n ：后面接数字，代表显示几行的意思 -f ：表示持续侦测后面所接的档名，要等到按下[ctrl]+c才会结束tail的侦测 123[root@hadoop100 ~]# tail /etc/man_db.conf # 默认的情况中，显示最后的十行！若要显示最后的 20 行，就得要这样：[root@hadoop100 ~]# tail -n 20 /etc/man_db.conf 对于部分程序员来说，tail -f或许是最常用的命令之一。它可以在控制终端，实时监控文件的变化，来看一些滚动日志。比如查看nginx或者tomcat日志等等。 12345678910111213# 滚动查看系统日志[root@hadoop100 ~]# tail -f anaconda-ks.cfg ignoredisk --only-use=nvme0n1autopart# Partition clearing informationclearpart --none --initlabel# System timezonetimezone America/New_York --utc#Root passwordrootpw --lock#光标不会退出文件，而会一直监听在文件的结尾处 这条命令会显示文件的最后 10 行内容，而且光标不会退出命令，每隔一秒会检查一下文件是否增加新的内容，如果增加就追加到原来的输出结果后面并显示。因此，这时如果向文件中追加一些数据（需要开启一个新终端）： 123[root@hadoop100 ~]# echo 2222222222 &gt;&gt; anaconda-ks.cfg [root@hadoop100 ~]# echo 3333333333 &gt;&gt; anaconda-ks.cfg #在新终端中通过echo命令向文件中追加数据 那么，在原始的正在监听的终端中，会看到如下信息： 12345678910111213[root@hadoop100 ~]# tail -f anaconda-ks.cfg ignoredisk --only-use=nvme0n1autopart# Partition clearing informationclearpart --none --initlabel# System timezonetimezone America/New_York --utc#Root passwordrootpw --lock22222222223333333333#在文件的结尾处监听到了新増数据 如果想终止输出，按[Ctrl]+c键中断 tail 命令即可。 通常情况下，日志滚动的过快，依然会造成一些困扰，需要配合grep命令达到过滤效果。 12# 滚动查看包含info字样的日志信息tail -f /var/log/messages | grep info 对于tail命令来说，还有一个大写的参数F。这个参数，能够监控到重新创建的文件。比如像一些log4j等日志是按天滚动的，tail -f无法监控到这种变化。 15.&gt; 输出重定向和 &gt;&gt; 追加1）基本语法 （1）ls -l &gt; 文件 （功能描述：列表的内容写入文件 a.txt 中（覆盖写）） （2）ls -al &gt;&gt; 文件 （功能描述：列表的内容追加到文件 aa.txt 的末尾） （3）cat 文件 1 &gt; 文件 2 （功能描述：将文件 1 的内容覆盖到文件 2） cat 文件1 文件2 &gt; 文件3（功能描述：将文件1 和 2的内容合并后输出到文件3中。） （4）echo “内容” &gt;&gt; 文件 2）案例实操 （1）将 ls 查看信息覆盖写入到文件中 [root@hadoop100 ~]# ls -l &gt; houge.txt （2）将 ls 查看信息追加写入到文件中 [root@hadoop100 ~]# ls -l &gt;&gt; houge.txt （3）采用 echo 将 hello 单词追加到文件中 [root@hadoop100 ~]# echo hello &gt;&gt; houge.txt （4）将文件 file1.txt 和 file2.txt 的内容合并后输出到文件 file3.txt 中。 12345678910111213141516171819202122[root@hadoop100 ~]# lsa1 Desktop Downloads Pictures Templatesanaconda-ks.cfg Documents Music Public Videos[root@hadoop100 ~]# mkdir ./Desktop/base[root@hadoop100 ~]# cd ./Desktop/base/[root@hadoop100 base]# touch file1.txt file2.txt[root@hadoop100 base]# lsfile1.txt file2.txt[root@hadoop100 base]# echo &quot;hadoop(file1.txt)&quot; &gt; file1.txt[root@hadoop100 base]# echo &quot;is great(file2.txt)&quot; &gt; file2.txt[root@hadoop100 base]# cat file1.txthadoop(file1.txt)[root@hadoop100 base]# cat file2.txtis great(file2.txt)[root@hadoop100 base]# cat file1.txt file2.txt &gt; file3.txt[root@hadoop100 base]# more file3.txt #more 命令可查看文件中的内容hadoop(file1.txt)is great(file2.txt)[root@hadoop100 base]# lsfile1.txt file2.txt file3.txt 16.history 查看已经执行过历史命令1）基本语法 history （功能描述：查看已经执行过历史命令） 2）案例实操 （1）查看已经执行过的历史命令 [root@hadoop100 test1]# history （2）显示最近3条命令历史 histroy 3 （3）清除历史记录 history -c 17.ln软链接软链接也称为符号链接，类似于 windows 里的快捷方式，有自己的数据块，主要存放了链接其他文件的路径。 1）基本语法 ln -s [原文件或目录] [软链接名] （功能描述：给原文件创建一个软链接） 2）经验技巧 ​ 删除软链接： rm -rf 软链接名，而不是 rm -rf 软链接名/ ​ 如果使用 rm -rf 软链接名&#x2F; 删除，会把软链接对应的真实目录下内容删掉 ​ 查询：通过 ll 就可以查看，列表属性第 1 位是 l，尾部会有位置指向。 3）案例实操 ​ （1）创建软连接 123[root@hadoop100 ~]# ln -s /root/Desktop/base/file3.txt ./new[root@hadoop100 ~]# ll newlrwxrwxrwx. 1 root root 28 Feb 21 01:40 new -&gt; /root/Desktop/base/file3.txt ​ （2）删除软连接(注意不要写最后的 &#x2F; ​ [root@hadoop100 ~]# rm -rf new ​ （3）进入软连接实际物理路径 123456[root@hadoop100 ~]# ln -s /root/Desktop/base/ ./new2[root@hadoop100 ~]# ll new2lrwxrwxrwx. 1 root root 19 Feb 21 01:44 new2 -&gt; /root/Desktop/base/[root@hadoop100 ~]# cd -P new2[root@hadoop100 base]# pwd/root/Desktop/base 18.总结18.1 文件剪贴删除复制重名等 pwd：Print Working Directory，显示当前工作目录的绝对路径。 ls：-a：显示当前目录所有的文件和目录，包括隐藏的； -l：以列表的方式显示信息。 cd：cd ~：回到自己的家目录；cd .. ：回到当前目录的上一级目录。 mkdir：创建目录；-p：创建多级目录。 rmdir：删除空目录。rmdir不能删除非空的目录。如果需要删除非空的目录，需要使用rm -rf。 cp：拷贝文件到指定目录； -r：递归复制整个文件夹。 强制覆盖不提示的方法：cp命令改为\\cp rm：移除文件或目录； -r：递归删除整个文件夹； -f：强制删除不提示。 mv：移动文件与目录或重命名，两种功能！ touch：创建空文件。可以一次性创建多个文件（多个文件间使用空格间隔） ln 给文件创建一个软连接 用法:ln -s [源文件或目录][软连接名] 18.2 文件查看 cat：查看文件内容。只能浏览文件，而不能修改文件。 -n：显示行号。 结尾加上 | more：分页显示，不会全部一下显示完。 more：是一个基于VI编辑器的文本过滤器，它以全屏幕的方式按页显示文本文件的内容。more还内置了很多快捷键： 空白键（Space）：向下翻一页 Enter：向下翻一行 q：立刻离开more，不再显示该文件内容 Ctrl + f：向下滚动一屏 Ctrl + b：返回上一屏 &#x3D; :输出当前行的行号 :f 输出文件名和当前行的行号 less：用来分屏查看文件内容，与more相似，但是更强大，支持各种显示终端。less指令在显示文件内容时，并不是一次将整个文件加载之后才显示，而是根据显示需要加载内容。对于显示大型文件具有较高的效率。 head：显示文件的开头部分。-n 5：看前面5行内容。 tail：输出文件中尾部的内容。 -n 5：看后面5行内容。 -f：时事追踪该文档的所有更新 &gt;指令：输出重定向。如果不存在会创建文件，否则会将原来的文件内容覆盖。 &gt;&gt;指令：追加。如果不存在会创建文件，否则不会覆盖原来的文件内容，而是追加到文件的尾部。 echo：输出内容到控制台。 history：查看历史指令 06 【时间日期类 用户和用户组管理】1.时间日期类1.1 显示当前日期 基本语法 date (功能描述:显示当前时间) date +%Y(功能描述:显示当前年份) date +%m(功能描述:显示当前月份) date +%d (功能描述:显示当前是哪一天) date &quot;+%Y-%m-%d %H:%M:%S&quot; (功能描述:显示年月日时分秒) date +%s (功能描述:显示当前日期时间戳) 应用实例 案例1:显示当前时间信息 date 12[root@hadoop100 ~]# dateFri Feb 21 01:46:56 AM EST 2025 案例2:显示当前时间年月日 date &quot;+%Y-%m-%d&quot; 12[root@hadoop100 ~]# date &quot;+%Y-%m-%d&quot;2025-02-21 案例3:显示当前时间年月日时分秒 date &quot;+%Y-%m-%d %H:%M:%S&quot; 12[root@hadoop100 ~]# date &quot;+%Y-%m-%d %H:%M:%S&quot;2025-02-21 01:49:20 案例3:显示当前时间戳 date &quot;+%s&quot; 12[root@hadoop100 ~]# date &quot;+%s&quot;1740120636 1.2 显示非当前时间1）基本语法 ​ （1）date -d “1 days ago”（功能描述：显示前一天时间） ​ （2）date -d “-1 days ago” （功能描述：显示明天时间） 2）案例实操 ​ （1）显示前一天 12[root@hadoop100 ~]# date -d &quot;1 days ago&quot;Thu Feb 20 01:51:06 AM EST 2025 ​ （2）显示明天时间 12[root@hadoop100 ~]# date -d &quot;-1 days ago&quot;Sat Feb 22 01:51:26 AM EST 2025 1.3 设置日期 基本语法 ​ date -s 字符串时间 应用实例 案例1:设置系统当前时间，比如设置成 2030-1-01 20:00:10 1[root@hadoop100 ~]# date -s &quot;2030-1-01 20:00:10&quot; ​ 同步时间： 1[root@hadoop100 ~]# ntpdate -u ntp1.aliyun.com 1.4 cal 指令 查看日历指令 cal 基本语法cal [选项](功能描述:不加选项，显示本月日历) 应用实例 案例1:显示当前日历cal 案例2:显示2026年日历: cal 2026 ​ 3.案例3:查看3个月的时间：cal -3 2.用户管理命令2.1 useradd 添加新用户Linux 系统中，可以使用 useradd 命令新建用户 1）基本语法 useradd 用户名 （功能描述：添加新用户） useradd -g 组名 用户名 （功能描述：添加新用户到某个组） 2）案例实操 （1）添加一个用户 12345[root@hadoop100 ~]# useradd tony[root@hadoop100 ~]# ll /home/total 0drwx------. 1 nailclipper nailclipper 296 Feb 20 03:09 nailclipperdrwx------. 1 tony tony 80 Feb 21 02:49 tony （2）创建时修改主文件夹名称 1[root@hadoop100 ~]# useradd -d /home/dave david 2.2 passwd 设置用户密码学习 useradd 命令我们知道，使用此命令创建新用户时，并没有设定用户密码，因此还无法用来登陆系统，本节就来学习 passwd 密码配置命令 。 1）基本语法 passwd 用户名 （功能描述：设置用户密码) 2）案例实操 例如，我们使用 root 账户修改 lamp 普通用户的密码，可以使用如下命令： 12345[root@hadoop100 ~]# passwd tonyNew password: &lt;--直接输入新的口令，但屏幕不会有任何反应BAD PASSWORD: The password is shorter than 8 characters &lt;--口令太简单或过短的错误！这里只是警告信息，输入的密码依旧能用Retype new password: &lt;--再次验证输入的密码，再输入一次即可passwd: password updated successfully &lt;--提示修改密码成功 当然，也可以使用 passwd 命令修改当前系统已登录用户的密码，但要注意的是，需省略掉 “选项” 和 “用户名”。例如，我们登陆 nailclipper 用户，并使用 passwd 命令修改 nailclipper 的登陆密码，执行过程如下： 123456[nailclipper@hadoop100 ~]$ passwd#passwd直接回车代表修改当前用户的密码Current password: &lt;--这里输入『原有的旧口令』New password: &lt;--这里输入新口令Retype new password: &lt;--通过口令验证！所以重复这个口令的输入passwd: password updated successfully &lt;--成功修改用户密码 注意，普通用户只能使用 passwd 命令修改自己的密码，而不能修改其他用户的密码。 可以看到，与使用 root 账户修改普通用户的密码不同，普通用户修改自己的密码需要先输入自己的旧密码，只有旧密码输入正确才能输入新密码。不仅如此，此种修改方式对密码的复杂度有严格的要求，新密码太短、太简单，都会被系统检测出来并禁止用户使用。 很多Linux 发行版为了系统安装，都使用了 PAM 模块进行密码的检验，设置密码太短、与用户名相同、是常见字符串等，都会被 PAM 模块检查出来，从而禁止用户使用此类密码。有关 PAM 模块，后续章节会进行详细介绍。 而使用 root 用户，无论是修改普通用户的密码，还是修改自己的密码，都可以不遵守 PAM 模块设定的规则，就比如我刚刚给 lamp 用户设定的密码是 “123”，系统虽然会提示密码过短和过于简单，但依然可以设置成功。当然，在实际应用中，就算是 root 身份，在设定密码时也要严格遵守密码规范，因为只有好的密码规范才是服务器安全的基础。 2.3 id 查看用户是否存在id 命令可以查询用户的UID、GID 和附加组的信息。命令比较简单，格式如下： id 用户名【例 1】 123[root@hadoop100 ~]# id tonyuid=1001(tony) gid=1001(tony) groups=1001(tony)#能看到uid(用户ID)、gid(初始组ID), groups是用户所在组，这里既可以看到初始组，如果有附加组，则也能看到附加组 【例 2】 12345[root@hadoop100 ~]# usermod -G root tony#把用户加入root组[root@hadoop100 ~]# id tonyuid=1001(tony) gid=1001(tony) groups=1001(tony),0(root)#大家发现root组中加入了tony用户的附加组信息 2.4 cat &#x2F;etc&#x2F;passwd 查看创建了哪些用户Linux 系统中的 /etc/passwd 文件，是系统用户配置文件，存储了系统中所有用户的基本信息，并且所有用户都可以对此文件执行读操作。 首先我们来打开这个文件，看看到底包含哪些内容，执行命令如下： 12345678[root@hadoop100 ~]# vim /etc/passwd#查看一下文件内容root:x:0:0:Super User:/root:/bin/bashbin:x:1:1:bin:/bin:/usr/sbin/nologindaemon:x:2:2:daemon:/sbin:/usr/sbin/nologinnailclipper:x:1000:1000:nailclipper:/home/nailclipper:/bin/bashtony:x:1001:1001::/home/tony:/bin/bash...省略部分输出... 可以看到，&#x2F;etc&#x2F;passwd 文件中的内容非常规律，每行记录对应一个用户。 读者可能会问，Linux 系统中默认怎么会有这么多的用户？这些用户中的绝大多数是系统或服务正常运行所必需的用户，这种用户通常称为系统用户或伪用户。系统用户无法用来登录系统，但也不能删除，因为一旦删除，依赖这些用户运行的服务或程序就不能正常执行，会导致系统问题。 不仅如此，每行用户信息都以 “：” 作为分隔符，划分为 7 个字段，每个字段所表示的含义如下： 用户名：密码：UID（用户ID）：GID（组ID）：描述性信息：主目录：默认Shell 接下来，给大家逐个介绍这些字段。 2.4.1 用户名用户名，就是一串代表用户身份的字符串。 前面讲过，用户名仅是为了方便用户记忆，Linux 系统是通过 UID 来识别用户身份，分配用户权限的。/etc/passwd 文件中就定义了用户名和 UID 之间的对应关系。 2.4.2 密码“x” 表示此用户设有密码，但不是真正的密码，真正的密码保存在 /etc/shadow 文件中。 在早期的 UNIX 中，这里保存的就是真正的加密密码串，但由于所有程序都能读取此文件，非常容易造成用户数据被窃取。 虽然密码是加密的，但是采用暴力破解的方式也是能够进行破解的。 因此，现在 Linux 系统把真正的加密密码串放置在 &#x2F;etc&#x2F;shadow 文件中，此文件只有 root 用户可以浏览和操作，这样就最大限度地保证了密码的安全。 需要注意的是，虽然 “x” 并不表示真正的密码，但也不能删除，如果删除了 “x”，那么系统会认为这个用户没有密码，从而导致只输入用户名而不用输入密码就可以登陆（只能在使用无密码登录，远程是不可以的），除非特殊情况（如破解用户密码），这当然是不可行的。 2.4.3 UIDUID，也就是用户 ID。每个用户都有唯一的一个 UID，Linux 系统通过 UID 来识别不同的用户。 实际上，UID 就是一个 0~65535 之间的数，不同范围的数字表示不同的用户身份，具体如表 1 所示。 UID 范围 用户身份 0 超级用户。UID 为 0 就代表这个账号是管理员账号。在 Linux 中，如何把普通用户升级成管理员呢？只需把其他用户的 UID 修改为 0 就可以了，这一点和 Windows 是不同的。不过不建议建立多个管理员账号。 1~499 系统用户（伪用户）。也就是说，此范围的 UID 保留给系统使用。其中，199 用于系统自行创建的账号；100499 分配给有系统账号需求的用户。 其实，除了 0 之外，其他的 UID 并无不同，这里只是默认 500 以下的数字给系统作为保留账户，只是一个公认的习惯而已。 500~65535 普通用户。通常这些 UID 已经足够用户使用了。但不够用也没关系，2.6.x 内核之后的 Linux 系统已经可以支持 232 个 UID 了。 2.4.4 GID全称“Group ID”，简称“组ID”，表示用户初始组的组 ID 号。q这里需要解释一下初始组和附加组的概念。 初始组，指用户登陆时就拥有这个用户组的相关权限。每个用户的初始组只能有一个，通常就是将和此用户的用户名相同的组名作为该用户的初始组。比如说，我们手工添加用户 tony，在建立用户 tony 的同时，就会建立 tony 组作为 tony 用户的初始组。 附加组，指用户可以加入多个其他的用户组，并拥有这些组的权限。每个用户只能有一个初始组，除初始组外，用户再加入其他的用户组，这些用户组就是这个用户的附加组。附加组可以有多个，而且用户可以有这些附加组的权限。 举例来说，刚刚的 tony 用户除属于初始组 tony 外，我又把它加入了 root 组，那么 tony 用户同时属于 tony 组和 root 组，其中 tony 是初始组，root 是附加组。 当然，初始组和附加组的身份是可以修改的，但是我们在工作中不修改初始组，只修改附加组，因为修改了初始组有时会让管理员逻辑混乱。 需要注意的是，在 /etc/passwd 文件的第四个字段中看到的 ID 是这个用户的初始组。 2.4.5 描述性信息这个字段并没有什么重要的用途，只是用来解释这个用户的意义而已。 2.4.6 主目录也就是用户登录后有操作权限的访问目录，通常称为用户的主目录。 例如，root 超级管理员账户的主目录为 &#x2F;root，普通用户的主目录为 /home/yourIDname，即在 &#x2F;home&#x2F; 目录下建立和用户名相同的目录作为主目录，如 tony 用户的主目录就是 /home/tony/ 目录。 2.4.7 默认的ShellShell 就是 Linux 的命令解释器，是用户和 Linux 内核之间沟通的桥梁。 我们知道，用户登陆 Linux 系统后，通过使用 Linux 命令完成操作任务，但系统只认识类似 0101 的机器语言，这里就需要使用命令解释器。也就是说，Shell 命令解释器的功能就是将用户输入的命令转换成系统可以识别的机器语言。 通常情况下，Linux 系统默认使用的命令解释器是 bash（&#x2F;bin&#x2F;bash），当然还有其他命令解释器，例如 sh、csh 等。 在 /etc/passwd 文件中，大家可以把这个字段理解为用户登录之后所拥有的权限。如果这里使用的是 bash 命令解释器，就代表这个用户拥有权限范围内的所有权限。例如： 12[root@hadoop100 ~]# cat /etc/passwd | grep tonytony:x:1001:1001::/home/tony:/bin/bash 我手工添加了 tony 用户，它使用的是 bash 命令解释器，那么这个用户就可以使用普通用户的所有权限。 如果我把 tony 用户的 Shell 命令解释器修改为 &#x2F;sbin&#x2F;nologin，那么，这个用户就不能登录了，例如： 12[root@hadoop100 ~]# vim /etc/passwdtony:x:502:502::/home/tony:/sbin/nologin 因为 /sbin/nologin 就是禁止登录的 Shell。同样，如果我在这里放入的系统命令，如 /usr/bin/passwd，例如： 12[root@hadoop100 ~]# vim /etc/passwdtony:x:502:502::/home/tony:/usr/bin/passwd 那么这个用户可以登录，但登录之后就只能修改自己的密码。这里不能随便写入和登陆没有关系的命令（如 ls），系统不会识别这些命令，同时也就意味着这个用户不能登录。 2.5 su 临时切换用户身份2.5.1 基本使用su 是最简单的用户切换命令，通过该命令可以实现任何身份的切换，包括从普通用户切换为 root 用户、从 root 用户切换为普通用户以及普通用户之间的切换。 普通用户之间切换以及普通用户切换至 root 用户，都需要知晓对方的密码，只有正确输入密码，才能实现切换；从 root 用户切换至其他用户，无需知晓对方密码，直接可切换成功。su 命令的基本格式如下： su [选项] 用户名选项： -：当前用户不仅切换为指定用户的身份，同时所用的工作环境也切换为此用户的环境（包括 PATH 变量、MAIL 变量等），单独使用 - 选项可省略用户名，默认会切换为 root 用户。 -l：同 - 的使用类似，也就是在切换用户身份的同时，完整切换工作环境，但后面需要添加欲切换的使用者账号。 -p：表示切换为指定用户的身份，但不改变当前的工作环境（不使用切换用户的配置文件）。 -m：和 -p 一样； -c 命令：仅切换用户执行一次命令，执行后自动切换回来，该选项后通常会带有要执行的命令。 【例 1】 1234567[tony@hadoop100 ~]$ su 或者[tony@hadoop100 ~]$ su - root或者[tony@hadoop100 ~]$ su - 密码： &lt;-- 输入 root 用户的密码#&quot;-&quot;代表连带环境变量一起切换，不能省略 【例 2】 123456789101112[tony@hadoop100 ~]$ whoamitony#当前我是tony[tony@hadoop100 ~]$ su - -c &quot;useradd user1&quot; rootPassword: #不切换成root，但是执行useradd命令添加user1用户[tony@hadoop100 ~]$ whoamitony#我还是tony[tony@hadoop100 ~]$ grep &quot;user1&quot; /etc/passwduser1:x:1002:1002::/home/user1:/bin/bash#user1用户已经添加了 除了像例 2 这样，执行一条命令后用户身份会随即自动切换回来，其他切换用户的方式不会自动切换，只能使用 exit 命令进行手动切换。 2.5.2 su 和 su - 的区别注意，使用 su 命令时，有 - 和没有 - 是完全不同的，- 选项表示在切换用户身份的同时，连当前使用的环境变量也切换成指定用户的。我们知道，环境变量是用来定义操作系统环境的，因此如果系统环境没有随用户身份切换，很多命令无法正确执行。 举个例子，普通用户 tony 通过 su 命令切换成 root 用户，但没有使用 - 选项，这样情况下，虽然看似是 root 用户，但系统中的 $PATH$ 环境变量依然是 tony 的（而不是 root 的），因此当前工作环境中，并不包含 &#x2F;sbin、&#x2F;usr&#x2F;sbin等超级用户命令的保存路径，这就导致很多管理员命令根本无法使用。不仅如此，当 root 用户接受邮件时，会发现收到的是 tony 用户的邮件，因为环境变量 $MAIL$ 也没有切换。 初学者可以这样理解它们之间的区别，即有 - 选项，切换用户身份更彻底；反之，只切换了一部分，这会导致某些命令运行出现问题或错误（例如无法使用 service 命令）。 通过下面这个例子，可直观的看到 su 和 su - 的区别： 123456789101112131415161718[tony@hadoop100 ~]$ whoamitony#查询用户身份，我是tony[tony@hadoop100 ~]$ su root密码：&lt;-输入root密码#切换到root，但是没有切换环境变量。注意：普通用户切换到root需要密码[root@hadoop100 ~]# env | grep tony#查看环境变量，提取包含tony的行LOGNAME=tonyUSER=tony#用户名还是lamp，而不是rootXDG_DATA_DIRS=/root/.local/share/flatpak/exports/share:/home/tony/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/sharePATH=/root/.local/bin:/root/bin:/home/tony/.local/bin:/home/tony/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin#命令査找的路径不包含超级用户路径MAIL=/var/spool/mail/tonyOLDPWD=/home/tony#邮箱MAIL、主目录OLDPWD、登陆用户名LOGNAME还是tony 可以看到，在不使用 su - 的情况下，虽然用户身份成功切换，但环境变量依旧用的是原用户的，切换并不完整。 2.6 userdel 删除用户userdel 命令功能很简单，就是删除用户的相关数据。此命令只有 root 用户才能使用。 通过前面的学习我们知道，用户的相关数据包含如下几项： 用户基本信息：存储在 /etc/passwd 文件中； 用户个人文件：主目录默认位于 /home/用户名 其实，userdel 命令的作用就是从以上文件中，删除与指定用户有关的数据信息。 userdel 命令的语法很简单，基本格式如下： userdel -r 用户名 -r 选项表示在删除用户的同时删除用户的家目录。 注意，在删除用户的同时如果不删除用户的家目录，那么家目录就会变成没有属主和属组的目录，也就是垃圾文件。 例如，删除前面章节中创建的 tony 用户，只需执行如下命令： [root@hadoop100 ~]# userdel -r tony 除了使用 userdel 命令删除用户，还可以手动方式删除，毕竟通过前面的学习，我们已经知道与用户相关信息的存储位置。虽然这样做没有实际意义，但对于初学者来说，可以加深对 userdel 命令的理解。 手动删除用户，仅是为了让读者对 userdel 命令理解地更透彻，实际使用中，使用 userdel 删除用户更方便。 （1）删除用户但保存用户主目录 123456[root@hadoop100 ~]# userdel user1[root@hadoop100 ~]# ll /home/total 0drwx------. 1 nailclipper nailclipper 296 Feb 20 03:09 nailclipperdrwx------. 1 tony tony 118 Feb 21 03:14 tonydrwx------. 1 1002 1002 80 Feb 21 03:12 user1 （2）删除用户和用户主目录，都删除 12345678910111213[root@hadoop100 ~]# useradd user2[root@hadoop100 ~]# ll /home/total 0drwx------. 1 nailclipper nailclipper 296 Feb 20 03:09 nailclipperdrwx------. 1 tony tony 118 Feb 21 03:14 tonydrwx------. 1 user1 user1 80 Feb 21 03:12 user1drwx------. 1 user2 user2 80 Feb 21 03:24 user2[root@hadoop100 ~]# userdel -r user2[root@hadoop100 ~]# ll /home/total 0drwx------. 1 nailclipper nailclipper 296 Feb 20 03:09 nailclipperdrwx------. 1 tony tony 118 Feb 21 03:14 tonydrwx------. 1 user1 user1 80 Feb 21 03:12 user1 最后需要大家注意的是，如果要删除的用户已经使用过系统一段时间，那么此用户可能在系统中留有其他文件，因此，如果我们想要从系统中彻底的删除某个用户，最好在使用 userdel 命令之前，先通过 find -user 用户名 命令查出系统中属于该用户的文件，然后在加以删除。 2.7 who 查看登录用户信息基本语法 （1）whoami （功能描述：显示自身用户名称） （2）who am i （功能描述：显示登录用户的用户名以及登陆时间） whoami 命令和 who am i 命令是不同的 2 个命令，前者用来打印当前执行操作的用户名，后者则用来打印登陆当前 Linux 系统的用户名。 为了能够更好地区分这 2 个命令的功能，给大家举个例子，我们首先使用用户名为“lamp”登陆 Linux 系统，然后执行如下命令： 1234[tony@hadoop100 ~]$ whoamitony[tony@hadoop100 ~]$ who am itony pts/2 2025-02-21 03:28 (192.168.26.1) 在此基础上，使用 su 命令切换到 root 用户下，再执行一遍上面的命令： 123456[tony@hadoop100 ~]$ su -Password: [root@hadoop100 ~]# whoamiroot[root@hadoop100 ~]# who am itony pts/2 2025-02-21 03:28 (192.168.26.1) 看到了吗？在未切换用户身份之前，whoami 和 who am i 命令的输出是一样的，但使用 su 命令切换用户身份后，使用 whoami 命令打印的是切换后的用户名，而 who am i 命令打印的仍旧是登陆系统时所用的用户名。 执行 whoami 命令，等同于执行 id -un 命令；执行 who am i 命令，等同于执行 who -m 命令。 也就是说，使用 su 或者 sudo 命令切换用户身份，骗得过 whoami，但骗不过 who am i。要解释这背后的运行机制，需要搞清楚什么是实际用户（UID）和有效用户（EUID，即 Effective UID）。 所谓实际用户，指的是登陆 Linux 系统时所使用的用户，因此在整个登陆会话过程中，实际用户是不会发生变化的；而有效用户，指的是当前执行操作的用户，也就是说真正决定权限高低的用户，这个是能够利用 su 或者 sudo 命令进行任意切换的。 一般情况下，实际用户和有效用户是相同的，如果出现用户身份切换的情况，它们会出现差异。需要注意的是，实际用户和有效用户出现差异，切换用户并不是唯一的触发机制，至于其他的触发条件，后续章节会做详细介绍。 那么，whoami 和 who am i通常应用在哪些场景中呢？通常，对那些经常需要切换用户的系统管理员来说，经常需要明确当前使用的是什么身份；另外，对于某些 shell 脚本，或者需要特别的用户才能执行，这时就需要利用 whoami 命令来搞清楚执行它的用户是谁；甚至还有一些 shell 脚本，一定要某个特别用户才能执行，即便使用 su 或者 sudo 命令切换到此身份都不行，此时就需要利用 who am i 来确认。 2.8 sudo 设置普通用户具有 root 权限我们知道，使用 su 命令可以让普通用户切换到 root 身份去执行某些特权命令，但存在一些问题，比如说： 仅仅为了一个特权操作就直接赋予普通用户控制系统的完整权限； 当多人使用同一台主机时，如果大家都要使用 su 命令切换到 root 身份，那势必就需要 root 的密码，这就导致很多人都知道 root 的密码； 考虑到使用 su 命令可能对系统安装造成的隐患，最常见的解决方法是使用 sudo 命令，此命令也可以让你切换至其他用户的身份去执行命令。 相对于使用 su 命令还需要新切换用户的密码，sudo 命令的运行只需要知道自己的密码即可，甚至于，我们可以通过手动修改 sudo 的配置文件，使其无需任何密码即可运行。 sudo 命令默认只有 root 用户可以运行。 例1 1）添加 lamp 用户，并对其设置密码。 123456[root@hadoop100 ~]# useradd jery[root@hadoop100 ~]# passwd jeryNew password: BAD PASSWORD: The password is shorter than 8 charactersRetype new password: passwd: password updated successfully 2）修改配置文件 前面说过，默认情况下 sudo 命令只有 root 身份可以使用，那么，如何让普通用户也能使用它呢？ 解决这个问题之前，先给大家分析一下 sudo 命令的执行过程。sudo命令的运行，需经历如下几步： 当用户运行 sudo 命令时，系统会先通过 &#x2F;etc&#x2F;sudoers 文件，验证该用户是否有运行 sudo 的权限； 确定用户具有使用 sudo 命令的权限后，还要让用户输入自己的密码进行确认。出于对系统安全性的考虑，如果用户在默认时间内（默认是 5 分钟）不使用 sudo 命令，此后使用时需要再次输入密码； 密码输入成功后，才会执行 sudo 命令后接的命令。 显然，能否使用 sudo 命令，取决于对 /etc/sudoers 文件的配置（默认情况下，此文件中只配置有 root 用户）。所以接下来，我们学习对 /etc/sudoers 文件进行合理的修改。 1[root@hadoop100 ~]# vim /etc/sudoers 修改 /etc/sudoers 文件，找到下面内容（第100行），在 root 下面添加一行，如下所示： 123456## Allow root to run any commands anywhere root ALL=(ALL) ALLjery ALL=(ALL) ALL#用户名 被管理主机的地址=(可使用的身份) 授权命令(绝对路径)#%wheel ALL=(ALL) ALL#%组名 被管理主机的地址=(可使用的身份) 授权命令(绝对路径) 或者配置成采用 sudo 命令时，不需要输入密码 123## Allow root to run any commands anywhere root ALL=(ALL) ALLjery ALL=(ALL) NOPASSWD:ALL 修改完毕，现在可以用 jery 帐号登录，然后用命令 sudo ，即可获得 root 权限进行操作。 对以上 2 个模板的各部分进行详细的说明。 模块 含义 用户名或群组名 表示系统中的那个用户或群组，可以使用 sudo 这个命令。 被管理主机的地址 用户可以管理指定 IP 地址的服务器。这里如果写 ALL，则代表用户可以管理任何主机；如果写固定 IP，则代表用户可以管理指定的服务器。如果我们在这里写本机的 IP 地址，不代表只允许本机的用户使用指定命令，而是代表指定的用户可以从任何 IP 地址来管理当前服务器。 可使用的身份 就是把来源用户切换成什么身份使用，（ALL）代表可以切换成任意身份。这个字段可以省略。 授权命令 表示 root 把什么命令命令授权给用户，换句话说，可以用切换的身份执行什么命令。需要注意的是，此命令必须使用绝对路径写。默认值是 ALL，表示可以执行任何命令。 3）案例实操 用普通用户在&#x2F;opt 目录下创建一个文件夹 123456789[jery@hadoop100 ~]$ sudo mkdir /opt/module[jery@hadoop100 ~]$ cd /opt[jery@hadoop100 opt]$ lltotal 0drwxr-xr-x. 1 root root 0 Feb 21 03:40 module[jery@hadoop100 opt]$ sudo chown jery:jery module/[jery@hadoop100 opt]$ lltotal 0drwxr-xr-x. 1 jery jery 0 Feb 21 03:40 module 例2 假设现在有 pro1，pro2，pro3 这 3 个用户，还有一个 group 群组，我们可以通过在 &#x2F;etc&#x2F;sudoers 文件配置 wheel 群组信息，令这 3 个用户同时拥有管理系统的权限。 首先，向 &#x2F;etc&#x2F;sudoers 文件中添加群组配置信息： 12345....(前面省略)....## Allows people in group wheel to run all commands%wheel ALL=(ALL) ALL%group ALL=(ALL) ALL#在 110 行#wheel这一行后面写入 此配置信息表示，group 这个群组中的所有用户都能够使用 sudo 切换任何身份，执行任何命令。接下来，我们使用 usermod 命令将 pro1 加入 group 群组，看看有什么效果： 12345678910111213141516171819202122232425262728[root@hadoop100 ~]# groupadd group[root@hadoop100 ~]# useradd -g group pro1[root@hadoop100 ~]# id pro1uid=1004(pro1) gid=1004(group) groups=1004(group)[root@hadoop100 ~]# useradd pro2[root@hadoop100 ~]# usermod -a -G group pro2[root@hadoop100 ~]# id pro2uid=1005(pro2) gid=1005(pro2) groups=1005(pro2),1004(group)[root@hadoop100 ~]# useradd pro3[root@hadoop100 ~]# id pro3uid=1006(pro3) gid=1006(pro3) groups=1006(pro3)[root@hadoop100 ~]# usermod -a -G group pro1[pro1@hadoop100 ~]$ sudo tail -n 1 /etc/shadow &lt;==注意身份是 pro1....(前面省略)....[sudo] password for pro1: &lt;==输入 pro1 的密码pro3:$y$j9T$0l8EniLnUAklWobeKJBgo1$J8bBQeQIk98MnyLjaUycRHl7NBoip.YZzFAnoBFF3Y1:20140:0:99999:7:::[pro2@hadoop100 ~]$ sudo tail -n 1 /etc/shadow &lt;==注意身份是 pro2[sudo] password for pro2: &lt;==输入 pro2 的密码pro3:$y$j9T$0l8EniLnUAklWobeKJBgo1$J8bBQeQIk98MnyLjaUycRHl7NBoip.YZzFAnoBFF3Y1:20140:0:99999:7:::[pro3@hadoop100 ~]$ sudo tail -n 1 /etc/shadow &lt;==注意身份是 pro3[sudo] password for pro3: &lt;==输入 pro3 的密码pro3 is not in the sudoers file.#此错误信息表示 pro3 不在 /etc/sudoers 的配置中。 可以看到，由于 pro1 加入到了 group 群组，因此 pro1 就可以使用 sudo 命令，而 pro3 不行。同样的道理，如果我们想让 pro3 也可以使用 sudo 命令，不用再修改 &#x2F;etc&#x2F;sudoers 文件，只需要将 pro3 加入 group 群组即可。 2.9 usermod 修改用户前面章节介绍了如何利用 useradd 命令添加用户，但如果不小心添错用户信息，后期如何修改呢？ 1）基本语法 usermod -g 用户组 用户 usermod -a -G [用户组1,用户组2] 用户 2）选项说明 -g 修改用户的初始登录组，给定的组必须存在。默认组 id 是 1。 -a -G 将现有的用户添加到多个附加组 3）案例实操 将用户加入到用户组，该操作会改变用户的初始组 12345[root@hadoop100 ~]# id pro3uid=1006(pro3) gid=1006(pro3) groups=1006(pro3)[root@hadoop100 ~]# usermod -g group pro3[root@hadoop100 ~]# id pro3uid=1006(pro3) gid=1004(group) groups=1004(group) 将用户添加到多个附加组，不改变用户的初始组 123[root@hadoop100 ~]# usermod -a -G root,group pro4[root@hadoop100 ~]# id pro4uid=1007(pro4) gid=1007(pro4) groups=1007(pro4),0(root),1004(group) 3.用户组管理命令3.1 用户和用户组Linux 是多用户多任务操作系统，换句话说，Linux 系统支持多个用户在同一时间内登陆，不同用户可以执行不同的任务，并且互不影响。 例如，某台 Linux 服务器上有 4 个用户，分别是 root、www、ftp 和 mysql，在同一时间内，root 用户可能在查看系统日志、管理维护系统；www 用户可能在修改自己的网页程序；ftp 用户可能在上传软件到服务器；mysql 用户可能在执行自己的 SQL 查询，每个用户互不干扰，有条不紊地进行着自己的工作。与此同时，每个用户之间不能越权访问，比如 www 用户不能执行 mysql 用户的 SQL 查询操作，ftp 用户也不能修改 www 用户的网页程序。 不同用户具有不问的权限，毎个用户在权限允许的范围内完成不同的任务，Linux 正是通过这种权限的划分与管理，实现了多用户多任务的运行机制。 因此，如果要使用 Linux 系统的资源，就必须向系统管理员申请一个账户，然后通过这个账户进入系统（账户和用户是一个概念）。通过建立不同属性的用户，一方面可以合理地利用和控制系统资源，另一方面也可以帮助用户组织文件，提供对用户文件的安全性保护。 每个用户都有唯一的用户名和密码。在登录系统时，只有正确输入用户名和密码，才能进入系统和自己的主目录。 用户组是具有相同特征用户的逻辑集合。简单的理解，有时我们需要让多个用户具有相同的权限，比如查看、修改某一个文件的权限，一种方法是分别对多个用户进行文件访问授权，如果有 10 个用户的话，就需要授权 10 次，那如果有 100、1000 甚至更多的用户呢？ 显然，这种方法不太合理。最好的方式是建立一个组，让这个组具有查看、修改此文件的权限，然后将所有需要访问此文件的用户放入这个组中。那么，所有用户就具有了和组一样的权限，这就是用户组。 将用户分组是 Linux 系统中对用户进行管理及控制访问权限的一种手段，通过定义用户组，很多程序上简化了对用户的管理工作。 Linux用户和组的关系 用户和用户组的对应关系有以下 4 种： 一对一：一个用户可以存在一个组中，是组中的唯一成员； 一对多：一个用户可以存在多个用户组中，此用户具有这多个组的共同权限； 多对一：多个用户可以存在一个组中，这些用户具有和组相同的权限； 多对多：多个用户可以存在多个组中，也就是以上 3 种关系的扩展。 用户和组之间的关系可以用图来表示： 3.2 UID和GID（用户ID和组ID）登陆 Linux 系统时，虽然输入的是自己的用户名和密码，但其实 Linux 并不认识你的用户名称，它只认识用户名对应的 ID 号（也就是一串数字）。Linux 系统将所有用户的名称与 ID 的对应关系都存储在 /etc/passwd 文件中。 说白了，用户名并无实际作用，仅是为了方便用户的记忆而已。 要论证 “Linux系统不认识用户名” 也很简单，在前面章节，我们曾经在网络上下载过 “.tar.gz” 或 “.tar.bz2” 格式的文件，在解压缩之后的文件中，你会发现文件拥有者的属性显示的是一串数字，这很正常，就是因为系统只认识代表你身份的 ID，这串数字就是用户的 ID（UID）号。 Linux 系统中，每个用户的 ID 细分为 2 种，分别是用户 ID（User ID，简称 UID）和组 ID（Group ID，简称 GID），这与文件有拥有者和拥有群组两种属性相对应。 从图中可以看到，该文件的拥有者是超级管理员 root，拥有群组也是 root。读者可能会问，既然 Linux 系统不认识用户名，文件是如何判别它的拥有者名称和群组名称的呢？ 每个文件都有自己的拥有者 ID 和群组 ID，当显示文件属性时，系统会根据 /etc/passwd 和 /etc/group 文件中的内容，分别找到 UID 和 GID 对应的用户名和群组名，然后显示出来。 /etc/passwd 文件和 /etc/group 文件，后续文章会做详细讲解，这里只需要知道，在 /etc/passwd 文件中，利用 UID 可以找到对应的用户名；在 /etc/group 文件中，利用 GID 可以找到对应的群组名。 3.3 groupadd 新增组添加用户组的命令是 groupadd，命令格式如下: groupadd [选项] 组名 选项： -g GID：指定组 ID； -r：创建系统群组。 使用 groupadd 命令创建新群组非常简单，例如： 12345[root@hadoop100 ~]# groupadd group1#添加group1组[root@hadoop100 ~]# grep &quot;group1&quot; /etc/group /etc/gshadow/etc/group:group1:x:1008:/etc/gshadow:group1:!:: 3.4 groupdel 删除组groupdel 命令用于删除用户组（群组），此命令基本格式为： groupdel 组名 通过前面的学习不难猜测出，使用 groupdel 命令删除群组，其实就是删除 /etc/gourp 文件和 /etc/gshadow 文件中有关目标群组的数据信息。 例如，删除前面章节中用 groupadd 命令创建的群组 group1，执行命令如下： 123456[root@hadoop100 ~]# grep &quot;group1&quot; /etc/group /etc/gshadow/etc/group:group1:x:1008:/etc/gshadow:group1:!::[root@hadoop100 ~]# groupdel group1[root@hadoop100 ~]# grep &quot;group1&quot; /etc/group /etc/gshadow[root@hadoop100 ~]# 注意，不能使用 groupdel 命令随意删除群组。此命令仅适用于删除那些 “不是任何用户初始组” 的群组，换句话说，如果有群组还是某用户的初始群组，则无法使用 groupdel 命令成功删除。例如： 1234567891011[root@hadoop100 ~]# useradd temp[root@hadoop100 ~]# id tempuid=1008(temp) gid=1008(temp) groups=1008(temp)#运行如上命令，可以看到 temp 用户建立的同时，还创建了 temp 群组，且将其作为 temp用户的初始组（组ID都是 1008）[root@hadoop100 ~]# grep &quot;temp&quot; /etc/passwd /etc/group /etc/gshadow/etc/passwd:temp:x:1008:1008::/home/temp:/bin/bash/etc/group:temp:x:1008:/etc/gshadow:temp:!::#下面尝试删除 temp 群组[root@hadoop100 ~]# groupdel tempgroupdel: cannot remove the primary group of user &#x27;temp&#x27; 可以看到，groupdel 命令删除 temp 群组失败，且提示“不能删除 temp 用户的初始组”。如果一定要删除 temp 群组，要么修改 temp 用户的 GID，也就是将其初始组改为其他群组，要么先删除 temp 用户。 切记，虽然我们已经学了如何手动删除群组数据，但胡乱地删除群组可能会给其他用户造成不小的麻烦，因此更改文件数据要格外慎重。 3.5 groupmod 修改groupmod 命令用于修改用户组的相关信息，命令格式如下： groupmod [选现] 新组名 旧组名 选项： -g GID：修改组 ID； -n 新组名：修改组名； 例子： 1234567[root@hadoop100 ~]# grep &quot;temp&quot; /etc/grouptemp:x:1008:[root@hadoop100 ~]# groupmod -n tmp temp#把组名temp修改为tmp[root@hadoop100 ~]# grep &quot;tmp&quot; /etc/grouptmp:x:1008:#注意GID还是1008，但是组名已经改变 不过大家还是要注意，用户名不要随意修改，组名和 GID 也不要随意修改，因为非常容易导致管理员逻辑混乱。如果非要修改用户名或组名，则建议大家先删除旧的，再建立新的。 3.6 cat &#x2F;etc&#x2F;group 查看创建了哪些组/ect/group 文件是用户组配置文件，即用户组的所有信息都存放在此文件中。 此文件是记录组 ID（GID）和组名相对应的文件。前面讲过，etc/passwd 文件中每行用户信息的第四个字段记录的是用户的初始组 ID，那么，此 GID 的组名到底是什么呢？就要从 &#x2F;etc&#x2F;group 文件中查找。 &#x2F;etc&#x2F;group 文件的内容可以通过 Vim 看到： 1234567891011121314[root@hadoop100 ~]# vim /etc/grouproot:x:0:tony,pro4bin:x:1:daemon:x:2:…省略部分输出…nailclipper:x:1000:tony:x:1001:user1:x:1002:jery:x:1003:group:x:1004:pro2,pro4pro2:x:1005:pro3:x:1006:pro4:x:1007:tmp:x:1008: 可以看到，此文件中每一行各代表一个用户组。在前面章节中，我们曾创建 tony 用户，系统默认生成一个 tony 用户组，在此可以看到，此用户组的 GID 为 1001，目前它仅作为 tony 用户的初始组。 各用户组中，还是以 “：” 作为字段之间的分隔符，分为 4 个字段，每个字段对应的含义为： 组名：密码：GID：该用户组中的用户列表 接下来，分别介绍各个字段具体的含义。 3.6.1 组名也就是是用户组的名称，有字母或数字构成。同 /etc/passwd 中的用户名一样，组名也不能重复。 3.6.2 组密码和 /etc/passwd 文件一样，这里的 “x” 仅仅是密码标识，真正加密后的组密码默认保存在 /etc/gshadow 文件中。 不过，用户设置密码是为了验证用户的身份，那用户组设置密码是用来做什么的呢？用户组密码主要是用来指定组管理员的，由于系统中的账号可能会非常多，root 用户可能没有时间进行用户的组调整，这时可以给用户组指定组管理员，如果有用户需要加入或退出某用户组，可以由该组的组管理员替代 root 进行管理。但是这项功能目前很少使用，我们也很少设置组密码。如果需要赋予某用户调整某个用户组的权限，则可以使用 sudo 命令代替。 3.6.3 组ID (GID)就是群组的 ID 号，Linux 系统就是通过 GID 来区分用户组的，同用户名一样，组名也只是为了便于管理员记忆。 这里的组 GID 与 /etc/passwd 文件中第 4 个字段的 GID 相对应，实际上，/etc/group 文件中使用 GID 对应的群组名，就是通过此文件对应得到的。 3.6.4 组中的用户此字段列出每个群组包含的所有用户。需要注意的是，如果该用户组是这个用户的初始组，则该用户不会写入这个字段，可以这么理解，该字段显示的用户都是这个用户组的附加用户。 举个例子，tony 组的组信息为 &quot;tony:x:1001:&quot;，可以看到，第四个字段没有写入 tony 用户，因为 tony 组是 tony 用户的初始组。如果要查询这些用户的初始组，则需要先到 /etc/passwd 文件中查看 GID（第四个字段），然后到 /etc/group 文件中比对组名。 每个用户都可以加入多个附加组，但是只能属于一个初始组。所以我们在实际工作中，如果需要把用户加入其他组，则需要以附加组的形式添加。例如，我们想让 tmp 也加入 root 这个群组，那么只需要在第一行的最后一个字段加入 tmp，即 root:x:0:tony,pro4,tmp 就可以了。 一般情况下，用户的初始组就是在建立用户的同时建立的和用户名相同的组。 到此，我们已经学习了/etc/passwd、/etc/shadow、/etc/group，它们之间的关系可以这样理解，即先在 /etc/group 文件中查询用户组的 GID 和组名；然后在 /etc/passwd 文件中查找该 GID 是哪个用户的初始组，同时提取这个用户的用户名和 UID；最后通过 UID 到 /etc/shadow 文件中提取和这个用户相匹配的密码。 07 【文件权限和搜索查找类命令】1.文件权限类1.1 权限管理的重要性和 Windows 系统不同，Linux 系统为每个文件都添加了很多的属性，最大的作用就是维护数据的安全。举个简单的例子，在你的 Linux 系统中，和系统服务相关的文件通常只有 root 用户才能读或写，就拿 &#x2F;etc&#x2F;shadow 这个文件来说，此文件记录了系统中所有用户的密码数据，非常重要，因此绝不能让任何人读取（否则密码数据会被窃取），只有 root 才可以有读取权限。 此外，如果你有一个软件开发团队，你希望团队中的每个人都可以使用某一些目录下的文件，而非团队的其他人则不予以开放。通过前面章节的学习我们知道，只需要将团队中的所有人加入新的群组，并赋予此群组读写目录的权限，即可实现要求。反之，如果你的目录权限没有做好，就很难防止其他人在你的系统中乱搞。 比如说，本来 root 用户才能做的开关机、ADSL 拨接程序，新增或删除用户等命令，一旦允许任何人拥有这些权限，系统很可能会经常莫名其妙的挂掉。而且，万一 root 用户的密码被其他人获取，他们就可以登录你的系统，从事一些只有 root 用户才能执行的操作，这是绝对不允许发生的。 因此，在服务器上，绝对不是所有的用户都使用 root 身份登录，而要根据不同的工作需要和职位需要，合理分配用户等级和权限等级。 在Linux中我们可以使用ll或者ls -l命令来显示一个文件的属性以及文件所属 的用户和组。 12345678[root@hadoop100 ~]# ls -altotal 60dr-xr-x---. 1 root root 382 Feb 21 04:27 .dr-xr-xr-x. 1 root root 158 Oct 24 10:49 ..drwxr-xr-x. 1 root root 4 Feb 21 00:41 a1-rw-------. 1 root root 472 Feb 21 01:17 anaconda-ks.cfg-rw-------. 1 root root 4242 Feb 21 04:27 .bash_history... 1.2 权限位Linux 系统，最常见的文件权限有 3 种，即对文件的读（用 r 表示）、写（用 w 表示）和执行（用 x 表示，针对可执行文件或目录）权限。在 Linux 系统中，每个文件都明确规定了不同身份用户的访问权限，通过 ls 命令即可看到。 除此之外，我们有时会看到 s（针对可执行文件或目录，使文件在执行阶段，临时拥有文件所有者的权限）和 t（针对目录，任何用户都可以在此目录中创建文件，但只能删除自己的文件），文件设置 s 和 t 权限，会占用 x 权限的位置。 例如，我们以 root 的身份登陆 Linux，并执行如下指令： 12345678[root@hadoop100 ~]# ls -altotal 60dr-xr-x---. 1 root root 382 Feb 21 04:27 .dr-xr-xr-x. 1 root root 158 Oct 24 10:49 ..drwxr-xr-x. 1 root root 4 Feb 21 00:41 a1-rw-------. 1 root root 472 Feb 21 01:17 anaconda-ks.cfg-rw-------. 1 root root 4242 Feb 21 04:27 .bash_history... 可以看到，每行的第一列表示的就是各文件针对不同用户设定的权限，一共 11 位，但第 1 位用于表示文件的具体类型，最后一位此文件受 SELinux 的安全规则管理，不是本节关心的内容。 因此，为文件设定不同用户的读、写和执行权限，仅涉及到 9 位字符，以 ls 命令输出信息中的 .bash_logout 文件为例，设定不同用户的访问权限是 rw-r–r–，各权限位的含义如图所示。 从图中可以看到，Linux 将访问文件的用户分为 3 类，分别是文件的所有者，所属组（也就是文件所属的群组）以及其他人。 除了所有者，以及所属群组中的用户可以访问文件外，其他用户（其他群组中的用户）也可以访问文件，这部分用户都归为其他人范畴。 很显然，Linux 系统为 3 种不同的用户身份，分别规定了是否对文件有读、写和执行权限。拿rw-r–r– 来说，文件所有者拥有对文件的读和写权限，但是没有执行权限；所属群组中的用户只拥有读权限，也就是说，这部分用户只能读取文件内容，无法修改文件；其他人也是只能读取文件。 Linux 系统中，多数文件的文件所有者和所属群组都是 root（都是 root 账户创建的），这也就是为什么，root 用户是超级管理员，权限足够大的原因。 1.3 读写执行权限（-r、-w、-x）的含义从左到右的 10 个字符表示 如果没有权限，就会出现减号[ - ]而已。从左至右用0-9这些数字来表示: （1）0 首位表示类型 ​ 在Linux中第一个字符代表这个文件是目录、文件或链接文件等等 - 代表文件 d 代表目录 l 链接文档(link file)； （2）第1-3位确定属主（该文件的所有者）拥有该文件的权限。—User （3）第4-6位确定属组（所有者的同组用户）拥有该文件的权限，—Group （4）第7-9位确定其他用户拥有该文件的权限 —Other rwx 作用文件和目录的不同解释 （1）作用到文件： [ r ]代表可读(read): 可以读取，查看 [ w ]代表可写(write): 可以修改，但是不代表可以删除该文件，删除一个文件的前提条件是对该文件所在的目录有写权限，才能删除该文件 [ x ]代表可执行(execute):可以被系统执行 （2）作用到目录： [ r ]代表可读(read): 可以读取，ls查看目录内容 [ w ]代表可写(write): 可以修改，目录内创建+删除+重命名目录 [ x ]代表可执行(execute):可以进入该目录 案例实操 1234567891011121314[root@hadoop100 ~]# lltotal 12drwxr-xr-x. 1 root root 4 Feb 21 00:41 a1-rw-------. 1 root root 472 Feb 21 01:17 anaconda-ks.cfgdrwxr-xr-x. 1 root root 14 Feb 21 01:35 Desktopdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Documentsdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Downloadsdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Musiclrwxrwxrwx. 1 root root 28 Feb 21 01:40 new -&gt; /root/Desktop/base/file3.txtlrwxrwxrwx. 1 root root 19 Feb 21 01:44 new2 -&gt; /root/Desktop/base/drwxr-xr-x. 1 root root 0 Feb 20 10:05 Picturesdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Publicdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Templatesdrwxr-xr-x. 1 root root 0 Feb 20 10:05 Videos （1）如果查看到是文件：链接数指的是硬链接个数。 （2）如果查看的是文件夹：链接数指的是子文件夹个数。 1.4 chmod 改变权限既然我们已经知道文件权限对于一个系统的重要性，也知道每个文件都设定了针对不同用户的访问权限，那么，是否可以手动修改文件的访问权限呢？ 可以，通过 chmod 命令即可。chmod 命令设定文件权限的方式有 2 种，分别可以使用数字或者符号来进行权限的变更。 1.4.1 chmod命令使用数字修改文件权限Linux 系统中，文件的基本权限由 9 个字符组成，以 rwxrw-r-x 为例，我们可以使用数字来代表各个权限，各个权限与数字的对应关系如下： 123r --&gt; 4w --&gt; 2x --&gt; 1 由于这 9 个字符分属 3 类用户，因此每种用户身份包含 3 个权限（r、w、x），通过将 3 个权限对应的数字累加，最终得到的值即可作为每种用户所具有的权限。 拿 rwxrw-r-x 来说，所有者、所属组和其他人分别对应的权限值为： 123所有者 = rwx = 4+2+1 = 7所属组 = rw- = 4+2 = 6其他人 = r-x = 4+1 = 5 所以，此权限对应的权限值就是 765。 使用数字修改文件权限的 chmod 命令基本格式为： chmod [-R] 权限值 文件名 -R（注意是大写）选项表示连同子目录中的所有文件，也都修改设定的权限。 例如，使用如下命令，即可完成对 .bashrc 目录文件的权限修改： 12345[root@hadoop100 ~]# ls -al .bashrc-rw-r--r--. 1 root root 429 Jul 18 2024 .bashrc[root@hadoop100 ~]# chmod 777 .bashrc[root@hadoop100 ~]# ls -al .bashrc-rwxrwxrwx. 1 root root 429 Jul 18 2024 .bashrc 再举个例子，通常我们以 Vim 编辑 Shell 文件批处理文件后，文件权限通常是 rw-r–r–（644），那么，如果要将该文件变成可执行文件，并且不让其他人修改此文件，则只需将此文件的权限该为 rwxr-xr-x（755）即可。 修改整个文件夹里面的所有文件的所有者、所属组、其他用户都具有可读可写可 执行权限。 1[root@hadoop100 ~]# chmod -R 777 .bashrc 1.4.2 chmod命令使用字母修改文件权限既然文件的基本权限就是 3 种用户身份（所有者、所属组和其他人）搭配 3 种权限（rwx），chmod 命令中用 u、g、o 分别代表 3 种身份，还用 a 表示全部的身份（all 的缩写）。另外，chmod 命令仍使用 r、w、x 分别表示读、写、执行权限。 使用字母修改文件权限的 chmod 命令，其基本格式如图所示。 例如，如果我们要设定 .bashrc 文件的权限为 rwxr-xr-x，则可执行如下命令： 12345[root@hadoop100 ~]# ls -al .bashrc-rwxrwxrwx. 1 root root 429 Jul 18 2024 .bashrc[root@hadoop100 ~]# chmod u=rwx,go=rx .bashrc[root@hadoop100 ~]# ls -al .bashrc-rwxr-xr-x. 1 root root 429 Jul 18 2024 .bashrc 再举个例子，如果想要增加 .bashrc 文件的每种用户都可做写操作的权限，可以使用如下命令： 12345[root@hadoop100 ~]# ls -al .bashrc-rwxr-xr-x. 1 root root 429 Jul 18 2024 .bashrc[root@hadoop100 ~]# chmod a+w .bashrc[root@hadoop100 ~]# ls -al .bashrc-rwxrwxrwx. 1 root root 429 Jul 18 2024 .bashrc 实际还是以数字修改为主 1.5 chown 改变所有者和所属组chown 命令，可以认为是 “change owner” 的缩写，主要用于修改文件（或目录）的所有者，除此之外，这个命令也可以修改文件（或目录）的所属组。 当只需要修改所有者时，可使用如下 chown 命令的基本格式： chown [-R] 所有者 文件或目录 -R（注意大写）选项表示连同子目录中的所有文件，都更改所有者。 如果需要同时更改所有者和所属组，chown 命令的基本格式为： chown [-R] 所有者:所属组 文件或目录 注意，在 chown 命令中，所有者和所属组中间也可以使用点（.），但会产生一个问题，如果用户在设定账号时加入了小数点（例如 zhangsan.temp），就会造成系统误判。因此，建议大家使用冒号连接所有者和所属组。 当然，chown 命令也支持单纯的修改文件或目录的所属组，例如 chown :group install.log 就表示修改 install.log 文件的所属组，但修改所属组通常使用 chgrp 命令，因此并不推荐大家使用 chown 命令。 另外需要注意的一点是，使用 chown 命令修改文件或目录的所有者（或所属者）时，要保证使用者用户（或用户组）存在，否则该命令无法正确执行，会提示 “invalid user” 或者 “invaild group”。 【例 1】其实，修改文件的所有者，更多时候是为了得到更高的权限，举一个实例： 12345678910[root@hadoop100 ~]# touch file#由root用户创建file文件[root@hadoop100 ~]# ll file-rw-r--r--. 1 root root 0 Feb 21 04:39 file#文件的所有者是root，普通用户user对这个文件拥有只读权限[root@hadoop100 ~]# chown tony file#修改文件的所有者[root@hadoop100 ~]# ll file-rw-r--r--. 1 tony root 0 Feb 21 04:39 file#所有者变成了tony用户，这时tony用户对这个文件就拥有了读、写权限 可以看到，通过修改 file 文件的所有者，tony 用户从其他人身份（只对此文件有读取权限）转变成了所有者身份，对此文件拥有读和写权限。 【例 2】Linux 系统中，用户等级权限的划分是非常清楚的，root 用户拥有最高权限，可以修改任何文件的权限，而普通用户只能修改自己文件的权限（所有者是自己的文件），例如： 1234567891011121314151617181920212223[root@hadoop100 ~]# cd /home/user#进入user用户的家目录[root@hadoop100 user]# touch test#由root用户新建文件test[root@hadoop100 user]# ll test-rw-r--r--. 1 root root 0 Feb 21 04:47 test#文件所有者和所属组都是root用户[root@hadoop100 user]# su - user#切换为user用户[user@hadoop100 ~]$ chmod 755 testchmod: changing permissions of &#x27;test&#x27;: Operation not permitted#user用户不能修改test文件的权限[user@hadoop100 ~]$ exit#退回到root身份[root@hadoop100 user]# chown user test#由root用户把test文件的所有者改为user用户[root@hadoop100 user]# su - user#切换为user用户[user@hadoop100 ~]$ chmod 755 test#user用户由于是test文件的所有者，所以可以修改文件的权限[user@hadoop100 ~]$ ll test-rwxr-xr-x. 1 user root 0 Feb 21 04:47 test#查看权限 可以看到，user 用户无权更改所有者为 root 用户文件的权限，只有普通用户是这个文件的所有者，才可以修改文件的权限。 【例 3】 12345[root@hadoop100 ~]# ll file-rw-r--r--. 1 tony root 0 Feb 21 04:39 file[root@hadoop100 ~]# chown user:group file[root@hadoop100 ~]# ll file-rw-r--r--. 1 user group 0 Feb 21 04:39 file 1.6 chgrp 改变所属组chgrp 命令用于修改文件（或目录）的所属组。 为了方便初学者记忆，可以将 chgrp 理解为是 “change group” 的缩写。 chgrp 命令的用法很简单，其基本格式为： chgrp [-R] 所属组 文件名（目录名） -R（注意是大写）选项长作用于更改目录的所属组，表示更改连同子目录中所有文件的所属组信息。 使用此命令需要注意的一点是，要被改变的群组名必须是真实存在的，否则命令无法正确执行，会提示 “invaild group name”。 举个例子，在主目录中新建nw文件，我们可以使用如下方法修改此文件的所属组： 123456789[root@hadoop100 ~]# groupadd grp1#新建用于测试的群组 grp1[root@hadoop100 ~]# chgrp grp1 nw#修改nw文件的所属组为grp1[root@hadoop100 ~]# ll nw-rw-r--r--. 1 root grp1 0 Feb 21 04:57 nw#修改生效[root@hadoop100 ~]# chgrp grp2 nwchgrp: invalid group: ‘grp2’ 可以看到，在具有 grp1 群组的前提下，我们成功修改了 nw 文件的所属组，但我们再次试图将所属组修改为 grp2 时，命令执行失败，就是因为系统的 &#x2F;etc&#x2F;group 文件中，没有 grp2 群组。 2.搜索查找类2.1 find 查找文件或者目录Linux find 命令用来在指定目录下查找文件。任何位于参数之前的字符串都将被视为欲查找的目录名。如果使用该命令时，不设置任何参数，则 find 命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示。find 命令有非常大的灵活性，可以向其指定丰富的搜索条件（如文件权限、属主、属组、文件类型、日期和大小等）来定位系统中的文件和目录。此外，find 还支持对搜索到的结果进行多种类型的命令操作。 1）基本语法 find [搜索范围] [选项] 2）选项说明 -name&lt;查询方式&gt; 按照指定的文件名查找模式查找文件 -user&lt;用户名&gt; 查找属于指定用户名所有文件 -size&lt;文件大小&gt; 按照指定的文件大小查找文件,单位为 b —— 块（512 字节） c —— 字节 w —— 字（2 字节） k —— 千字节 M —— 兆字节 G ——千兆字节 3）案例实操 （1）按文件名：根据名称查找&#x2F;目录下的filename.txt文件。 find xiyou/ -name &quot;*.txt&quot; (2) 将当前目录及其子目录下所有文件后缀为 .c 的文件列出来 find . -name &quot;*.c&quot; （3）按拥有者：查找&#x2F;opt目录下，用户名称为 atguigu 的文件 find xiyou/ -user atguigu （4）按文件大小：在&#x2F;home目录下查找大于200m的文件（+n 大于 -n小于 n等于） find /home -size +204800 2.2 locate 快速定位文件路径Linux locate命令用于查找符合条件的文档，他会去保存文档和目录名称的数据库内，查找合乎范本样式条件的文档或目录。 一般情况我们只需要输入 locate your_file_name 即可查找指定文件。 Locate 指令无需遍历整个文件系统，查询速度较快。为了保证查询结果的准确 度，管理员必须定期更新 locate 时刻。 1）基本语法 ​ locate 搜索文件 2）经验技巧 locate 与 find 不同: find 是去硬盘找，locate 只在 /var/lib/slocate 资料库中找。 locate 的速度比 find 快，它并不是真的查找，而是查数据库，一般文件数据库在 /var/lib/plocate 中，所以 locate 的查找并不是实时的，而是以数据库的更新为准，一般是系统自己维护，也可以手工升级数据库 ，命令为： 1updatedb 3）案例实操 查询文件夹 12[root@hadoop100 ~]# updatedb[root@hadoop100 ~]# locate new2 查找 passwd 文件，输入以下命令： 1[root@hadoop100 ~]# locate passwd 2.3 grep 过滤查找Linux grep 命令用于查找文件里符合条件的字符串。 grep 指令用于查找内容包含指定的范本样式的文件，如果发现某文件的内容符合所指定的范本样式，预设 grep 指令会把含有范本样式的那一列显示出来。若不指定任何文件名称，或是所给予的文件名为 -，则 grep 指令会从标准输入设备读取数据。 基本语法 grep 选项 查找内容 源文件 -n 或 –line-number : 在显示符合样式的那一行之前，标示出该行的列数编号。 实例 1、在当前目录中，查找后缀有 file 字样的文件中包含 test 字符串的文件，并打印出该字符串的行。此时，可以使用如下命令：ll 1[root@hadoop100 ~]# grep test *file 查找前缀有“test”的文件包含“test”字符串的文件 1234[root@hadoop100 ~]# grep test test* #查找前缀有“test”的文件包含“test”字符串的文件 testfile1:This a Linux testfile! #列出testfile1 文件中包含test字符的行 testfile_2:This is a linux testfile! #列出testfile_2 文件中包含test字符的行 testfile_2:Linux test #列出testfile_2 文件中包含test字符的行 2、系统报警显示了时间，但是日志文件太大无法直接 cat 查看。(查询含有特定文本的文件，并拿到这些文本所在的行) 1[root@hadoop100 ~]# grep -n &#x27;2025-2-21 00:18:11&#x27; *.log 2.4 “|”管道符 管道符主要用于多重命令处理，前面命令的打印结果作为后面命令的输入。简单点说就是，就像工厂的流水线一样，进行完一道工序后，继续传送给下一道工序处理… # cat /etc/passwd | grep /bin/bash 这条命令使用了两个管道，利用第一个管道将cat命令（显示passwd文件的内容）的输出送给grep命令，grep命令找出含有/bin/bash的所有行； **例 ** 查找某文件在第几行 [root@hadoop100 ~]# ls | grep -n test 2.5 wc 计算字数Linux wc命令用于计算字数。 利用wc指令我们可以计算文件的Byte数、字数、或是列数，若不指定文件名称、或是所给予的文件名为”-“，则wc指令会从标准输入设备读取数据。 语法 wc [-clw][--help][--version][文件...] -c或–bytes或–chars 只显示Bytes数。 -l或–lines 显示行数。 -w或–words 只显示字数。 –help 在线帮助。 –version 显示版本信息。 例1 在默认的情况下，wc将计算指定文件的行数、字数，以及字节数。使用的命令为： 1[root@hadoop100 ~]# wc testfile 先查看testfile文件的内容，可以看到： 12345678[root@hadoop100 ~]# cat testfile Linux networks are becoming more and more common, but scurity is often an overlooked issue. Unfortunately, in today’s environment all networks are potential hacker targets, fro0m tp-secret military research networks to small home LANs. Linux Network Securty focuses on securing Linux in a networked environment, where the security of the entire network needs to be considered rather than just isolated machines. It uses a mix of theory and practicl techniques to teach administrators how to install and use security applications, as well as how the applcations work and why they are necesary. 使用 wc统计，结果如下： 12[root@hadoop100 ~]# wc testfile # testfile文件的统计信息 3 92 598 testfile # testfile文件的行数为3、单词数92、字节数598 其中，3 个数字分别表示testfile文件的行数、单词数，以及该文件的字节数。 例2 如果想同时统计多个文件的信息，例如同时统计testfile、testfile_1、testfile_2，可使用如下命令： 1[root@hadoop100 ~]# wc testfile testfile_1 testfile_2 #统计三个文件的信息 输出结果如下： 12345[root@hadoop100 ~]# wc testfile testfile_1 testfile_2 #统计三个文件的信息 3 92 598 testfile #第一个文件行数为3、单词数92、字节数598 9 18 78 testfile_1 #第二个文件的行数为9、单词数18、字节数78 3 6 32 testfile_2 #第三个文件的行数为3、单词数6、字节数32 15 116 708 总用量 #三个文件总共的行数为15、单词数116、字节数708 08 【压缩和解压类】1.打包（归档）和压缩归档，也称为打包，指的是一个文件或目录的集合，而这个集合被存储在一个文件中。归档文件没有经过压缩，因此，它占用的空间是其中所有文件和目录的总和。 通常，归档总是会和系统（数据）备份联系在一起，不过，有关数据备份的内容，留到后续章节讲，本章仅学习归档命令的基本使用。 和归档文件类似，压缩文件也是一个文件和目录的集合，且这个集合也被存储在一个文件中，但它们的不同之处在于，压缩文件采用了不同的存储方式，使其所占用的磁盘空间比集合中所有文件大小的总和要小。 压缩是指利用算法将文件进行处理，已达到保留最大文件信息，而让文件体积变小的目的。其基本原理为，通过查找文件内的重复字节，建立一个相同字节的词典文件，并用一个代码表示。比如说，在压缩文件中，有不止一处出现了 “C语言中文网”，那么，在压缩文件时，这个词就会用一个代码表示并写入词典文件，这样就可以实现缩小文件体积的目的。 由于计算机处理的信息是以二进制的形式表示的，因此，压缩软件就是把二进制信息中相同的字符串以特殊字符标记，只要通过合理的数学计算，文件的体积就能够被大大压缩。把一个或者多个文件用压缩软件进行压缩，形成一个文件压缩包，既可以节省存储空间，又方便在网络上传送。 如果你能够理解文件压缩的基本原理，那么很容易就能想到，对文件进行压缩，很可能损坏文件中的内容，因此，压缩又可以分为有损压缩和无损压缩。无损压缩很好理解，指的是压缩数据必须准确无误；有损压缩指的是即便丢失个别的数据，对文件也不会造成太大的影响。有损压缩广泛应用于动画、声音和图像文件中，典型代表就是影碟文件格式 mpeg、音乐文件格式 mp3 以及图像文件格式 jpg。 采用压缩工具对文件进行压缩，生成的文件称为压缩包，该文件的体积通常只有原文件的一半甚至更小。需要注意的是，压缩包中的数据无法直接使用，使用前需要利用压缩工具将文件数据还原，此过程又称解压缩。 Linux 下，常用归档命令有 2 个，分别是 tar 和 dd（相对而言，tar 的使用更为广泛）；常用的压缩命令有很多，比如 gzip、zip、bzip2 等。这些命令的详细用法，后续文件会做一一介绍。 注意，tar 命令也可以作为压缩命令，也很常用。 2.gzip&#x2F;gunzip 压缩2.1 gzip压缩文件gzip 是 Linux 系统中经常用来对文件进行压缩和解压缩的命令，通过此命令压缩得到的新文件，其扩展名通常标记为“.gz”。 再强调一下，gzip 命令只能用来压缩文件，不能压缩目录，即便指定了目录，也只能压缩目录内的所有文件。 gzip 命令的基本格式如下： gzip [选项] 源文件 命令中的源文件，当进行压缩操作时，指的是普通文件；当进行解压缩操作时，指的是压缩文件。 选项 含义 -c 将压缩数据输出到标准输出中，并保留源文件。 -d 对压缩文件进行解压缩。 -r 递归压缩指定目录下以及子目录下的所有文件。 -v 对于每个压缩和解压缩的文件，显示相应的文件名和压缩比。 -l 对每一个压缩文件，显示以下字段：压缩文件的大小；未压缩文件的大小；压缩比；未压缩文件的名称。 -数字 用于指定压缩等级，-1 压缩等级最低，压缩比最差；-9 压缩比最高。默认压缩比是 -6。 【例 1】基本压缩。gzip 压缩命令非常简单，甚至不需要指定压缩之后的压缩包名，只需指定源文件名即可。我们来试试： 1234567[root@hadoop100 ~]# gzip file#压缩 file 文件[root@hadoop100 ~]# lsa1 Documents Music nw Templatesanaconda-ks.cfg Downloads new Pictures VideosDesktop file.gz new2 Public#压缩文件生成，但是源文件也消失了 【例 2】保留源文件压缩。在使用 gzip 命令压缩文件时，源文件会消失，从而生成压缩文件。能不能在压缩文件的时候，不让源文件消失？ 1234567[root@hadoop100 ~]# gzip -c anaconda-ks.cfg &gt; anaconda-ks.cfg.gz#使用-c选项，但是不让压缩数据输出到屏幕上，而是重定向到压缩文件中，这样可以缩文件的同时不删除源文件[root@hadoop100 ~]# lsa1 Desktop file.gz new2 Publicanaconda-ks.cfg Documents Music nw Templatesanaconda-ks.cfg.gz Downloads new Pictures Videos#可以看到压缩文件和源文件都存在 【例 3】 压缩目录。我们可能会想当然地认为 gzip 命令可以压缩目录。 我们来试试： 1234567891011121314[root@hadoop100 ~]# mkdir test[root@hadoop100 ~]# touch test/&#123;test1,test2,test3&#125;#建立测试目录，并在里面建立几个测试文件[root@hadoop100 ~]# gzip -r test/#压缩目录，并没有报错[root@hadoop100 ~]# lsa1 Documents new Publicanaconda-ks.cfg Downloads new2 Templatesanaconda-ks.cfg.gz file.gz nw testDesktop Music Pictures Videos#但是查看发现test目录依然存在，并没有变为压缩文件[root@hadoop100 ~]# ls test/test1.gz test2.gz test3.gz#原来gzip命令不会打包目录，而是把目录下所有的子文件分别压缩 在 Linux 中，打包和压缩是分开处理的。而 gzip 命令只会压缩，不能打包，所以才会出现没有打包目录，而只把目录下的文件进行压缩的情况。 2.2 gunzip解压缩文件gunzip 是一个使用广泛的解压缩命令，它用于解压被 gzip 压缩过的文件（扩展名为 .gz）。 对于解压被 gzip 压缩过的文件，还可以使用 gzip 自己，即 gzip -d 解压缩包。 gunzip 命令的基本格式为： gunzip [选项] 文件 选项 含义 -r 递归处理，解压缩指定目录下以及子目录下的所有文件。 -c 把解压缩后的文件输出到标准输出设备。 -f 强制解压缩文件，不理会文件是否已存在等情况。 -l 列出压缩文件内容。 -v 显示命令执行过程。 -t 测试压缩文件是否正常，但不对其做解压缩操作。 【例 1】直接解压缩文件。 [root@hadoop100 ~]# gunzip file.gz 当然，”gunzip -r”依然只会解压缩目录下的文件，而不会解打包。要想解压缩”.gz”格式，还可以使用 “gzip -d”命令，例如： [root@hadoop100 ~]# gzip -d anaconda-ks.cfg.gz 【例 2】要解压缩目录下的内容，则需使用 “-r” 选项，例如： [root@hadoop100 ~]# gunzip -r test/ 注意，如果我们压缩的是一个纯文本文件，则可以直接使用 zcat 命令在不解压缩的情况下查看这个文本文件中的内容。例如： [root@hadoop100 ~]# zcat anaconda-ks.cfg.gz 总结 （1）只能压缩文件不能压缩目录 （2）不保留原来的文件 （3）同时多个文件会产生多个压缩包 3.zip&#x2F;unzip 压缩3.1 zip压缩文件或目录我们经常会在 Windows 系统上使用 “.zip”格式压缩文件，其实“.zip”格式文件是 Windows 和 Linux 系统都通用的压缩文件类型，属于几种主流的压缩格式（zip、rar等）之一，是一种相当简单的分别压缩每个文件的存储格式， 本节要讲的 zip 命令，类似于 Windows 系统中的 winzip 压缩程序，其基本格式如下： zip [选项] 压缩包名 源文件或源目录列表 注意，zip 压缩命令需要手工指定压缩之后的压缩包名，注意写清楚扩展名，以便解压缩时使用。 选项 含义 -r 递归压缩目录，及将制定目录下的所有文件以及子目录全部压缩。 -m 将文件压缩之后，删除原始文件，相当于把文件移到压缩文件中。 -v 显示详细的压缩过程信息。 -q 在压缩的时候不显示命令的执行过程。 -压缩级别 压缩级别是从 1~9 的数字，-1 代表压缩速度更快，-9 代表压缩效果更好。 -u 更新压缩文件，即往压缩文件中添加新文件。 下面给大家举几个例子。 【例 1】zip 命令的基本使用。 123456[root@hadoop100 ~]# zip ana.zip anaconda-ks.cfg adding: anaconda-ks.cfg (deflated 35%)#压缩[root@hadoop100 ~]# ll ana.zip-rw-r--r--. 1 root root 486 Feb 21 05:28 ana.zip#压缩文件生成 不仅如此，所有的压缩命令都可以同时压缩多个文件，例如： 12345678[root@hadoop100 ~]# zip test.zip nw file ana.zip adding: nw (stored 0%) adding: file (stored 0%) adding: ana.zip (stored 0%)#同时压缩多个文件到test.zip压缩包中[root@hadoop100 ~]# ll test.zip-rw-r--r--. 1 root root 918 Feb 21 05:30 test.zip#压缩文件生成 【例 2】使用 zip 命令压缩目录，需要使用“-r”选项，例如： 12345678[root@hadoop100 ~]# mkdir dir1#建立测试目录[root@hadoop100 ~]# zip -r dir1.zip dir1adding: dir1/(stored 0%)#压缩目录[root@hadoop100 ~]# ls -dl dir1.zip-rw-r--r-- 1 root root 160 Feb 21 05:30 dir1.zip#压缩文件生成 3.2 unzip解压zip文件unzip 命令可以查看和解压缩 zip 文件。该命令的基本格式如下： unzip [选项] 压缩包名 选项 含义 -d 目录名 将压缩文件解压到指定目录下。 -n 解压时并不覆盖已经存在的文件。 -o 解压时覆盖已经存在的文件，并且无需用户确认。 -v 查看压缩文件的详细信息，包括压缩文件中包含的文件大小、文件名以及压缩比等，但并不做解压操作。 -t 测试压缩文件有无损坏，但并不解压。 -x 文件列表 解压文件，但不包含文件列表中指定的文件。 【例 1】不论是文件压缩包，还是目录压缩包，都可以直接解压缩，例如： 1234[root@hadoop100 ~]# unzip dir1.zipArchive: dir1.zipcreating: dirl/#解压缩 【例 2】使用 -d 选项手动指定解压缩位置，例如： 1234[root@hadoop100 ~]# unzip -d /tmp/ ana.zipArchive: ana.zipinflating: /tmp/anaconda-ks.cfg#把压缩包解压到指定位置 总结 zip 压缩命令在windows&#x2F;linux都通用，可以压缩目录且保留源文件。 4.tar 打包Linux 系统中，最常用的归档（打包）命令就是 tar，该命令可以将许多文件一起保存到一个单独的磁带或磁盘中进行归档。不仅如此，该命令还可以从归档文件中还原所需文件，也就是打包的反过程，称为解打包。 使用 tar 命令归档的包通常称为 tar 包（tar 包文件都是以“.tar”结尾的）。 4.1 tar命令做打包操作当 tar 命令用于打包操作时，该命令的基本格式为： tar [选项] 源文件或目录 选项 含义 -z 打包同时压缩 -c 将多个文件或目录进行打包。 -A 追加 tar 文件到归档文件。 -f 包名 指定包的文件名。包的扩展名是用来给管理员识别格式的，所以一定要正确指定扩展名； -v 显示打包文件过程； 需要注意的是，在使用 tar 命令指定选项时可以不在选项前面输入“-”。例如，使用“cvf”选项和 “-cvf”起到的作用一样。 下面给大家举几个例子，一起看看如何使用 tar 命令打包文件和目录。 【例 1】打包文件和目录。 123[root@hadoop100 ~]# tar -cvf anaconda-ks.tar anaconda-ks.cfganaconda-ks.cfg#把anacondehks.cfg打包为 anacondehks.tar文件 选项 “-cvf” 一般是习惯用法，记住打包时需要指定打包之后的文件名，而且要用 “.tar” 作为扩展名。打包目录也是如此： 123456789[root@hadoop100 ~]# ll -d test/drwxr-xr-x. 1 root root 30 Feb 21 05:27 test/#test是我们之前的测试目录[root@hadoop100 ~]# tar -cvf test.tar test/test/test/test1test/test2test/test3#把目录打包为test.tar文件 tar命令也可以打包多个文件或目录，只要用空格分开即可。例如: 1234[root@hadoop100 ~]# tar -cvf an.tar ana.zip anaconda-ks.cfgana.zipanaconda-ks.cfg#把anaconda-ks.cfg文件和ana.zip文件打包成an.tar文件包 【例 2】打包并压缩多个文件。 12345[root@hadoop100 opt]# tar -zcvf houma.tar.gz houge.txt bailongma.txthouge.txtbailongma.txt[root@hadoop100 opt]# lshouma.tar.gz houge.txt bailongma.txt 【例 3】打包压缩目录。 1234[root@hadoop100 ~]# tar -zcvf xiyou.tar.gz xiyou/xiyou/xiyou/dsst/xiyou/dsst/houge.txt 4.2 tar命令做解打包操作当 tar 命令用于对 tar 包做解打包操作时，该命令的基本格式如下： tar [选项] 压缩包当用于解打包时，常用的选项与含义如表 2 所示。 选项 含义 -x 对 tar 包做解打包操作。 -f 指定要解压的 tar 包的包名。 -t 只查看 tar 包中有哪些文件或目录，不对 tar 包做解打包操作。 -C 目录 指定解打包位置。 -v 显示解打包的具体过程。 其实解打包和打包相比，只是把打包选项 “-cvf” 更换为 “-xvf”。我们来试试： 12[root@hadoop100 ~]# tar -xvf anaconda-ks.cfg.tar#解打包到当前目录下 如果使用 “-xvf” 选项，则会把包中的文件解压到当前目录下。如果想要指定解压位置，则需要使用 “-C(大写)” 选项。例如： 12[root@hadoop100 ~]# tar -xvf test.tar -C /tmp#把文件包test.tar解打包到/tmp/目录下 如果只想查看文件包中有哪些文件，则可以把解打包选项 “-x” 更换为测试选项 “-t”。例如： 123456[root@hadoop100 ~]# tar -tvf test.tardrwxr-xr-x root/root 0 2025-02-21 05:27 test/-rw-r--r-- root/root 0 2025-02-21 05:21 test/test1-rw-r--r-- root/root 0 2025-02-21 05:21 test/test2-rw-r--r-- root/root 0 2025-02-21 05:21 test/test3#会用长格式显示test.tar文件包中文件的详细信息 ​ 09 【磁盘查看和分区类】1.du 查看文件和目录占用的磁盘空间du: disk usage 磁盘占用情况 du 是统计目录或文件所占磁盘空间大小的命令。 需要注意的是，使用”ls -r”命令是可以看到文件的大小的。但是大家会发现，在使用”ls -r”命令査看目录大小时，目录的大小多数是 4KB，这是因为目录下的子目录名和子文件名是保存到父目录的 block（默认大小为 4KB）中的，如果父目录下的子目录和子文件并不多，一个 block 就能放下，那么这个父目录就只占用了一个 block 大小。 大家可以将其想象成图书馆的书籍目录和实际书籍。如果我们用”ls-l”命令査看，则只能看到这些书籍占用了 1 页纸的书籍目录，但是实际书籍到底有多少是看不到的，哪怕它堆满了几个房间。 但是我们在统计目录时，不是想看父目录下的子目录名和子文件名到底占用了多少空间，而是想看父目录下的子目录和子文件的总磁盘占用量大小，这时就需要使用 du 命令才能统计目录的真正磁盘占用量大小。 du 命令的格式如下： du [选项] [目录或文件名] 选项： -a：显示每个子文件的磁盘占用量。默认只统计子目录的磁盘占用量 -h：使用习惯单位显示磁盘占用量，如 KB、MB 或 GB 等； -s：统计总磁盘占用量，而不列出子目录和子文件的磁盘占用量 -max-depth&#x3D;n：指定统计子目录的深度为第n层 【例 1】 123456789[root@hadoop100 ~]# du | tail -n 3#统计当前目录的总磁盘占用量大小，同时会统计当前目录下所有子目录的磁盘占用量大小，不统计子文件磁盘占用量的大小。默认单位为KB0 ./a1/b2/c30 ./a1/b20 ./a10 ./test#统计每个子目录的大小16588 .#统计当前目录总大小 【例 2】 12345678[root@hadoop100 ~]# du -a#统计当前目录的总大小，同时会统计当前目录下所有子文件和子目录磁盘占用量的大小。默认单位为 KB…省略部分输出…4 ./test.zip12 ./anaconda-ks.tar12 ./test.tar12 ./an.tar16588 . 【例 3】 123[root@hadoop100 ~]# du -sh#只统计磁盘占用量总的大小，同时使用习惯单位显示17M . 2.df 查看磁盘空间使用情况df: disk free 空余磁盘 df 命令，用于显示 Linux 系统中各文件系统的硬盘使用情况，包括文件系统所在硬盘分区的总容量、已使用的容量、剩余容量等。 df 命令主要读取的数据几乎都针对的是整个文件系统。 df 命令的基本格式为： df [选项] [目录或文件名] 选项 作用 -a 显示所有文件系统信息，包括系统特有的 &#x2F;proc、&#x2F;sysfs 等文件系统； -m 以 MB 为单位显示容量； -k 以 KB 为单位显示容量，默认以 KB 为单位； -h 使用人们习惯的 KB、MB 或 GB 等单位自行显示容量； -T 显示该分区的文件系统类型； -i 不用硬盘容量显示，而是以含有 inode 的数量来显示。 【例 1】 1234567891011121314151617181920[root@hadoop100 ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/nvme0n1p3 40891392 5609432 34660584 14% /devtmpfs 4096 0 4096 0% /devtmpfs 978592 8 978584 1% /dev/shmtmpfs 391440 1408 390032 1% /runtmpfs 1024 0 1024 0% /run/credentials/systemd-journald.servicetmpfs 1024 0 1024 0% /run/credentials/systemd-network-generator.servicetmpfs 1024 0 1024 0% /run/credentials/systemd-udev-load-credentials.servicetmpfs 1024 0 1024 0% /run/credentials/systemd-tmpfiles-setup-dev-early.servicetmpfs 1024 0 1024 0% /run/credentials/systemd-sysctl.servicetmpfs 1024 0 1024 0% /run/credentials/systemd-tmpfiles-setup-dev.servicetmpfs 978592 8 978584 1% /tmp/dev/nvme0n1p3 40891392 5609432 34660584 14% /home/dev/nvme0n1p2 996780 274744 653224 30% /boottmpfs 1024 0 1024 0% /run/credentials/systemd-tmpfiles-setup.servicetmpfs 1024 0 1024 0% /run/credentials/systemd-resolved.servicetmpfs 1024 0 1024 0% /run/credentials/systemd-vconsole-setup.servicetmpfs 195716 88 195628 1% /run/user/42tmpfs 195716 72 195644 1% /run/user/0 不使用任何选项的 df 命令，默认会将系统内所有的文件系统信息，以 KB 为单位显示出来。 本例中，由 df 命令显示出的各列信息的含义分别是： Filesystem：表示该文件系统位于哪个分区，因此该列显示的是设备名称； 1K-blocks：此列表示文件系统的总大小，默认以 KB 为单位； Used：表示用掉的硬盘空间大小； Available：表示剩余的硬盘空间大小； Use%：硬盘空间使用率。如果使用率高达 90% 以上，就需要额外注意，因为容量不足，会严重影响系统的正常运行； Mounted on：文件系统的挂载点，也就是硬盘挂载的目录位置。 【例 2】 1234567891011121314151617181920[root@hadoop100 ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/nvme0n1p3 39G 5.4G 34G 14% /devtmpfs 4.0M 0 4.0M 0% /devtmpfs 956M 8.0K 956M 1% /dev/shmtmpfs 383M 1.4M 381M 1% /runtmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-journald.servicetmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-network-generator.servicetmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-udev-load-credentials.servicetmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-tmpfiles-setup-dev-early.servicetmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-sysctl.servicetmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-tmpfiles-setup-dev.servicetmpfs 956M 8.0K 956M 1% /tmp/dev/nvme0n1p3 39G 5.4G 34G 14% /home/dev/nvme0n1p2 974M 269M 638M 30% /boottmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-tmpfiles-setup.servicetmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-resolved.servicetmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-vconsole-setup.servicetmpfs 192M 88K 192M 1% /run/user/42tmpfs 192M 72K 192M 1% /run/user/0 同例 1 不同，这里使用了 -h 选项，因此文件系统的各种容量数据，会以人们习惯的单位（通常使用 GB 或 MB）显示出来。 【例 3】 123[root@hadoop100 ~]# df -h /etcFilesystem Size Used Avail Use% Mounted on/dev/nvme0n1p3 39G 5.4G 34G 14% / 同之前的 2 个例子不同，这里在 df 命令后添加了目录名，在这种情况下，df 命令会自动分析该目录所在的分区，并将所在分区的有关信息显示出来。由此，我们就可以知道，该目录下还可以使用多少容量。 【例 4】 123456789101112131415161718192021222324252627282930313233343536373839[root@hadoop100 ~]# df -aTFilesystem Type 1K-blocks Used Available Use% Mounted on/dev/nvme0n1p3 btrfs 40891392 5609788 34660228 14% /devtmpfs devtmpfs 4096 0 4096 0% /devtmpfs tmpfs 978592 8 978584 1% /dev/shmdevpts devpts 0 0 0 - /dev/ptssysfs sysfs 0 0 0 - /syssecurityfs securityfs 0 0 0 - /sys/kernel/securitycgroup2 cgroup2 0 0 0 - /sys/fs/cgrouppstore pstore 0 0 0 - /sys/fs/pstorebpf bpf 0 0 0 - /sys/fs/bpfconfigfs configfs 0 0 0 - /sys/kernel/configproc proc 0 0 0 - /proctmpfs tmpfs 391440 1408 390032 1% /runselinuxfs selinuxfs 0 0 0 - /sys/fs/selinuxsystemd-1 - - - - - /proc/sys/fs/binfmt_miscdebugfs debugfs 0 0 0 - /sys/kernel/debugmqueue mqueue 0 0 0 - /dev/mqueuehugetlbfs hugetlbfs 0 0 0 - /dev/hugepagestracefs tracefs 0 0 0 - /sys/kernel/tracingtmpfs tmpfs 1024 0 1024 0% /run/credentials/systemd-journald.servicetmpfs tmpfs 1024 0 1024 0% /run/credentials/systemd-network-generator.servicetmpfs tmpfs 1024 0 1024 0% /run/credentials/systemd-udev-load-credentials.servicefusectl fusectl 0 0 0 - /sys/fs/fuse/connectionstmpfs tmpfs 1024 0 1024 0% /run/credentials/systemd-tmpfiles-setup-dev-early.servicetmpfs tmpfs 1024 0 1024 0% /run/credentials/systemd-sysctl.servicetmpfs tmpfs 1024 0 1024 0% /run/credentials/systemd-tmpfiles-setup-dev.servicetmpfs tmpfs 978592 8 978584 1% /tmp/dev/nvme0n1p3 btrfs 40891392 5609788 34660228 14% /home/dev/nvme0n1p2 ext4 996780 274744 653224 30% /bootbinfmt_misc binfmt_misc 0 0 0 - /proc/sys/fs/binfmt_misctmpfs tmpfs 1024 0 1024 0% /run/credentials/systemd-tmpfiles-setup.servicetmpfs tmpfs 1024 0 1024 0% /run/credentials/systemd-resolved.servicesunrpc rpc_pipefs 0 0 0 - /var/lib/nfs/rpc_pipefstmpfs tmpfs 1024 0 1024 0% /run/credentials/systemd-vconsole-setup.servicetmpfs tmpfs 195716 88 195628 1% /run/user/42portal fuse.portal 0 0 0 - /run/user/42/doctmpfs tmpfs 195716 72 195644 1% /run/user/0tracefs tracefs 0 0 0 - /sys/kernel/debug/tracing 注意，使用 -a 选项，会将很多特殊的文件系统显示出来，这些文件系统包含的大多是系统数据，存在于内存中，不会占用硬盘空间，因此你会看到，它们所占据的硬盘总容量为 0。 3.du命令和df命令的区别有时我们会发现，使用 du 命令和 df 命令去统计分区的使用情况时，得到的数据是不一样的。那是因为df命令是从文件系统的角度考虑的，通过文件系统中未分配的空间来确定文件系统中已经分配的空间大小。也就是说，在使用 df 命令统计分区时，不仅要考虑文件占用的空间，还要统计被命令或程序占用的空间（最常见的就是文件已经删除，但是程序并没有释放空间）。 而 du 命令是面向文件的，只会计算文件或目录占用的磁盘空间。也就是说，df 命令统计的分区更准确，是真正的空闲空间。 4.lsblk 查看设备挂载情况 lsblk命令的英文是“list block”，即用于列出所有可用块设备的信息，而且还能显示他们之间的依赖关系，但是它不会列出RAM盘的信息。块设备有硬盘，闪存盘，CD-ROM等等。lsblk命令包含在util-linux-ng包中，现在该包改名为util-linux。 【例1】列出所有块设备 直接输入lsblk命令和lsblk -a输出相同 123456789[root@hadoop100 ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTSsr0 11:0 1 2.3G 0 rom zram0 252:0 0 1.9G 0 disk [SWAP]nvme0n1 259:0 0 40G 0 disk ├─nvme0n1p1 259:1 0 1M 0 part ├─nvme0n1p2 259:2 0 1G 0 part /boot└─nvme0n1p3 259:3 0 39G 0 part /home / NAME：这是块设备名。 MAJ:MIN：本栏显示主要和次要设备号。 RM：本栏显示设备是否可移动设备。注意，在本例中设备sdb和sr0的RM值等于1，这说明他们是可移动设备。 SIZE：本栏列出设备的容量大小信息。例如298.1G表明该设备大小为298.1GB，而1K表明该设备大小为1KB。 RO：该项表明设备是否为只读。在本案例中，所有设备的RO值为0，表明他们不是只读的。 TYPE：本栏显示块设备是否是磁盘或磁盘上的一个分区。在本例中，sda和sdb是磁盘，而sr0是只读存储（rom）。 MOUNTPOINT：本栏指出设备挂载的挂载点。 5.mount&#x2F;umount 挂载&#x2F;卸载对于Linux用户来讲，不论有几个分区，分别分给哪一个目录使用，它总归就是一个根 目录、一个独立且唯一的文件结构。 Linux中每个分区都是用来组成整个文件系统的一部分，它在用一种叫做“挂载”的处理 方法，它整个文件系统中包含了一整套的文件和目录，并将一个分区和一个目录联系起来， 要载入的那个分区将使它的存储空间在这个目录下获得。 5.1 mount 挂载所有的硬件设备必须挂载之后才能使用，只不过，有些硬件设备（比如硬盘分区）在每次系统启动时会自动挂载，而有些（比如 U 盘、光盘）则需要手动进行挂载。 通过学习 Linux 文件系统，我们可以对挂载的含义进行引申，挂载指的是将硬件设备的文件系统和 Linux 系统中的文件系统，通过指定目录（作为挂载点）进行关联。而要将文件系统挂载到 Linux 系统上，就需要使用 mount 挂载命令。 mount 命令的常用格式有以下几种： mount [-l] 单纯使用 mount 命令，会显示出系统中已挂载的设备信息，使用 -l 选项，会额外显示出卷标名称（读者可自行运行，查看输出结果）； mount -a -a 选项的含义是自动检查 &#x2F;etc&#x2F;fstab 文件中有无疏漏被挂载的设备文件，如果有，则进行自动挂载操作。这里简单介绍一下 &#x2F;etc&#x2F;fstab 文件，此文件是自动挂载文件，系统开机时会主动读取 &#x2F;etc&#x2F;fstab 这个文件中的内容，根据该文件的配置，系统会自动挂载指定设备。 mount [-t 系统类型] [-L 卷标名] [-o 特殊选项] [-n] 设备文件名 挂载点 各选项的含义分别是： -t 系统类型：指定欲挂载的文件系统类型。Linux 常见的支持类型有 EXT2、EXT3、EXT4、iso9660（光盘格式）、vfat、reiserfs 等。如果不指定具体类型，挂载时 Linux 会自动检测。 -L 卷标名：除了使用设备文件名（例如 &#x2F;dev&#x2F;hdc6）之外，还可以利用文件系统的卷标名称进行挂载。 -n：在默认情况下，系统会将实际挂载的情况实时写入 &#x2F;etc&#x2F;mtab 文件中，但在某些场景下（例如单人维护模式），为了避免出现问题，会刻意不写入，此时就需要使用这个选项； -o 特殊选项：可以指定挂载的额外选项，比如读写权限、同步&#x2F;异步等，如果不指定，则使用默认值（defaults）。具体的特殊选项参见表 1； 选项 功能 rw&#x2F;ro 是否对挂载的文件系统拥有读写权限，rw 为默认值，表示拥有读写权限；ro 表示只读权限。 async&#x2F;sync 此文件系统是否使用同步写入（sync）或异步（async）的内存机制，默认为异步 async。 dev&#x2F;nodev 是否允许从该文件系统的 block 文件中提取数据，为了保证数据安装，默认是 nodev。 auto&#x2F;noauto 是否允许此文件系统被以 mount -a 的方式进行自动挂载，默认是 auto。 suid&#x2F;nosuid 设定文件系统是否拥有 SetUID 和 SetGID 权限，默认是拥有。 exec&#x2F;noexec 设定在文件系统中是否允许执行可执行文件，默认是允许。 user&#x2F;nouser 设定此文件系统是否允许让普通用户使用 mount 执行实现挂载，默认是不允许（nouser），仅有 root 可以。 defaults 定义默认值，相当于 rw、suid、dev、exec、auto、nouser、async 这 7 个选项。 remount 重新挂载已挂载的文件系统，一般用于指定修改特殊权限。 【例 1】 123456[root@hadoop100 ~]# mount/dev/nvme0n1p3 on / type btrfs (rw,relatime,seclabel,compress=zstd:1,ssd,space_cache=v2,subvolid=257,subvol=/root)&lt;--含义是，将 /dev/nvme0n1p3 分区挂载到了 / 目录上，文件系统是 btrfs，具有读写权限devtmpfs on /dev type devtmpfs (rw,nosuid,seclabel,size=4096k,nr_inodes=239746,mode=755,inode64)tmpfs on /dev/shm type tmpfs (rw,nosuid,nodev,seclabel,inode64)devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,seclabel,gid=5,mode=620,ptmxmode=000)/dev/nvme0n1p2 on /boot type ext4 (rw,relatime,seclabel) 【例 2】修改特殊权限。通过例 1 我们查看到，&#x2F;boot 分区已经被挂载了，而且采用的是 defaults 选项。这里我们重新挂载分区，并采用 noexec 权限禁止执行文件执行，看看会出现什么情况（注意不要用 &#x2F; 分区做实验，否则系统命令也就不能执行了。 12345678910111213[root@hadoop100 ~]# mount -o remount noexec /boot#重新挂载 /boot 分区，并使用 noexec 权限[root@hadoop100 sh]# cd /boot#写一个 shell 脚本，看是否会运行[root@hadoop100 boot]# #vi hello.sh#!/bin/bashecho &quot;hello!!&quot;[root@hadoop100 boot]# chmod 755 hello.sh[root@hadoop100 boot]# ./hello.sh-bash:./hello.sh:权限不够#虽然赋予了hello.sh执行权限，但是仍然无法执行[root@hadoop100 boot]# mount -o remount exec /boot#记得改回来，否则会影响系统启动 对于特殊选项的修改，除非特殊场景下需要，否则不建议大家随意修改，非常容易造成系统出现问题，而且还找不到问题的根源。 【例 3】挂载分区。 1234[root@hadoop100 ~]# mkdir /mnt/disk1#建立挂载点目录[root@hadoop100 ~]# mount /dev/nvme0n1p3 /mnt/disk1#挂载分区 &#x2F;dev&#x2F;nvme0n1p3 分区还没有被划分。我们在这里只看看挂载分区的方式，非常简单，甚至不需要使用 “-ext4” 命令指定文件系统，因为系统可以自动检测。 为什么使用 Linux 系统的硬盘分区这么麻烦，而不能像 Windows 系统那样，硬盘安装上就可以使用？ 其实，硬盘分区（设备）挂载和卸载（使用 umount 命令）的概念源自 UNIX，UNIX 系统一般是作为服务器使用的，系统安全非常重要，特别是在网络上，最简单有效的方法就是“不使用的硬盘分区（设备）不挂载”，因为没有挂载的硬盘分区是无法访问的，这样系统也就更安全了。 另外，这样也可以减少挂载的硬盘分区数量，相应地，也就可以减少系统维护文件的规模，当然也就减少了系统的开销，即提高了系统的效率。 5.2 umount 卸载硬盘分区是否需要卸载，取决于你下次是否还需要使用，一般不对硬盘分区执行卸载操作。 umount 命令用于卸载已经挂载的硬件设备，该命令的基本格式如下： umount 设备文件名或挂载点注意，卸载命令后面既可以加设备文件名，也可以加挂载点，不过只能二选一，比如： 123456[root@hadoop100 ~]# umount /mnt/usb#卸载U盘[root@hadoop100 ~]# umount /mnt/cdrom#卸载光盘[root@hadoop100 ~]# umount /dev/sr0#命令加设备文件名同样是可以卸载的 如果加了两个（如下所示），从理论上分析，会对光驱卸载两次，当然，卸载第二次的时候就会报错。 mount /dev/sr0 /mnt/cdrom/另外，我们在卸载时有可能会出现以下情况： 12345[root@hadoop100 ~]# cd /mnt/cdrom/#进入光盘挂载点[root@hadoop100 cdrom]# umount /mnt/cdrom/umount: /mnt/cdrom: device is busy.#报错，设备正忙 这种报错是因为我们已经进入了挂载点，因此，如果要卸载某硬件设备，在执行 umount 命令之前，用户须退出挂载目录。 卸载硬件设备成功与否，除了执行 umount 命令不报错之外，还可以使用 df 命令或 mount -l 来查看目标设备是否还挂载在系统中。 6.fdisk 分区我们在安装操作系统的过程中已经对系统硬盘进行了分区，但如果新添加了一块硬盘，想要正常使用，难道需要重新安装操作系统才可以分区吗？ 当然不是，在 Linux 中有专门的分区命令 fdisk 和 parted。其中 fdisk 命令较为常用，但不支持大于 2TB 的分区；如果需要支持大于 2TB 的分区，则需要使用 parted 命令，当然 parted 命令也能分配较小的分区。我们先来看看如何使用 fdisk 命令进行分区。 fdisk 命令的格式如下： 1234[root@hadoop100 ~]# fdisk -l#列出系统分区[root@hadoop100 ~]# fdisk 设备文件名#给硬盘分区 该命令必须在 root 用户下才能使用 使用 “fdisk -l” 查看分区信息，能够看到我们的硬盘信息。我们解释一下这些信息， 其上半部分态是硬盘的整体状态： 1.Disk &#x2F;dev&#x2F;nvme0n1 硬盘的总大小是 40 GiB, 注意，GiB 和 GB 是不同的单位， $ 1 GiB &#x3D; 1024^3$ 字节。磁盘的总大小为 42949672960 字节，磁盘的总扇区数为83886080，每个扇区的大小是 512 字节。 2.Disk model: VMware Virtual NVMe Disk 这是磁盘的模型信息，显示该磁盘是一个虚拟磁盘，由 VMware 提供的虚拟机环境生成。VMware Virtual NVMe Disk 表示它是虚拟机中的一个 NVMe 类型磁盘。 3.Units: sectors of 1 * 512 &#x3D; 512 bytes 这是磁盘的单位，每个扇区的大小为 512 字节。在很多磁盘和操作系统中，磁盘的基本操作单位是扇区（sector） 4.Sector size (logical&#x2F;physical): 512 bytes &#x2F; 512 bytes Logical sector size: 逻辑扇区的大小，这里是 512 字节。Physical sector size: 物理扇区的大小，这里也是 512 字节。大多数磁盘的逻辑和物理扇区是相同的，但某些高级磁盘（例如大容量硬盘）可能会有不同的值。 5.I&#x2F;O size (minimum&#x2F;optimal): 512 bytes &#x2F; 512 bytes Minimum I&#x2F;O size: 最小的输入输出操作大小，这里是 512 字节。: 最小的输入输出操作大小，这里是 512 字节。Optimal I&#x2F;O size: 最佳输入输出操作大小，这里也是 512 字节。大多数现代硬盘支持的最小和最优 I&#x2F;O 操作大小通常相同。 6.Disklabel type: gpt GPT（GUID Partition Table）是磁盘分区的类型之一。它比传统的 MBR（Master Boot Record）更现代，支持更大的磁盘和更多的分区。 7.Disk identifier: 13E14872-47AE-469E-81C8-CA6BF408E45A 这是磁盘的唯一标识符，用于在系统中区分不同的磁盘。这个标识符是一个全球唯一的 GUID（全球唯一标识符） 信息的下半部分是分区的信息，共 7 列，含义如下： Device：分区的设备文件名。/dev/nvme0n1p1 表示该分区是 /dev/nvme0n1 磁盘上的第一个分区。 Start：起始扇区，代表分区从哪里开始。2048: 该分区从磁盘的第 2048 个扇区开始。注意，现代磁盘通常从 2048 扇区开始，这样可以确保与某些设备和操作系统兼容。 End：终止扇区，代表分区到哪里结束。4095: 该分区的结束扇区是 4095。 Sectors：2048：该分区占用了 2048 个扇区。 Size：1M：该分区的大小是 1 兆字节（MB） Type：BIOS boot：该分区是一个 BIOS boot 分区，用于传统 BIOS 启动。对于使用传统 BIOS 启动模式的系统，这个分区包含了启动所需的引导程序。Linux extended boot：这个分区被标记为 “Linux extended boot” 类型，它是一个扩展分区，允许创建多个逻辑分区。通常这种类型的分区在较旧的磁盘布局中使用，但它在现代系统中不常见。Linux filesystem：该分区的类型是 “Linux filesystem”，即它是一个标准的 Linux 文件系统分区，通常会用于存储 Linux 系统的文件和数据。 在 fdisk 交互界面中输入 m 可以得到帮助，帮助里列出了 fdisk 可以识别的交互命令，我们来解释一下这些命令 命令 说 明 a 设置可引导标记 b 编辑 bsd 磁盘标签 c 设置 DOS 操作系统兼容标记 d 删除一个分区 1 显示已知的文件系统类型。82 为 Linux swap 分区，83 为 Linux 分区 m 显示帮助菜单 n 新建分区 0 建立空白 DOS 分区表 P 显示分区列表 q 不保存退出 s 新建空白 SUN 磁盘标签 t 改变一个分区的系统 ID u 改变显示记录单位 V 验证分区表 w 保存退出 10 【进程管理类】无论是 Linux 系统管理员还是普通用户，监视系统进程的运行情况并适时终止一些失控的进程，是每天的例行事务。和 Linux 系统相比，进程管理在 Windows 中更加直观，它主要是使用”任务管理器”来进行进程管理的。 通常，使用”任务管理器”主要有 3 个目的： 利用”应用程序”和”进程”标签来査看系统中到底运行了哪些程序和进程； 利用”性能”和”用户”标签来判断服务器的健康状态； 在”应用程序”和”进程”标签中强制中止任务和进程； Linux 中虽然使用命令进行进程管理，但是进程管理的主要目的是一样的，即查看系统中运行的程序和进程、判断服务器的健康状态和强制中止不需要的进程。 那么，到底什么是进程呢？它和我们平时所说的“程序”又有什么联系呢？ 1.什么是进程和程序进程是正在执行的一个程序或命令，每个进程都是一个运行的实体，都有自己的地址空间，并占用一定的系统资源。程序是人使用计算机语言编写的可以实现特定目标或解决特定问题的代码集合。 这么讲很难理解，那我们换一种说法。程序是人使用计算机语言编写的，可以实现一定功能，并且可以执行的代码集合。而进程是正在执行中的程序。当程序被执行时，执行人的权限和属性，以及程序的代码都会被加载入内存，操作系统给这个进程分配一个 ID，称为 PID（进程 ID）。 也就是说，在操作系统中，所有可以执行的程序与命令都会产生进程。只是有些程序和命令非常简单，如 ls 命令、touch 命令等，它们在执行完后就会结束，相应的进程也就会终结，所以我们很难捕捉到这些进程。但是还有一些程序和命令，比如 httpd 进程，启动之后就会一直驻留在系统当中，我们把这样的进程称作常驻内存进程。 某些进程会产生一些新的进程，我们把这些进程称作子进程，而把这个进程本身称作父进程。比如，我们必须正常登录到 Shell 环境中才能执行系统命令，而 Linux 的标准 Shell 是 bash。我们在 bash 当中执行了 ls 命令，那么 bash 就是父进程，而 ls 命令是在 bash 进程中产生的进程，所以 ls 进程是 bash 进程的子进程。也就是说，子进程是依赖父进程而产生的，如果父进程不存在，那么子进程也不存在了。 2.进程管理的作用在使用 Windows 系统的过程中，使用任务管理器，很大程度上是为了强制关闭“未反应”的软件，也就是杀死进程。的确，这是很多使用进程管理工具或进程管理命令的人最常见的使用方法。不过，杀死进程（强制中止进程）只是进程管理工作中最不常用的手段，因为每个进程都有自己正确的结束方法，而杀死进程是在正常方法已经失效的情况下的后备手段。 那么，进程管理到底应该是做什么的呢？我以为，进程管理主要有以下 3 个作用。 1) 判断服务器的健康状态 运维工程师最主要的工作就是保证服务器安全、稳定地运行。理想的状态是，在服务器出现问题，但是还没有造成服务器宕机或停止服务时，就人为干预解决了问题。 进程管理最主要的工作就是判断服务器当前运行是否健康，是否需要人为干预。如果服务器的 CPU 占用率、内存占用率过高，就需要人为介入解决问题了。这又出现了一个问题，我们发现服务器的 CPU 或内存占用率很高，该如何介入呢？是直接终止高负载的进程吗？ 当然不是，应该判断这个进程是否是正常进程，如果是正常进程，则说明你的服务器已经不能满足应用需求，你需要更好的硬件或搭建集群了；如果是非法进程占用了系统资源，则更不能直接中止进程，而要判断非法进程的来源、作用和所在位置，从而把它彻底清除。 当然，如果服务器数量很少，我们完全可以人为通过进程管理命令来进行监控与干预，但如果服务器数量较多，那么人为手工监控就变得非常困难了，这时我们就需要相应的监控服务，如 cacti 或 nagios。总之，进程管理工作中最重要的工作就是判断服务器的健康状 态，最理想的状态是服务器宕机之前就解决问题，从而避免服务器的宕机。 2) 查看系统中所有的进程 我们需要查看看系统中所有正在运行的进程，通过这些进程可以判断系统中运行了哪些服务、是否有非法服务在运行。 3) 杀死进程 这是进程管理中最不常用的手段。当需要停止服务时，会通过正确关闭命令来停止服务（如 apache 服务可以通过 service httpd stop 命令来关闭）。只有在正确终止进程的手段失效的情况下，才会考虑使用 kill 命令杀死进程。 其实，进程管理和 Windows 中任务管理器的作用非常类似，不过大家在使用任务管理器时是为了杀死进程，而不是为了判断服务器的健康状态。 3.ps 查看当前系统进程状态ps 命令是最常用的监控进程的命令，通过此命令可以查看系统中所有运行进程的详细信息。 ps 命令有多种不同的使用方法，这常常给初学者带来困惑。在各种 Linux 论坛上，询问 ps 命令语法的帖子屡见不鲜，而出现这样的情况，还要归咎于 UNIX 悠久的历史和庞大的派系。在不同的 Linux 发行版上，ps 命令的语法各不相同，为此，Linux 采取了一个折中的方法，即融合各种不同的风格，兼顾那些已经习惯了其它系统上使用 ps 命令的用户。 ps 命令的基本格式如下： 1234[root@hadoop100 ~]# ps aux#查看系统中所有的进程[root@hadoop100 ~]# ps -ef#可以查看子父进程之间的关系 选项： a：显示一个终端的所有进程，除会话引线外； u：显示进程的归属用户及内存的使用情况； x：显示没有控制终端的进程； -l：长格式显示更加详细的信息； -e：显示所有进程； -f：显示完整格式的进程列表 可以看到，ps 命令有些与众不同，它的部分选项不能加入”-“，比如命令”ps aux”，其中”aux”是选项，但是前面不能带“-”。 大家如果执行 “man ps” 命令，则会发现 ps 命令的帮助为了适应不同的类 UNIX 系统，可用格式非常多，不方便记忆。所以，我建议大家记忆几个固定选项即可。比如： “ps aux” 可以查看系统中所有的进程； “ps -ef” 可以查看系统中所有的进程，而且还能看到进程的父进程的 PID 和进程优先级； “ps -l” 只能看到当前 Shell 产生的进程； 有这三个命令就足够了，下面分别来查看。 【例 1】 12345678910111213[root@hadoop100 ~]# ps aux#查看系统中所有的进程USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.1 1.3 64244 26152 ? Ss 00:35 0:44 /usr/lib/systemd/systemd --switched-root --system --deserialize=51 rhgbroot 2 0.0 0.0 0 0 ? S 00:35 0:00 [kthreadd]root 3 0.0 0.0 0 0 ? S 00:35 0:00 [pool_workqueue_release]root 4 0.0 0.0 0 0 ? I&lt; 00:35 0:00 [kworker/R-rcu_gp]root 5 0.0 0.0 0 0 ? I&lt; 00:35 0:00 [kworker/R-sync_wq]root 6 0.0 0.0 0 0 ? I&lt; 00:35 0:00 [kworker/R-slub_flushwq]root 7 0.0 0.0 0 0 ? I&lt; 00:35 0:00 [kworker/R-netns]root 10 0.0 0.0 0 0 ? I&lt; 00:35 0:00 [kworker/0:0H-events_highpri]root 12 0.0 0.0 0 0 ? I&lt; 00:35 0:00 [kworker/R-mm_percpu_wq]…省略部分输出… 以上输出信息中各列的具体含义。 表头 含义 USER 该进程是由哪个用户产生的。 PID 进程的 ID。 %CPU 该进程占用 CPU 资源的百分比，占用的百分比越高，进程越耗费资源。 %MEM 该进程占用物理内存的百分比，占用的百分比越高，进程越耗费资源。 VSZ 该进程占用虚拟内存的大小，单位为 KB。 RSS 该进程占用实际物理内存的大小，单位为 KB。 TTY 该进程是在哪个终端运行的。其中，tty1 ~ tty7 代表本地控制台终端（可以通过 Alt+F1 ~ F7 快捷键切换不同的终端），tty1~tty6 是本地的字符界面终端，tty7 是图形终端。pts&#x2F;0 ~ 255 代表虚拟终端，一般是远程连接的终端，第一个远程连接占用 pts&#x2F;0，第二个远程连接占用 pts&#x2F;1，依次増长。 STAT 进程状态。常见的状态有以下几种：-D：不可被唤醒的睡眠状态，通常用于 I&#x2F;O 情况。-R：该进程正在运行。-S：该进程处于睡眠状态，可被唤醒。-T：停止状态，可能是在后台暂停或进程处于除错状态。-W：内存交互状态（从 2.6 内核开始无效）。-X：死掉的进程（应该不会出现）。-Z：僵尸进程。进程已经中止，但是部分程序还在内存当中。-&lt;：高优先级（以下状态在 BSD 格式中出现）。-N：低优先级。-L：被锁入内存。-s：包含子进程。-l：多线程（小写 L）。-+：位于后台。 START 该进程的启动时间。 TIME 该进程占用 CPU 的运算时间，注意不是系统时间。 COMMAND 产生此进程的命令名。 【例 2】”ps aux”命令可以看到系统中所有的进程，”ps -ef”命令也能看到系统中所有的进程。 12345678910111213[root@hadoop100 ~]# ps -eflF S UID PID PPID C PRI NI ADDR SZ WCHAN STIME TTY TIME CMD4 S root 1 0 0 80 0 - 16061 do_epo 00:35 ? 00:00:44 /usr/lib/systemd/systemd --switched-root --system --deserialize=51 rhgb1 S root 2 0 0 80 0 - 0 kthrea 00:35 ? 00:00:00 [kthreadd]1 S root 3 2 0 80 0 - 0 kthrea 00:35 ? 00:00:00 [pool_workqueue_release]1 I root 4 2 0 60 -20 - 0 rescue 00:35 ? 00:00:00 [kworker/R-rcu_gp]1 I root 5 2 0 60 -20 - 0 rescue 00:35 ? 00:00:00 [kworker/R-sync_wq]1 I root 6 2 0 60 -20 - 0 rescue 00:35 ? 00:00:00 [kworker/R-slub_flushwq]1 I root 7 2 0 60 -20 - 0 rescue 00:35 ? 00:00:00 [kworker/R-netns]1 I root 10 2 0 60 -20 - 0 worker 00:35 ? 00:00:00 [kworker/0:0H-events_highpri]1 I root 12 2 0 60 -20 - 0 rescue 00:35 ? 00:00:00 [kworker/R-mm_percpu_wq]…省略部分输出… 以上输出信息中各列的含义。 表头 含义 F 进程标志，说明进程的权限，常见的标志有两个: 1：进程可以被复制，但是不能被执行；4：进程使用超级用户权限； S 进程状态。具体的状态和”psaux”命令中的 STAT 状态一致； UID 运行此进程的用户的 ID； PID 进程的 ID； PPID 父进程的 ID； C 该进程的 CPU 使用率，单位是百分比； PRI 进程的优先级，数值越小，该进程的优先级越高，越早被 CPU 执行； NI 进程的优先级，数值越小，该进程越早被执行； ADDR 该进程在内存的哪个位置； SZ 该进程占用多大内存； WCHAN 该进程是否运行。”-“代表正在运行； TTY 该进程由哪个终端产生； TIME 该进程占用 CPU 的运算时间，注意不是系统时间； CMD 产生此进程的命令名； 【例 3】如果不想看到所有的进程，只想查看一下当前登录产生了哪些进程，那只需使用 “ps -l” 命令就足够了： 12345[root@hadoop100 ~]# ps -l#查看当前登录产生的进程F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD4 S 0 1729039 1729038 0 80 0 - 58256 do_wai pts/0 00:00:00 bash4 R 0 1729555 1729039 0 80 0 - 58122 - pts/0 00:00:00 ps 可以看到，这次从 pts&#x2F;0 虚拟终端登录，只产生了两个进程：一个是登录之后生成的 Shell，也就是 bash；另一个是正在执行的 ps 命令。 我们再来说说僵尸进程。僵尸进程的产生一般是由于进程非正常停止或程序编写错误，导致子进程先于父进程结束，而父进程又没有正确地回收子进程，从而造成子进程一直存在于内存当中，这就是僵尸进程。 僵尸进程会对主机的稳定性产生影响，所以，在产生僵尸进程后，一定要对产生僵尸进程的软件进行优化，避免一直产生僵尸进程；对于已经产生的僵尸进程，可以在查找出来之后强制中止。 4.kill 终止进程4.1 kill 终止进程kill 从字面来看，就是用来杀死进程的命令，但事实上，这个或多或少带有一定的误导性。从本质上讲，kill 命令只是用来向进程发送一个信号，至于这个信号是什么，是用户指定的。 也就是说，kill 命令的执行原理是这样的，kill 命令会向操作系统内核发送一个信号（多是终止信号）和目标进程的 PID，然后系统内核根据收到的信号类型，对指定进程进行相应的操作。 kill 命令的基本格式如下： kill [信号] PID kill 命令是按照 PID 来确定进程的，所以 kill 命令只能识别 PID，而不能识别进程名。Linux 定义了几十种不同类型的信号，读者可以使用 kill -l 命令查看所有信号及其编号，这里仅列出几个常用的信号。 信号编号 信号名 含义 0 EXIT 程序退出时收到该信息。 1 HUP 挂掉电话线或终端连接的挂起信号，这个信号也会造成某些进程在没有终止的情况下重新初始化。 2 INT 表示结束进程，但并不是强制性的，常用的 “Ctrl+C” 组合键发出就是一个 kill -2 的信号。 3 QUIT 退出。 9 KILL 杀死进程，即强制结束进程。 11 SEGV 段错误。 15 TERM 正常结束进程，是 kill 命令的默认信号。 需要注意的是，表中省略了各个信号名称的前缀 SIG，也就是说，SIGTERM 和 TERM 这两种写法都对，kill 命令都可以理解。 下面，我们举几个例子来说明一下 kill 命令。 【例 1】 标准 kill 命令。 123[root@hadoop100 ~]# kill 2248#杀死PID是2248的httpd进程，默认信号是15，正常停止#如果默认信号15不能杀死进程，则可以尝试-9信号，强制杀死进程 【例 2】使用“-1”信号，让进程重启。 12[root@hadoop100 ~]# kill -1 2246使用“-1 (数字1)”信号，让httpd的主进程重新启动 学会如何使用 kill 命令之后，再思考一个问题，使用 kill 命令一定可以终止一个进程吗？ 答案是否定的。文章开头说过，kill 命令只是“发送”一个信号，因此，只有当信号被程序成功“捕获”，系统才会执行 kill 命令指定的操作；反之，如果信号被“封锁”或者“忽略”，则 kill 命令将会失效。 4.2 killall 终止特定的一类进程killall 也是用于关闭进程的一个命令，但和 kill 不同的是，killall 命令不再依靠 PID 来杀死单个进程，而是通过程序的进程名来杀死一类进程，也正是由于这一点，该命令常与 ps、pstree 等命令配合使用。 killall 命令的基本格式如下： killall [选项] 进程名 注意，此命令的信号类型同 kill 命令一样，因此这里不再赘述，此命令常用的选项有如下 2 个： -i：交互式，询问是否要杀死某个进程； -I：忽略进程名的大小写； 接下来，给大家举几个例子。 【例 1】杀死 httpd 进程。 1234[root@hadoop100 ~]# killall httpd#杀死所有进程名是httpd的进程[root@hadoop100 ~]# ps aux | grep &quot;httpd&quot; | grep -v &quot;grep&quot;#查询发现所有的httpd进程都消失了 5.pstree 查看进程树pstree 命令是以树形结构显示程序和进程之间的关系，此命令的基本格式如下： pstree [选项] [PID或用户名] pstree 命令常用选项以及各自的含义。 选项 含义 -a 显示启动每个进程对应的完整指令，包括启动进程的路径、参数等。 -c 不使用精简法显示进程信息，即显示的进程中包含子进程和父进程。 -n 根据进程 PID 号来排序输出，默认是以程序名排序输出的。 -p 显示进程的 PID。 -u 显示进程对应的用户名称。 需要注意的是，在使用 pstree 命令时，如果不指定进程的 PID 号，也不指定用户名称，则会以 systemd 进程为根进程，显示系统中所有程序和进程的信息；反之，若指定 PID 号或用户名，则将以 PID 或指定命令为根进程，显示 PID 或用户对应的所有程序和进程。 systemd 进程是系统启动的第一个进程，进程的 PID 是 1，也是系统中所有进程的父进程。【例 1】 12345678910111213141516[root@hadoop100 ~]# pstreesystemd─┬─ModemManager───3*[&#123;ModemManager&#125;] ├─NetworkManager───3*[&#123;NetworkManager&#125;] ├─VGAuthService ...省略部分输出... ├─polkitd───3*[&#123;polkitd&#125;] #有3个polkitd进程存在（1个父进程，2个子进程） ├─rtkit-daemon───2*[&#123;rtkit-daemon&#125;] ├─sshd───sshd-session───sshd-session─┬─bash───pstree │ ├─bash───top │ └─bash───sleep #Pstree命令进程是在远程连接中被执行的 ├─xdg-document-po─┬─fusermount3 │ └─6*[&#123;xdg-document-po&#125;] └─xdg-permission-───3*[&#123;xdg-permission-&#125;] 【例 2】如果想知道某个用户都启动了哪些进程，使用 pstree 命令可以很容易实现，以 mysql 用户为例： 12[root@hadoop100 ~]# pstree mysqlmysqid---6*[&#123;mysqid&#125;] 此输出结果显示了 mysql 用户对应的进程为 mysqid，并且 mysqid 进程拥有 5 个子进程（外加 1 个父进程，共计 6 个进程）。 6.top 实时监控系统进程状态ps 命令可以一次性给出当前系统中进程状态，但使用此方式得到的信息缺乏时效性，并且，如果管理员需要实时监控进程运行情况，就必须不停地执行 ps 命令，这显然是缺乏效率的。 为此，Linux 提供了 top 命令。top 命令可以动态地持续监听进程地运行状态，与此同时，该命令还提供了一个交互界面，用户可以根据需要，人性化地定制自己的输出，进而更清楚地了进程的运行状态。 使用权限：所有使用者。 top 命令的基本格式如下： top [选项] 选项： -d 秒数：指定 top 命令每隔几秒更新。默认是 3 秒； -b：使用批处理模式输出。一般和”-n”选项合用，用于把 top 命令重定向到文件中； -n 次数：指定 top 命令执行的次数。一般和”-“选项合用； -p 进程PID：仅查看指定 ID 的进程； -s：使 top 命令在安全模式中运行，避免在交互模式中出现错误； -u 用户名：只监听某个用户的进程； 在 top 命令的显示窗口中，还可以使用如下按键，进行一下交互操作： ? 或 h：显示交互模式的帮助； P：按照 CPU 的使用率排序，默认就是此选项； M：按照内存的使用率排序； N：按照 PID 排序； T：按照 CPU 的累积运算时间排序，也就是按照 TIME+ 项排序； k：按照 PID 给予某个进程一个信号。一般用于中止某个进程，信号 9 是强制中止的信号； r：按照 PID 给某个进程重设优先级（Nice）值； q：退出 top 命令； 我们看看 top 命令的执行结果，如下： 1234567891011121314151617181920212223[root@hadoop100 ~]# toptop - 07:12:51 up 6:37, 4 users, load average: 0.17, 0.16, 0.17Tasks: 261 total, 1 running, 260 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.6 us, 2.3 sy, 0.0 ni, 96.9 id, 0.0 wa, 0.2 hi, 0.1 si, 0.0 st MiB Mem : 1911.3 total, 108.0 free, 866.8 used, 1113.4 buff/cache MiB Swap: 1911.0 total, 1910.2 free, 0.8 used. 1044.5 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 807 root 20 0 538924 8604 7196 S 0.7 0.4 0:23.50 vmtoolsd 1729038 root 20 0 15772 7688 5236 S 0.7 0.4 0:04.10 sshd-session 731 systemd+ 20 0 16032 7212 6444 S 0.3 0.4 0:32.98 systemd-oomd 799 root 20 0 16036 7608 6712 S 0.3 0.4 0:30.22 systemd-machine 1067 root 20 0 415984 27904 15232 S 0.3 1.4 0:03.94 tuned-ppd 1729177 root 20 0 233340 5184 3136 S 0.3 0.3 0:01.33 top 1753214 root 20 0 233364 5356 3308 R 0.3 0.3 0:00.03 top 1 root 20 0 64244 26152 10964 S 0.0 1.3 0:45.10 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.06 kthreadd 3 root 20 0 0 0 0 S 0.0 0.0 0:00.00 pool_workqueue_release 4 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 kworker/R-rcu_gp 5 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 kworker/R-sync_wq 6 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 kworker/R-slub_flushwq 7 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 kworker/R-netns 10 root 0 -20 0 0 0 I 0.0 0.0 0:00.0 我们解释一下命令的输出。top 命令的输出内容是动态的，默认每隔 3 秒刷新一次。命令的输出主要分为两部分： 第一部分是前五行，显示的是整个系统的资源使用状况，我们就是通过这些输出来判断服务器的资源使用状态的； 第二部分从第六行开始，显示的是系统中进程的信息； 我们先来说明第一部分的作用。 第一行为任务队列信息。 内 容 说 明 07:12:51 系统当前时间 up 6:37 系统的运行时间.本机己经运行 6 小时 37 分钟 4 users 当前登录了 4 个用户 load average: 0.17, 0.16, 0.17 系统在之前 1 分钟、5 分钟、15 分钟的平均负载。如果 CPU 是单核的，则这个数值超过 1 就是高负载：如果 CPU 是四核的，则这个数值超过 4 就是高负载 （这个平均负载完全是依据个人经验来进行判断的，一般认为不应该超过服务器 CPU 的核数） 第二行为进程信息。 内 容 说 明 Tasks: 261 total 系统中的进程总数 1 running 正在运行的进程数 260 sleeping 睡眠的进程数 0 stopped 正在停止的进程数 0 zombie 僵尸进程数。如果不是 0，则需要手工检查僵尸进程 第三行为 CPU 信息。 内 容 说 明 %Cpu(s): 0.6 us 用户模式占用的 CPU 百分比 2.3 sy 系统模式占用的 CPU 百分比 0.0 ni 改变过优先级的用户进程占用的 CPU 百分比 96.9 id 空闲 CPU 占用的 CPU 百分比 0.0 wa 等待输入&#x2F;输出的进程占用的 CPU 百分比 0.2 hi 硬中断请求服务占用的 CPU 百分比 0.1 si 软中断请求服务占用的 CPU 百分比 0.0 st st（steal time）意为虚拟时间百分比，就是当有虚拟机时，虚拟 CPU 等待实际 CPU 的时间百分比 第四行为物理内存信息。 内 容 说 明 MiB Mem : 1911.3 total 物理内存的总量，单位为MiB 866.8 used 己经使用的物理内存数量 108.0 free 空闲的物理内存数量 1113.4 buff&#x2F;cache 作为缓存和缓冲区的内存数量 第五行为交换分区（swap）信息。 内 容 说 明 MiB Swap: 1911.0 total 交换分区（虚拟内存）的总大小 0.8 used 已经使用的交换分区的大小 1910.2 free 空闲交换分区的大小 1044.5 avail Mem 表示可用内存，包括空闲内存和可以被回收的缓存内存，当前有 1044.5 MiB 我们通过 top 命令的第一部分就可以判断服务器的健康状态。如果 1 分钟、5 分钟、15 分钟的平均负载高于 1，则证明系统压力较大。如果 CPU 的使用率过高或空闲率过低，则证明系统压力较大。如果物理内存的空闲内存过小，则也证明系统压力较大。 这时，我们就应该判断是什么进程占用了系统资源。如果是不必要的进程，就应该结束这些进程；如果是必需进程，那么我们该増加服务器资源（比如増加虚拟机内存），或者建立集群服务器。 我们还要解释一下缓冲（buffer）和缓存（cache）的区别： 缓存（cache）是在读取硬盘中的数据时，把最常用的数据保存在内存的缓存区中，再次读取该数据时，就不去硬盘中读取了，而在缓存中读取。 缓冲（buffer）是在向硬盘写入数据时，先把数据放入缓冲区,然后再一起向硬盘写入，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。 简单来说，缓存（cache）是用来加速数据从硬盘中”读取”的，而缓冲（buffer）是用来加速数据”写入”硬盘的。 再来看 top 命令的第二部分输出，主要是系统进程信息，各个字段的含义如下： PID：进程的 ID。 USER：该进程所属的用户。 PR：优先级，数值越小优先级越高。 NI：优先级，数值越小、优先级越高。 VIRT：该进程使用的虚拟内存的大小，单位为 KB。 RES：该进程使用的物理内存的大小，单位为 KB。 SHR：共享内存大小，单位为 KB。 S：进程状态。 %CPU：该进程占用 CPU 的百分比。 %MEM：该进程占用内存的百分比。 TIME+：该进程共占用的 CPU 时间。 COMMAND：进程的命令名。 这部分和 ps 命令的输出比较类似，只是如果在终端执行 top 命令，则不能看到所有的进程，而只能看到占比靠前的进程。接下来我们举几个 top 命令常用的实例。 【例 1】如果只想让 top 命令查看某个进程，就可以使用 “-p 选项”。命令如下： 12345678910[root@hadoop100 ~]# top -p 1#只查看 PID为 1 的 root 进程top - 07:26:06 up 6:51, 4 users, load average: 0.28, 0.22, 0.19Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.5 us, 2.3 sy, 0.0 ni, 96.9 id, 0.1 wa, 0.2 hi, 0.1 si, 0.0 st MiB Mem : 1911.3 total, 84.6 free, 868.8 used, 1134.8 buff/cache MiB Swap: 1911.0 total, 1910.2 free, 0.8 used. 1042.5 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 64244 26152 10964 S 0.0 1.3 0:45.74 systemd 7.netstat 显示网络状态和端口占用信息1）基本语法 netstat -anp | grep 进程号 （功能描述：查看该进程网络信息） netstat –nlp | grep 端口号 （功能描述：查看网络端口号占用情况 2）选项说明 -a 显示所有正在监听（listen）和未监听的套接字（socket） -n 拒绝显示别名，能显示数字的全部转化成数字 -l 仅列出在监听的服务状态 -p 表示显示哪个进程在调用 3）案例实操 （1）通过进程号查看sshd进程的网络信息 123456789[root@hadoop100 ~]# netstat -anp | grep sshdtcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 982/sshd: /usr/sbin tcp 0 68 192.168.26.100:22 192.168.26.1:55264 ESTABLISHED 1729034/sshd-sessio tcp6 0 0 :::22 :::* LISTEN 982/sshd: /usr/sbin unix 2 [ ] DGRAM CONNECTED 4637404 1729034/sshd-sessio unix 2 [ ] STREAM CONNECTED 4638368 1729034/sshd-sessio unix 3 [ ] STREAM CONNECTED 4637412 1729034/sshd-sessio unix 3 [ ] STREAM CONNECTED 4637411 1729038/sshd-sessio unix 3 [ ] STREAM CONNECTED 13170 982/sshd: /usr/sbin （2）查看某端口号是否被占用 123[root@hadoop100 ~]# netstat -nltp | grep 22tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 982/sshd: /usr/sbin tcp6 0 0 :::22 :::* LISTEN 982/sshd: /usr/sbin 11 【定时任务 软件安装 克隆虚拟机】1.crontab 系统定时任务在实际工作中，系统的定时任务一般是需要重复执行的，这就需要使用 crontab 命令来执行循环定时任务。 每个用户都可以实现自己的 crontab 定时任务，只需使用这个用户身份执行“crontab -e”命令即可。当然，这个用户不能写入 &#x2F;etc&#x2F;cron.deny 文件。 crontab 命令的基本格式如下： crontab [选项] [file] 注意，这里的 file 指的是命令文件的名字，表示将 file 作为 crontab 的任务列表文件并载入 crontab，若在命令行中未指定文件名，则此命令将接受标准输入（键盘）上键入的命令，并将它们键入 crontab。 选项 功能 -u user 用来设定某个用户的 crontab 服务，例如 “-u demo” 表示设备 demo 用户的 crontab 服务，此选项一般有 root 用户来运行。 -e 编辑某个用户的 crontab 文件内容。如果不指定用户，则表示编辑当前用户的 crontab 文件。 -l 显示某用户的 crontab 文件内容，如果不指定用户，则表示显示当前用户的 crontab 文件内容。 -r 从 &#x2F;var&#x2F;spool&#x2F;cron 删除某用户的 crontab 文件，如果不指定用户，则默认删除当前用户的 crontab 文件。 -i 在删除用户的 crontab 文件时，给确认提示。 其实 crontab 定时任务非常简单，只需执行“crontab -e”命令，然后输入想要定时执行的任务即可。不过，当我们执行“crontab -e”命令时，打开的是一个空文件，而且操作方法和 Vim 是一致的。那么，这个文件的格式才是我们真正需要学习的内容。文件格式如下： 123[root@hadoop100 ~]# crontab -e#进入 crontab 编辑界面。会打开Vim编辑你的任务* * * * * 执行的任务 这个文件中是通过 5 个“ * ” 来确定命令或任务的执行时间的，这 5 个“ * “: 项目 含义 范围 第一个”*” 一小时当中的第几分钟（minute） 0~59 第二个”*” 一天当中的第几小时（hour） 0~23 第三个”*” 一个月当中的第几天（day） 1~31 第四个”*” 一年当中的第几个月（month） 1~12 第五个”*” 一周当中的星期几（week） 0~7（0和7都代表星期日） 在时间表示中，还有一些特殊符号需要学习。 特殊符号 含义 *（星号） 代表任何时间。比如第一个”*”就代表一小时种每分钟都执行一次的意思。 ,（逗号） 代表不连续的时间。比如”0 8，12，16***命令”就代表在每天的 8 点 0 分、12 点 0 分、16 点 0 分都执行一次命令。 -（中杠） 代表连续的时间范围。比如”0 5 ** 1-6命令”，代表在周一到周六的凌晨 5 点 0 分执行命令。 *&#x2F;n 代表每隔多久执行一次。比如”*&#x2F;10 **** 命令”，代表每隔 10 分钟就执行一次命令。 当“crontab -e”编辑完成之后，一旦保存退出，那么这个定时任务实际就会写入 &#x2F;var&#x2F;spool&#x2F;cron&#x2F; 目录中，每个用户的定时任务用自己的用户名进行区分。而且 crontab 命令只要保存就会生效，只要 crond 服务是启动的。知道了这 5 个时间字段的含义，我们多举几个时间的例子来熟悉一下时间字段。 时间 含义 45 22 ***命令 在 22 点 45 分执行命令 0 17 ** 1命令 在每周一的 17 点 0 分执行命令 0 5 1，15**命令 在每月 1 日和 15 日的凌晨 5 点 0 分执行命令 40 4 ** 1-5命令 在每周一到周五的凌晨 4 点 40 分执行命令 *&#x2F;10 4 ***命令 在每天的凌晨 4 点，每隔 10 分钟执行一次命令 0 0 1，15 * 1命令 在每月 1 日和 15 日，每周一个 0 点 0 分都会执行命令，注意：星期几和几日最好不要同时出现，因为它们定义的都是天，非常容易让管理员混淆 现在我们已经对这 5 个时间字段非常熟悉了，可是在“执行的任务”字段中都可以写什么呢？既可以定时执行系统命令，也可以定时执行某个 Shell 脚本，这里举几个实际的例子。 【例 1】让系统每隔 5 分钟就向 /tmp/test 文件中写入一行“11”，验证一下系统定时任务是否会执行。 123[root@hadoop100 ~]# crontab -e#进入编辑界面*/5 * * * * /bin/echo &quot;11&quot; &gt;&gt; /tmp/test 这个任务在时间工作中没有任何意义，但是可以很简单地验证我们的定时任务是否可以正常执行。如果觉得每隔 5 分钟太长，那就换成“*&#x2F;1”，让它每分钟执行一次。而且和 at 命令一样，如果我们定时执行的是系统命令，那么最好使用绝对路径。 【例 2】让系统在每周二的凌晨 5 点 05 分重启一次。 12[root@hadoop100 ~]# crontab -e5 5 * * 2 /sbin/shutdown -r now 如果服务器的负载压力比较大，则建议每周重启一次，让系统状态归零。比如绝大多数游戏服务器每周维护一次，维护时最主要的工作就是重启，让系统状态归零。这时可以让我们的服务器自动来定时执行。 【例 3】在每月 1 日、10 日、15 日的凌晨 3 点 30 分都定时执行日志备份脚本 autobak.sh。 12[root@hadoop100 ~]# crontab -e30.3 1，10，15 * * /root/sh/autobak.sh 这些定时任务保存之后，就可以在指定的时间执行了。我们可以使用命令来查看和删除定时任务，命令如下： 1234567891011[root@hadoop100 ~]# crontab -l#查看root用户的crontab任务*/5 * * * * /bin/echo &quot;11&quot; &gt;&gt; /tmp/test5.5 * * 2 /sbin/shutdown -r now30.3 1，10，15 * * /root/sh/autobak.sh[root@hadoop100 ~]# crontab -r#删除root用户所有的定时任务。如果只想删除某个定时任务，则可以执行“crontab -e”命令进入#编辑模式手工删除[root@hadoop100 ~]# crontab -lno crontab for root#删除后，再查询就没有root用户的定时任务了 在书写 crontab 定时任务时，需要注意以下几个事项： 6 个选项都不能为空，必须填写。如果不确定，则使用“*”代表任意时间。 crontab 定时任务的最小有效时间是分钟，最大有效时间是月。像 2018 年某时执行、3 点 30 分 30 秒这样的时间都不能被识别。 在定义时间时，日期和星期最好不要在一条定时任务中出现，因为它们都以天为单位，非常容易让管理员混淆。 在定时任务中，不管是直接写命令，还是在脚本中写命令，最好都使用绝对路径。有时使用相对路径的命令会报错。 2.软件包管理2.1 源码包和二进制包Linux下的软件包众多，且几乎都是经 GPL 授权、免费开源（无偿公开源代码）的。这意味着如果你具备修改软件源代码的能力，只要你愿意，可以随意修改。 GPL，全称 General Public License，中文名称“通用性公开许可证”，简单理解 GPL 就是一个保护软件自由的一个协议，经 GPL 协议授权的软件必须开源，请猛击《开源协议》了解更多信息。 Linux下的软件包可细分为两种，分别是源码包和二进制包。 2.1.1 源码包实际上，源码包就是一大堆源代码程序，是由程序员按照特定的格式和语法编写出来的。 我们都知道，计算机只能识别机器语言，也就是二进制语言，所以源码包的安装需要一名“翻译官”将“abcd”翻译成二进制语言，这名“翻译官”通常被称为编译器。 “编译”指的是从源代码到直接被计算机（或虚拟机）执行的目标代码的翻译过程，编译器的功能就是把源代码翻译为二进制代码，让计算机识别并运行。 虽然源码包免费开源，但用户不会编程怎么办？一大堆源代码程序不会使用怎么办？源码包容易安装吗？等等这些都是使用源码包安装方式无法解答的问题。 另外，由于源码包的安装需要把源代码编译为二进制代码，因此安装时间较长。比如，大家应该都在 Windows下安装过 QQ，QQ 功能较多，程序相对较大（有 70 MB左右），但由于其并非是以源码包的形式发布，而是编译后才发布的，因此只需几分钟（经过简单的配置）即可安装成功。但如果我们以源码包安装的方式在 Linux 中安装一个 MySQL 数据库，即便此软件的压缩包仅有 23 MB左右，也需要 30 分钟左右的时间（根据硬件配置不同，略有差异）。 通过对比你会发现，源码包的编译是很费时间的，况且绝多大数用户并不熟悉程序语言，在安装过程中我们只能祈祷程序不要报错，否则初学者很难解决。 为了解决使用源码包安装方式的这些问题，Linux 软件包的安装出现了使用二进制包的安装方式。 2.1.2 二进制包二进制包，也就是源码包经过成功编译之后产生的包。由于二进制包在发布之前就已经完成了编译的工作，因此用户安装软件的速度较快（同 Windows下安装软件速度相当），且安装过程报错几率大大减小。 二进制包是 Linux 下默认的软件安装包，因此二进制包又被称为默认安装软件包。目前主要有以下 2 大主流的二进制包管理系统： RPM 包管理系统：功能强大，安装、升级、査询和卸载非常简单方便，因此很多 Linux 发行版都默认使用此机制作为软件安装的管理方式，例如 Fedora、CentOS、SuSE 等。 DPKG 包管理系统：由 Debian Linux 所开发的包管理机制，通过 DPKG 包，Debian Linux 就可以进行软件包管理，主要应用在 Debian 和 Ubuntu 中。 RPM 包管理系统和 DPKG 管理系统的原理和形式大同小异，可以触类旁通。由于本教程使用的是 Fedora 41 版本，因此本节主要讲解 RPM 二进制包。 2.1.3 源码包 VS RPM二进制包源码包一般包含多个文件，为了方便发布，通常会将源码包做打包压缩处理，Linux 中最常用的打包压缩格式为“tar.gz”，因此源码包又被称为 Tarball。 Tarball 是 Linux 系统的一款打包工具，可以对源码包进行打包压缩处理，人们习惯上将最终得到的打包压缩文件称为 Tarball 文件。 源码包需要我们自己去软件官方网站进行下载，包中通常包含以下内容： 源代码文件。 配置和检测程序（如 configure 或 config 等）。 软件安装说明和软件说明（如 INSTALL 或 README）。 总的来说，使用源码包安装软件具有以下几点好处： 开源。如果你有足够的能力，则可以修改源代码。 可以自由选择所需的功能。 因为软件是编译安装的，所以更加适合自己的系统，更加稳定，效率也更高。 卸载方便。 但同时，使用源码包安装软件也有几点不足： 安装过程步骤较多，尤其是在安装较大的软件集合时（如 LAMP 环境搭建），容易出现拼写错误。 编译时间较长，所以安装时间比二进制安装要长。 因为软件是编译安装的，所以在安装过程中一旦报错，新手很难解决。 相比源码包，二进制包是在软件发布时已经进行过编译的软件包，所以安装速度比源码包快得多（和 Windows 下软件安装速度相当）。也正是因为已经进行通译，大家无法看到软件的源代码。 使用 RMP 包安装软件具有以下 2 点好处： 包管理系统简单，只通过几个命令就可以实现包的安装、升级、査询和卸载。 安装速度比源码包安装快得多。 与此同时，使用 RMP 包安装软件有如下不足： 经过编译，不能在看到源代码。 功能选择不如源码包灵活。 依赖性。有时我们会发现，在安装软件包 a 时需要先安装 b 和 c，而在安装 b 时需要先安装 d 和 e。这就需要先安装 d 和 e，再安装 b 和 c，最后才能安装 a。比如，我买了一个漂亮的灯具，打算安装在客厅里，可是在安装灯具之前，客厅需要有顶棚，并且顶棚需要刷好油漆。安装软件和装修及其类似，需要有一定的顺序，但是有时依赖性会非常强。 2.1.4 如何选择通过源码包和 RMP 二进制包的对比，在 Linux 进行软件安装时，我们应该使用哪种软件包呢？ 为了更好的区别两种软件包，这里举个例子。假设我们想做一套家具，源码包就像所有的家具完全由自己动手手工打造（手工编译），想要什么样的板材、油漆、颜色和样式都由自己决定（功能自定义，甚至可以修改源代码）。想想就觉得爽，完全不用被黑心的厂商所左右，而且不用担心质量问题（软件更适合自己的系统，效率更高，更加稳定）。但是，所花费的时间大大超过了买一套家具的时间（编译浪费时间），而且自己真的有做木工这个能力吗（需要对源代码非常了解）？就算请别人定制好的家具，再由自己组装，万一哪个部件不匹配（报错很难解决），怎么办？ 那么二进制包呢？也是我们需要一套家具，去商场买了一套（安装简单），家具都是现成的，不会有哪个部件不匹配，除非因为自身问题没有量好尺寸而导致放不下（报错很少）。但是我们完全不知道这套家具用的是什么材料、油漆是否合格，而且家具的样式不能随意选择（软件基本不能自定义功能）。 2.2 RPM包统一命名规则RPM 二进制包的命名需遵守统一的命名规则，用户通过名称就可以直接获取这类包的版本、适用平台等信息。 RPM 二进制包命名的一般格式如下： 包名-版本号-发布次数-发行商-Linux平台-适合的硬件平台-包扩展名 例如，RPM 包的名称是httpd-2.2.15-15.el6.centos.1.i686.rpm，其中： httped：软件包名。这里需要注意，httped 是包名，而 httpd-2.2.15-15.el6.centos.1.i686.rpm 通常称为包全名，包名和包全名是不同的，在某些 Linux 命令中，有些命令（如包的安装和升级）使用的是包全名，而有些命令（包的查询和卸载）使用的是包名，一不小心就会弄错。 2.2.15：包的版本号，版本号的格式通常为主版本号.次版本号.修正号。 15：二进制包发布的次数，表示此 RPM 包是第几次编程生成的。 el*：软件发行商，el6 表示此包是由 Red Hat 公司发布，适合在 RHEL 6.x (Red Hat Enterprise Unux) 和 CentOS 6.x 上使用。 centos：表示此包适用于 CentOS 系统。 i686：表示此包使用的硬件平台，目前的 RPM 包支持的平台如表所示： 平台名称 适用平台信息 i386 386 以上的计算机都可以安装 i586 686 以上的计算机都可以安装 i686 奔腾 II 以上的计算机都可以安装，目前所有的 CPU 是奔腾 II 以上的，所以这个软件版本居多 x86_64 64 位 CPU 可以安装 noarch 没有硬件限制 rpm：RPM 包的扩展名，表明这是编译好的二进制包，可以使用 rpm 命令直接安装。此外，还有以 src.rpm 作为扩展名的 RPM 包，这表明是源代码包，需要安装生成源码，然后对其编译并生成 rpm 格式的包，最后才能使用 rpm 命令进行安装。 有人可能会问，Linux 系统不靠扩展名分区文件类型，那为什么包全名中要包含 .rpm 扩展名呢？其实，这里的扩展名是为系统管理员准备的，如果我们不对 RPM 包标注扩展名，管理员很难知道这是一个 RPM 包，当然也就无法正确使用。 2.3 RPM包安装、卸载和升级2.3.1 RPM包默认安装路径通常情况下，RPM 包采用系统默认的安装路径，所有安装文件会按照类别分散安装到表所示的目录中。 安装路径 含 义 &#x2F;etc&#x2F; 配置文件安装目录 &#x2F;usr&#x2F;bin&#x2F; 可执行的命令安装目录 &#x2F;usr&#x2F;lib&#x2F; 程序所使用的函数库保存位置 &#x2F;usr&#x2F;share&#x2F;doc&#x2F; 基本的软件使用手册保存位置 &#x2F;usr&#x2F;share&#x2F;man&#x2F; 帮助文件保存位置 RPM 包的默认安装路径是可以通过命令查询的。 除此之外，RPM 包也支持手动指定安装路径，但此方式并不推荐。因为一旦手动指定安装路径，所有的安装文件会集中安装到指定位置，且系统中用来查询安装路径的命令也无法使用（需要进行手工配置才能被系统识别），得不偿失。 与 RPM 包不同，源码包的安装通常采用手动指定安装路径（习惯安装到 /usr/local/ 中）的方式。既然安装路径不同，同一 apache 程序的源码包和 RPM 包就可以安装到一台 Linux 服务器上（但同一时间只能开启一个，因为它们需要占用同一个 80 端口）。 2.3.2 RPM 包的安装安装 RPM 的命令格式为： rpm -ivh 包全名 注意一定是包全名。涉及到包全名的命令，一定要注意路径，可能软件包在光盘中，因此需提前做好设备的挂载工作。 此命令中各选项参数的含义为： -i：安装（install）; -v：显示更详细的信息（verbose）; -h：打印 #，显示安装进度（hash）; 例如，使用此命令安装 httpd 软件包，如下所示： 1234567[root@hadoop100 ~]# rpm -ivh /mnt/cdrom/Packages/httpd-2.4.62-2.fc41.x86_64.rpmPreparing...####################[100%]1:httpd####################[100%] 注意，直到出现两个 100% 才是真正的安装成功，第一个 100% 仅表示完成了安装准备工作。 此命令还可以一次性安装多个软件包，仅需将包全名用空格分开即可，如下所示： rpm -ivh a.rpm b.rpm c.rpm 如果还有其他安装要求（比如强制安装某软件而不管它是否有依赖性），可以通过以下选项进行调整： -nodeps：不检测依赖性安装。软件安装时会检测依赖性，确定所需的底层软件是否安装，如果没有安装则会报错。如果不管依赖性，想强制安装，则可以使用这个选项。注意，这样不检测依赖性安装的软件基本上是不能使用的，所以不建议这样做。 -replacefiles：替换文件安装。如果要安装软件包，但是包中的部分文件已经存在，那么在正常安装时会报”某个文件已经存在”的错误，从而导致软件无法安装。使用这个选项可以忽略这个报错而覆盖安装。 -replacepkgs：替换软件包安装。如果软件包已经安装，那么此选项可以把软件包重复安装一遍。 -force：强制安装。不管是否已经安装，都重新安装。也就是 -replacefiles 和 -replacepkgs 的综合。 -test：测试安装。不会实际安装，只是检测一下依赖性。 -prefix：指定安装路径。为安装软件指定安装路径，而不使用默认安装路径。 apache 服务安装完成后，可以尝试启动： 1[root@hadoop100 ~]# systemctl start|stop|restart|status 服务名 各参数含义： start：启动服务； stop：停止服务； restart：重启服务； status: 查看服务状态； 例如： [root@hadoop100 ~]# systemctl start apache #启动apache服务 服务启动后，可以查看端口号 80 是否出现。命令如下： 12[root@hadoop100 ~]# netstat -tlun | grep 80tcp 0 0 :::80:::* LISTEN 2.3.3 RPM包的升级使用如下命令即可实现 RPM 包的升级： rpm -Uvh 包全名 -U（大写）选项的含义是：如果该软件没安装过则直接安装；若已安装则升级至最新版本。 rpm -Fvh 包全名 -F（大写）选项的含义是：如果该软件没有安装，则不会安装，必须安装有较低版本才能升级。 2.4.4 RPM包的卸载RPM 软件包的卸载要考虑包之间的依赖性。例如，我们先安装的 httpd 软件包，后安装 httpd 的功能模块 mod_ssl 包，那么在卸载时，就必须先卸载 mod_ssl，然后卸载 httpd，否则会报错。 软件包卸载和拆除大楼是一样的，本来先盖的 2 楼，后盖的 3 楼，那么拆楼时一定要先拆除 3 楼。 如果卸载 RPM 软件不考虑依赖性，执行卸载命令会包依赖性错误，例如： 123[root@hadoop100 ~]# rpm -e httpderror: Failed dependencies: httpd is needed by (installed) gnome-user-share-47.0-1.fc41.x86_64 2.4 rpm命令查询软件包rpm 命令还可用来对 RPM 软件包做查询操作，具体包括： 查询软件包是否已安装； 查询系统中所有已安装的软件包； 查看软件包的详细信息； 查询软件包的文件列表； 查询某系统文件具体属于哪个 RPM 包。 使用 rpm 做查询命令的格式如下： rpm 选项 查询对象 2.4.1 rpm -q：查询软件包是否安装用 rpm 查询软件包是否安装的命令格式为： rpm -q 包名 -q 表示查询，是 query 的首字母。 例如，查看 Linux 系统中是否安装 apache，rpm 查询命令应写成： 12[root@hadoop100 ~]# rpm -q httpdhttpd-2.4.62-2.fc41.x86_64 注意这里使用的是包名，而不是包全名。因为已安装的软件包只需给出包名，系统就可以成功识别（使用包全名反而无法识别）。 2.4.2 rpm -qa：查询系统中所有安装的软件包使用 rpm 查询 Linux 系统中所有已安装软件包的命令为： 123456[root@hadoop100 ~]# rpm -qalibgcc-14.2.1-3.fc41.x86_64fonts-filesystem-2.0.5-17.fc41.noarchgoogle-noto-fonts-common-20240701-2.fc41.noarchgoogle-noto-sans-vf-fonts-20240701-2.fc41.noarch…省略部分输出… 此外，这里还可以使用管道符查找出需要的内容，比如： 123456[root@hadoop100 ~]# rpm -qa | grep httpdhttpd-filesystem-2.4.62-2.fc41.noarchfedora-logos-httpd-38.1.0-6.fc41.noarchhttpd-tools-2.4.62-2.fc41.x86_64httpd-core-2.4.62-2.fc41.x86_64httpd-2.4.62-2.fc41.x86_64 相比rpm -q 包名命令，采用这种方式可以找到含有包名的所有软件包。 2.4.3 rpm -qi：查询软件包的详细信息通过 rpm 命令可以查询软件包的详细信息，命令格式如下： rpm -qi 包名 -i 选项表示查询软件信息，是 information 的首字母。 例如，想查看 httpd 包的详细信息，可以使用如下命令： 123456789101112131415161718192021222324252627282930313233343536373839[root@hadoop100 ~]# rpm -qi httpdName : httpd#包名。httpd 是 Apache HTTP 服务器的名称，通常用于处理 HTTP 请求的 Web 服务器Version : 2.4.62#版本号。表示该包是 Apache HTTP Server 的 2.4 版本系列中的第 62 个更新版本Release : 2.fc41#该包在 Fedora 41 版本中的发布编号。fc41 表示这是 Fedora 41 版本中的一个包，2 表示这是该包的第二次发布Architecture: x86_64#表示这个包是为 64 位 x86 架构的计算机编译的Install Date: Thu 24 Oct 2024 10:50:46 AM EDT#表示包被安装的日期和时间，表示该包在 2024 年 10 月 24 日上午 10:50:46 被安装Group : Unspecified#表示该包的分类组，通常在某些操作系统中，包会根据功能被分组。在这个输出中，Group 被标记为 Unspecified，意味着该包没有明确的分组Size : 66354#表示该包的大小为 66354 字节，大约是 66 KBLicense : Apache-2.0 AND (BSD-3-Clause AND metamail AND HPND-sell-variant AND Spencer-94)#表示该包的许可协议。httpd 使用了多个开源许可协议：Apache-2.0: Apache 2.0 许可证，允许免费使用、修改和分发。后面的一些许可证（如 BSD-3-Clause, metamail, HPND-sell-variant, Spencer-94）表示该包可能包含了其他组件，这些组件的许可证要求也包含在内。Signature : RSA/SHA256, Thu 01 Aug 2024 09:52:49 AM EDT, Key ID d0622462e99d6ad1#表示包的数字签名信息。RSA/SHA256 表示使用 RSA 算法和 SHA-256 哈希算法对包进行了签名，签名是在 2024 年 8 月 1 日由 Fedora 项目的密钥 d0622462e99d6ad1 生成的Source RPM : httpd-2.4.62-2.fc41.src.rpm#表示用于构建这个二进制包的源包名称。源包是 httpd-2.4.62-2.fc41.src.rpm，包含了源代码和构建说明Build Date : Thu 01 Aug 2024 09:47:39 AM EDT#表示该包的构建日期，显示为 2024 年 8 月 1 日 09:47:39Build Host : buildhw-x86-08.iad2.fedoraproject.org#表示该包的构建机器的主机名。它是在 buildhw-x86-08.iad2.fedoraproject.org 上构建的，表明这是 Fedora 项目的构建主机Packager : Fedora Project#表示包的打包者或维护者。在这个例子中是 Fedora Project，意味着 Fedora 项目负责维护这个包Vendor : Fedora Project#表示该包的供应商，也是 Fedora Project，意味着该包是由 Fedora 项目提供的URL : https://httpd.apache.org/#是包的官方网站，httpd 是 Apache HTTP Server 项目的 Web 服务器，官方网站为 https://httpd.apache.org/Bug URL : https://bugzilla.redhat.com/#提供了报告该包问题或缺陷的页面 URL。此处是 https://bugzilla.redhat.com/，这是 Red Hat 提供的 Bug 跟踪系统，Fedora 作为其衍生版本也使用这个系统Summary : Apache HTTP Server#是该包的简短描述。Apache HTTP Server（简称 httpd）是一个强大、高效且可扩展的 Web 服务器Description :The Apache HTTP Server is a powerful, efficient, and extensibleweb server.#提供了该包的详细描述。httpd 是 Apache HTTP Server，广泛使用的 Web 服务器，旨在提供高效、灵活和可扩展的 Web 服务 2.4.4 rpm -ql：命令查询软件包的文件列表通过前面的学习我们知道，rpm 软件包通常采用默认路径安装，各安装文件会分门别类安放在适当的目录文件下。使用 rpm 命令可以查询到已安装软件包中包含的所有文件及各自安装路径，命令格式为： rpm -ql 包名 -l 选项表示列出软件包所有文件的安装目录。 例如，查看 httpd 软件包中所有文件以及各自的安装位置，可使用如下命令： 123456789101112[root@hadoop100 ~]# rpm -ql httpd/etc/httpd/conf.modules.d/00-brotli.conf/etc/httpd/conf.modules.d/00-systemd.conf/usr/lib/.build-id/usr/lib/.build-id/3c/usr/lib/.build-id/3c/e31c04b38d4c5387cb3d3088a180349b870133/usr/lib/.build-id/6e/usr/lib/.build-id/6e/33ce7b420764dd48861ae7cd2824511091ee13/usr/lib/systemd/system/htcacheclean.service/usr/lib/systemd/system/httpd.service/usr/lib/systemd/system/httpd.socket…省略部分输出… 同时，rpm 命令还可以查询未安装软件包中包含的所有文件以及打算安装的路径，命令格式如下： rpm -qlp 包全名 -p 选项表示查询未安装的软件包信息，是 package 的首字母。 注意，由于软件包还未安装，因此需要使用“绝对路径+包全名”的方式才能确定包。 比如，我们想查看 bing 软件包（未安装，绝对路径为：&#x2F;mnt&#x2F;cdrom&#x2F;Packages&#x2F;bind-9.8.2-0.10.rc1.el6.i686.rpm）中的所有文件及各自打算安装的位置，可以执行如下命令： 12345678[root@hadoop100 ~]# rpm -qlp /mnt/cdrom/Packages/bind-9.8.2-0.10.rc1.el6.i686.rpm/etc/NetworkManager/dispatcher.d/13-named/etc/logrotate.d/named/etc/named/etc/named.conf/etc/named.iscdlv.key/etc/named.rfc1912.zones…省略部分输出… 2.5 yum是什么本节介绍一种可自动安装软件包（自动解决包之间依赖关系）的安装方式。 yum，全称“Yellow dog Updater, Modified”，是一个专门为了解决包的依赖关系而存在的软件包管理器。就好像 Windows 系统上可以通过 360 软件管家实现软件的一键安装、升级和卸载，Linux 系统也提供有这样的工具，就是 yum。 可以这么说，yum 是改进型的 RPM 软件管理器，它很好的解决了 RPM 所面临的软件包依赖问题。yum 在服务器端存有所有的 RPM 包，并将各个包之间的依赖关系记录在文件中，当管理员使用 yum 安装 RPM 包时，yum 会先从服务器端下载包的依赖性文件，通过分析此文件从服务器端一次性下载所有相关的 RPM 包并进行安装。 yum 软件可以用 rpm 命令安装，安装之前可以通过如下命令查看 yum 是否已安装： 12[root@hadoop100 ~]# rpm -q yumpackage yum is not installed 可以看到，系统上没有安装了 yum。 使用 yum 安装软件包之前，需指定好 yum 下载 RPM 包的位置，此位置称为 yum 源。换句话说，yum 源指的就是软件安装包的来源。 使用 yum 安装软件时至少需要一个 yum 源。yum 源既可以使用网络 yum 源，也可以将本地光盘作为 yum 源。接下来就给大家介绍这两种 yum 源的搭建方式。 2.6 yum命令（查询、安装、升级和卸载软件包）2.6.1 yum查询命令使用 yum 对软件包执行查询操作，常用命令可分为以下几种： yum list：查询所有已安装和可安装的软件包。例如： 12345678910111213141516[root@hadoop100 ~]# yum list#查询所有可用软件包列表Updating and loading repositories:Repositories loaded.Installed packagesBox2D.x86_64 2.4.2-1.fc41 anacondaImageMagick.x86_64 1:7.1.1.38-1.fc41 anacondaImageMagick-libs.x86_64 1:7.1.1.38-1.fc41 …省略部分输出…Available Packages#还可以安装的软件包zziplib-devel.x86_64 0.13.74-2.fc41 fzziplib-utils.x86_64 0.13.74-2.fc41 fzzuf.x86_64 0.15-23.fc41 #软件名 版本 所在位置（光盘）…省略部分输出… yum list 包名：查询执行软件包的安装情况。例如： 123456[root@hadoop100 ~]# yum list sambaUpdating and loading repositories:Repositories loaded.Available packagessamba.x86_64 2:4.21.4-1.fc41 updates#查询 samba 软件包的安装情况 yum search 关键字：从 yum 源服务器上查找与关键字相关的所有软件包。例如： 123456789101112[root@hadoop100 ~]# yum search samba#搜索服务器上所有和samba相关的软件包Updating and loading repositories:Repositories loaded.Matched fields: name (exact) samba.x86_64: Server and Client software to interoperate with Windows machinesMatched fields: name, summary freeipa-client-samba.x86_64: Tools to configure Samba on IPA client ncid-samba.noarch: NCID samba module sends Caller ID information to windows machines pcp-pmda-samba.x86_64: Performance Co-Pilot (PCP) metrics for Samba python3-samba.x86_64: Samba Python3 libraries…省略部分输出… yum info 包名：查询执行软件包的详细信息。例如： 1234567891011121314151617181920[root@hadoop100 ~]# yum info samba#查询samba软件包的信息Updating and loading repositories:Repositories loaded.Available packages Name : samba Epoch : 2Version : 4.21.4Release : 1.fc41Architecture : x86_64Download size : 1.0 MiBInstalled size : 3.0 MiBSource : samba-4.21.4-1.fc41.src.rpmRepository : updatesSummary : Server and Client software to interoperate with Windows machinesURL : https://www.samba.orgLicense : GPL-3.0-or-later AND LGPL-3.0-or-laterDescription : Samba is the standard Windows interoperability suite of programs for Linux and : Unix.Vendor : Fedora Project 2.6.2 yum安装命令yum 安装软件包的命令基本格式为： yum -y install 包名 其中： install：表示安装软件包。 -y：自动回答 yes。如果不加 -y，那么每个安装的软件都需要手工回答 yes；例如使用此 yum 命令安装 gcc： 12[root@hadoop100 ~]# yum -y install gcc#使用yum自动安装gcc gcc 是 C 语言的编译器，鉴于该软件包涉及到的依赖包较多，建议使用 yum 命令安装。 2.6.3 yum 升级命令使用 yum 升级软件包，需确保 yum 源服务器中软件包的版本比本机安装的软件包版本高。 yum 升级软件包常用命令如下： yum -y update：升级所有软件包。不过考虑到服务器强调稳定性，因此该命令并不常用。 yum -y update 包名：升级特定的软件包。 2.6.4 yum 卸载命令使用 yum 卸载软件包时，会同时卸载所有与该包有依赖关系的其他软件包，即便有依赖包属于系统运行必备文件，也会被 yum 无情卸载，带来的直接后果就是使系统崩溃。 除非你能确定卸载此包以及它的所有依赖包不会对系统产生影响，否则不要使用 yum 卸载软件包。 yum 卸载命令的基本格式如下： yum remove 包名 例如，使用 yum 卸载 samba 软件包的命令如下： 12[root@hadoop100 ~]# yum remove samba#卸载samba软件包 2.6.5 yum命令补充 check-update 检查是否有可用的更新 rpm 软件包 clean 清理 yum 过期的缓存 deplist 显示 yum 软件包的所有依赖关系 2.7 dnf命令DNF 是新一代的rpm软件包管理器。他首先出现在 Fedora 18 这个发行版中。渐渐，它取代了yum，正式成为 Fedora 22 的包管理器。 DNF包管理器克服了YUM包管理器的一些瓶颈，提升了包括用户体验，内存占用，依赖分析，运行速度等多方面的内容。DNF使用 RPM, libsolv 和 hawkey 库进行包管理操作。尽管它没有预装在 CentOS 和 RHEL 7 中，但你可以在使用 YUM 的同时使用 DNF 。 DNF 的最新稳定发行版版本号是 4.21，这一版本的 DNF 包管理器（包括在他之前的所有版本） 都大部分采用 Python 编写，发行许可为GPL v2. 常用命令： 1234567891011121314151617181920212223242526#检查并升级可用软件包：dnf update#删除缓存:dnf clean all#列出可用的软件源：dnf repolist#搜索软件:dnf search $package#查看软件的详细信息dnf info $package#安装软件：dnf install $package#升级软件包：dnf update $package#重新安装软件包dnf reinstall $package#列出所有安装的RPM包dnf list installed#删除软件包：dnf remove $package#删除所有原先因为依赖关系安装的不需要的软件包dnf autoremove $package#只下载软件包，不安装dnf download $package#查看更多命令: dnf help dnf –help显示的帮助信息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184[root@hadoop100 ~]# dnf --helpUsage: dnf5 [GLOBAL OPTIONS] &lt;COMMAND&gt; ...Description: DNF5 is a program for maintaining packages.Commands:alias #列出命令别名或为命令创建别名autoremove #删除所有原先因为依赖关系安装的不需要的软件包check #在包数据库中寻找问题check-update #检查是否有软件包升级clean #删除已缓存的数据deplist #列出软件包的依赖关系和提供这些软件包的源distro-sync #同步已经安装的软件包到最新可用版本downgrade #降级包group #显示或使用组信息help #显示一个有帮助的用法信息history #显示或使用事务历史info #显示关于软件包或软件包组的详细信息install #向系统中安装一个或多个软件包list #列出一个或一组软件包makecache #创建元数据缓存mark #在已安装的软件包中标记或者取消标记由用户安装的软件包。module #与模块交互。provides #查找提供指定内容的软件包reinstall #重装一个包remove #从系统中移除一个或多个软件包repolist #显示已配置的软件仓库repoquery #搜索匹配关键字的软件包repository-packages #对指定仓库中的所有软件包运行命令search #在软件包详细信息中搜索指定字符串shell #运行交互式的DNF终端swap #运行交互式的 DNF 终端以删除或者安装 spec 描述文件updateinfo #显示软件包的参考建议upgrade #升级系统中的一个或多个软件包upgrade-minimal #升级，但只有“最新”的软件包已修复可能影响你的系统的问题可选参数:-c [config file], --config [config file]配置文件位置-q, --quiet #静默执行-v, --verbose #详尽执行--version #显示 DNF 版本信息并退出--installroot [path] #设置目标根目录--nodocs #不要安装文档--noplugins #禁用所有插件--enableplugin [plugin] #启用指定名称的插件--disableplugin [plugin] #禁用指定名称的插件--releasever RELEASEVER #覆盖在配置文件和仓库文件中 $releasever 的值--setopt SETOPTS #设置任意配置和仓库选项--skip-broken #通过跳过软件包来解决依赖问题-h, --help, --help-cmd显示命令帮助--allowerasing #允许解决依赖关系时删除已安装软件包-b, --best #在事务中尝试最佳软件包版本。-C, --cacheonly #完全从系统缓存运行，不升级缓存-R [minutes], --randomwait [minutes] #最大命令等待时间-d [debug level], --debuglevel [debug level] #调试输出级别--debugsolver #转储详细解决结果至文件--showduplicates 在 list/search #命令下，显示仓库里重复的条目-e ERRORLEVEL, --errorlevel ERRORLEVEL #错误输出级别--obsoletes 对 upgrade #启用 dnf 的过期处理逻辑，或对 info、list 和 repoquery显示软件包过期的功能--rpmverbosity [debug level name] #rpm调试输出等级-y, --assumeyes #全部问题自动应答为是--assumeno #全部问题自动应答为否--enablerepo [repo]--disablerepo [repo]--repo [repo], --repoid [repo] #启用指定 id 或 glob 的仓库，可以指定多次--enable, --set-enabledenable repos with config-manager command(automatically saves)--disable, --set-disableddisable repos with config-manager command(automatically saves)-x [package], --exclude [package], --excludepkgs [package] #用全名或通配符排除软件包--disableexcludes [repo], --disableexcludepkgs [repo] #禁用 excludepkgs--repofrompath [repo,path] #指向附加仓库的标记和路径，可以指定多次。--noautoremove #禁用删除不再被使用的依赖软件包--nogpgcheck disable gpg signature checking (if RPM policy allows)--color COLOR #配置是否使用颜色--refresh #在运行命令之前将元数据标记为过期。-4 #仅解析 IPv4 地址-6 #仅解析 IPv6 地址--destdir DESTDIR, --downloaddir DESTDIR #设置软件包要复制到的目录--downloadonly #仅下载软件包--comment COMMENT #为事务添加一个注释--bugfix #在更新中包括与 bug 修复有关的软件包--enhancement #在更新中包括与功能增强有关的软件包。--newpackage #在更新中包括与新软件包有关的软件包--security #在更新中包括与安全有关的软件包--advisory ADVISORY, --advisories ADVISORY #在更新中包括修复指定公告所必须的软件包--bzs BUGZILLA #在更新中包括修复给定 BZ 所必须的软件包--cves CVES #在更新中包括修复给定 CVE 所必须的软件包--sec-severity &#123;Critical,Important,Moderate,Low&#125;, --secseverity &#123;Critical,Important,Moderate,Low&#125; #在更新中包括匹配给定安全等级的安全相关的软件包--forcearch ARCH #强制使用一个架构安装包 3.克隆虚拟机 ▶克隆虚拟机 1）从现有虚拟机(关机状态)克隆出新虚拟机，右键选择管理&#x3D;&gt;克隆2）点击下一步3）选择虚拟机中的当前状态4）选择创建完整克隆5）设置虚拟机名称及存储位置6）等等等……等待克隆完成 参考资料：www.bilibili.com/video/BV1WY4y1H7d3 ↩","categories":[{"name":"Shell","slug":"Shell","permalink":"https://wxwdaydayup.top/categories/Shell/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"},{"name":"Fedora","slug":"Fedora","permalink":"https://wxwdaydayup.top/tags/Fedora/"}],"author":null},{"title":"基于Fluid主题搭建Hexo博客的一些常用命令","slug":"基于Fluid主题搭建Hexo博客的一些常用命令","date":"2025-02-05T02:00:00.000Z","updated":"2025-03-02T15:42:58.515Z","comments":true,"path":"基于Fluid主题搭建Hexo博客的一些常用命令/","permalink":"https://wxwdaydayup.top/%E5%9F%BA%E4%BA%8EFluid%E4%B8%BB%E9%A2%98%E6%90%AD%E5%BB%BAHexo%E5%8D%9A%E5%AE%A2%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"Fluid 是基于Hexo的一款Material Design风格的主题，由Fluid-dev负责开发与维护。","text":"1、安装主题1.1 获取最新版本Hexo 5.0.0 版本以上，通过 npm 直接安装，进入博客目录执行命令： 1$ npm install --save hexo-theme-fluid 然后在博客目录下创建 _config.fluid.yml，将主题的 config.yml 内容复制过去。 1.2 指定主题修改 Hexo 博客目录中的 _config.yml： 123theme: fluid # 指定主题language: zh-CN # 指定语言，会影响主题显示的语言，按需修改 1.3 创建关于页首次使用主题的「关于页」需要手动创建： 1$ hexo new page about 创建成功后修改 /source/about/index.md，添加 layout 属性。 修改后的文件示例如下： 123456---title: 标题layout: about---这里写关于页的正文，支持 Markdown, HTML WARNINGlayout: about 必须存在，并且不能修改成其他值，否则不会显示头像等样式。 1.4 更新主题在博客目录下执行命令： 1$ npm update --save hexo-theme-fluid 2、快速开始创建一篇新的文章1$ hexo new &quot;My New Post&quot; 运行服务1$ hexo server 生成静态页面1$ hexo generate 部署到远程服务器1$ hexo deploy 3、常用语法3,1 脚注12这是一句话[^1][^1]: 这是对应的脚注 3.2 便签在 markdown 中加入如下的代码来使用便签： 123&#123;% note success %&#125;文字 或者 `markdown` 均可&#123;% endnote %&#125; 可选便签： WARNING使用时 &lt;div class=&quot;note note-primary&quot;&gt; &lt;p&gt;&lt;code&gt;和&lt;/code&gt;&lt;/p&gt; &lt;/div&gt; 需单独一行，否则会出现问题 3.3 行内标签在 markdown 中加入如下的代码来使用 Label： 1&#123;% label primary @text %&#125; 可选 Label： 3.4 折叠块使用折叠块，可以折叠代码、图片、文字等任何内容，可以在 markdown 中按如下格式： 123&#123;% fold info @title %&#125;需要折叠的一段内容，支持 markdown&#123;% endfold %&#125; info: 和行内标签类似的可选参数 title: 折叠块上的标题 3.5 勾选框在 markdown 中加入如下的代码来使用 Checkbox： 1&#123;% cb text, checked?, incline? %&#125; text：显示的文字checked：默认是否已勾选，默认 falseincline: 是否内联（可以理解为后面的文字是否换行），默认 false 3.6 按钮你可以在 markdown 中加入如下的代码来使用 Button： 1&#123;% btn url, text, title %&#125; url：跳转链接text：显示的文字title：鼠标悬停时显示的文字（可选） 3.7 组图如果想把多张图片按一定布局组合显示，你可以在 markdown 中按如下格式： 1234567&#123;% gi total n1-n2-... %&#125; ![](url) ![](url) ![](url) ![](url) ![](url)&#123;% endgi %&#125; total：图片总数量，对应中间包含的图片 url 数量n1-n2-…：每行的图片数量，可以省略，默认单行最多 3 张图，求和必须相等于 total，否则按默认样式 如下图为 &#123;% gi 5 3-2 %&#125; 示例，代表共 5 张图，第一行 3 张图，第二行 2 张图。 参考资料：https://hexo.fluid-dev.com/docs/guide/ ↩","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://wxwdaydayup.top/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://wxwdaydayup.top/tags/Hexo/"},{"name":"Fluid","slug":"Fluid","permalink":"https://wxwdaydayup.top/tags/Fluid/"}],"author":null},{"title":"Hexo发生error：spawn failed错误的解决方法","slug":"Hexo发生error：spawn failed错误的解决方法","date":"2025-02-02T02:00:00.000Z","updated":"2025-03-04T15:23:01.350Z","comments":true,"path":"Hexo发生error：spawn failed错误的解决方法/","permalink":"https://wxwdaydayup.top/Hexo%E5%8F%91%E7%94%9Ferror%EF%BC%9Aspawn%20failed%E9%94%99%E8%AF%AF%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","excerpt":"","text":"问题描述：将项目部署到远端时，报错401 解决办法：首先检查公钥是否出现了问题1、打开git Bash here 2、生成密钥ssh-keygen -t rsa -C &quot;邮箱&quot;，三次Enter 2、&quot;C:\\Users\\用户名\\\\.ssh\\id_rsa.pub&quot;打开此路径的公钥文件，重新添加公钥 右上角： 左边栏： 版心栏： 使用SSH地址打开仓库 打开博客根目录的_config.yml文件 type确认为git，把刚才复制到的ssh地址贴到repo: 的后面，保存 以上两种方法均不可行则暴力解决到了这一步，大多是因为git 进行push或者hexo d的时候改变了一些.deploy_git文件下的内容而产生的问题 因此解决办法为： 打开博客根目录，删除.deploy_git文件夹 输入git config --global core.autocrlf false 然后，依次执行：hexo cleanhexo ghexo d","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://wxwdaydayup.top/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://wxwdaydayup.top/tags/Hexo/"},{"name":"疑难杂症","slug":"疑难杂症","permalink":"https://wxwdaydayup.top/tags/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"}]},{"title":"Win11 桌面图标白板的解决办法","slug":"Win11 桌面图标白板的解决办法","date":"2024-12-20T02:00:00.000Z","updated":"2025-03-04T15:22:45.857Z","comments":true,"path":"Win11 桌面图标白板的解决办法/","permalink":"https://wxwdaydayup.top/Win11%20%E6%A1%8C%E9%9D%A2%E5%9B%BE%E6%A0%87%E7%99%BD%E6%9D%BF%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/","excerpt":"","text":"问题描述：Win11在每次小更新后总是出现各种疑难杂症，在最近的一次更新中，重启后发现部分桌面图标变成了白板，调整桌面分辨率后依然无效。 解决办法：由于图标缓存文件是隐藏文件，我们需要在资源管理器中将设置改为显示所有文件随便打开一个文件夹，点击查看菜单，然后勾选隐藏的项目 按下快捷键Win+R，在运行窗口中输入%localappdata%，按下Enter，在打开的文件夹中，找到Iconcache.db（这是个文件，不是文件夹），将其删除（删除是为了重建） 打开任务管理器，在任务管理器找到Windows资源管理器，右击鼠标，选择重新启动即可重建图标缓存。Win11 底边栏右键可选择任务管理器打开 找到图中所指，右键选择重新启动即可","categories":[{"name":"Windows","slug":"Windows","permalink":"https://wxwdaydayup.top/categories/Windows/"}],"tags":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"https://wxwdaydayup.top/tags/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"},{"name":"Windows","slug":"Windows","permalink":"https://wxwdaydayup.top/tags/Windows/"}]}],"categories":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/categories/Arch/"},{"name":"Shell","slug":"Shell","permalink":"https://wxwdaydayup.top/categories/Shell/"},{"name":"Hexo","slug":"Hexo","permalink":"https://wxwdaydayup.top/categories/Hexo/"},{"name":"Windows","slug":"Windows","permalink":"https://wxwdaydayup.top/categories/Windows/"}],"tags":[{"name":"Arch","slug":"Arch","permalink":"https://wxwdaydayup.top/tags/Arch/"},{"name":"疑难杂症","slug":"疑难杂症","permalink":"https://wxwdaydayup.top/tags/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/"},{"name":"Linux","slug":"Linux","permalink":"https://wxwdaydayup.top/tags/Linux/"},{"name":"Fedora","slug":"Fedora","permalink":"https://wxwdaydayup.top/tags/Fedora/"},{"name":"Hexo","slug":"Hexo","permalink":"https://wxwdaydayup.top/tags/Hexo/"},{"name":"Fluid","slug":"Fluid","permalink":"https://wxwdaydayup.top/tags/Fluid/"},{"name":"Windows","slug":"Windows","permalink":"https://wxwdaydayup.top/tags/Windows/"}]}